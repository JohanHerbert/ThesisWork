Restoring modules from user's Johans_collection
######################### Running test with dataset: InDepWeight ###########
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0178990364074707, Constraint losses: L1: 17.613672256469727, L2: 0.00012196637544548139, L3: 1.0000818967819214, L4: 1.0000816583633423
Epoch 500, Loss: 0.0019718792755156755, Constraint losses: L1: -1.0826014280319214, L2: 0.0, L3: 0.002526521682739258, L4: 0.0005279590841382742
Epoch 1000, Loss: 0.001209347858093679, Constraint losses: L1: -1.1152135133743286, L2: 0.0, L3: 0.002162158489227295, L4: 0.00016240293916780502
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.007840633392334, Constraint losses: L1: 8.293357849121094, L2: 5.496609105648531e-07, L3: 0.9997735023498535, L4: 0.999773383140564
Epoch 500, Loss: 0.0022007282823324203, Constraint losses: L1: -0.9427782297134399, L2: 0.0, L3: 0.002570509910583496, L4: 0.0005729966214857996
Epoch 1000, Loss: 0.0012851693900302052, Constraint losses: L1: -1.0471265316009521, L2: 0.0, L3: 0.0021657347679138184, L4: 0.00016656122170388699
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.72726821899414, Losses: L1: 18.324687957763672, L2: 0.0032334341667592525, L3: 1.0032318830490112, L4: 67.552734375, L5: 0.24596410989761353
Epoch 500, Loss: 0.9581215381622314, Losses: L1: 0.36432743072509766, L2: 0.044984884560108185, L3: 0.07377755641937256, L4: 1.0565011501312256, L5: 0.012324529699981213
Epoch 1000, Loss: 26.141460418701172, Losses: L1: 5.225674152374268, L2: 0.19495464861392975, L3: 0.9723736643791199, L4: 40.50035095214844, L5: 0.16389431059360504
Epoch 1500, Loss: 5.677515983581543, Losses: L1: 1.7498594522476196, L2: 0.44067123532295227, L3: 0.12404155731201172, L4: 7.240645408630371, L5: 0.049955613911151886
Epoch 2000, Loss: 7.479398727416992, Losses: L1: 3.7261452674865723, L2: 0.27962419390678406, L3: 0.2548103332519531, L4: 6.915221214294434, L5: 0.056850939989089966
Epoch 2500, Loss: 6.1128058433532715, Losses: L1: 2.643986701965332, L2: 0.2681802213191986, L3: 0.19601362943649292, L4: 6.380749225616455, L5: 0.09269525855779648
Epoch 3000, Loss: 5.193050861358643, Losses: L1: 2.9067270755767822, L2: 0.2920989990234375, L3: 0.21839308738708496, L4: 3.9853649139404297, L5: 0.0767907053232193
Epoch 3500, Loss: 5.158121109008789, Losses: L1: 2.8334803581237793, L2: 0.29241040349006653, L3: 0.21500611305236816, L4: 4.068470001220703, L5: 0.0733950212597847
Epoch 4000, Loss: 29.596214294433594, Losses: L1: 4.44310998916626, L2: 0.0, L3: 0.9631215929985046, L4: 49.097007751464844, L5: 0.24607689678668976
Epoch 4500, Loss: 4.958037376403809, Losses: L1: 2.6834805011749268, L2: 0.27641206979751587, L3: 0.21284902095794678, L4: 3.9839420318603516, L5: 0.07591096311807632
Epoch 5000, Loss: 4.916962623596191, Losses: L1: 2.689558744430542, L2: 0.2794627249240875, L3: 0.21051079034805298, L4: 3.887566566467285, L5: 0.07726743817329407
Epoch 5500, Loss: 4.8909196853637695, Losses: L1: 2.6929659843444824, L2: 0.2811117470264435, L3: 0.2089635133743286, L4: 3.827627658843994, L5: 0.07820466160774231
Epoch 6000, Loss: 4.8733367919921875, Losses: L1: 2.695587158203125, L2: 0.2820579707622528, L3: 0.20809704065322876, L4: 3.786648988723755, L5: 0.07869518548250198
Epoch 6500, Loss: 4.860846996307373, Losses: L1: 2.6967947483062744, L2: 0.2823864817619324, L3: 0.20773661136627197, L4: 3.7590458393096924, L5: 0.07893576472997665
Epoch 7000, Loss: 4.851704120635986, Losses: L1: 2.697148561477661, L2: 0.2824691832065582, L3: 0.20752865076065063, L4: 3.740011215209961, L5: 0.07910244166851044
Epoch 7500, Loss: 4.8450212478637695, Losses: L1: 2.697300434112549, L2: 0.2825314402580261, L3: 0.20739412307739258, L4: 3.726289749145508, L5: 0.07922681421041489
Epoch 8000, Loss: 4.840169906616211, Losses: L1: 2.697378635406494, L2: 0.2825588285923004, L3: 0.20731258392333984, L4: 3.7164015769958496, L5: 0.07930924743413925
Epoch 8500, Loss: 4.836670398712158, Losses: L1: 2.6974966526031494, L2: 0.28258395195007324, L3: 0.20727264881134033, L4: 3.7091457843780518, L5: 0.0793454721570015
Epoch 9000, Loss: 4.834165096282959, Losses: L1: 2.6975324153900146, L2: 0.28256282210350037, L3: 0.20726191997528076, L4: 3.7040767669677734, L5: 0.07936400175094604
Epoch 9500, Loss: 4.832396030426025, Losses: L1: 2.697557210922241, L2: 0.2825392484664917, L3: 0.2072685956954956, L4: 3.7004990577697754, L5: 0.07937079668045044
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0195024013519287, Constraint losses: L1: 18.42068099975586, L2: 0.0003606357204262167, L3: 1.0003606081008911, L4: 1.0003604888916016
Epoch 500, Loss: 0.0023777326568961143, Constraint losses: L1: -0.9972251653671265, L2: 0.0, L3: 0.0026865601539611816, L4: 0.0006883977330289781
Epoch 1000, Loss: 0.0012891726801171899, Constraint losses: L1: -1.1171914339065552, L2: 0.0, L3: 0.002202928066253662, L4: 0.0002034361386904493
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002958059310913, Constraint losses: L1: 6.392322540283203, L2: 0.0, L3: 0.9982828497886658, L4: 0.9982828497886658
Epoch 500, Loss: 0.002721640281379223, Constraint losses: L1: -0.8748230934143066, L2: 0.0, L3: 0.002796947956085205, L4: 0.0007995156338438392
Epoch 1000, Loss: 0.001415605889633298, Constraint losses: L1: -1.043384075164795, L2: 0.0, L3: 0.002229154109954834, L4: 0.00022983580129221082
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 39.32133865356445, Losses: L1: 6.179521083831787, L2: 0.0, L3: 0.9979088306427002, L4: 64.83191680908203, L5: 0.22690512239933014
Epoch 500, Loss: 15.008222579956055, Losses: L1: 5.555080890655518, L2: 0.3789723515510559, L3: 0.3520351052284241, L4: 17.887372970581055, L5: 0.1439516246318817
Epoch 1000, Loss: 7.353043079376221, Losses: L1: 4.138418674468994, L2: 0.30906495451927185, L3: 0.16499263048171997, L4: 5.8065571784973145, L5: 0.07431751489639282
Epoch 1500, Loss: 44.17167282104492, Losses: L1: 18.42068099975586, L2: 2.6279549274477176e-05, L3: 1.0000262260437012, L4: 50.00013732910156, L5: 0.2508971095085144
Epoch 2000, Loss: 44.17167282104492, Losses: L1: 18.42068099975586, L2: 2.670242975000292e-05, L3: 1.0000267028808594, L4: 50.0001335144043, L5: 0.2508973479270935
Epoch 2500, Loss: 44.171669006347656, Losses: L1: 18.42068099975586, L2: 2.7056914404965937e-05, L3: 1.000027060508728, L4: 50.00012969970703, L5: 0.2508975863456726
Epoch 3000, Loss: 44.17166519165039, Losses: L1: 18.42068099975586, L2: 2.73463756457204e-05, L3: 1.0000272989273071, L4: 50.0001220703125, L5: 0.25089773535728455
Epoch 3500, Loss: 44.17166519165039, Losses: L1: 18.42068099975586, L2: 2.757725269475486e-05, L3: 1.0000275373458862, L4: 50.0001220703125, L5: 0.2508978545665741
Epoch 4000, Loss: 44.17166519165039, Losses: L1: 18.42068099975586, L2: 2.7761852834373713e-05, L3: 1.0000277757644653, L4: 50.000118255615234, L5: 0.25089794397354126
Epoch 4500, Loss: 44.17166519165039, Losses: L1: 18.42068099975586, L2: 2.790889448078815e-05, L3: 1.0000278949737549, L4: 50.000118255615234, L5: 0.25089800357818604
Epoch 5000, Loss: 44.17166519165039, Losses: L1: 18.42068099975586, L2: 2.8026157451677136e-05, L3: 1.0000280141830444, L4: 50.0001220703125, L5: 0.2508980929851532
Epoch 5500, Loss: 44.171661376953125, Losses: L1: 18.42068099975586, L2: 2.8115331588196568e-05, L3: 1.000028133392334, L4: 50.00011444091797, L5: 0.2508980929851532
Epoch 6000, Loss: 44.171661376953125, Losses: L1: 18.42068099975586, L2: 2.81867560261162e-05, L3: 1.000028133392334, L4: 50.00011444091797, L5: 0.250898152589798
Epoch 6500, Loss: 44.17165756225586, Losses: L1: 18.42068099975586, L2: 2.8242473490536213e-05, L3: 1.0000282526016235, L4: 50.0001106262207, L5: 0.250898152589798
Epoch 7000, Loss: 44.17166519165039, Losses: L1: 18.42068099975586, L2: 2.8287580789765343e-05, L3: 1.0000282526016235, L4: 50.000118255615234, L5: 0.25089818239212036
Epoch 7500, Loss: 44.171661376953125, Losses: L1: 18.42068099975586, L2: 2.8318798285908997e-05, L3: 1.000028371810913, L4: 50.00011444091797, L5: 0.25089818239212036
Epoch 8000, Loss: 44.171661376953125, Losses: L1: 18.42068099975586, L2: 2.8347500119707547e-05, L3: 1.000028371810913, L4: 50.00011444091797, L5: 0.25089818239212036
Epoch 8500, Loss: 44.171661376953125, Losses: L1: 18.42068099975586, L2: 2.8370492145768367e-05, L3: 1.000028371810913, L4: 50.00011444091797, L5: 0.25089818239212036
Epoch 9000, Loss: 44.17165756225586, Losses: L1: 18.42068099975586, L2: 2.838914042513352e-05, L3: 1.000028371810913, L4: 50.0001106262207, L5: 0.25089824199676514
Epoch 9500, Loss: 44.17165756225586, Losses: L1: 18.42068099975586, L2: 2.840038541762624e-05, L3: 1.000028371810913, L4: 50.0001106262207, L5: 0.25089824199676514
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0212602615356445, Constraint losses: L1: 18.42068099975586, L2: 0.0009466055198572576, L3: 1.0009466409683228, L4: 1.0009464025497437
Epoch 500, Loss: 0.0022216783836483955, Constraint losses: L1: -1.0504248142242432, L2: 0.0, L3: 0.0026351213455200195, L4: 0.0006369820330291986
Epoch 1000, Loss: 0.0012749123852699995, Constraint losses: L1: -1.1179920434951782, L2: 0.0, L3: 0.002196192741394043, L4: 0.0001967117132153362
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0387535095214844, Constraint losses: L1: 18.42068099975586, L2: 0.006777701899409294, L3: 1.0067776441574097, L4: 1.0067775249481201
Epoch 500, Loss: 0.0024933423846960068, Constraint losses: L1: -1.005621314048767, L2: 0.0, L3: 0.0027484893798828125, L4: 0.0007504745153710246
Epoch 1000, Loss: 0.001434591133147478, Constraint losses: L1: -1.0488471984863281, L2: 0.0, L3: 0.0022414326667785645, L4: 0.00024200574262067676
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 57.20045471191406, Losses: L1: 14.841598510742188, L2: 0.0006197398179210722, L3: 1.0004591941833496, L4: 82.3309326171875, L5: 0.3464236855506897
Epoch 500, Loss: 1.2911564111709595, Losses: L1: 0.21160340309143066, L2: 0.09815116971731186, L3: 0.05520188808441162, L4: 1.9635162353515625, L5: 0.01055920496582985
Epoch 1000, Loss: 1.998289942741394, Losses: L1: 0.23081618547439575, L2: 0.04223242029547691, L3: 0.07605743408203125, L4: 3.3090014457702637, L5: 0.026914043352007866
Epoch 1500, Loss: 1.0626578330993652, Losses: L1: 0.17826053500175476, L2: 0.039833031594753265, L3: 0.0552789568901062, L4: 1.6320345401763916, L5: 0.010412050411105156
Epoch 2000, Loss: 0.4114034175872803, Losses: L1: 0.11374449729919434, L2: 0.03290645778179169, L3: 0.05294990539550781, L4: 0.48185408115386963, L5: 0.006901837885379791
Epoch 2500, Loss: 0.33319589495658875, Losses: L1: 0.09041690081357956, L2: 0.035962775349617004, L3: 0.04921698570251465, L4: 0.37549448013305664, L5: 0.006220932584255934
Epoch 3000, Loss: 0.29298165440559387, Losses: L1: 0.0747067928314209, L2: 0.031110869720578194, L3: 0.048720479011535645, L4: 0.3328220248222351, L5: 0.005974090192466974
Epoch 3500, Loss: 0.2684868276119232, Losses: L1: 0.06363516300916672, L2: 0.030645979568362236, L3: 0.04874587059020996, L4: 0.3086656332015991, L5: 0.005411459598690271
Epoch 4000, Loss: 0.22285833954811096, Losses: L1: 0.06467189639806747, L2: 0.028331657871603966, L3: 0.049022376537323, L4: 0.21889249980449677, L5: 0.005031587090343237
Epoch 4500, Loss: 0.20817168056964874, Losses: L1: 0.06397876143455505, L2: 0.0280578825622797, L3: 0.04883682727813721, L4: 0.19132746756076813, L5: 0.005040911957621574
Epoch 5000, Loss: 0.20454514026641846, Losses: L1: 0.0628892257809639, L2: 0.028085675090551376, L3: 0.04871642589569092, L4: 0.18642880022525787, L5: 0.0050202347338199615
Epoch 5500, Loss: 0.2022700309753418, Losses: L1: 0.06241539120674133, L2: 0.0280178040266037, L3: 0.04863917827606201, L4: 0.18305926024913788, L5: 0.004998259246349335
Epoch 6000, Loss: 0.2005021870136261, Losses: L1: 0.06199916824698448, L2: 0.02794855274260044, L3: 0.04858154058456421, L4: 0.18055932223796844, L5: 0.004979156423360109
Epoch 6500, Loss: 0.1992378830909729, Losses: L1: 0.06156077980995178, L2: 0.02791910246014595, L3: 0.04854118824005127, L4: 0.1790432184934616, L5: 0.004962676204741001
Epoch 7000, Loss: 0.1983214020729065, Losses: L1: 0.061370108276605606, L2: 0.027863485738635063, L3: 0.04851192235946655, L4: 0.17771269381046295, L5: 0.004953620955348015
Epoch 7500, Loss: 0.19771777093410492, Losses: L1: 0.06115799769759178, L2: 0.027876121923327446, L3: 0.04847460985183716, L4: 0.17698214948177338, L5: 0.0049466704949736595
Epoch 8000, Loss: 0.19717058539390564, Losses: L1: 0.06106395646929741, L2: 0.027844775468111038, L3: 0.048458635807037354, L4: 0.1761499047279358, L5: 0.004939988721162081
Epoch 8500, Loss: 0.19681692123413086, Losses: L1: 0.060954585671424866, L2: 0.02783029153943062, L3: 0.0484464168548584, L4: 0.17570346593856812, L5: 0.00493612652644515
Epoch 9000, Loss: 0.19655466079711914, Losses: L1: 0.06085712090134621, L2: 0.02783861942589283, L3: 0.04843246936798096, L4: 0.17539069056510925, L5: 0.004933326505124569
Epoch 9500, Loss: 0.19636088609695435, Losses: L1: 0.06080888211727142, L2: 0.027839159592986107, L3: 0.048422932624816895, L4: 0.17511698603630066, L5: 0.004931231029331684
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.003603935241699, Constraint losses: L1: 6.473109722137451, L2: 0.0, L3: 0.998565673828125, L4: 0.9985651969909668
Epoch 500, Loss: 0.002644425258040428, Constraint losses: L1: -1.1008161306381226, L2: 0.0, L3: 0.002871572971343994, L4: 0.00087366858497262
Epoch 1000, Loss: 0.001454789424315095, Constraint losses: L1: -1.1180351972579956, L2: 0.0, L3: 0.002286076545715332, L4: 0.00028674816712737083
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0216622352600098, Constraint losses: L1: 18.42068099975586, L2: 0.001080463407561183, L3: 1.0010805130004883, L4: 1.0010805130004883
Epoch 500, Loss: 0.0025965392123907804, Constraint losses: L1: -1.0410295724868774, L2: 0.0, L3: 0.002817809581756592, L4: 0.0008197592105716467
Epoch 1000, Loss: 0.0014911070466041565, Constraint losses: L1: -1.0497934818267822, L2: 0.0, L3: 0.0022701025009155273, L4: 0.0002707981038838625
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 80.15235900878906, Losses: L1: 5.45183801651001, L2: 4.400003945193021e-06, L3: 0.9945400357246399, L4: 74.05679321289062, L5: 0.29291123151779175
Epoch 500, Loss: 58.240257263183594, Losses: L1: 7.649410247802734, L2: 0.007766200229525566, L3: 0.9879713654518127, L4: 49.97438049316406, L5: 0.2371986210346222
Epoch 1000, Loss: 15.186164855957031, Losses: L1: 4.6516828536987305, L2: 0.1236991435289383, L3: 0.21832036972045898, L4: 10.335298538208008, L5: 0.05634684860706329
Epoch 1500, Loss: 16.029443740844727, Losses: L1: 4.722938537597656, L2: 0.2399240881204605, L3: 0.3304489254951477, L4: 10.99898910522461, L5: 0.044658590108156204
Epoch 2000, Loss: 12.490787506103516, Losses: L1: 3.474991798400879, L2: 0.201374351978302, L3: 0.30729854106903076, L4: 8.742607116699219, L5: 0.037704966962337494
Epoch 2500, Loss: 38.714683532714844, Losses: L1: 6.18147611618042, L2: 0.17344632744789124, L3: 0.7694430351257324, L4: 32.009639739990234, L5: 0.10424764454364777
Epoch 3000, Loss: 13.10714340209961, Losses: L1: 3.9129159450531006, L2: 0.2990148067474365, L3: 0.30053746700286865, L4: 8.862310409545898, L5: 0.06428075581789017
Epoch 3500, Loss: 10.802447319030762, Losses: L1: 3.565685272216797, L2: 0.19534194469451904, L3: 0.2814626097679138, L4: 6.9781494140625, L5: 0.04042036458849907
Epoch 4000, Loss: 10.261951446533203, Losses: L1: 3.3537251949310303, L2: 0.18800388276576996, L3: 0.27384233474731445, L4: 6.658127784729004, L5: 0.0383516363799572
Epoch 4500, Loss: 9.641166687011719, Losses: L1: 2.9540836811065674, L2: 0.160698801279068, L3: 0.2622540593147278, L4: 6.457722187042236, L5: 0.03576815128326416
Epoch 5000, Loss: 9.37130355834961, Losses: L1: 2.8257691860198975, L2: 0.15546666085720062, L3: 0.2597860097885132, L4: 6.320118427276611, L5: 0.03557993844151497
Epoch 5500, Loss: 9.250131607055664, Losses: L1: 2.8264942169189453, L2: 0.15558935701847076, L3: 0.25767195224761963, L4: 6.19912576675415, L5: 0.03576342761516571
Epoch 6000, Loss: 9.08436393737793, Losses: L1: 2.7482330799102783, L2: 0.15124067664146423, L3: 0.25630760192871094, L4: 6.114596366882324, L5: 0.035520970821380615
Epoch 6500, Loss: 8.939430236816406, Losses: L1: 2.66580867767334, L2: 0.14814938604831696, L3: 0.2557065486907959, L4: 6.0540900230407715, L5: 0.03520641848444939
Epoch 7000, Loss: 8.885906219482422, Losses: L1: 2.662234306335449, L2: 0.14778581261634827, L3: 0.25522613525390625, L4: 6.00449275970459, L5: 0.035347823053598404
Epoch 7500, Loss: 8.84573745727539, Losses: L1: 2.661283254623413, L2: 0.14765188097953796, L3: 0.25490713119506836, L4: 5.965461254119873, L5: 0.035426657646894455
Epoch 8000, Loss: 8.815396308898926, Losses: L1: 2.6606788635253906, L2: 0.14755547046661377, L3: 0.2546337842941284, L4: 5.9358720779418945, L5: 0.03550231084227562
Epoch 8500, Loss: 8.792500495910645, Losses: L1: 2.660245656967163, L2: 0.14747560024261475, L3: 0.2544141411781311, L4: 5.913527965545654, L5: 0.03556366637349129
Epoch 9000, Loss: 8.775315284729004, Losses: L1: 2.659817934036255, L2: 0.1474301964044571, L3: 0.2542329430580139, L4: 5.896860122680664, L5: 0.03561229258775711
Epoch 9500, Loss: 8.762516021728516, Losses: L1: 2.659485340118408, L2: 0.14737457036972046, L3: 0.2541046142578125, L4: 5.884466171264648, L5: 0.03564978390932083
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0002293586730957, Constraint losses: L1: 5.848822116851807, L2: 0.0, L3: 0.9971904158592224, L4: 0.9971902370452881
Epoch 500, Loss: 0.0021100714802742004, Constraint losses: L1: -1.0690077543258667, L2: 0.0, L3: 0.0025886893272399902, L4: 0.0005903899436816573
Epoch 1000, Loss: 0.0012507240753620863, Constraint losses: L1: -1.1180843114852905, L2: 0.0, L3: 0.002184152603149414, L4: 0.00018465594621375203
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.023406982421875, Constraint losses: L1: 18.42068099975586, L2: 0.0016621180111542344, L3: 1.0016621351242065, L4: 1.0016618967056274
Epoch 500, Loss: 0.0023773754946887493, Constraint losses: L1: -0.9265395998954773, L2: 0.0, L3: 0.0026509761810302734, L4: 0.0006529390811920166
Epoch 1000, Loss: 0.001356120454147458, Constraint losses: L1: -1.0457520484924316, L2: 0.0, L3: 0.0022006630897521973, L4: 0.00020120949193369597
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 98.20952606201172, Losses: L1: 17.606037139892578, L2: 0.0012659047497436404, L3: 1.0012341737747192, L4: 79.77369689941406, L5: 0.32854515314102173
Epoch 500, Loss: 8.337138175964355, Losses: L1: 3.98748517036438, L2: 1.1746912002563477, L3: 0.1277381181716919, L4: 3.650083065032959, L5: 0.048355069011449814
Epoch 1000, Loss: 7.997063159942627, Losses: L1: 2.624159812927246, L2: 0.2117774784564972, L3: 0.13271605968475342, L4: 5.167006492614746, L5: 0.03364972770214081
Epoch 1500, Loss: 1.707566499710083, Losses: L1: 0.4900146722793579, L2: 0.08060701936483383, L3: 0.0879252552986145, L4: 1.109667181968689, L5: 0.023618463426828384
Epoch 2000, Loss: 2.0948891639709473, Losses: L1: 0.5506640672683716, L2: 0.08008190989494324, L3: 0.10415059328079224, L4: 1.4403456449508667, L5: 0.011763164773583412
Epoch 2500, Loss: 11.311830520629883, Losses: L1: 3.590205192565918, L2: 0.19225479662418365, L3: 0.23696517944335938, L4: 7.378089904785156, L5: 0.1289251148700714
Epoch 3000, Loss: 2.8218557834625244, Losses: L1: 0.7449209690093994, L2: 0.04473022744059563, L3: 0.13941365480422974, L4: 1.9685859680175781, L5: 0.016277054324746132
Epoch 3500, Loss: 2.248342990875244, Losses: L1: 0.6659084558486938, L2: 0.05796225368976593, L3: 0.12336844205856323, L4: 1.472395896911621, L5: 0.019373366609215736
Epoch 4000, Loss: 1.99866783618927, Losses: L1: 0.6281777620315552, L2: 0.06331764161586761, L3: 0.11323833465576172, L4: 1.2573879957199097, L5: 0.024823999032378197
Epoch 4500, Loss: 1.7775706052780151, Losses: L1: 0.48017916083335876, L2: 0.062106553465127945, L3: 0.1072455644607544, L4: 1.1875272989273071, L5: 0.025188112631440163
Epoch 5000, Loss: 1.6644078493118286, Losses: L1: 0.45137879252433777, L2: 0.06191520392894745, L3: 0.10459327697753906, L4: 1.1036186218261719, L5: 0.026156194508075714
Epoch 5500, Loss: 1.6203702688217163, Losses: L1: 0.44590842723846436, L2: 0.06152045726776123, L3: 0.10365098714828491, L4: 1.0656754970550537, L5: 0.02620065025985241
Epoch 6000, Loss: 1.5894089937210083, Losses: L1: 0.44342994689941406, L2: 0.061183299869298935, L3: 0.10277950763702393, L4: 1.0376791954040527, L5: 0.026318449527025223
Epoch 6500, Loss: 1.56757390499115, Losses: L1: 0.4421738386154175, L2: 0.06060979887843132, L3: 0.10220909118652344, L4: 1.0176175832748413, L5: 0.02637302875518799
Epoch 7000, Loss: 1.550567388534546, Losses: L1: 0.44146254658699036, L2: 0.060263633728027344, L3: 0.10172075033187866, L4: 1.0017609596252441, L5: 0.026351701468229294
Epoch 7500, Loss: 1.5379691123962402, Losses: L1: 0.44107386469841003, L2: 0.059912435710430145, L3: 0.10145103931427002, L4: 0.9899585843086243, L5: 0.026254942640662193
Epoch 8000, Loss: 1.5289453268051147, Losses: L1: 0.4410078525543213, L2: 0.059701696038246155, L3: 0.10117816925048828, L4: 0.9812500476837158, L5: 0.026247555390000343
Epoch 8500, Loss: 1.52241849899292, Losses: L1: 0.4410609304904938, L2: 0.05948599800467491, L3: 0.10101675987243652, L4: 0.9748774170875549, L5: 0.0262287650257349
Epoch 9000, Loss: 1.5175483226776123, Losses: L1: 0.4411516785621643, L2: 0.059388939291238785, L3: 0.10085535049438477, L4: 0.9700556993484497, L5: 0.026218801736831665
Epoch 9500, Loss: 1.5141103267669678, Losses: L1: 0.44123154878616333, L2: 0.05930308252573013, L3: 0.10076272487640381, L4: 0.9666468501091003, L5: 0.026199055835604668
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0231945514678955, Constraint losses: L1: 18.42068099975586, L2: 0.001591154607012868, L3: 1.0015912055969238, L4: 1.0015915632247925
Epoch 500, Loss: 0.00228566350415349, Constraint losses: L1: -1.094468116760254, L2: 0.0, L3: 0.002689063549041748, L4: 0.0006910682423040271
Epoch 1000, Loss: 0.0013324874453246593, Constraint losses: L1: -1.1182764768600464, L2: 0.0, L3: 0.002225041389465332, L4: 0.00022572251327801496
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0213370323181152, Constraint losses: L1: 18.42068099975586, L2: 0.0009720284142531455, L3: 1.000972032546997, L4: 1.0009722709655762
Epoch 500, Loss: 0.0025829547084867954, Constraint losses: L1: -1.0197944641113281, L2: 0.0, L3: 0.0028003454208374023, L4: 0.0008024038397707045
Epoch 1000, Loss: 0.001472198637202382, Constraint losses: L1: -1.049521803855896, L2: 0.0, L3: 0.002260565757751465, L4: 0.0002611547242850065
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 88.4478530883789, Losses: L1: 11.76147747039795, L2: 0.0010711140930652618, L3: 1.0002244710922241, L4: 75.58033752441406, L5: 0.3026949167251587
Epoch 500, Loss: 22.372451782226562, Losses: L1: 5.453780651092529, L2: 1.8746980428695679, L3: 0.3631383180618286, L4: 15.437049865722656, L5: 0.18135204911231995
Epoch 1000, Loss: 51.13743591308594, Losses: L1: 7.5838518142700195, L2: 0.39295434951782227, L3: 0.8927280902862549, L4: 42.52836608886719, L5: 0.19118814170360565
Epoch 1500, Loss: 13.678668975830078, Losses: L1: 5.740351676940918, L2: 1.7676604986190796, L3: 0.22709667682647705, L4: 6.59330940246582, L5: 0.17381475865840912
Epoch 2000, Loss: 44.03913879394531, Losses: L1: 4.541646480560303, L2: 0.4979126751422882, L3: 0.8856823444366455, L4: 38.48045349121094, L5: 0.16261960566043854
Epoch 2500, Loss: 44.10736846923828, Losses: L1: 4.416694641113281, L2: 0.729846715927124, L3: 0.9680202007293701, L4: 38.51303482055664, L5: 0.16435304284095764
Epoch 3000, Loss: 43.29734420776367, Losses: L1: 4.1730756759643555, L2: 1.029672384262085, L3: 0.9406623244285583, L4: 37.816993713378906, L5: 0.16105423867702484
Epoch 3500, Loss: 43.329017639160156, Losses: L1: 3.9100406169891357, L2: 0.7677562832832336, L3: 0.9904152154922485, L4: 38.21472930908203, L5: 0.16258051991462708
Epoch 4000, Loss: 42.84243392944336, Losses: L1: 4.061316967010498, L2: 0.8042637705802917, L3: 1.0034383535385132, L4: 37.555213928222656, L5: 0.16102658212184906
Epoch 4500, Loss: 42.774200439453125, Losses: L1: 4.0824198722839355, L2: 0.7941225171089172, L3: 1.00973641872406, L4: 37.46910858154297, L5: 0.16037116944789886
Epoch 5000, Loss: 42.733551025390625, Losses: L1: 4.105278491973877, L2: 0.7868650555610657, L3: 1.017796516418457, L4: 37.40593719482422, L5: 0.1600017249584198
Epoch 5500, Loss: 42.7105598449707, Losses: L1: 4.113905429840088, L2: 0.7747226357460022, L3: 1.0177141427993774, L4: 37.38092803955078, L5: 0.15975436568260193
Epoch 6000, Loss: 42.69548797607422, Losses: L1: 4.11985445022583, L2: 0.7653989195823669, L3: 1.016402006149292, L4: 37.36552047729492, L5: 0.15960708260536194
Epoch 6500, Loss: 42.714439392089844, Losses: L1: 4.14699125289917, L2: 0.7456740736961365, L3: 0.9895200133323669, L4: 37.38041305541992, L5: 0.15972018241882324
Epoch 7000, Loss: 42.68072509765625, Losses: L1: 4.133492469787598, L2: 0.7567479014396667, L3: 1.0117013454437256, L4: 37.344730377197266, L5: 0.15913709998130798
Epoch 7500, Loss: 42.672889709472656, Losses: L1: 4.1243462562561035, L2: 0.7544946670532227, L3: 1.0128852128982544, L4: 37.346832275390625, L5: 0.15900959074497223
Epoch 8000, Loss: 42.66797637939453, Losses: L1: 4.121188163757324, L2: 0.752050518989563, L3: 1.0130304098129272, L4: 37.34638214111328, L5: 0.15893414616584778
Epoch 8500, Loss: 42.66452407836914, Losses: L1: 4.122547149658203, L2: 0.7507166862487793, L3: 1.0130934715270996, L4: 37.342262268066406, L5: 0.1589057743549347
Epoch 9000, Loss: 42.662017822265625, Losses: L1: 4.123793125152588, L2: 0.7496446371078491, L3: 1.013074517250061, L4: 37.33909606933594, L5: 0.15888366103172302
Epoch 9500, Loss: 42.66019058227539, Losses: L1: 4.124532222747803, L2: 0.7487728595733643, L3: 1.013020396232605, L4: 37.33702850341797, L5: 0.15886686742305756
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.029440402984619, Constraint losses: L1: 18.42068099975586, L2: 0.003673156024888158, L3: 1.0036731958389282, L4: 1.0036733150482178
Epoch 500, Loss: 0.0022992475423961878, Constraint losses: L1: -1.1052289009094238, L2: 0.0, L3: 0.0027013421058654785, L4: 0.0007031343411654234
Epoch 1000, Loss: 0.0013392233522608876, Constraint losses: L1: -1.1176519393920898, L2: 0.0, L3: 0.002228081226348877, L4: 0.00022879417520016432
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0058631896972656, Constraint losses: L1: 7.2585649490356445, L2: 0.0, L3: 0.9993023872375488, L4: 0.9993023872375488
Epoch 500, Loss: 0.002598689403384924, Constraint losses: L1: -1.0347660779953003, L2: 0.0, L3: 0.002815723419189453, L4: 0.0008177319541573524
Epoch 1000, Loss: 0.0014927351148799062, Constraint losses: L1: -1.0505871772766113, L2: 0.0, L3: 0.0022713541984558105, L4: 0.00027196816517971456
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 176.38694763183594, Losses: L1: 6.047447204589844, L2: 0.0, L3: 0.9975433349609375, L4: 84.82913970947266, L5: 0.3648989796638489
Epoch 500, Loss: 14.76737117767334, Losses: L1: 6.702609539031982, L2: 0.9201365113258362, L3: 0.23031795024871826, L4: 3.7204043865203857, L5: 0.0974513366818428
Epoch 1000, Loss: 16.66004753112793, Losses: L1: 6.845027446746826, L2: 1.9803268909454346, L3: 0.19585639238357544, L4: 4.342845916748047, L5: 0.08247385174036026
Epoch 1500, Loss: 15.5337495803833, Losses: L1: 7.87148380279541, L2: 1.5291422605514526, L3: 0.1231653094291687, L4: 3.3937740325927734, L5: 0.0971282422542572
Epoch 2000, Loss: 9.393370628356934, Losses: L1: 4.741784572601318, L2: 1.27066171169281, L3: 0.14018547534942627, L4: 1.9498894214630127, L5: 0.0927685871720314
Epoch 2500, Loss: 109.20356750488281, Losses: L1: 8.594347953796387, L2: 0.0006298684165813029, L3: 0.9989594221115112, L4: 49.992122650146484, L5: 0.25036123394966125
Epoch 3000, Loss: 108.31724548339844, Losses: L1: 7.720975875854492, L2: 0.0012611100682988763, L3: 0.9978950619697571, L4: 49.98588943481445, L5: 0.24983637034893036
Epoch 3500, Loss: 107.76006317138672, Losses: L1: 7.175731182098389, L2: 0.00192428776063025, L3: 0.996772050857544, L4: 49.98017501831055, L5: 0.2492685168981552
Epoch 4000, Loss: 107.36914825439453, Losses: L1: 6.798425197601318, L2: 0.0027067752089351416, L3: 0.9954911470413208, L4: 49.97365951538086, L5: 0.24861273169517517
Epoch 4500, Loss: 107.06815338134766, Losses: L1: 6.5132670402526855, L2: 0.0035450563300400972, L3: 0.9941340088844299, L4: 49.966041564941406, L5: 0.24792629480361938
Epoch 5000, Loss: 106.829345703125, Losses: L1: 6.291168689727783, L2: 0.004381622187793255, L3: 0.9927871227264404, L4: 49.957984924316406, L5: 0.24725449085235596
Epoch 5500, Loss: 106.63876342773438, Losses: L1: 6.117010116577148, L2: 0.005175244063138962, L3: 0.9915140271186829, L4: 49.95004653930664, L5: 0.24662655591964722
Epoch 6000, Loss: 106.4867172241211, Losses: L1: 5.9803338050842285, L2: 0.005898851435631514, L3: 0.9903565049171448, L4: 49.94261169433594, L5: 0.24605917930603027
Epoch 6500, Loss: 106.36573791503906, Losses: L1: 5.873217582702637, L2: 0.006537484470754862, L3: 0.9893372654914856, L4: 49.9359016418457, L5: 0.24556444585323334
Epoch 7000, Loss: 106.26985168457031, Losses: L1: 5.78946590423584, L2: 0.007086121942847967, L3: 0.9884630441665649, L4: 49.93001937866211, L5: 0.2451431304216385
Epoch 7500, Loss: 106.1942367553711, Losses: L1: 5.724219799041748, L2: 0.007546893320977688, L3: 0.987730085849762, L4: 49.924991607666016, L5: 0.24479486048221588
Epoch 8000, Loss: 106.1349868774414, Losses: L1: 5.673624038696289, L2: 0.00792617630213499, L3: 0.9871273040771484, L4: 49.92079162597656, L5: 0.2445094734430313
Epoch 8500, Loss: 106.08891296386719, Losses: L1: 5.634659767150879, L2: 0.008232709020376205, L3: 0.986640214920044, L4: 49.91733932495117, L5: 0.24427956342697144
Epoch 9000, Loss: 106.05345916748047, Losses: L1: 5.604936599731445, L2: 0.008475651033222675, L3: 0.9862542748451233, L4: 49.914554595947266, L5: 0.24409781396389008
Epoch 9500, Loss: 106.02655792236328, Losses: L1: 5.58256196975708, L2: 0.008664499036967754, L3: 0.9859544634819031, L4: 49.912353515625, L5: 0.24395692348480225
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0221920013427734, Constraint losses: L1: 18.42068099975586, L2: 0.0012571181869134307, L3: 1.001257061958313, L4: 1.0012571811676025
Epoch 500, Loss: 0.002457608934491873, Constraint losses: L1: -1.1158363819122314, L2: 0.0, L3: 0.0027857422828674316, L4: 0.0007877030875533819
Epoch 1000, Loss: 0.001408965908922255, Constraint losses: L1: -1.1180377006530762, L2: 0.0, L3: 0.0022631287574768066, L4: 0.0002638748846948147
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.024143695831299, Constraint losses: L1: 18.42068099975586, L2: 0.0019173374166712165, L3: 1.0019029378890991, L4: 1.0019025802612305
Epoch 500, Loss: 0.002619482111185789, Constraint losses: L1: -1.0354331731796265, L2: 0.0, L3: 0.002826392650604248, L4: 0.0008285226067528129
Epoch 1000, Loss: 0.0014879682566970587, Constraint losses: L1: -1.0514568090438843, L2: 0.0, L3: 0.0022693872451782227, L4: 0.0002700378536246717
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 159.64541625976562, Losses: L1: 16.33919334411621, L2: 0.001523804385215044, L3: 1.0013072490692139, L4: 71.2662353515625, L5: 0.27233582735061646
Epoch 500, Loss: 8.517496109008789, Losses: L1: 3.777362823486328, L2: 0.8933519124984741, L3: 0.1280606985092163, L4: 2.0729286670684814, L5: 0.08357009291648865
Epoch 1000, Loss: 10.725713729858398, Losses: L1: 3.533627986907959, L2: 0.5719112157821655, L3: 0.1147456169128418, L4: 3.3895254135131836, L5: 0.06970576196908951
Epoch 1500, Loss: 2.7348837852478027, Losses: L1: 0.7354744076728821, L2: 0.014540636911988258, L3: 0.10653233528137207, L4: 0.9542282819747925, L5: 0.030416149646043777
Epoch 2000, Loss: 3.2866761684417725, Losses: L1: 0.2948515713214874, L2: 0.037949126213788986, L3: 0.0722959041595459, L4: 1.456149697303772, L5: 0.024402577430009842
Epoch 2500, Loss: 2.019595146179199, Losses: L1: 0.24679966270923615, L2: 0.031829386949539185, L3: 0.06700718402862549, L4: 0.8530775308609009, L5: 0.01722211018204689
Epoch 3000, Loss: 1.5548968315124512, Losses: L1: 0.2066042125225067, L2: 0.033922307193279266, L3: 0.06391596794128418, L4: 0.6427529454231262, L5: 0.013867618516087532
Epoch 3500, Loss: 0.7437043190002441, Losses: L1: 0.1926390826702118, L2: 0.027113305404782295, L3: 0.06360995769500732, L4: 0.24770411849021912, L5: 0.010295365937054157
Epoch 4000, Loss: 0.6870779395103455, Losses: L1: 0.18855109810829163, L2: 0.027076594531536102, L3: 0.062453389167785645, L4: 0.22208371758460999, L5: 0.009594367817044258
Epoch 4500, Loss: 0.6652319431304932, Losses: L1: 0.18573853373527527, L2: 0.026694243773818016, L3: 0.061845362186431885, L4: 0.21313834190368652, L5: 0.008946909569203854
Epoch 5000, Loss: 0.6469143629074097, Losses: L1: 0.18396490812301636, L2: 0.026325911283493042, L3: 0.06144821643829346, L4: 0.20523352921009064, L5: 0.008595321327447891
Epoch 5500, Loss: 0.6346299052238464, Losses: L1: 0.18267212808132172, L2: 0.026209862902760506, L3: 0.061088502407073975, L4: 0.1999867856502533, L5: 0.008335067890584469
Epoch 6000, Loss: 0.6266169548034668, Losses: L1: 0.18149973452091217, L2: 0.026155510917305946, L3: 0.06079745292663574, L4: 0.19674690067768097, L5: 0.008146940730512142
Epoch 6500, Loss: 0.6205689907073975, Losses: L1: 0.1807655394077301, L2: 0.02605891041457653, L3: 0.060605406761169434, L4: 0.19423142075538635, L5: 0.00800846517086029
Epoch 7000, Loss: 0.6159393191337585, Losses: L1: 0.18036822974681854, L2: 0.02595512941479683, L3: 0.06044888496398926, L4: 0.19222399592399597, L5: 0.007921097800135612
Epoch 7500, Loss: 0.6125844120979309, Losses: L1: 0.17987193167209625, L2: 0.025923144072294235, L3: 0.06032615900039673, L4: 0.1908678412437439, L5: 0.007852130569517612
Epoch 8000, Loss: 0.60993891954422, Losses: L1: 0.17954900860786438, L2: 0.02593902125954628, L3: 0.06021839380264282, L4: 0.18975527584552765, L5: 0.007800627499818802
Epoch 8500, Loss: 0.6080838441848755, Losses: L1: 0.1793685406446457, L2: 0.025889892131090164, L3: 0.060159504413604736, L4: 0.1889641284942627, L5: 0.007762326393276453
Epoch 9000, Loss: 0.6726845502853394, Losses: L1: 0.14998698234558105, L2: 0.02363913506269455, L3: 0.06087625026702881, L4: 0.23634454607963562, L5: 0.0077507514506578445
Epoch 9500, Loss: 0.6117961406707764, Losses: L1: 0.14942923188209534, L2: 0.023829132318496704, L3: 0.06068849563598633, L4: 0.2061873972415924, L5: 0.007733270060271025
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9946883916854858, Constraint losses: L1: 5.212789535522461, L2: 0.0, L3: 0.9947382211685181, L4: 0.9947373867034912
Epoch 500, Loss: 0.0022022444754838943, Constraint losses: L1: -1.1045843362808228, L2: 0.0, L3: 0.0026526451110839844, L4: 0.000654183910228312
Epoch 1000, Loss: 0.0013095284812152386, Constraint losses: L1: -1.1164180040359497, L2: 0.0, L3: 0.002212703227996826, L4: 0.00021324330009520054
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.018864631652832, Constraint losses: L1: 18.42068099975586, L2: 0.00014806032413616776, L3: 1.000148057937622, L4: 1.000147819519043
Epoch 500, Loss: 0.002070089103654027, Constraint losses: L1: -1.0325862169265747, L2: 0.0, L3: 0.0025506019592285156, L4: 0.0005520733539015055
Epoch 1000, Loss: 0.0013047234388068318, Constraint losses: L1: -1.0507053136825562, L2: 0.0, L3: 0.0021775364875793457, L4: 0.0001778923033270985
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 162.97267150878906, Losses: L1: 14.220112800598145, L2: 0.0006630916614085436, L3: 1.0003403425216675, L4: 73.83830261230469, L5: 0.2877265512943268
Epoch 500, Loss: 18.418691635131836, Losses: L1: 5.658195495605469, L2: 2.2430877685546875, L3: 0.07761597633361816, L4: 5.6871185302734375, L5: 0.11295460909605026
Epoch 1000, Loss: 10.864155769348145, Losses: L1: 4.527334213256836, L2: 0.761166512966156, L3: 0.14665359258651733, L4: 2.8586416244506836, L5: 0.08281400054693222
Epoch 1500, Loss: 11.1011323928833, Losses: L1: 5.155791282653809, L2: 0.616107702255249, L3: 0.0939282774925232, L4: 2.7696280479431152, L5: 0.025533024221658707
Epoch 2000, Loss: 1.8793725967407227, Losses: L1: 0.3569912910461426, L2: 0.058811742812395096, L3: 0.06607723236083984, L4: 0.6989156007766724, L5: 0.031052831560373306
Epoch 2500, Loss: 1.271353006362915, Losses: L1: 0.3002362847328186, L2: 0.0547022707760334, L3: 0.061708927154541016, L4: 0.43183836340904236, L5: 0.024617217481136322
Epoch 3000, Loss: 0.9400991201400757, Losses: L1: 0.2976774573326111, L2: 0.05331404134631157, L3: 0.060024380683898926, L4: 0.2677972614765167, L5: 0.02507896162569523
Epoch 3500, Loss: 0.8817460536956787, Losses: L1: 0.2972767949104309, L2: 0.050772491842508316, L3: 0.05896341800689697, L4: 0.23975500464439392, L5: 0.02504562772810459
Epoch 4000, Loss: 0.8307547569274902, Losses: L1: 0.29313424229621887, L2: 0.049596067517995834, L3: 0.05828183889389038, L4: 0.21699431538581848, L5: 0.024846479296684265
Epoch 4500, Loss: 0.7995976209640503, Losses: L1: 0.29259949922561646, L2: 0.048009905964136124, L3: 0.05783259868621826, L4: 0.20227889716625214, L5: 0.024759529158473015
Epoch 5000, Loss: 0.7818436026573181, Losses: L1: 0.2922000288963318, L2: 0.0467836894094944, L3: 0.057425618171691895, L4: 0.1942504346370697, L5: 0.02451901324093342
Epoch 5500, Loss: 0.7644008994102478, Losses: L1: 0.2910641133785248, L2: 0.04609294235706329, L3: 0.05714690685272217, L4: 0.18664216995239258, L5: 0.024216271936893463
Epoch 6000, Loss: 0.7541763782501221, Losses: L1: 0.28948232531547546, L2: 0.04555173218250275, L3: 0.05695903301239014, L4: 0.1826280802488327, L5: 0.024091243743896484
Epoch 6500, Loss: 0.7474721074104309, Losses: L1: 0.28945374488830566, L2: 0.04520495980978012, L3: 0.05674034357070923, L4: 0.1794760674238205, L5: 0.024046801030635834
Epoch 7000, Loss: 0.7420946955680847, Losses: L1: 0.2891923487186432, L2: 0.044983264058828354, L3: 0.056562960147857666, L4: 0.17711660265922546, L5: 0.023948021233081818
Epoch 7500, Loss: 0.7386311888694763, Losses: L1: 0.2889373302459717, L2: 0.04478857293725014, L3: 0.0564497709274292, L4: 0.17565324902534485, L5: 0.023884084075689316
Epoch 8000, Loss: 0.7362077236175537, Losses: L1: 0.28894588351249695, L2: 0.04467073082923889, L3: 0.05635190010070801, L4: 0.17453262209892273, L5: 0.023842638358473778
Epoch 8500, Loss: 0.7344457507133484, Losses: L1: 0.2887305021286011, L2: 0.04458129033446312, L3: 0.05630218982696533, L4: 0.17382629215717316, L5: 0.023810479789972305
Epoch 9000, Loss: 0.7332198023796082, Losses: L1: 0.2887130677700043, L2: 0.04450897127389908, L3: 0.0562596321105957, L4: 0.17328105866909027, L5: 0.02378014102578163
Epoch 9500, Loss: 0.7323639392852783, Losses: L1: 0.2886832356452942, L2: 0.044463321566581726, L3: 0.05623197555541992, L4: 0.17290633916854858, L5: 0.023760203272104263
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0045409202575684, Constraint losses: L1: 6.766408443450928, L2: 0.0, L3: 0.9988872408866882, L4: 0.9988871812820435
Epoch 500, Loss: 0.002028909046202898, Constraint losses: L1: -1.099898338317871, L2: 0.0, L3: 0.0025635957717895508, L4: 0.0005652116378769279
Epoch 1000, Loss: 0.0012483875034376979, Constraint losses: L1: -1.1180877685546875, L2: 0.0, L3: 0.0021829605102539062, L4: 0.00018351481412537396
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0306203365325928, Constraint losses: L1: 18.42068099975586, L2: 0.004066321533173323, L3: 1.0040663480758667, L4: 1.0040669441223145
Epoch 500, Loss: 0.0021368241868913174, Constraint losses: L1: -1.0218238830566406, L2: 0.0, L3: 0.0025783777236938477, L4: 0.0005802704254165292
Epoch 1000, Loss: 0.0013215243816375732, Constraint losses: L1: -1.0497314929962158, L2: 0.0, L3: 0.0021852850914001465, L4: 0.00018597079906612635
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 41.261260986328125, Losses: L1: 6.714239597320557, L2: 4.710982466349378e-06, L3: 0.9983684420585632, L4: 66.85896301269531, L5: 0.23834088444709778
Epoch 500, Loss: 30.368629455566406, Losses: L1: 4.7408223152160645, L2: 0.07947865128517151, L3: 0.9457277655601501, L4: 49.09720230102539, L5: 0.1874782294034958
Epoch 1000, Loss: 14.761963844299316, Losses: L1: 4.842954158782959, L2: 0.7747467756271362, L3: 0.2638281583786011, L4: 18.367794036865234, L5: 0.16782251000404358
Epoch 1500, Loss: 12.283638954162598, Losses: L1: 5.679981708526611, L2: 0.7470839619636536, L3: 0.25288939476013184, L4: 11.877172470092773, L5: 0.07728040218353271
Epoch 2000, Loss: 2.6480188369750977, Losses: L1: 1.0008540153503418, L2: 0.11072777956724167, L3: 0.14524555206298828, L4: 2.851625919342041, L5: 0.04148488491773605
Epoch 2500, Loss: 2.9060184955596924, Losses: L1: 1.5094541311264038, L2: 0.13087104260921478, L3: 0.17868024110794067, L4: 2.277864456176758, L5: 0.02703307382762432
Epoch 3000, Loss: 4.237037181854248, Losses: L1: 1.9295560121536255, L2: 0.10864841192960739, L3: 0.19599145650863647, L4: 4.075607776641846, L5: 0.0387243889272213
Epoch 3500, Loss: 1.9977614879608154, Losses: L1: 0.9851735830307007, L2: 0.08335461467504501, L3: 0.14895379543304443, L4: 1.623813509941101, L5: 0.020100051537156105
Epoch 4000, Loss: 1.7364927530288696, Losses: L1: 0.9215639233589172, L2: 0.08300849050283432, L3: 0.12544429302215576, L4: 1.2769525051116943, L5: 0.019008053466677666
Epoch 4500, Loss: 1.6929672956466675, Losses: L1: 0.9038559198379517, L2: 0.0834607183933258, L3: 0.12026059627532959, L4: 1.2358534336090088, L5: 0.01838722452521324
Epoch 5000, Loss: 1.6384683847427368, Losses: L1: 0.8671923875808716, L2: 0.08089481294155121, L3: 0.11709702014923096, L4: 1.2095482349395752, L5: 0.017914822325110435
Epoch 5500, Loss: 1.6196937561035156, Losses: L1: 0.8542733788490295, L2: 0.08090703934431076, L3: 0.11518824100494385, L4: 1.2020589113235474, L5: 0.01749853417277336
Epoch 6000, Loss: 1.6082669496536255, Losses: L1: 0.8452556133270264, L2: 0.0808291882276535, L3: 0.11417782306671143, L4: 1.1996304988861084, L5: 0.01720745861530304
Epoch 6500, Loss: 1.6001774072647095, Losses: L1: 0.8388575315475464, L2: 0.08083124458789825, L3: 0.11339110136032104, L4: 1.1980043649673462, L5: 0.017021847888827324
Epoch 7000, Loss: 1.594279170036316, Losses: L1: 0.8342562317848206, L2: 0.08080380409955978, L3: 0.11282241344451904, L4: 1.1966809034347534, L5: 0.016916433349251747
Epoch 7500, Loss: 1.5898425579071045, Losses: L1: 0.8307529091835022, L2: 0.08083512634038925, L3: 0.11233365535736084, L4: 1.1958423852920532, L5: 0.016834508627653122
Epoch 8000, Loss: 1.5865232944488525, Losses: L1: 0.8281716704368591, L2: 0.08084316551685333, L3: 0.11198443174362183, L4: 1.1951223611831665, L5: 0.01676892675459385
Epoch 8500, Loss: 1.5840181112289429, Losses: L1: 0.8262356519699097, L2: 0.08084240555763245, L3: 0.11171901226043701, L4: 1.1945550441741943, L5: 0.016729669645428658
Epoch 9000, Loss: 1.5821309089660645, Losses: L1: 0.8247994780540466, L2: 0.08083553612232208, L3: 0.11153125762939453, L4: 1.194079875946045, L5: 0.01668502762913704
Epoch 9500, Loss: 1.5806912183761597, Losses: L1: 0.8237107396125793, L2: 0.08083083480596542, L3: 0.11138254404067993, L4: 1.1937031745910645, L5: 0.01666184514760971
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.991222858428955, Constraint losses: L1: 4.94775915145874, L2: 0.0, L3: 0.9931380152702332, L4: 0.993137001991272
Epoch 500, Loss: 0.002061698352918029, Constraint losses: L1: -1.1024250984191895, L2: 0.0, L3: 0.0025812387466430664, L4: 0.0005828847642987967
Epoch 1000, Loss: 0.0012493801768869162, Constraint losses: L1: -1.1174910068511963, L2: 0.0, L3: 0.0021831393241882324, L4: 0.00018373189959675074
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.024949073791504, Constraint losses: L1: 18.42068099975586, L2: 0.0021759066730737686, L3: 1.0021759271621704, L4: 1.0021765232086182
Epoch 500, Loss: 0.0023229289799928665, Constraint losses: L1: -0.9464413523674011, L2: 0.0, L3: 0.0026336312294006348, L4: 0.0006357392994686961
Epoch 1000, Loss: 0.0013330423971638083, Constraint losses: L1: -1.0459848642349243, L2: 0.0, L3: 0.0021892189979553223, L4: 0.00018980832828674465
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.110870361328125, Losses: L1: 5.597109794616699, L2: 0.0, L3: 0.9962493777275085, L4: 90.24252319335938, L5: 0.3962484300136566
Epoch 500, Loss: 29.137910842895508, Losses: L1: 3.8723697662353516, L2: 0.014972141943871975, L3: 0.9262523055076599, L4: 48.30828857421875, L5: 0.17765891551971436
Epoch 1000, Loss: 6.569362640380859, Losses: L1: 2.8579468727111816, L2: 0.24908149242401123, L3: 0.21881461143493652, L4: 6.592912673950195, L5: 0.07160399109125137
Epoch 1500, Loss: 18.763416290283203, Losses: L1: 6.219505786895752, L2: 0.8981918692588806, L3: 0.3896695375442505, L4: 23.21025848388672, L5: 0.10001548379659653
Epoch 2000, Loss: 44.673892974853516, Losses: L1: 18.420263290405273, L2: 8.269063767052387e-10, L3: 1.0, L4: 50.01055145263672, L5: 0.24835710227489471
Epoch 2500, Loss: 44.67378616333008, Losses: L1: 18.420204162597656, L2: 8.056849631898899e-10, L3: 1.0, L4: 50.01036071777344, L5: 0.24840101599693298
Epoch 3000, Loss: 44.67369842529297, Losses: L1: 18.420154571533203, L2: 7.906028054449621e-10, L3: 1.0, L4: 50.01021194458008, L5: 0.24843409657478333
Epoch 3500, Loss: 44.673622131347656, Losses: L1: 18.42011070251465, L2: 7.78963726855153e-10, L3: 1.0, L4: 50.010101318359375, L5: 0.24845895171165466
Epoch 4000, Loss: 44.673553466796875, Losses: L1: 18.420066833496094, L2: 7.694295200977308e-10, L3: 1.0, L4: 50.01001739501953, L5: 0.2484777271747589
Epoch 4500, Loss: 44.67349624633789, Losses: L1: 18.420026779174805, L2: 7.620216679882219e-10, L3: 1.0, L4: 50.009952545166016, L5: 0.24849186837673187
Epoch 5000, Loss: 44.67344665527344, Losses: L1: 18.419992446899414, L2: 7.56347873220875e-10, L3: 1.0, L4: 50.00990676879883, L5: 0.24850262701511383
Epoch 5500, Loss: 44.67341613769531, Losses: L1: 18.419963836669922, L2: 7.518315969790024e-10, L3: 1.0, L4: 50.0098762512207, L5: 0.24851077795028687
Epoch 6000, Loss: 44.67337417602539, Losses: L1: 18.419939041137695, L2: 7.482122699187244e-10, L3: 1.0, L4: 50.00984191894531, L5: 0.2485169917345047
Epoch 6500, Loss: 44.6733512878418, Losses: L1: 18.419918060302734, L2: 7.455973061176735e-10, L3: 1.0, L4: 50.009822845458984, L5: 0.2485218197107315
Epoch 7000, Loss: 44.6733283996582, Losses: L1: 18.41990089416504, L2: 7.435492777041475e-10, L3: 1.0, L4: 50.00980758666992, L5: 0.24852541089057922
Epoch 7500, Loss: 44.67331314086914, Losses: L1: 18.419889450073242, L2: 7.418242131684849e-10, L3: 1.0, L4: 50.00979232788086, L5: 0.24852824211120605
Epoch 8000, Loss: 44.67329788208008, Losses: L1: 18.419878005981445, L2: 7.406730229142511e-10, L3: 1.0, L4: 50.00978088378906, L5: 0.2485305368900299
Epoch 8500, Loss: 44.67329025268555, Losses: L1: 18.419872283935547, L2: 7.396682710769653e-10, L3: 1.0, L4: 50.00977325439453, L5: 0.24853233993053436
Epoch 9000, Loss: 44.673282623291016, Losses: L1: 18.419862747192383, L2: 7.39059202725656e-10, L3: 1.0, L4: 50.009769439697266, L5: 0.2485336810350418
Epoch 9500, Loss: 44.67327880859375, Losses: L1: 18.419858932495117, L2: 7.382574551684229e-10, L3: 1.0, L4: 50.009765625, L5: 0.24853451550006866
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9992921352386475, Constraint losses: L1: 5.726110458374023, L2: 0.0, L3: 0.9967832565307617, L4: 0.9967827796936035
Epoch 500, Loss: 0.002155706752091646, Constraint losses: L1: -1.1049773693084717, L2: 0.0, L3: 0.002629578113555908, L4: 0.0006311060860753059
Epoch 1000, Loss: 0.001295729074627161, Constraint losses: L1: -1.1184353828430176, L2: 0.0, L3: 0.002206861972808838, L4: 0.00020730245159938931
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019329309463501, Constraint losses: L1: 18.42068099975586, L2: 0.00031149349524639547, L3: 1.0002985000610352, L4: 1.0002986192703247
Epoch 500, Loss: 0.0022438315209001303, Constraint losses: L1: -1.0318200588226318, L2: 0.0, L3: 0.0026370882987976074, L4: 0.0006385633023455739
Epoch 1000, Loss: 0.0013588666915893555, Constraint losses: L1: -1.0521221160888672, L2: 0.0, L3: 0.0022052526473999023, L4: 0.00020573619985952973
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 42.70206069946289, Losses: L1: 5.222638130187988, L2: 2.1815503714606166e-05, L3: 0.9919845461845398, L4: 71.89016723632812, L5: 0.27117210626602173
Epoch 500, Loss: 30.264522552490234, Losses: L1: 4.221238136291504, L2: 9.098947884922381e-06, L3: 0.9608403444290161, L4: 49.310089111328125, L5: 0.2136974036693573
Epoch 1000, Loss: 10.467716217041016, Losses: L1: 4.425360202789307, L2: 0.5708441138267517, L3: 0.1944645643234253, L4: 10.83994197845459, L5: 0.07124897837638855
Epoch 1500, Loss: 7.717071056365967, Losses: L1: 3.4226205348968506, L2: 0.3008899986743927, L3: 0.20124900341033936, L4: 7.618217468261719, L5: 0.0668240338563919
Epoch 2000, Loss: 5.459749698638916, Losses: L1: 2.296621561050415, L2: 0.21106375753879547, L3: 0.17955493927001953, L4: 5.493503570556641, L5: 0.06564478576183319
Epoch 2500, Loss: 31.579524993896484, Losses: L1: 4.9569292068481445, L2: 0.0, L3: 0.9826894998550415, L4: 50.462799072265625, L5: 0.20425309240818024
Epoch 3000, Loss: 6.65068244934082, Losses: L1: 3.627572536468506, L2: 0.32061097025871277, L3: 0.1602933406829834, L4: 5.149128437042236, L5: 0.06397344917058945
Epoch 3500, Loss: 25.78801727294922, Losses: L1: 2.075767993927002, L2: 0.001239232369698584, L3: 0.7922552227973938, L4: 45.10371017456055, L5: 0.18375931680202484
Epoch 4000, Loss: 12.529463768005371, Losses: L1: 4.097512722015381, L2: 0.6409843564033508, L3: 0.35893356800079346, L4: 15.200323104858398, L5: 0.07618208974599838
Epoch 4500, Loss: 11.716532707214355, Losses: L1: 4.167818546295166, L2: 0.7206979990005493, L3: 0.32571250200271606, L4: 13.404671669006348, L5: 0.08015824854373932
Epoch 5000, Loss: 11.306252479553223, Losses: L1: 4.176968097686768, L2: 0.7164143323898315, L3: 0.30587828159332275, L4: 12.604475975036621, L5: 0.0814807340502739
Epoch 5500, Loss: 11.040620803833008, Losses: L1: 4.176689624786377, L2: 0.7038790583610535, L3: 0.2917490601539612, L4: 12.112804412841797, L5: 0.08191994577646255
Epoch 6000, Loss: 10.843947410583496, Losses: L1: 4.173831462860107, L2: 0.6929417848587036, L3: 0.28009510040283203, L4: 11.75908088684082, L5: 0.08200516551733017
Epoch 6500, Loss: 10.68453598022461, Losses: L1: 4.172542572021484, L2: 0.6828416585922241, L3: 0.2701544761657715, L4: 11.472562789916992, L5: 0.08206859976053238
Epoch 7000, Loss: 10.54758071899414, Losses: L1: 4.173067569732666, L2: 0.6721063852310181, L3: 0.2613694667816162, L4: 11.225473403930664, L5: 0.08217678219079971
Epoch 7500, Loss: 10.42248821258545, Losses: L1: 4.175343036651611, L2: 0.6622661352157593, L3: 0.2528402805328369, L4: 10.997106552124023, L5: 0.08230934292078018
Epoch 8000, Loss: 10.303190231323242, Losses: L1: 4.1787824630737305, L2: 0.6550730466842651, L3: 0.24398833513259888, L4: 10.775949478149414, L5: 0.08245369046926498
Epoch 8500, Loss: 10.193721771240234, Losses: L1: 4.182867050170898, L2: 0.6496224999427795, L3: 0.23552948236465454, L4: 10.570596694946289, L5: 0.08260771632194519
Epoch 9000, Loss: 10.105783462524414, Losses: L1: 4.187166213989258, L2: 0.6422359943389893, L3: 0.22926068305969238, L4: 10.405380249023438, L5: 0.08277411013841629
Epoch 9500, Loss: 10.041170120239258, Losses: L1: 4.1913838386535645, L2: 0.6345748901367188, L3: 0.22517895698547363, L4: 10.282783508300781, L5: 0.08296381682157516
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.006080389022827, Constraint losses: L1: 7.326962947845459, L2: 0.00012404992594383657, L3: 0.9993148446083069, L4: 0.9993144869804382
Epoch 500, Loss: 0.002378969918936491, Constraint losses: L1: -1.1069250106811523, L2: 0.0, L3: 0.002741992473602295, L4: 0.0007439024630002677
Epoch 1000, Loss: 0.0013702742289751768, Constraint losses: L1: -1.1186965703964233, L2: 0.0, L3: 0.0022441744804382324, L4: 0.00024479645071551204
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0309839248657227, Constraint losses: L1: 18.42068099975586, L2: 0.004187660291790962, L3: 1.0041877031326294, L4: 1.0041879415512085
Epoch 500, Loss: 0.0022396640852093697, Constraint losses: L1: -1.005473256111145, L2: 0.0, L3: 0.0026217103004455566, L4: 0.0006234270404092968
Epoch 1000, Loss: 0.0013409046223387122, Constraint losses: L1: -1.0491015911102295, L2: 0.0, L3: 0.002194702625274658, L4: 0.00019530358258634806
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 79.39832305908203, Losses: L1: 8.264289855957031, L2: 0.0001439066109014675, L3: 0.9987648129463196, L4: 70.00403594970703, L5: 0.26231470704078674
Epoch 500, Loss: 18.596464157104492, Losses: L1: 5.888482570648193, L2: 0.5918005704879761, L3: 0.3599469065666199, L4: 12.017024993896484, L5: 0.07021833211183548
Epoch 1000, Loss: 54.99554443359375, Losses: L1: 4.097017765045166, L2: 0.008495929650962353, L3: 0.9684884548187256, L4: 49.809730529785156, L5: 0.23211288452148438
Epoch 1500, Loss: 6.626713752746582, Losses: L1: 0.8435929417610168, L2: 0.01561000943183899, L3: 0.23383855819702148, L4: 5.523392677307129, L5: 0.036169227212667465
Epoch 2000, Loss: 4.705542087554932, Losses: L1: 0.8254013061523438, L2: 0.0029834904707968235, L3: 0.19653797149658203, L4: 3.6666157245635986, L5: 0.030990654602646828
Epoch 2500, Loss: 5.215127468109131, Losses: L1: 1.7281243801116943, L2: 0.0359698049724102, L3: 0.2002587914466858, L4: 3.2562966346740723, L5: 0.02492642216384411
Epoch 3000, Loss: 4.81177282333374, Losses: L1: 1.3317357301712036, L2: 0.03194434568285942, L3: 0.19565922021865845, L4: 3.255692720413208, L5: 0.02542632445693016
Epoch 3500, Loss: 53.92488479614258, Losses: L1: 3.8723080158233643, L2: 0.0, L3: 0.9734088778495789, L4: 48.97199630737305, L5: 0.2143380492925644
Epoch 4000, Loss: 17.01387596130371, Losses: L1: 4.549052715301514, L2: 0.34454140067100525, L3: 0.3610789179801941, L4: 11.904866218566895, L5: 0.05321512743830681
Epoch 4500, Loss: 14.860213279724121, Losses: L1: 4.830170154571533, L2: 0.2902647852897644, L3: 0.3162831664085388, L4: 9.541640281677246, L5: 0.05397433787584305
Epoch 5000, Loss: 18.13956069946289, Losses: L1: 3.637781858444214, L2: 0.17168551683425903, L3: 0.308479905128479, L4: 14.058954238891602, L5: 0.09700508415699005
Epoch 5500, Loss: 13.328536033630371, Losses: L1: 4.038010597229004, L2: 0.2752043306827545, L3: 0.26248323917388916, L4: 8.86016845703125, L5: 0.06054335832595825
Epoch 6000, Loss: 13.129146575927734, Losses: L1: 4.051753044128418, L2: 0.2644815742969513, L3: 0.2626493573188782, L4: 8.652364730834961, L5: 0.06027659773826599
Epoch 6500, Loss: 13.01181411743164, Losses: L1: 4.053121089935303, L2: 0.25768154859542847, L3: 0.261243999004364, L4: 8.538566589355469, L5: 0.06008290871977806
Epoch 7000, Loss: 12.926634788513184, Losses: L1: 4.049769401550293, L2: 0.2534419298171997, L3: 0.2597355246543884, L4: 8.460474014282227, L5: 0.05987028777599335
Epoch 7500, Loss: 12.862407684326172, Losses: L1: 4.047865867614746, L2: 0.25010350346565247, L3: 0.25865602493286133, L4: 8.400979995727539, L5: 0.05970849469304085
Epoch 8000, Loss: 12.813619613647461, Losses: L1: 4.046523571014404, L2: 0.2475021481513977, L3: 0.2578631639480591, L4: 8.355691909790039, L5: 0.059580374509096146
Epoch 8500, Loss: 12.776448249816895, Losses: L1: 4.045533180236816, L2: 0.2454845905303955, L3: 0.2572757601737976, L4: 8.321158409118652, L5: 0.059477392584085464
Epoch 9000, Loss: 12.748139381408691, Losses: L1: 4.044785022735596, L2: 0.2439202070236206, L3: 0.25683993101119995, L4: 8.294857025146484, L5: 0.05939577519893646
Epoch 9500, Loss: 12.726608276367188, Losses: L1: 4.044264316558838, L2: 0.2427053600549698, L3: 0.25652217864990234, L4: 8.274805068969727, L5: 0.0593281127512455
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0018105506896973, Constraint losses: L1: 6.104471206665039, L2: 0.0, L3: 0.99785315990448, L4: 0.9978529214859009
Epoch 500, Loss: 0.0024866159074008465, Constraint losses: L1: -1.112748384475708, L2: 0.0, L3: 0.002798795700073242, L4: 0.0008005686104297638
Epoch 1000, Loss: 0.001413797726854682, Constraint losses: L1: -1.1177754402160645, L2: 0.0, L3: 0.0022655129432678223, L4: 0.0002660602913238108
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0032947063446045, Constraint losses: L1: 6.579400539398193, L2: 0.00011486681614769623, L3: 0.9983001947402954, L4: 0.9983002543449402
Epoch 500, Loss: 0.001976992469280958, Constraint losses: L1: -1.0440870523452759, L2: 0.0, L3: 0.002509891986846924, L4: 0.0005111874779686332
Epoch 1000, Loss: 0.0012793696951121092, Constraint losses: L1: -1.052600383758545, L2: 0.0, L3: 0.0021657347679138184, L4: 0.00016623531701043248
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.41887664794922, Losses: L1: 16.62440299987793, L2: 0.0030511999502778053, L3: 1.0027729272842407, L4: 69.5362319946289, L5: 0.2539444863796234
Epoch 500, Loss: 3.582998752593994, Losses: L1: 0.3888188600540161, L2: 0.13551680743694305, L3: 0.07984071969985962, L4: 3.0221433639526367, L5: 0.024437330663204193
Epoch 1000, Loss: 11.850592613220215, Losses: L1: 5.63836669921875, L2: 2.0734057426452637, L3: 0.1518169641494751, L4: 4.931742191314697, L5: 0.09196335822343826
Epoch 1500, Loss: 54.600685119628906, Losses: L1: 3.5416910648345947, L2: 0.011227532289922237, L3: 0.9248858690261841, L4: 49.934852600097656, L5: 0.19364188611507416
Epoch 2000, Loss: 15.05349349975586, Losses: L1: 6.908218860626221, L2: 1.6215754747390747, L3: 0.26415127515792847, L4: 7.011533260345459, L5: 0.05880254879593849
Epoch 2500, Loss: 8.98515796661377, Losses: L1: 4.944309711456299, L2: 0.303028404712677, L3: 0.2072899341583252, L4: 3.641697883605957, L5: 0.04034583270549774
Epoch 3000, Loss: 25.490039825439453, Losses: L1: 6.953176021575928, L2: 1.856262445449829, L3: 0.13441014289855957, L4: 17.304340362548828, L5: 0.16998299956321716
Epoch 3500, Loss: 16.741209030151367, Losses: L1: 5.294593811035156, L2: 0.8585458993911743, L3: 0.26855695247650146, L4: 10.649358749389648, L5: 0.09942597150802612
Epoch 4000, Loss: 14.96568775177002, Losses: L1: 4.946059703826904, L2: 0.7062029838562012, L3: 0.2468705177307129, L4: 9.32753849029541, L5: 0.09211859852075577
Epoch 4500, Loss: 13.797316551208496, Losses: L1: 4.944157600402832, L2: 0.6526795625686646, L3: 0.23702991008758545, L4: 8.207159996032715, L5: 0.08262965083122253
Epoch 5000, Loss: 13.424689292907715, Losses: L1: 5.08927059173584, L2: 0.6208598017692566, L3: 0.2383829951286316, L4: 7.7079997062683105, L5: 0.07860619574785233
Epoch 5500, Loss: 12.586685180664062, Losses: L1: 4.975982189178467, L2: 0.6097980737686157, L3: 0.24007517099380493, L4: 6.9942522048950195, L5: 0.07147565484046936
Epoch 6000, Loss: 12.182662010192871, Losses: L1: 5.010286331176758, L2: 0.6036215424537659, L3: 0.2435992956161499, L4: 6.558911323547363, L5: 0.06805463135242462
Epoch 6500, Loss: 11.909486770629883, Losses: L1: 5.024623870849609, L2: 0.577511191368103, L3: 0.2438930869102478, L4: 6.28543758392334, L5: 0.06677637994289398
Epoch 7000, Loss: 11.857508659362793, Losses: L1: 5.170927047729492, L2: 0.5520452857017517, L3: 0.24307066202163696, L4: 6.103254318237305, L5: 0.0642348974943161
Epoch 7500, Loss: 11.715858459472656, Losses: L1: 5.171053886413574, L2: 0.5529437065124512, L3: 0.24129188060760498, L4: 5.962247371673584, L5: 0.06479223817586899
Epoch 8000, Loss: 11.664551734924316, Losses: L1: 5.172791957855225, L2: 0.5471729636192322, L3: 0.24133968353271484, L4: 5.91212272644043, L5: 0.06471125036478043
Epoch 8500, Loss: 11.600798606872559, Losses: L1: 5.184748649597168, L2: 0.5403549671173096, L3: 0.23826897144317627, L4: 5.842728614807129, L5: 0.06487566232681274
Epoch 9000, Loss: 11.575937271118164, Losses: L1: 5.186984539031982, L2: 0.5378172993659973, L3: 0.23916572332382202, L4: 5.81632661819458, L5: 0.0645526871085167
Epoch 9500, Loss: 11.562203407287598, Losses: L1: 5.1861348152160645, L2: 0.5364310145378113, L3: 0.2391146421432495, L4: 5.804166793823242, L5: 0.06457101553678513
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0056354999542236, Constraint losses: L1: 7.167839050292969, L2: 0.0, L3: 0.9992339611053467, L4: 0.9992337822914124
Epoch 500, Loss: 0.001966457348316908, Constraint losses: L1: -1.1046074628829956, L2: 0.0, L3: 0.002534925937652588, L4: 0.0005361390067264438
Epoch 1000, Loss: 0.001233680173754692, Constraint losses: L1: -1.1163883209228516, L2: 0.0, L3: 0.0021747946739196777, L4: 0.00017527391901239753
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.020625114440918, Constraint losses: L1: 18.42068099975586, L2: 0.0007347053615376353, L3: 1.0007346868515015, L4: 1.0007350444793701
Epoch 500, Loss: 0.002090941881760955, Constraint losses: L1: -1.035476565361023, L2: 0.0, L3: 0.0025624632835388184, L4: 0.0005639551673084497
Epoch 1000, Loss: 0.0013128130231052637, Constraint losses: L1: -1.0495728254318237, L2: 0.0, L3: 0.0021809935569763184, L4: 0.0001813923445297405
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 78.89726257324219, Losses: L1: 11.446720123291016, L2: 6.672218296444044e-05, L3: 0.9998484253883362, L4: 65.9754867553711, L5: 0.23758696019649506
Epoch 500, Loss: 17.80923080444336, Losses: L1: 7.329649448394775, L2: 1.716185450553894, L3: 0.21577411890029907, L4: 9.212961196899414, L5: 0.09637636691331863
Epoch 1000, Loss: 12.270623207092285, Losses: L1: 4.602786064147949, L2: 0.9164689183235168, L3: 0.24107670783996582, L4: 6.803552627563477, L5: 0.08248640596866608
Epoch 1500, Loss: 12.090076446533203, Losses: L1: 5.79849910736084, L2: 1.4262676239013672, L3: 0.2223135232925415, L4: 5.0632758140563965, L5: 0.1464271992444992
Epoch 2000, Loss: 11.66115951538086, Losses: L1: 6.13543176651001, L2: 1.6184093952178955, L3: 0.21928638219833374, L4: 4.282488822937012, L5: 0.10737426578998566
Epoch 2500, Loss: 10.380790710449219, Losses: L1: 6.003353595733643, L2: 1.6967583894729614, L3: 0.18360662460327148, L4: 3.0930395126342773, L5: 0.126205712556839
Epoch 3000, Loss: 10.298538208007812, Losses: L1: 5.457791328430176, L2: 1.5205944776535034, L3: 0.18000662326812744, L4: 3.666224956512451, L5: 0.11710918694734573
Epoch 3500, Loss: 10.917183876037598, Losses: L1: 4.383840084075928, L2: 0.7991200089454651, L3: 0.2127336859703064, L4: 5.798673629760742, L5: 0.06118830293416977
Epoch 4000, Loss: 7.708524703979492, Losses: L1: 3.938842296600342, L2: 0.5960193872451782, L3: 0.20615482330322266, L4: 3.1472771167755127, L5: 0.05912024900317192
Epoch 4500, Loss: 7.308554172515869, Losses: L1: 4.590914249420166, L2: 0.7751774191856384, L3: 0.1883164644241333, L4: 2.010270118713379, L5: 0.06573241204023361
Epoch 5000, Loss: 6.928829193115234, Losses: L1: 4.344126224517822, L2: 0.7723302245140076, L3: 0.18289905786514282, L4: 1.8853046894073486, L5: 0.0651668831706047
Epoch 5500, Loss: 6.790735244750977, Losses: L1: 4.316890716552734, L2: 0.7839791774749756, L3: 0.17959439754486084, L4: 1.7732760906219482, L5: 0.0644921287894249
Epoch 6000, Loss: 6.67848014831543, Losses: L1: 4.275983810424805, L2: 0.7725532054901123, L3: 0.1770172119140625, L4: 1.7112934589385986, L5: 0.06395429372787476
Epoch 6500, Loss: 6.635383605957031, Losses: L1: 4.277862071990967, L2: 0.7638195157051086, L3: 0.17498719692230225, L4: 1.6731058359146118, L5: 0.06375943869352341
Epoch 7000, Loss: 6.586580753326416, Losses: L1: 4.25863790512085, L2: 0.7600183486938477, L3: 0.17344439029693604, L4: 1.6475918292999268, L5: 0.06344875693321228
Epoch 7500, Loss: 6.564268589019775, Losses: L1: 4.255970001220703, L2: 0.7572898268699646, L3: 0.17230725288391113, L4: 1.630812406539917, L5: 0.06326695531606674
Epoch 8000, Loss: 6.557616710662842, Losses: L1: 4.255735397338867, L2: 0.7556568384170532, L3: 0.17213010787963867, L4: 1.6258033514022827, L5: 0.06305962800979614
Epoch 8500, Loss: 6.512084484100342, Losses: L1: 4.21711540222168, L2: 0.7523377537727356, L3: 0.17180263996124268, L4: 1.6213184595108032, L5: 0.06283969432115555
Epoch 9000, Loss: 6.492332935333252, Losses: L1: 4.200252056121826, L2: 0.7518157958984375, L3: 0.17143219709396362, L4: 1.6191054582595825, L5: 0.06281791627407074
Epoch 9500, Loss: 6.488632678985596, Losses: L1: 4.199197769165039, L2: 0.7515045404434204, L3: 0.17123961448669434, L4: 1.6168956756591797, L5: 0.06277348101139069
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0052568912506104, Constraint losses: L1: 7.002412796020508, L2: 0.0, L3: 0.9991272687911987, L4: 0.9991271495819092
Epoch 500, Loss: 0.002079244237393141, Constraint losses: L1: -1.0694235563278198, L2: 0.0, L3: 0.0025734901428222656, L4: 0.0005751777207478881
Epoch 1000, Loss: 0.0012423923471942544, Constraint losses: L1: -1.1177525520324707, L2: 0.0, L3: 0.002179741859436035, L4: 0.0001804030907806009
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0058791637420654, Constraint losses: L1: 7.242130279541016, L2: 0.0, L3: 0.9993185997009277, L4: 0.999318540096283
Epoch 500, Loss: 0.0024005621671676636, Constraint losses: L1: -0.9539726972579956, L2: 0.0, L3: 0.0026761889457702637, L4: 0.0006783459102734923
Epoch 1000, Loss: 0.001360559370368719, Constraint losses: L1: -1.0500596761703491, L2: 0.0, L3: 0.0022050142288208008, L4: 0.00020560479606501758
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 169.31076049804688, Losses: L1: 17.1080265045166, L2: 0.0022729213815182447, L3: 1.0021905899047852, L4: 75.52545928955078, L5: 0.2969646453857422
Epoch 500, Loss: 3.4205265045166016, Losses: L1: 0.6234421133995056, L2: 0.0984758585691452, L3: 0.056722402572631836, L4: 1.3395143747329712, L5: 0.024190889671444893
Epoch 1000, Loss: 7.435279846191406, Losses: L1: 1.8296897411346436, L2: 0.12262114137411118, L3: 0.10914278030395508, L4: 2.7070412635803223, L5: 0.04210821911692619
Epoch 1500, Loss: 6.122298240661621, Losses: L1: 0.46610063314437866, L2: 0.045464567840099335, L3: 0.09915339946746826, L4: 2.7596781253814697, L5: 0.029911180958151817
Epoch 2000, Loss: 1.6612663269042969, Losses: L1: 0.3464648723602295, L2: 0.05879942327737808, L3: 0.07941877841949463, L4: 0.5988349914550781, L5: 0.01662594825029373
Epoch 2500, Loss: 2.063910722732544, Losses: L1: 0.31093597412109375, L2: 0.05537804961204529, L3: 0.07644784450531006, L4: 0.8212575912475586, L5: 0.01264520175755024
Epoch 3000, Loss: 2.202094078063965, Losses: L1: 0.3044940233230591, L2: 0.053377456963062286, L3: 0.07265603542327881, L4: 0.8961994647979736, L5: 0.011712344363331795
Epoch 3500, Loss: 1.0967074632644653, Losses: L1: 0.3013109266757965, L2: 0.04770386964082718, L3: 0.07106715440750122, L4: 0.34708350896835327, L5: 0.01262088306248188
Epoch 4000, Loss: 1.000784993171692, Losses: L1: 0.29395079612731934, L2: 0.045837949961423874, L3: 0.0693158507347107, L4: 0.30425143241882324, L5: 0.012193060480058193
Epoch 4500, Loss: 0.9256990551948547, Losses: L1: 0.27106064558029175, L2: 0.044124409556388855, L3: 0.067665696144104, L4: 0.2795615792274475, L5: 0.011574631556868553
Epoch 5000, Loss: 0.900227427482605, Losses: L1: 0.2653560936450958, L2: 0.044248633086681366, L3: 0.06664520502090454, L4: 0.2701989412307739, L5: 0.011407814919948578
Epoch 5500, Loss: 0.8726528882980347, Losses: L1: 0.2622049152851105, L2: 0.04369565472006798, L3: 0.06628531217575073, L4: 0.258317232131958, L5: 0.011360706761479378
Epoch 6000, Loss: 0.862032413482666, Losses: L1: 0.25984200835227966, L2: 0.0441073402762413, L3: 0.06586456298828125, L4: 0.25430163741111755, L5: 0.011337773874402046
Epoch 6500, Loss: 0.8556249141693115, Losses: L1: 0.25816139578819275, L2: 0.044054850935935974, L3: 0.0656474232673645, L4: 0.2520645558834076, L5: 0.011319173499941826
Epoch 7000, Loss: 0.8504207134246826, Losses: L1: 0.25676557421684265, L2: 0.044145695865154266, L3: 0.06546890735626221, L4: 0.2502368092536926, L5: 0.011279591359198093
Epoch 7500, Loss: 0.8475136756896973, Losses: L1: 0.2558038532733917, L2: 0.04413997754454613, L3: 0.06535911560058594, L4: 0.24932265281677246, L5: 0.011270789429545403
Epoch 8000, Loss: 0.8449115753173828, Losses: L1: 0.25505414605140686, L2: 0.044153083115816116, L3: 0.06527841091156006, L4: 0.24843862652778625, L5: 0.011250522918999195
Epoch 8500, Loss: 0.8431992530822754, Losses: L1: 0.25463446974754333, L2: 0.044193021953105927, L3: 0.06520652770996094, L4: 0.24781833589076996, L5: 0.011250106617808342
Epoch 9000, Loss: 0.8420928120613098, Losses: L1: 0.25429239869117737, L2: 0.044207166880369186, L3: 0.06516134738922119, L4: 0.24745699763298035, L5: 0.011242954060435295
Epoch 9500, Loss: 0.8413566946983337, Losses: L1: 0.2541276514530182, L2: 0.04422568157315254, L3: 0.06512749195098877, L4: 0.24718298017978668, L5: 0.011245512403547764
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9980015754699707, Constraint losses: L1: 5.57643985748291, L2: 0.0, L3: 0.9962126612663269, L4: 0.9962124228477478
Epoch 500, Loss: 0.0020988876931369305, Constraint losses: L1: -1.106961727142334, L2: 0.0, L3: 0.0026020407676696777, L4: 0.000603808555752039
Epoch 1000, Loss: 0.0012752999318763614, Constraint losses: L1: -1.1182247400283813, L2: 0.0, L3: 0.00219649076461792, L4: 0.00019703395082615316
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0020461082458496, Constraint losses: L1: 6.078257083892822, L2: 0.0, L3: 0.9979844689369202, L4: 0.9979833960533142
Epoch 500, Loss: 0.002407690277323127, Constraint losses: L1: -1.0088838338851929, L2: 0.0, L3: 0.002707362174987793, L4: 0.0007092120940797031
Epoch 1000, Loss: 0.001394702703692019, Constraint losses: L1: -1.0514723062515259, L2: 0.0, L3: 0.0022228360176086426, L4: 0.00022333909873850644
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 191.75860595703125, Losses: L1: 17.02717399597168, L2: 0.002610590774565935, L3: 1.0024911165237427, L4: 86.67198181152344, L5: 0.383670449256897
Epoch 500, Loss: 9.287689208984375, Losses: L1: 1.1272265911102295, L2: 0.03654179722070694, L3: 0.08392202854156494, L4: 4.0137505531311035, L5: 0.03076818212866783
Epoch 1000, Loss: 6.227688312530518, Losses: L1: 0.6546279191970825, L2: 0.08244279772043228, L3: 0.05788123607635498, L4: 2.7221639156341553, L5: 0.029630223289132118
Epoch 1500, Loss: 3.673492670059204, Losses: L1: 1.5761140584945679, L2: 0.5580881834030151, L3: 0.0720442533493042, L4: 0.862308144569397, L5: 0.021674001589417458
Epoch 2000, Loss: 1.015310287475586, Losses: L1: 0.33612751960754395, L2: 0.03971167653799057, L3: 0.05429905652999878, L4: 0.29609689116477966, L5: 0.012834114022552967
Epoch 2500, Loss: 0.5984874963760376, Losses: L1: 0.1271626502275467, L2: 0.03413765877485275, L3: 0.05008220672607422, L4: 0.19739991426467896, L5: 0.009373973123729229
Epoch 3000, Loss: 1.339630365371704, Losses: L1: 0.12063469737768173, L2: 0.030806928873062134, L3: 0.04982709884643555, L4: 0.5716760158538818, L5: 0.010413057170808315
Epoch 3500, Loss: 0.5538480877876282, Losses: L1: 0.10931668430566788, L2: 0.03198491781949997, L3: 0.04893839359283447, L4: 0.18610742688179016, L5: 0.0073856632225215435
Epoch 4000, Loss: 0.427615761756897, Losses: L1: 0.10991296917200089, L2: 0.029846131801605225, L3: 0.04845142364501953, L4: 0.1234467476606369, L5: 0.007434812840074301
Epoch 4500, Loss: 0.41039055585861206, Losses: L1: 0.10739545524120331, L2: 0.02965669520199299, L3: 0.04811751842498779, L4: 0.11640788614749908, L5: 0.007233468350023031
Epoch 5000, Loss: 0.4023002088069916, Losses: L1: 0.1059793010354042, L2: 0.029710082337260246, L3: 0.0478440523147583, L4: 0.11323492974042892, L5: 0.00715192686766386
Epoch 5500, Loss: 0.3785554766654968, Losses: L1: 0.08813008666038513, L2: 0.02980145253241062, L3: 0.047632038593292236, L4: 0.11049418151378632, L5: 0.006904258392751217
Epoch 6000, Loss: 0.37122154235839844, Losses: L1: 0.08696392923593521, L2: 0.029712243005633354, L3: 0.047581255435943604, L4: 0.10751230269670486, L5: 0.0067956531420350075
Epoch 6500, Loss: 0.3671015202999115, Losses: L1: 0.08636762201786041, L2: 0.029513411223888397, L3: 0.047544002532958984, L4: 0.10584418475627899, L5: 0.006744829472154379
Epoch 7000, Loss: 0.3648303151130676, Losses: L1: 0.08562267571687698, L2: 0.029509276151657104, L3: 0.047515034675598145, L4: 0.10512350499629974, L5: 0.006690958980470896
Epoch 7500, Loss: 0.3618885278701782, Losses: L1: 0.08528829365968704, L2: 0.02946290746331215, L3: 0.047480881214141846, L4: 0.10385561734437943, L5: 0.006676682271063328
Epoch 8000, Loss: 0.3602798581123352, Losses: L1: 0.08491361141204834, L2: 0.02941243164241314, L3: 0.0474696159362793, L4: 0.10326709598302841, L5: 0.00665622390806675
Epoch 8500, Loss: 0.35923323035240173, Losses: L1: 0.08464039862155914, L2: 0.029400097206234932, L3: 0.047460079193115234, L4: 0.10289699584245682, L5: 0.006638731807470322
Epoch 9000, Loss: 0.3583836555480957, Losses: L1: 0.08446577936410904, L2: 0.029372021555900574, L3: 0.04745280742645264, L4: 0.10257545858621597, L5: 0.006628142204135656
Epoch 9500, Loss: 0.35785165429115295, Losses: L1: 0.08433205634355545, L2: 0.029367869719862938, L3: 0.04744589328765869, L4: 0.10238534212112427, L5: 0.00661909906193614
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0269598960876465, Constraint losses: L1: 18.42068099975586, L2: 0.0028463539201766253, L3: 1.002846360206604, L4: 1.0028464794158936
Epoch 500, Loss: 0.0022886970546096563, Constraint losses: L1: -1.0289299488067627, L2: 0.0, L3: 0.0026577115058898926, L4: 0.0006599154439754784
Epoch 1000, Loss: 0.001283174380660057, Constraint losses: L1: -1.1166043281555176, L2: 0.0, L3: 0.002199530601501465, L4: 0.00020024825062137097
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.006523609161377, Constraint losses: L1: 7.620922088623047, L2: 3.755209032618723e-09, L3: 0.9994512796401978, L4: 0.9994512796401978
Epoch 500, Loss: 0.0024355859495699406, Constraint losses: L1: -0.9788604974746704, L2: 0.0, L3: 0.0027061104774475098, L4: 0.0007083359523676336
Epoch 1000, Loss: 0.0013855407014489174, Constraint losses: L1: -1.0449106693267822, L2: 0.0, L3: 0.0022148489952087402, L4: 0.00021560242748819292
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 180.67820739746094, Losses: L1: 13.18254566192627, L2: 0.0005744079244323075, L3: 0.9999846816062927, L4: 82.89505004882812, L5: 0.3526464104652405
Epoch 500, Loss: 10.963689804077148, Losses: L1: 0.7588541507720947, L2: 0.0771985724568367, L3: 0.0816044807434082, L4: 4.994558811187744, L5: 0.047756996005773544
Epoch 1000, Loss: 10.575010299682617, Losses: L1: 3.59082293510437, L2: 0.5747936367988586, L3: 0.11814439296722412, L4: 3.249943971633911, L5: 0.03937903046607971
Epoch 1500, Loss: 52.27686309814453, Losses: L1: 10.481756210327148, L2: 2.35127329826355, L3: 0.0697205662727356, L4: 20.098079681396484, L5: 0.17679685354232788
Epoch 2000, Loss: 6.325439453125, Losses: L1: 1.036311149597168, L2: 0.09565489739179611, L3: 0.09956276416778564, L4: 2.535118579864502, L5: 0.03575032949447632
Epoch 2500, Loss: 112.58821105957031, Losses: L1: 12.69516372680664, L2: 0.0429418720304966, L3: 0.9921963810920715, L4: 49.196693420410156, L5: 0.24299608170986176
Epoch 3000, Loss: 34.202354431152344, Losses: L1: 9.15157699584961, L2: 1.8755682706832886, L3: 0.373518705368042, L4: 11.782514572143555, L5: 0.08722241222858429
Epoch 3500, Loss: 17.391897201538086, Losses: L1: 4.793461322784424, L2: 1.316736102104187, L3: 0.18628579378128052, L4: 5.818402290344238, L5: 0.05848853662610054
Epoch 4000, Loss: 15.062026023864746, Losses: L1: 4.981712341308594, L2: 1.109413981437683, L3: 0.18475067615509033, L4: 4.619799613952637, L5: 0.05062839761376381
Epoch 4500, Loss: 13.933415412902832, Losses: L1: 5.020665168762207, L2: 0.8830989003181458, L3: 0.17285090684890747, L4: 4.102020263671875, L5: 0.04715501517057419
Epoch 5000, Loss: 11.475489616394043, Losses: L1: 4.603017807006836, L2: 0.4661687910556793, L3: 0.16920864582061768, L4: 3.196533203125, L5: 0.03855667635798454
Epoch 5500, Loss: 8.883349418640137, Losses: L1: 3.101640224456787, L2: 0.26709526777267456, L3: 0.16570895910263062, L4: 2.705293655395508, L5: 0.035932645201683044
Epoch 6000, Loss: 8.089988708496094, Losses: L1: 2.740549087524414, L2: 0.22908465564250946, L3: 0.1599927544593811, L4: 2.500173568725586, L5: 0.0372784398496151
Epoch 6500, Loss: 7.837093353271484, Losses: L1: 2.758194923400879, L2: 0.22343100607395172, L3: 0.15553796291351318, L4: 2.3670971393585205, L5: 0.03872530162334442
Epoch 7000, Loss: 7.6331024169921875, Losses: L1: 2.743265151977539, L2: 0.22090007364749908, L3: 0.1522914171218872, L4: 2.2738938331604004, L5: 0.03965410962700844
Epoch 7500, Loss: 7.529679775238037, Losses: L1: 2.756059169769287, L2: 0.2180364429950714, L3: 0.14985597133636475, L4: 2.2171754837036133, L5: 0.04019762948155403
Epoch 8000, Loss: 7.4555816650390625, Losses: L1: 2.764568328857422, L2: 0.21609896421432495, L3: 0.1480315923690796, L4: 2.176973342895508, L5: 0.04049282148480415
Epoch 8500, Loss: 7.399932861328125, Losses: L1: 2.7703986167907715, L2: 0.21478329598903656, L3: 0.14660120010375977, L4: 2.1470744609832764, L5: 0.0406961664557457
Epoch 9000, Loss: 7.330159664154053, Losses: L1: 2.7417256832122803, L2: 0.21356840431690216, L3: 0.14532780647277832, L4: 2.127286911010742, L5: 0.040874313563108444
Epoch 9500, Loss: 7.26970100402832, Losses: L1: 2.7144007682800293, L2: 0.2129722386598587, L3: 0.14457356929779053, L4: 2.1111183166503906, L5: 0.04100193455815315
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.019752025604248, Constraint losses: L1: 18.42068099975586, L2: 0.0004438442992977798, L3: 1.0004438161849976, L4: 1.0004435777664185
Epoch 500, Loss: 0.0022109979763627052, Constraint losses: L1: -1.084457516670227, L2: 0.0, L3: 0.002646803855895996, L4: 0.0006486517377197742
Epoch 1000, Loss: 0.0012976889265701175, Constraint losses: L1: -1.1170579195022583, L2: 0.0, L3: 0.0022071003913879395, L4: 0.00020764647342730314
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.023533821105957, Constraint losses: L1: 18.42068099975586, L2: 0.0017044831765815616, L3: 1.001704454421997, L4: 1.0017043352127075
Epoch 500, Loss: 0.002047098008915782, Constraint losses: L1: -0.9907573461532593, L2: 0.0, L3: 0.0025180578231811523, L4: 0.0005197974969632924
Epoch 1000, Loss: 0.0012661811197176576, Constraint losses: L1: -1.0504522323608398, L2: 0.0, L3: 0.0021579861640930176, L4: 0.00015864716260693967
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.276153564453125, Losses: L1: 7.809045791625977, L2: 5.917356247664429e-06, L3: 0.999052107334137, L4: 78.6161880493164, L5: 0.3218139410018921
Epoch 500, Loss: 34.424835205078125, Losses: L1: 7.256131649017334, L2: 0.011799938976764679, L3: 0.9920499920845032, L4: 50.113067626953125, L5: 0.2443363219499588
Epoch 1000, Loss: 45.51369857788086, Losses: L1: 18.387643814086914, L2: 3.607019630896824e-12, L3: 1.0, L4: 50.0008659362793, L5: 0.2512435019016266
Epoch 1500, Loss: 23.14790916442871, Losses: L1: 4.457728385925293, L2: 1.4697827100753784, L3: 0.5307642221450806, L4: 33.58913803100586, L5: 0.19838422536849976
Epoch 2000, Loss: 7.7307209968566895, Losses: L1: 3.1760661602020264, L2: 0.2445937693119049, L3: 0.2588508725166321, L4: 7.764385223388672, L5: 0.06492684036493301
Epoch 2500, Loss: 7.569746971130371, Losses: L1: 3.587249755859375, L2: 0.43191400170326233, L3: 0.1720070242881775, L4: 6.759586334228516, L5: 0.08546645194292068
Epoch 3000, Loss: 11.498852729797363, Losses: L1: 3.9054572582244873, L2: 0.869895875453949, L3: 0.0011947154998779297, L4: 14.221251487731934, L5: 0.09086328744888306
Epoch 3500, Loss: 5.497640132904053, Losses: L1: 2.1309196949005127, L2: 0.3977796137332916, L3: 0.017180562019348145, L4: 6.1500654220581055, L5: 0.11687345802783966
Epoch 4000, Loss: 4.677829742431641, Losses: L1: 2.416200876235962, L2: 0.4493477940559387, L3: 0.0007613897323608398, L4: 3.9670767784118652, L5: 0.10378701984882355
Epoch 4500, Loss: 4.50296688079834, Losses: L1: 2.3389816284179688, L2: 0.4356561303138733, L3: 0.00035822391510009766, L4: 3.7864155769348145, L5: 0.1044650599360466
Epoch 5000, Loss: 4.444169044494629, Losses: L1: 2.326115846633911, L2: 0.4272117614746094, L3: 2.8014183044433594e-05, L4: 3.704653024673462, L5: 0.10412932187318802
Epoch 5500, Loss: 4.400849342346191, Losses: L1: 2.3167426586151123, L2: 0.4221286475658417, L3: 0.00036787986755371094, L4: 3.641063690185547, L5: 0.10354989767074585
Epoch 6000, Loss: 4.353641986846924, Losses: L1: 2.2915220260620117, L2: 0.4155852794647217, L3: 0.0004992485046386719, L4: 3.603879928588867, L5: 0.10277750343084335
Epoch 6500, Loss: 4.3327860832214355, Losses: L1: 2.2903192043304443, L2: 0.413211852312088, L3: 7.992982864379883e-05, L4: 3.5686144828796387, L5: 0.102787546813488
Epoch 7000, Loss: 4.317702770233154, Losses: L1: 2.2901134490966797, L2: 0.41193923354148865, L3: 0.0001569986343383789, L4: 3.5399184226989746, L5: 0.1026921346783638
Epoch 7500, Loss: 4.307076454162598, Losses: L1: 2.2888882160186768, L2: 0.4103068709373474, L3: 0.0001302957534790039, L4: 3.5228567123413086, L5: 0.10269191861152649
Epoch 8000, Loss: 4.29917049407959, Losses: L1: 2.288428544998169, L2: 0.4094439446926117, L3: 6.42538070678711e-05, L4: 3.509158134460449, L5: 0.10262487828731537
Epoch 8500, Loss: 4.293824672698975, Losses: L1: 2.287766933441162, L2: 0.4085422456264496, L3: 0.0001074671745300293, L4: 3.500548839569092, L5: 0.10259560495615005
Epoch 9000, Loss: 4.28986120223999, Losses: L1: 2.2874526977539062, L2: 0.4080791473388672, L3: 2.473592758178711e-05, L4: 3.494109630584717, L5: 0.10252836346626282
Epoch 9500, Loss: 4.287153720855713, Losses: L1: 2.287003993988037, L2: 0.40755847096443176, L3: 1.895427703857422e-05, L4: 3.490142345428467, L5: 0.10252243280410767
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0216453075408936, Constraint losses: L1: 18.42068099975586, L2: 0.0010748680215328932, L3: 1.0010749101638794, L4: 1.0010747909545898
Epoch 500, Loss: 0.002260965760797262, Constraint losses: L1: -1.0112780332565308, L2: 0.0, L3: 0.002635061740875244, L4: 0.000637182267382741
Epoch 1000, Loss: 0.0012643123045563698, Constraint losses: L1: -1.1173290014266968, L2: 0.0, L3: 0.002190530300140381, L4: 0.00019111097208224237
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005293846130371, Constraint losses: L1: 7.068248271942139, L2: 0.0, L3: 0.9991127848625183, L4: 0.9991129636764526
Epoch 500, Loss: 0.002301034051924944, Constraint losses: L1: -1.029526948928833, L2: 0.0, L3: 0.0026643872261047363, L4: 0.0006661738734692335
Epoch 1000, Loss: 0.0013821432366967201, Constraint losses: L1: -1.0508720874786377, L2: 0.0, L3: 0.0022162199020385742, L4: 0.00021679549536202103
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 61.528648376464844, Losses: L1: 18.028575897216797, L2: 0.003344559343531728, L3: 1.0033260583877563, L4: 82.29360961914062, L5: 0.3449411988258362
Epoch 500, Loss: 35.476097106933594, Losses: L1: 8.228196144104004, L2: 4.8585432523395866e-05, L3: 0.9995426535606384, L4: 49.995609283447266, L5: 0.2509864270687103
Epoch 1000, Loss: 31.197288513183594, Losses: L1: 3.4779210090637207, L2: 0.051060184836387634, L3: 0.8911073207855225, L4: 51.44674301147461, L5: 0.1882522702217102
Epoch 1500, Loss: 12.655487060546875, Losses: L1: 5.372926235198975, L2: 0.3867543339729309, L3: 0.28523170948028564, L4: 12.826974868774414, L5: 0.10523331165313721
Epoch 2000, Loss: 11.784419059753418, Losses: L1: 4.471832752227783, L2: 0.37483763694763184, L3: 0.315682053565979, L4: 12.791860580444336, L5: 0.0978725254535675
Epoch 2500, Loss: 10.330007553100586, Losses: L1: 3.5084869861602783, L2: 0.33856087923049927, L3: 0.28882360458374023, L4: 11.948470115661621, L5: 0.10035692155361176
Epoch 3000, Loss: 32.98910140991211, Losses: L1: 6.070372581481934, L2: 0.0009360543917864561, L3: 0.9868007302284241, L4: 49.43307113647461, L5: 0.22812426090240479
Epoch 3500, Loss: 7.796978950500488, Losses: L1: 2.5113179683685303, L2: 0.21282482147216797, L3: 0.21957933902740479, L4: 9.332534790039062, L5: 0.07382269203662872
Epoch 4000, Loss: 4.743202209472656, Losses: L1: 1.2480849027633667, L2: 0.08952359110116959, L3: 0.19802629947662354, L4: 6.011063098907471, L5: 0.0487714521586895
Epoch 4500, Loss: 4.075461387634277, Losses: L1: 1.0648603439331055, L2: 0.07518782466650009, L3: 0.19714784622192383, L4: 5.072558879852295, L5: 0.04243185371160507
Epoch 5000, Loss: 3.942481279373169, Losses: L1: 1.0718022584915161, L2: 0.07254357635974884, L3: 0.1948615312576294, L4: 4.807790756225586, L5: 0.04078879952430725
Epoch 5500, Loss: 3.8563785552978516, Losses: L1: 1.0750330686569214, L2: 0.07020324468612671, L3: 0.19333696365356445, L4: 4.639891624450684, L5: 0.039624251425266266
Epoch 6000, Loss: 3.7992465496063232, Losses: L1: 1.075426697731018, L2: 0.0682072564959526, L3: 0.1918720006942749, L4: 4.534390449523926, L5: 0.03877710923552513
Epoch 6500, Loss: 3.759897470474243, Losses: L1: 1.0743985176086426, L2: 0.06683798134326935, L3: 0.19073569774627686, L4: 4.464624404907227, L5: 0.03829650953412056
Epoch 7000, Loss: 3.732053756713867, Losses: L1: 1.0746893882751465, L2: 0.06583523750305176, L3: 0.18983465433120728, L4: 4.413294315338135, L5: 0.03813028335571289
Epoch 7500, Loss: 3.7121264934539795, Losses: L1: 1.0736831426620483, L2: 0.06499768793582916, L3: 0.18929702043533325, L4: 4.379095077514648, L5: 0.03780287504196167
Epoch 8000, Loss: 3.6982784271240234, Losses: L1: 1.0738030672073364, L2: 0.06436224281787872, L3: 0.18893826007843018, L4: 4.353666305541992, L5: 0.03758462518453598
Epoch 8500, Loss: 3.6882247924804688, Losses: L1: 1.0740889310836792, L2: 0.06391748040914536, L3: 0.18860870599746704, L4: 4.335012435913086, L5: 0.037453602999448776
Epoch 9000, Loss: 3.6808650493621826, Losses: L1: 1.0741881132125854, L2: 0.06359388679265976, L3: 0.18841588497161865, L4: 4.3214030265808105, L5: 0.03734663501381874
Epoch 9500, Loss: 3.6755447387695312, Losses: L1: 1.0742480754852295, L2: 0.06334837526082993, L3: 0.18825793266296387, L4: 4.311667442321777, L5: 0.037272825837135315
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0189826488494873, Constraint losses: L1: 18.399316787719727, L2: 0.00023657651036046445, L3: 1.0001732110977173, L4: 1.000173568725586
Epoch 500, Loss: 0.002176388632506132, Constraint losses: L1: -1.0578038692474365, L2: 0.0, L3: 0.0026161670684814453, L4: 0.0006180255440995097
Epoch 1000, Loss: 0.001266751321963966, Constraint losses: L1: -1.1163396835327148, L2: 0.0, L3: 0.0021912455558776855, L4: 0.00019184546545147896
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.00557804107666, Constraint losses: L1: 7.054232597351074, L2: 7.865010047680698e-07, L3: 0.999261736869812, L4: 0.9992613196372986
Epoch 500, Loss: 0.0026677583809942007, Constraint losses: L1: -1.0356173515319824, L2: 0.0, L3: 0.002850651741027832, L4: 0.0008527240715920925
Epoch 1000, Loss: 0.001515189534984529, Constraint losses: L1: -1.0505411624908447, L2: 0.0, L3: 0.002282559871673584, L4: 0.00028317084070295095
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.53932571411133, Losses: L1: 18.42068099975586, L2: 0.01436874084174633, L3: 1.0143687725067139, L4: 71.06541442871094, L5: 0.27500736713409424
Epoch 500, Loss: 28.56725311279297, Losses: L1: 9.262561798095703, L2: 0.05194128304719925, L3: 0.848064124584198, L4: 34.57406234741211, L5: 0.1477818489074707
Epoch 1000, Loss: 45.82907485961914, Losses: L1: 18.324108123779297, L2: 3.226183542537342e-09, L3: 1.0, L4: 50.04655075073242, L5: 0.24084603786468506
Epoch 1500, Loss: 10.307103157043457, Losses: L1: 3.2228939533233643, L2: 0.2067081481218338, L3: 0.25596868991851807, L4: 12.571245193481445, L5: 0.09164776653051376
Epoch 2000, Loss: 33.84855651855469, Losses: L1: 5.632821559906006, L2: 0.0, L3: 0.9932234883308411, L4: 51.72463607788086, L5: 0.18348489701747894
Epoch 2500, Loss: 32.49656295776367, Losses: L1: 4.743286609649658, L2: 0.0, L3: 0.9839385151863098, L4: 50.819969177246094, L5: 0.1877087652683258
Epoch 3000, Loss: 9.147881507873535, Losses: L1: 3.8269765377044678, L2: 0.271306574344635, L3: 0.24738729000091553, L4: 9.126562118530273, L5: 0.06359836459159851
Epoch 3500, Loss: 8.88070297241211, Losses: L1: 3.7974181175231934, L2: 0.2520861029624939, L3: 0.24637794494628906, L4: 8.684432029724121, L5: 0.06113509461283684
Epoch 4000, Loss: 8.710895538330078, Losses: L1: 3.781377077102661, L2: 0.24400199949741364, L3: 0.24400639533996582, L4: 8.397031784057617, L5: 0.0604945607483387
Epoch 4500, Loss: 8.593482971191406, Losses: L1: 3.771676540374756, L2: 0.241480752825737, L3: 0.24055087566375732, L4: 8.197029113769531, L5: 0.06072460860013962
Epoch 5000, Loss: 8.50904655456543, Losses: L1: 3.7664477825164795, L2: 0.2396293431520462, L3: 0.23925423622131348, L4: 8.045051574707031, L5: 0.06087492033839226
Epoch 5500, Loss: 8.446776390075684, Losses: L1: 3.7625017166137695, L2: 0.23807938396930695, L3: 0.2384963035583496, L4: 7.932311534881592, L5: 0.0610433891415596
Epoch 6000, Loss: 8.39986801147461, Losses: L1: 3.7591261863708496, L2: 0.23712460696697235, L3: 0.23811495304107666, L4: 7.847658157348633, L5: 0.061060599982738495
Epoch 6500, Loss: 8.364479064941406, Losses: L1: 3.7562131881713867, L2: 0.23610667884349823, L3: 0.23807138204574585, L4: 7.784038543701172, L5: 0.061025165021419525
Epoch 7000, Loss: 8.337726593017578, Losses: L1: 3.754021167755127, L2: 0.23555155098438263, L3: 0.23808658123016357, L4: 7.735642433166504, L5: 0.06096746027469635
Epoch 7500, Loss: 8.31758975982666, Losses: L1: 3.7524259090423584, L2: 0.23521320521831512, L3: 0.23809409141540527, L4: 7.69899845123291, L5: 0.060934387147426605
Epoch 8000, Loss: 8.302579879760742, Losses: L1: 3.751193046569824, L2: 0.2348303645849228, L3: 0.23813092708587646, L4: 7.671727180480957, L5: 0.06092321500182152
Epoch 8500, Loss: 8.291553497314453, Losses: L1: 3.7503068447113037, L2: 0.23469921946525574, L3: 0.23819857835769653, L4: 7.651467323303223, L5: 0.06088292598724365
Epoch 9000, Loss: 8.283607482910156, Losses: L1: 3.749688148498535, L2: 0.2345801442861557, L3: 0.23827379941940308, L4: 7.636745452880859, L5: 0.0608544647693634
Epoch 9500, Loss: 8.277996063232422, Losses: L1: 3.7492594718933105, L2: 0.23452651500701904, L3: 0.23835259675979614, L4: 7.626245498657227, L5: 0.06082259863615036
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020657777786255, Constraint losses: L1: 18.42068099975586, L2: 0.0007456139428541064, L3: 1.0007456541061401, L4: 1.0007457733154297
Epoch 500, Loss: 0.0021899868734180927, Constraint losses: L1: -0.9485248327255249, L2: 0.0, L3: 0.002568066120147705, L4: 0.000570445554330945
Epoch 1000, Loss: 0.0011985404416918755, Constraint losses: L1: -1.1163806915283203, L2: 0.0, L3: 0.002157151699066162, L4: 0.00015776953659951687
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001093864440918, Constraint losses: L1: 5.939803123474121, L2: 0.0, L3: 0.9975773692131042, L4: 0.9975767731666565
Epoch 500, Loss: 0.0024951056111603975, Constraint losses: L1: -0.8854199647903442, L2: 0.0, L3: 0.0026891231536865234, L4: 0.0006914025289006531
Epoch 1000, Loss: 0.0013517505722120404, Constraint losses: L1: -1.046506404876709, L2: 0.0, L3: 0.00219881534576416, L4: 0.00019944165251217782
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 90.6134033203125, Losses: L1: 18.42068099975586, L2: 0.0022399863228201866, L3: 1.0022399425506592, L4: 70.05554962158203, L5: 0.2631532847881317
Epoch 500, Loss: 2.467820405960083, Losses: L1: 0.16556881368160248, L2: 0.07150334864854813, L3: 0.05946540832519531, L4: 2.138599157333374, L5: 0.017939932644367218
Epoch 1000, Loss: 3.0161633491516113, Losses: L1: 0.18251997232437134, L2: 0.051790930330753326, L3: 0.06589853763580322, L4: 2.6641829013824463, L5: 0.02353557012975216
Epoch 1500, Loss: 1.448328971862793, Losses: L1: 0.09060725569725037, L2: 0.041906896978616714, L3: 0.054734766483306885, L4: 1.2225834131240845, L5: 0.009430528618395329
Epoch 2000, Loss: 0.530052661895752, Losses: L1: 0.06305582821369171, L2: 0.04178670048713684, L3: 0.050456106662750244, L4: 0.34246718883514404, L5: 0.0054481178522109985
Epoch 2500, Loss: 0.5868068337440491, Losses: L1: 0.06884878873825073, L2: 0.0370025672018528, L3: 0.04767417907714844, L4: 0.4015064537525177, L5: 0.0052038561552762985
Epoch 3000, Loss: 0.3925679922103882, Losses: L1: 0.06030549108982086, L2: 0.036013197153806686, L3: 0.04698914289474487, L4: 0.2178390622138977, L5: 0.004877077881246805
Epoch 3500, Loss: 0.33523330092430115, Losses: L1: 0.058228787034749985, L2: 0.03598194941878319, L3: 0.0462876558303833, L4: 0.16384465992450714, L5: 0.005187071859836578
Epoch 4000, Loss: 0.3209632337093353, Losses: L1: 0.05774310976266861, L2: 0.03594598546624184, L3: 0.04600280523300171, L4: 0.1506561040878296, L5: 0.005170802120119333
Epoch 4500, Loss: 0.27096760272979736, Losses: L1: 0.05865946039557457, L2: 0.035617996007204056, L3: 0.04546988010406494, L4: 0.10102912783622742, L5: 0.005060513038188219
Epoch 5000, Loss: 0.2653370201587677, Losses: L1: 0.058881472796201706, L2: 0.03545732796192169, L3: 0.045247018337249756, L4: 0.09571711719036102, L5: 0.005031451117247343
Epoch 5500, Loss: 0.2623620629310608, Losses: L1: 0.05918390303850174, L2: 0.0353216826915741, L3: 0.044879376888275146, L4: 0.09325043857097626, L5: 0.00501621700823307
Epoch 6000, Loss: 0.26028627157211304, Losses: L1: 0.059567708522081375, L2: 0.03518121689558029, L3: 0.04464536905288696, L4: 0.09133292734622955, L5: 0.0050085773691535
Epoch 6500, Loss: 0.258974552154541, Losses: L1: 0.0597149096429348, L2: 0.035138677805662155, L3: 0.04449725151062012, L4: 0.09019004553556442, L5: 0.005011510103940964
Epoch 7000, Loss: 0.2578163743019104, Losses: L1: 0.0598180815577507, L2: 0.03511420637369156, L3: 0.04436910152435303, L4: 0.08919919282197952, L5: 0.005007567349821329
Epoch 7500, Loss: 0.2571250796318054, Losses: L1: 0.059990253299474716, L2: 0.03508954495191574, L3: 0.044253408908843994, L4: 0.08857977390289307, L5: 0.005006910767406225
Epoch 8000, Loss: 0.2565237879753113, Losses: L1: 0.06010271608829498, L2: 0.035071324557065964, L3: 0.04418230056762695, L4: 0.08801702409982681, L5: 0.005007594358175993
Epoch 8500, Loss: 0.25615134835243225, Losses: L1: 0.06019008904695511, L2: 0.03505382686853409, L3: 0.044127047061920166, L4: 0.08767524361610413, L5: 0.005010000430047512
Epoch 9000, Loss: 0.25589096546173096, Losses: L1: 0.06022238731384277, L2: 0.03506280854344368, L3: 0.04409456253051758, L4: 0.08744311332702637, L5: 0.005009896121919155
Epoch 9500, Loss: 0.25570249557495117, Losses: L1: 0.060281459242105484, L2: 0.035057712346315384, L3: 0.04406535625457764, L4: 0.08725593239068985, L5: 0.005011097993701696
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.029834747314453, Constraint losses: L1: 18.42068099975586, L2: 0.0038047553971409798, L3: 1.0038048028945923, L4: 1.0038046836853027
Epoch 500, Loss: 0.0020553525537252426, Constraint losses: L1: -1.102670431137085, L2: 0.0, L3: 0.0025781989097595215, L4: 0.0005798239726573229
Epoch 1000, Loss: 0.0012596896849572659, Constraint losses: L1: -1.1187024116516113, L2: 0.0, L3: 0.0021889209747314453, L4: 0.00018947118951473385
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0273385047912598, Constraint losses: L1: 18.42068099975586, L2: 0.0029725267086178064, L3: 1.0029724836349487, L4: 1.0029728412628174
Epoch 500, Loss: 0.0026234672404825687, Constraint losses: L1: -0.9134051203727722, L2: 0.0, L3: 0.0027670860290527344, L4: 0.0007697861874476075
Epoch 1000, Loss: 0.0014052368933334947, Constraint losses: L1: -1.0490713119506836, L2: 0.0, L3: 0.0022268295288085938, L4: 0.0002274787111673504
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 102.12023162841797, Losses: L1: 16.270000457763672, L2: 0.0022087637335062027, L3: 1.0020614862442017, L4: 83.49285888671875, L5: 0.3521420359611511
Epoch 500, Loss: 63.41434097290039, Losses: L1: 11.117534637451172, L2: 4.912184067507042e-06, L3: 0.9999250769615173, L4: 50.059791564941406, L5: 0.23716485500335693
Epoch 1000, Loss: 12.926660537719727, Losses: L1: 6.324860572814941, L2: 1.1781624555587769, L3: 0.2597338557243347, L4: 5.40352201461792, L5: 0.08972910791635513
Epoch 1500, Loss: 66.45668029785156, Losses: L1: 14.19754695892334, L2: 0.0, L3: 0.9999983310699463, L4: 50.01081085205078, L5: 0.24832464754581451
Epoch 2000, Loss: 10.34931755065918, Losses: L1: 3.6690115928649902, L2: 0.39083510637283325, L3: 0.2789485454559326, L4: 5.850994110107422, L5: 0.075996994972229
Epoch 2500, Loss: 9.327469825744629, Losses: L1: 3.4356422424316406, L2: 0.3199770152568817, L3: 0.23256134986877441, L4: 5.202960968017578, L5: 0.0637555867433548
Epoch 3000, Loss: 7.415218830108643, Losses: L1: 2.8204689025878906, L2: 0.1944858431816101, L3: 0.212898850440979, L4: 4.018395900726318, L5: 0.05331353470683098
Epoch 3500, Loss: 5.891007423400879, Losses: L1: 2.2486813068389893, L2: 0.14612342417240143, L3: 0.18330711126327515, L4: 3.1543407440185547, L5: 0.048309411853551865
Epoch 4000, Loss: 5.061235427856445, Losses: L1: 1.985049843788147, L2: 0.13820897042751312, L3: 0.1689816117286682, L4: 2.624178886413574, L5: 0.04493916407227516
Epoch 4500, Loss: 4.558268070220947, Losses: L1: 1.8094847202301025, L2: 0.1343667209148407, L3: 0.16169726848602295, L4: 2.3152859210968018, L5: 0.04291978478431702
Epoch 5000, Loss: 4.803389549255371, Losses: L1: 1.8208898305892944, L2: 0.13652047514915466, L3: 0.15619993209838867, L4: 2.5645289421081543, L5: 0.03731066361069679
Epoch 5500, Loss: 4.103603363037109, Losses: L1: 1.645575761795044, L2: 0.1308709681034088, L3: 0.15489321947097778, L4: 2.0409722328186035, L5: 0.041833341121673584
Epoch 6000, Loss: 3.967024326324463, Losses: L1: 1.5802078247070312, L2: 0.1296934336423874, L3: 0.15261006355285645, L4: 1.9750697612762451, L5: 0.041679807007312775
Epoch 6500, Loss: 3.9292714595794678, Losses: L1: 1.543445110321045, L2: 0.1291951686143875, L3: 0.150781512260437, L4: 1.9766935110092163, L5: 0.04297224059700966
Epoch 7000, Loss: 3.87276291847229, Losses: L1: 1.5586533546447754, L2: 0.13049812614917755, L3: 0.14907348155975342, L4: 1.9087625741958618, L5: 0.04195098206400871
Epoch 7500, Loss: 3.8379201889038086, Losses: L1: 1.5425124168395996, L2: 0.13005094230175018, L3: 0.14854443073272705, L4: 1.8913354873657227, L5: 0.041957855224609375
Epoch 8000, Loss: 3.8221592903137207, Losses: L1: 1.540613055229187, L2: 0.13017915189266205, L3: 0.14785218238830566, L4: 1.8787410259246826, L5: 0.04201135039329529
Epoch 8500, Loss: 3.811568260192871, Losses: L1: 1.539448857307434, L2: 0.13004562258720398, L3: 0.14755487442016602, L4: 1.8700026273727417, L5: 0.041984036564826965
Epoch 9000, Loss: 3.804241180419922, Losses: L1: 1.5388948917388916, L2: 0.13010336458683014, L3: 0.14720594882965088, L4: 1.8638677597045898, L5: 0.04201514273881912
Epoch 9500, Loss: 3.799165725708008, Losses: L1: 1.538507342338562, L2: 0.1301744282245636, L3: 0.14696258306503296, L4: 1.8596066236495972, L5: 0.04203932732343674
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9952119588851929, Constraint losses: L1: 5.286214351654053, L2: 0.0, L3: 0.9949628114700317, L4: 0.9949629306793213
Epoch 500, Loss: 0.002291484270244837, Constraint losses: L1: -1.1014466285705566, L2: 0.0, L3: 0.0026955008506774902, L4: 0.0006974302232265472
Epoch 1000, Loss: 0.001333492691628635, Constraint losses: L1: -1.1186020374298096, L2: 0.0, L3: 0.0022257566452026367, L4: 0.00022633820481132716
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0258126258850098, Constraint losses: L1: 18.42068099975586, L2: 0.0024639293551445007, L3: 1.002463936805725, L4: 1.0024641752243042
Epoch 500, Loss: 0.0024073305539786816, Constraint losses: L1: -1.031103253364563, L2: 0.0, L3: 0.002718210220336914, L4: 0.0007202235283330083
Epoch 1000, Loss: 0.0014163637533783913, Constraint losses: L1: -1.0515309572219849, L2: 0.0, L3: 0.0022336244583129883, L4: 0.00023427029373124242
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 101.19515228271484, Losses: L1: 18.41187286376953, L2: 0.00151255342643708, L3: 1.0015122890472412, L4: 80.11233520507812, L5: 0.33358120918273926
Epoch 500, Loss: 56.624908447265625, Losses: L1: 4.670746803283691, L2: 0.03860350698232651, L3: 0.9479674696922302, L4: 49.670814514160156, L5: 0.1840548813343048
Epoch 1000, Loss: 66.01431274414062, Losses: L1: 13.504437446594238, L2: 1.3311166924268036e-07, L3: 0.9999969601631165, L4: 50.01399612426758, L5: 0.24794384837150574
Epoch 1500, Loss: 10.344383239746094, Losses: L1: 2.185971260070801, L2: 0.012765633873641491, L3: 0.2546166181564331, L4: 7.551802158355713, L5: 0.04549681767821312
Epoch 2000, Loss: 10.109856605529785, Losses: L1: 2.1729989051818848, L2: 0.019224751740694046, L3: 0.24896162748336792, L4: 7.316978454589844, L5: 0.05617178976535797
Epoch 2500, Loss: 59.887454986572266, Losses: L1: 7.424591064453125, L2: 0.0, L3: 0.99929279088974, L4: 49.965370178222656, L5: 0.2494550198316574
Epoch 3000, Loss: 11.417668342590332, Losses: L1: 2.873322010040283, L2: 0.054399486631155014, L3: 0.23642182350158691, L4: 7.937143802642822, L5: 0.053579699248075485
Epoch 3500, Loss: 10.707538604736328, Losses: L1: 3.3494040966033936, L2: 0.049668215215206146, L3: 0.2689339518547058, L4: 6.728200912475586, L5: 0.03361601009964943
Epoch 4000, Loss: 8.672077178955078, Losses: L1: 2.5623912811279297, L2: 0.04715622588992119, L3: 0.22584420442581177, L4: 5.558889389038086, L5: 0.03776494786143303
Epoch 4500, Loss: 8.117255210876465, Losses: L1: 2.5188426971435547, L2: 0.04939379543066025, L3: 0.22427386045455933, L4: 5.048388481140137, L5: 0.03838953375816345
Epoch 5000, Loss: 7.477166175842285, Losses: L1: 2.079261302947998, L2: 0.03699542209506035, L3: 0.22649484872817993, L4: 4.857346534729004, L5: 0.03453531488776207
Epoch 5500, Loss: 7.284132480621338, Losses: L1: 2.0905587673187256, L2: 0.03798883408308029, L3: 0.22351312637329102, L4: 4.65637731552124, L5: 0.035588137805461884
Epoch 6000, Loss: 7.030632495880127, Losses: L1: 1.9582903385162354, L2: 0.0356978140771389, L3: 0.22418344020843506, L4: 4.536377906799316, L5: 0.03487410396337509
Epoch 6500, Loss: 6.754710674285889, Losses: L1: 1.717954158782959, L2: 0.03015843965113163, L3: 0.22841894626617432, L4: 4.498483657836914, L5: 0.03317788243293762
Epoch 7000, Loss: 6.707995414733887, Losses: L1: 1.7160320281982422, L2: 0.030235204845666885, L3: 0.22731012105941772, L4: 4.455894470214844, L5: 0.033165402710437775
Epoch 7500, Loss: 6.675599098205566, Losses: L1: 1.7130396366119385, L2: 0.03092050738632679, L3: 0.22542047500610352, L4: 4.429286479949951, L5: 0.0334857702255249
Epoch 8000, Loss: 6.651352882385254, Losses: L1: 1.7113405466079712, L2: 0.031432416290044785, L3: 0.22405505180358887, L4: 4.408732891082764, L5: 0.03372667729854584
Epoch 8500, Loss: 6.633205413818359, Losses: L1: 1.710159182548523, L2: 0.03179316222667694, L3: 0.22308683395385742, L4: 4.39316987991333, L5: 0.03390303626656532
Epoch 9000, Loss: 6.619673252105713, Losses: L1: 1.709345817565918, L2: 0.03204861283302307, L3: 0.22240126132965088, L4: 4.381441116333008, L5: 0.034029770642519
Epoch 9500, Loss: 6.548470973968506, Losses: L1: 1.5482676029205322, L2: 0.02900814078748226, L3: 0.22435063123703003, L4: 4.467813491821289, L5: 0.03459228575229645
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0181796550750732, Constraint losses: L1: 17.432146072387695, L2: 0.0003718096704687923, L3: 1.0001877546310425, L4: 1.0001879930496216
Epoch 500, Loss: 0.002070838352665305, Constraint losses: L1: -1.1021672487258911, L2: 0.0, L3: 0.0025856494903564453, L4: 0.0005873561021871865
Epoch 1000, Loss: 0.001261450001038611, Constraint losses: L1: -1.1112136840820312, L2: 0.0, L3: 0.0021860599517822266, L4: 0.00018660379282664508
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019130229949951, Constraint losses: L1: 18.42068099975586, L2: 0.00023648412025067955, L3: 1.0002365112304688, L4: 1.0002366304397583
Epoch 500, Loss: 0.0022260439582169056, Constraint losses: L1: -1.0352107286453247, L2: 0.0, L3: 0.0026297569274902344, L4: 0.0006314977072179317
Epoch 1000, Loss: 0.0013646245934069157, Constraint losses: L1: -1.049293875694275, L2: 0.0, L3: 0.0022066831588745117, L4: 0.00020723527995869517
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 161.1868438720703, Losses: L1: 18.42068099975586, L2: 0.006820795126259327, L3: 1.006820797920227, L4: 70.30729675292969, L5: 0.26905009150505066
Epoch 500, Loss: 18.873048782348633, Losses: L1: 4.571671009063721, L2: 0.9223071932792664, L3: 0.09489870071411133, L4: 6.792129993438721, L5: 0.13233682513237
Epoch 1000, Loss: 116.2974853515625, Losses: L1: 14.16649055480957, L2: 6.375561856231116e-09, L3: 0.9999986886978149, L4: 50.00296401977539, L5: 0.25013667345046997
Epoch 1500, Loss: 17.386322021484375, Losses: L1: 4.140303134918213, L2: 0.42723366618156433, L3: 0.28535306453704834, L4: 6.212897777557373, L5: 0.0718015804886818
Epoch 2000, Loss: 27.966045379638672, Losses: L1: 4.745471000671387, L2: 0.4293690323829651, L3: 0.3053302764892578, L4: 11.182697296142578, L5: 0.05967101827263832
Epoch 2500, Loss: 14.77608585357666, Losses: L1: 3.3021326065063477, L2: 0.28921642899513245, L3: 0.23818570375442505, L4: 5.404365539550781, L5: 0.08848468959331512
Epoch 3000, Loss: 10.352509498596191, Losses: L1: 3.270453691482544, L2: 0.23115302622318268, L3: 0.20630013942718506, L4: 3.2589821815490723, L5: 0.07182970643043518
Epoch 3500, Loss: 7.657658576965332, Losses: L1: 2.6718080043792725, L2: 0.1968739628791809, L3: 0.164476215839386, L4: 2.263887882232666, L5: 0.061371102929115295
Epoch 4000, Loss: 7.146295547485352, Losses: L1: 2.336622476577759, L2: 0.17886100709438324, L3: 0.15313374996185303, L4: 2.191432476043701, L5: 0.06222002953290939
Epoch 4500, Loss: 6.521514415740967, Losses: L1: 2.318636178970337, L2: 0.17751340568065643, L3: 0.14738136529922485, L4: 1.8953659534454346, L5: 0.05725429579615593
Epoch 5000, Loss: 6.406002998352051, Losses: L1: 2.308730125427246, L2: 0.17733126878738403, L3: 0.14433050155639648, L4: 1.8458530902862549, L5: 0.05648014321923256
Epoch 5500, Loss: 6.301808834075928, Losses: L1: 2.287808656692505, L2: 0.17538534104824066, L3: 0.14257127046585083, L4: 1.8063747882843018, L5: 0.05682997405529022
Epoch 6000, Loss: 6.246355056762695, Losses: L1: 2.284618854522705, L2: 0.17433251440525055, L3: 0.14127933979034424, L4: 1.7818894386291504, L5: 0.056465353816747665
Epoch 6500, Loss: 6.2077178955078125, Losses: L1: 2.2825927734375, L2: 0.17362958192825317, L3: 0.1404285430908203, L4: 1.7646071910858154, L5: 0.056477513164281845
Epoch 7000, Loss: 6.183314800262451, Losses: L1: 2.2812113761901855, L2: 0.17322199046611786, L3: 0.13992667198181152, L4: 1.7536959648132324, L5: 0.05649445578455925
Epoch 7500, Loss: 6.1553635597229, Losses: L1: 2.2658560276031494, L2: 0.172625333070755, L3: 0.139900803565979, L4: 1.747562289237976, L5: 0.05653664469718933
Epoch 8000, Loss: 6.145209312438965, Losses: L1: 2.264986515045166, L2: 0.17237496376037598, L3: 0.13973188400268555, L4: 1.7431466579437256, L5: 0.05655648186802864
Epoch 8500, Loss: 6.138114929199219, Losses: L1: 2.264472484588623, L2: 0.17219199240207672, L3: 0.1396256685256958, L4: 1.7400093078613281, L5: 0.05655256286263466
Epoch 9000, Loss: 6.087923049926758, Losses: L1: 2.2100260257720947, L2: 0.17090067267417908, L3: 0.14003539085388184, L4: 1.7419935464859009, L5: 0.05677797645330429
Epoch 9500, Loss: 6.079730033874512, Losses: L1: 2.208531618118286, L2: 0.17052017152309418, L3: 0.14004862308502197, L4: 1.7387769222259521, L5: 0.0565742552280426
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0072782039642334, Constraint losses: L1: 7.924652576446533, L2: 3.3627841844463546e-07, L3: 0.9996767044067383, L4: 0.999676525592804
Epoch 500, Loss: 0.0022952582221478224, Constraint losses: L1: -1.1005665063858032, L2: 0.0, L3: 0.0026970505714416504, L4: 0.0006987742963247001
Epoch 1000, Loss: 0.0013387289363890886, Constraint losses: L1: -1.1185550689697266, L2: 0.0, L3: 0.0022283196449279785, L4: 0.00022896431619301438
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0205800533294678, Constraint losses: L1: 18.42068099975586, L2: 0.0007199061219580472, L3: 1.0007199048995972, L4: 1.0007195472717285
Epoch 500, Loss: 0.0022573682945221663, Constraint losses: L1: -1.0364990234375, L2: 0.0, L3: 0.002646148204803467, L4: 0.0006477190763689578
Epoch 1000, Loss: 0.001377905486151576, Constraint losses: L1: -1.049743890762329, L2: 0.0, L3: 0.002213597297668457, L4: 0.00021405212464742362
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 148.98631286621094, Losses: L1: 5.7192702293396, L2: 0.0, L3: 0.996592104434967, L4: 70.50408172607422, L5: 0.2657032310962677
Epoch 500, Loss: 9.176473617553711, Losses: L1: 3.070241928100586, L2: 0.5183623433113098, L3: 0.06863200664520264, L4: 2.84289813041687, L5: 0.023990530520677567
Epoch 1000, Loss: 13.388486862182617, Losses: L1: 0.49572208523750305, L2: 0.03470921516418457, L3: 0.08712434768676758, L4: 6.323434352874756, L5: 0.05429251492023468
Epoch 1500, Loss: 3.3778834342956543, Losses: L1: 0.29819872975349426, L2: 0.05579083040356636, L3: 0.058344244956970215, L4: 1.458850383758545, L5: 0.01739996299147606
Epoch 2000, Loss: 1.2290048599243164, Losses: L1: 0.24033939838409424, L2: 0.048081859946250916, L3: 0.055767059326171875, L4: 0.4164453148841858, L5: 0.020199716091156006
Epoch 2500, Loss: 1.8056219816207886, Losses: L1: 0.2220182865858078, L2: 0.04482482746243477, L3: 0.05242788791656494, L4: 0.7196412086486816, L5: 0.01705305650830269
Epoch 3000, Loss: 0.8244892954826355, Losses: L1: 0.19030506908893585, L2: 0.03831746056675911, L3: 0.05271637439727783, L4: 0.24575349688529968, L5: 0.018085796386003494
Epoch 3500, Loss: 0.7525731921195984, Losses: L1: 0.1919708102941513, L2: 0.034349553287029266, L3: 0.05207347869873047, L4: 0.21060393750667572, L5: 0.018072789534926414
Epoch 4000, Loss: 0.7000070810317993, Losses: L1: 0.1885041445493698, L2: 0.032104868441820145, L3: 0.05168217420578003, L4: 0.18710863590240479, L5: 0.017868878319859505
Epoch 4500, Loss: 0.6644585132598877, Losses: L1: 0.17127418518066406, L2: 0.030725209042429924, L3: 0.05133998394012451, L4: 0.17871293425559998, L5: 0.017715871334075928
Epoch 5000, Loss: 0.6478303074836731, Losses: L1: 0.16954506933689117, L2: 0.02987784892320633, L3: 0.05101114511489868, L4: 0.1718839854001999, L5: 0.017556019127368927
Epoch 5500, Loss: 0.6359999775886536, Losses: L1: 0.16842365264892578, L2: 0.029416784644126892, L3: 0.0506744384765625, L4: 0.1669977456331253, L5: 0.017523596063256264
Epoch 6000, Loss: 0.6279691457748413, Losses: L1: 0.16808323562145233, L2: 0.028875017538666725, L3: 0.050476908683776855, L4: 0.16348062455654144, L5: 0.0175333209335804
Epoch 6500, Loss: 0.6203245520591736, Losses: L1: 0.16754132509231567, L2: 0.028478732332587242, L3: 0.05032336711883545, L4: 0.1602124571800232, L5: 0.017472190782427788
Epoch 7000, Loss: 0.6154447793960571, Losses: L1: 0.16715949773788452, L2: 0.02821122668683529, L3: 0.05018872022628784, L4: 0.15818274021148682, L5: 0.01743677258491516
Epoch 7500, Loss: 0.6120631694793701, Losses: L1: 0.16714228689670563, L2: 0.027960307896137238, L3: 0.050099849700927734, L4: 0.15663865208625793, L5: 0.01746375299990177
Epoch 8000, Loss: 0.608699381351471, Losses: L1: 0.16688141226768494, L2: 0.027926024049520493, L3: 0.05001872777938843, L4: 0.15518924593925476, L5: 0.017439013347029686
Epoch 8500, Loss: 0.5916185975074768, Losses: L1: 0.15155905485153198, L2: 0.027962539345026016, L3: 0.04997384548187256, L4: 0.15434116125106812, L5: 0.017448240891098976
Epoch 9000, Loss: 0.5901395678520203, Losses: L1: 0.1512918621301651, L2: 0.02789238840341568, L3: 0.04996061325073242, L4: 0.15376874804496765, L5: 0.017442740499973297
Epoch 9500, Loss: 0.5891348719596863, Losses: L1: 0.15109340846538544, L2: 0.027876567095518112, L3: 0.04994708299636841, L4: 0.1533825844526291, L5: 0.017443861812353134
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023705005645752, Constraint losses: L1: 18.42068099975586, L2: 0.0017614834941923618, L3: 1.0017614364624023, L4: 1.0017614364624023
Epoch 500, Loss: 0.002251201309263706, Constraint losses: L1: -1.0363303422927856, L2: 0.0, L3: 0.002642810344696045, L4: 0.0006447214400395751
Epoch 1000, Loss: 0.0012612089049071074, Constraint losses: L1: -1.1173906326293945, L2: 0.0, L3: 0.002189040184020996, L4: 0.00018955938867293298
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0298290252685547, Constraint losses: L1: 18.42068099975586, L2: 0.0038025223184376955, L3: 1.0038025379180908, L4: 1.0038033723831177
Epoch 500, Loss: 0.002133832313120365, Constraint losses: L1: -1.0368973016738892, L2: 0.0, L3: 0.0025844573974609375, L4: 0.0005862721591256559
Epoch 1000, Loss: 0.0013274837983772159, Constraint losses: L1: -1.0511101484298706, L2: 0.0, L3: 0.0021889805793762207, L4: 0.0001896134199341759
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 149.97738647460938, Losses: L1: 8.51468276977539, L2: 0.00022817253193352371, L3: 0.9983178973197937, L4: 69.47784423828125, L5: 0.2551347315311432
Epoch 500, Loss: 9.77993106842041, Losses: L1: 0.5468790531158447, L2: 0.09873364865779877, L3: 0.06397843360900879, L4: 4.489073753356934, L5: 0.03879036754369736
Epoch 1000, Loss: 109.79716491699219, Losses: L1: 7.225352764129639, L2: 0.00017891555035021156, L3: 0.9988316297531128, L4: 50.03668212890625, L5: 0.25034573674201965
Epoch 1500, Loss: 107.14534759521484, Losses: L1: 4.234543323516846, L2: 0.011112414300441742, L3: 0.968322217464447, L4: 50.25489044189453, L5: 0.22941234707832336
Epoch 2000, Loss: 110.58335876464844, Losses: L1: 7.992738723754883, L2: 0.01636345125734806, L3: 0.9965001344680786, L4: 50.04676818847656, L5: 0.24795040488243103
Epoch 2500, Loss: 105.08296966552734, Losses: L1: 3.9493157863616943, L2: 0.08299364149570465, L3: 0.9462333917617798, L4: 49.39237594604492, L5: 0.20747067034244537
Epoch 3000, Loss: 110.2303237915039, Losses: L1: 7.826892852783203, L2: 0.003973457030951977, L3: 0.9991578459739685, L4: 49.9522819519043, L5: 0.24928109347820282
Epoch 3500, Loss: 109.70825958251953, Losses: L1: 7.337279796600342, L2: 0.004740171134471893, L3: 0.9999158382415771, L4: 49.93659210205078, L5: 0.24780075252056122
Epoch 4000, Loss: 25.84488868713379, Losses: L1: 3.8472750186920166, L2: 0.5592082142829895, L3: 0.2400275468826294, L4: 10.516528129577637, L5: 0.10244888812303543
Epoch 4500, Loss: 18.538114547729492, Losses: L1: 3.916954755783081, L2: 0.4935753345489502, L3: 0.28096020221710205, L4: 6.826695442199707, L5: 0.07952946424484253
Epoch 5000, Loss: 17.025880813598633, Losses: L1: 4.132211208343506, L2: 0.4889506697654724, L3: 0.27927303314208984, L4: 5.963318347930908, L5: 0.08200529217720032
Epoch 5500, Loss: 16.138282775878906, Losses: L1: 4.140267848968506, L2: 0.46526020765304565, L3: 0.2783505320549011, L4: 5.52180814743042, L5: 0.08253394067287445
Epoch 6000, Loss: 15.609199523925781, Losses: L1: 4.159177303314209, L2: 0.45355647802352905, L3: 0.2746541500091553, L4: 5.253896713256836, L5: 0.0830712765455246
Epoch 6500, Loss: 15.2703857421875, Losses: L1: 4.164742946624756, L2: 0.4430052638053894, L3: 0.2726779580116272, L4: 5.0861663818359375, L5: 0.08322551101446152
Epoch 7000, Loss: 15.186909675598145, Losses: L1: 4.07642936706543, L2: 0.43895912170410156, L3: 0.2692485451698303, L4: 5.091325759887695, L5: 0.08492590487003326
Epoch 7500, Loss: 15.048113822937012, Losses: L1: 4.064739227294922, L2: 0.43237751722335815, L3: 0.2712339162826538, L4: 5.028359413146973, L5: 0.08399960398674011
Epoch 8000, Loss: 14.934027671813965, Losses: L1: 4.025846481323242, L2: 0.4250808358192444, L3: 0.27193963527679443, L4: 4.9918718338012695, L5: 0.08400872349739075
Epoch 8500, Loss: 14.87765121459961, Losses: L1: 4.023758888244629, L2: 0.4231771230697632, L3: 0.2728770971298218, L4: 4.9645676612854, L5: 0.08370715379714966
Epoch 9000, Loss: 14.840326309204102, Losses: L1: 4.02476167678833, L2: 0.4221382737159729, L3: 0.27332019805908203, L4: 4.9453959465026855, L5: 0.08353131264448166
Epoch 9500, Loss: 14.819648742675781, Losses: L1: 4.025435924530029, L2: 0.42205560207366943, L3: 0.2731924057006836, L4: 4.934876441955566, L5: 0.08352385461330414
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0058200359344482, Constraint losses: L1: 7.247238636016846, L2: 0.0, L3: 0.9992863535881042, L4: 0.999286413192749
Epoch 500, Loss: 0.002353524789214134, Constraint losses: L1: -1.0641601085662842, L2: 0.0, L3: 0.002707839012145996, L4: 0.0007098460337147117
Epoch 1000, Loss: 0.00133214658126235, Constraint losses: L1: -1.11772620677948, L2: 0.0, L3: 0.002224564552307129, L4: 0.0002253082930110395
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9953577518463135, Constraint losses: L1: 5.190514087677002, L2: 0.0, L3: 0.9950848817825317, L4: 0.995082437992096
Epoch 500, Loss: 0.002170856576412916, Constraint losses: L1: -1.0414502620697021, L2: 0.0, L3: 0.0026053786277770996, L4: 0.0006069282535463572
Epoch 1000, Loss: 0.0013483668444678187, Constraint losses: L1: -1.050602674484253, L2: 0.0, L3: 0.002199232578277588, L4: 0.00019973705639131367
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.08289337158203, Losses: L1: 12.762701034545898, L2: 0.0007415455183945596, L3: 1.0000715255737305, L4: 71.37022399902344, L5: 0.268602192401886
Epoch 500, Loss: 8.668866157531738, Losses: L1: 3.656766414642334, L2: 0.13115839660167694, L3: 0.3388078808784485, L4: 9.333017349243164, L5: 0.09005699306726456
Epoch 1000, Loss: 2.8501524925231934, Losses: L1: 0.9557014107704163, L2: 0.064958855509758, L3: 0.09673863649368286, L4: 3.52192759513855, L5: 0.04031839221715927
Epoch 1500, Loss: 1.573610544204712, Losses: L1: 0.6817585825920105, L2: 0.04562746360898018, L3: 0.12208539247512817, L4: 1.548960566520691, L5: 0.021402914077043533
Epoch 2000, Loss: 1.0634480714797974, Losses: L1: 0.46369054913520813, L2: 0.03787984699010849, L3: 0.10197514295578003, L4: 1.0044679641723633, L5: 0.017312271520495415
Epoch 2500, Loss: 0.9456428289413452, Losses: L1: 0.4297301173210144, L2: 0.03778834640979767, L3: 0.09422177076339722, L4: 0.8481932878494263, L5: 0.013833651319146156
Epoch 3000, Loss: 0.8105537295341492, Losses: L1: 0.3414585292339325, L2: 0.032809801399707794, L3: 0.08747363090515137, L4: 0.7687172889709473, L5: 0.016379963606595993
Epoch 3500, Loss: 0.7547719478607178, Losses: L1: 0.3159574866294861, L2: 0.03287040814757347, L3: 0.0862695574760437, L4: 0.7123904228210449, L5: 0.013228167779743671
Epoch 4000, Loss: 0.720306932926178, Losses: L1: 0.2958568334579468, L2: 0.03321200981736183, L3: 0.08469498157501221, L4: 0.6860702037811279, L5: 0.01171099953353405
Epoch 4500, Loss: 0.6979717016220093, Losses: L1: 0.28620627522468567, L2: 0.032896142452955246, L3: 0.08341455459594727, L4: 0.663278341293335, L5: 0.011045647785067558
Epoch 5000, Loss: 0.6871398687362671, Losses: L1: 0.28242236375808716, L2: 0.03259897232055664, L3: 0.08279669284820557, L4: 0.6509149074554443, L5: 0.010525413788855076
Epoch 5500, Loss: 0.6618375778198242, Losses: L1: 0.26475897431373596, L2: 0.03229452297091484, L3: 0.08216249942779541, L4: 0.6373531222343445, L5: 0.010052533820271492
Epoch 6000, Loss: 0.6549627780914307, Losses: L1: 0.26253238320350647, L2: 0.03219223394989967, L3: 0.08174788951873779, L4: 0.6290618777275085, L5: 0.009666512720286846
Epoch 6500, Loss: 0.6499386429786682, Losses: L1: 0.26093626022338867, L2: 0.03211114928126335, L3: 0.08146965503692627, L4: 0.6228814125061035, L5: 0.009431473910808563
Epoch 7000, Loss: 0.6463890671730042, Losses: L1: 0.25954708456993103, L2: 0.032278891652822495, L3: 0.08114945888519287, L4: 0.6187217235565186, L5: 0.009255065582692623
Epoch 7500, Loss: 0.6435597538948059, Losses: L1: 0.2585609257221222, L2: 0.03235521912574768, L3: 0.0809469223022461, L4: 0.6152488589286804, L5: 0.009091485291719437
Epoch 8000, Loss: 0.6209771633148193, Losses: L1: 0.2317926287651062, L2: 0.029654350131750107, L3: 0.08206760883331299, L4: 0.6279915571212769, L5: 0.009001205675303936
Epoch 8500, Loss: 0.6150451302528381, Losses: L1: 0.23130662739276886, L2: 0.030105987563729286, L3: 0.08151137828826904, L4: 0.6168467998504639, L5: 0.008906867355108261
Epoch 9000, Loss: 0.6126619577407837, Losses: L1: 0.23082290589809418, L2: 0.030451131984591484, L3: 0.08117741346359253, L4: 0.6127010583877563, L5: 0.008897356688976288
Epoch 9500, Loss: 0.6112803220748901, Losses: L1: 0.23016579449176788, L2: 0.030545225366950035, L3: 0.08103728294372559, L4: 0.6111955642700195, L5: 0.008905790746212006
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.00313663482666, Constraint losses: L1: 6.353529453277588, L2: 0.0, L3: 0.99839186668396, L4: 0.9983912110328674
Epoch 500, Loss: 0.0022803533356636763, Constraint losses: L1: -1.090185523033142, L2: 0.0, L3: 0.002684295177459717, L4: 0.0006862437003292143
Epoch 1000, Loss: 0.0013170195743441582, Constraint losses: L1: -1.1167030334472656, L2: 0.0, L3: 0.002216517925262451, L4: 0.00021720465156249702
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.031236410140991, Constraint losses: L1: 18.42068099975586, L2: 0.004271817393600941, L3: 1.0042718648910522, L4: 1.0042721033096313
Epoch 500, Loss: 0.0023560638073831797, Constraint losses: L1: -1.0329192876815796, L2: 0.0, L3: 0.002693653106689453, L4: 0.0006953301490284503
Epoch 1000, Loss: 0.0013978654751554132, Constraint losses: L1: -1.0508482456207275, L2: 0.0, L3: 0.0022240877151489258, L4: 0.00022462608467321843
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 55.055912017822266, Losses: L1: 18.42068099975586, L2: 0.007284482941031456, L3: 1.0072845220565796, L4: 71.69779968261719, L5: 0.27540072798728943
Epoch 500, Loss: 44.1595458984375, Losses: L1: 18.408321380615234, L2: 1.39336972515558e-10, L3: 1.0, L4: 50.00005340576172, L5: 0.2511991262435913
Epoch 1000, Loss: 30.692476272583008, Losses: L1: 5.376180171966553, L2: 0.14589273929595947, L3: 0.9194959402084351, L4: 49.04192352294922, L5: 0.1896943747997284
Epoch 1500, Loss: 27.214384078979492, Losses: L1: 7.527550220489502, L2: 1.7800095081329346, L3: 0.7246230840682983, L4: 34.77783966064453, L5: 0.1555921882390976
Epoch 2000, Loss: 7.905898094177246, Losses: L1: 3.8290839195251465, L2: 0.4405742585659027, L3: 0.2713671922683716, L4: 6.849060535430908, L5: 0.07602579146623611
Epoch 2500, Loss: 5.693346977233887, Losses: L1: 2.5540764331817627, L2: 0.21026787161827087, L3: 0.250974178314209, L4: 5.445140838623047, L5: 0.08094505220651627
Epoch 3000, Loss: 33.39506149291992, Losses: L1: 7.653031826019287, L2: 0.0, L3: 0.9994094371795654, L4: 49.994728088378906, L5: 0.24495936930179596
Epoch 3500, Loss: 7.840660095214844, Losses: L1: 1.771727204322815, L2: 0.28860941529273987, L3: 0.18251460790634155, L4: 11.195900917053223, L5: 0.09111592173576355
Epoch 4000, Loss: 3.7796108722686768, Losses: L1: 1.2241345643997192, L2: 0.12658153474330902, L3: 0.23974454402923584, L4: 4.4886884689331055, L5: 0.06467816978693008
Epoch 4500, Loss: 3.2051708698272705, Losses: L1: 1.2220441102981567, L2: 0.1364433318376541, L3: 0.22699904441833496, L4: 3.3328728675842285, L5: 0.0667475238442421
Epoch 5000, Loss: 3.053600311279297, Losses: L1: 1.2464836835861206, L2: 0.13530725240707397, L3: 0.22127795219421387, L4: 2.9880564212799072, L5: 0.06714225560426712
Epoch 5500, Loss: 2.9690451622009277, Losses: L1: 1.2576990127563477, L2: 0.1322452574968338, L3: 0.2170863151550293, L4: 2.8067080974578857, L5: 0.067203588783741
Epoch 6000, Loss: 2.91422963142395, Losses: L1: 1.2592777013778687, L2: 0.13000236451625824, L3: 0.21473932266235352, L4: 2.7011470794677734, L5: 0.06700624525547028
Epoch 6500, Loss: 2.876474618911743, Losses: L1: 1.2609834671020508, L2: 0.12877094745635986, L3: 0.21231001615524292, L4: 2.6274333000183105, L5: 0.06684856861829758
Epoch 7000, Loss: 2.8490538597106934, Losses: L1: 1.2624304294586182, L2: 0.12783531844615936, L3: 0.21041226387023926, L4: 2.5737709999084473, L5: 0.06669662892818451
Epoch 7500, Loss: 2.8290257453918457, Losses: L1: 1.263274908065796, L2: 0.12706881761550903, L3: 0.2089167833328247, L4: 2.535271167755127, L5: 0.0665881335735321
Epoch 8000, Loss: 2.8146159648895264, Losses: L1: 1.262876033782959, L2: 0.1263560801744461, L3: 0.20788121223449707, L4: 2.509870767593384, L5: 0.06650792062282562
Epoch 8500, Loss: 2.804239511489868, Losses: L1: 1.2622673511505127, L2: 0.12592458724975586, L3: 0.20712554454803467, L4: 2.492110252380371, L5: 0.06642968952655792
Epoch 9000, Loss: 2.796840190887451, Losses: L1: 1.261594295501709, L2: 0.12561620771884918, L3: 0.2065836787223816, L4: 2.479926109313965, L5: 0.06637489795684814
Epoch 9500, Loss: 2.7916111946105957, Losses: L1: 1.260879397392273, L2: 0.12541279196739197, L3: 0.2062056064605713, L4: 2.4717628955841064, L5: 0.06633477658033371
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.026947259902954, Constraint losses: L1: 18.42068099975586, L2: 0.0028420339804142714, L3: 1.0028420686721802, L4: 1.0028424263000488
Epoch 500, Loss: 0.00220287311822176, Constraint losses: L1: -1.103601098060608, L2: 0.0, L3: 0.002652406692504883, L4: 0.0006540676113218069
Epoch 1000, Loss: 0.0013085162499919534, Constraint losses: L1: -1.1185295581817627, L2: 0.0, L3: 0.0022131800651550293, L4: 0.00021386580192483962
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.020905017852783, Constraint losses: L1: 18.42068099975586, L2: 0.0008280485053546727, L3: 1.0008280277252197, L4: 1.0008282661437988
Epoch 500, Loss: 0.0027644196525216103, Constraint losses: L1: -0.9839379787445068, L2: 0.0, L3: 0.002872943878173828, L4: 0.0008754138834774494
Epoch 1000, Loss: 0.0015029340283945203, Constraint losses: L1: -1.0516806840896606, L2: 0.0, L3: 0.0022769570350646973, L4: 0.0002776577603071928
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.47152328491211, Losses: L1: 12.764303207397461, L2: 0.0018056805711239576, L3: 1.0011014938354492, L4: 81.06449890136719, L5: 0.3363077938556671
Epoch 500, Loss: 2.1406095027923584, Losses: L1: 0.3765162229537964, L2: 0.08606936782598495, L3: 0.06483149528503418, L4: 3.2339510917663574, L5: 0.014316297136247158
Epoch 1000, Loss: 1.235725998878479, Losses: L1: 0.2857556939125061, L2: 0.08115602284669876, L3: 0.0689697265625, L4: 1.6188857555389404, L5: 0.012443230487406254
Epoch 1500, Loss: 1.292871356010437, Losses: L1: 0.26705315709114075, L2: 0.056610532104969025, L3: 0.07448017597198486, L4: 1.8030691146850586, L5: 0.015216510742902756
Epoch 2000, Loss: 0.6356947422027588, Losses: L1: 0.1733606904745102, L2: 0.05521872267127037, L3: 0.06528294086456299, L4: 0.7211092114448547, L5: 0.006959621794521809
Epoch 2500, Loss: 0.6229365468025208, Losses: L1: 0.17255279421806335, L2: 0.048986975103616714, L3: 0.062104105949401855, L4: 0.7137444019317627, L5: 0.006736251059919596
Epoch 3000, Loss: 0.5422112941741943, Losses: L1: 0.15788733959197998, L2: 0.04066900908946991, L3: 0.06224179267883301, L4: 0.6012176275253296, L5: 0.00596259580925107
Epoch 3500, Loss: 0.4135074019432068, Losses: L1: 0.13665805757045746, L2: 0.040151193737983704, L3: 0.05986595153808594, L4: 0.3916788697242737, L5: 0.005462870001792908
Epoch 4000, Loss: 0.33818334341049194, Losses: L1: 0.13214728236198425, L2: 0.04020054638385773, L3: 0.058908700942993164, L4: 0.2514781355857849, L5: 0.005321051459759474
Epoch 4500, Loss: 0.34673088788986206, Losses: L1: 0.13037735223770142, L2: 0.03987033665180206, L3: 0.05833244323730469, L4: 0.27343690395355225, L5: 0.005299268756061792
Epoch 5000, Loss: 0.3290645480155945, Losses: L1: 0.12955310940742493, L2: 0.039033494889736176, L3: 0.058234214782714844, L4: 0.24142685532569885, L5: 0.005323708988726139
Epoch 5500, Loss: 0.3249606192111969, Losses: L1: 0.1285344362258911, L2: 0.03889450430870056, L3: 0.05801433324813843, L4: 0.235829159617424, L5: 0.005304969381541014
Epoch 6000, Loss: 0.32090136408805847, Losses: L1: 0.12791594862937927, L2: 0.03878730535507202, L3: 0.057841360569000244, L4: 0.2293851673603058, L5: 0.005292432848364115
Epoch 6500, Loss: 0.3190789222717285, Losses: L1: 0.12756431102752686, L2: 0.038698602467775345, L3: 0.05771714448928833, L4: 0.22675663232803345, L5: 0.005289555061608553
Epoch 7000, Loss: 0.31805211305618286, Losses: L1: 0.12726251780986786, L2: 0.03864128142595291, L3: 0.05762821435928345, L4: 0.22552615404129028, L5: 0.005285560619086027
Epoch 7500, Loss: 0.3171961009502411, Losses: L1: 0.12707050144672394, L2: 0.03861236944794655, L3: 0.05755650997161865, L4: 0.22433386743068695, L5: 0.005284029990434647
Epoch 8000, Loss: 0.31671810150146484, Losses: L1: 0.12691256403923035, L2: 0.03861060366034508, L3: 0.05748939514160156, L4: 0.223779559135437, L5: 0.005280223675072193
Epoch 8500, Loss: 0.3161565363407135, Losses: L1: 0.1268208771944046, L2: 0.038580358028411865, L3: 0.05745762586593628, L4: 0.22292974591255188, L5: 0.005280802026391029
Epoch 9000, Loss: 0.31586480140686035, Losses: L1: 0.12675897777080536, L2: 0.038576625287532806, L3: 0.05742746591567993, L4: 0.2225058376789093, L5: 0.0052812714129686356
Epoch 9500, Loss: 0.31566300988197327, Losses: L1: 0.1266987919807434, L2: 0.03857564553618431, L3: 0.05740618705749512, L4: 0.22224687039852142, L5: 0.005281009711325169
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0212273597717285, Constraint losses: L1: 18.42068099975586, L2: 0.0009355287766084075, L3: 1.0009355545043945, L4: 1.0009355545043945
Epoch 500, Loss: 0.0023476011119782925, Constraint losses: L1: -1.0405786037445068, L2: 0.0, L3: 0.0026929378509521484, L4: 0.0006952419644221663
Epoch 1000, Loss: 0.0013179457746446133, Constraint losses: L1: -1.117286205291748, L2: 0.0, L3: 0.0022172927856445312, L4: 0.00021793920313939452
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0198540687561035, Constraint losses: L1: 18.42068099975586, L2: 0.00047779380111023784, L3: 1.0004777908325195, L4: 1.00047767162323
Epoch 500, Loss: 0.002440005075186491, Constraint losses: L1: -1.0444170236587524, L2: 0.0, L3: 0.0027412772178649902, L4: 0.0007431447738781571
Epoch 1000, Loss: 0.0014411951415240765, Constraint losses: L1: -1.0504298210144043, L2: 0.0, L3: 0.0022454261779785156, L4: 0.0002461987896822393
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 81.3481216430664, Losses: L1: 7.280970096588135, L2: 0.0, L3: 0.9992945194244385, L4: 73.42448425292969, L5: 0.2860383093357086
Epoch 500, Loss: 51.008419036865234, Losses: L1: 9.796758651733398, L2: 0.11734049022197723, L3: 0.9994570016860962, L4: 40.51651382446289, L5: 0.1561574935913086
Epoch 1000, Loss: 66.60858917236328, Losses: L1: 15.975995063781738, L2: 1.7361626305500977e-05, L3: 1.000009298324585, L4: 50.007904052734375, L5: 0.24934647977352142
Epoch 1500, Loss: 69.06240844726562, Losses: L1: 18.41960334777832, L2: 0.0, L3: 1.0, L4: 50.01939010620117, L5: 0.24682563543319702
Epoch 2000, Loss: 69.05742645263672, Losses: L1: 18.418851852416992, L2: 0.0, L3: 1.0, L4: 50.01462936401367, L5: 0.2478894293308258
Epoch 2500, Loss: 69.04991149902344, Losses: L1: 18.413137435913086, L2: 0.0, L3: 1.0, L4: 50.01259994506836, L5: 0.24834637343883514
Epoch 3000, Loss: 17.50324821472168, Losses: L1: 5.414840221405029, L2: 0.7629621028900146, L3: 0.31732064485549927, L4: 11.12692642211914, L5: 0.07971971482038498
Epoch 3500, Loss: 9.893863677978516, Losses: L1: 3.60559344291687, L2: 0.36644116044044495, L3: 0.2805800437927246, L4: 5.7429022789001465, L5: 0.07727375626564026
Epoch 4000, Loss: 8.14918041229248, Losses: L1: 3.34452223777771, L2: 0.3521377444267273, L3: 0.24502670764923096, L4: 4.289902687072754, L5: 0.0802096277475357
Epoch 4500, Loss: 55.35728073120117, Losses: L1: 5.176698207855225, L2: 0.0, L3: 0.9787164330482483, L4: 49.56748962402344, L5: 0.2474643737077713
Epoch 5000, Loss: 49.3336067199707, Losses: L1: 3.2399942874908447, L2: 0.0, L3: 0.7560876607894897, L4: 45.59627151489258, L5: 0.23859135806560516
Epoch 5500, Loss: 7.98089075088501, Losses: L1: 3.035360336303711, L2: 0.3552759289741516, L3: 0.2295171022415161, L4: 4.432668209075928, L5: 0.08565636724233627
Epoch 6000, Loss: 7.75856351852417, Losses: L1: 3.0401599407196045, L2: 0.3565391004085541, L3: 0.2243417501449585, L4: 4.207385540008545, L5: 0.08461663872003555
Epoch 6500, Loss: 7.723389148712158, Losses: L1: 3.0398709774017334, L2: 0.355907142162323, L3: 0.22309386730194092, L4: 4.173686504364014, L5: 0.08475460112094879
Epoch 7000, Loss: 7.700113773345947, Losses: L1: 3.038564682006836, L2: 0.3553970158100128, L3: 0.22258710861206055, L4: 4.152450084686279, L5: 0.08481668680906296
Epoch 7500, Loss: 7.683113098144531, Losses: L1: 3.038142204284668, L2: 0.3548245429992676, L3: 0.22233855724334717, L4: 4.136563777923584, L5: 0.08482687175273895
Epoch 8000, Loss: 7.670995712280273, Losses: L1: 3.037515640258789, L2: 0.35464897751808167, L3: 0.22200804948806763, L4: 4.125434875488281, L5: 0.08478341996669769
Epoch 8500, Loss: 7.6618852615356445, Losses: L1: 3.0371148586273193, L2: 0.3545275926589966, L3: 0.22177016735076904, L4: 4.116988182067871, L5: 0.08473855257034302
Epoch 9000, Loss: 7.655153751373291, Losses: L1: 3.036637306213379, L2: 0.3543727993965149, L3: 0.22156739234924316, L4: 4.110992431640625, L5: 0.08473483473062515
Epoch 9500, Loss: 7.650344371795654, Losses: L1: 3.036370277404785, L2: 0.35421377420425415, L3: 0.22137439250946045, L4: 4.106691360473633, L5: 0.08476398885250092
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0283594131469727, Constraint losses: L1: 18.42068099975586, L2: 0.00331293698400259, L3: 1.0033129453659058, L4: 1.0033128261566162
Epoch 500, Loss: 0.0024641656782478094, Constraint losses: L1: -1.1160863637924194, L2: 0.0, L3: 0.0027892589569091797, L4: 0.0007909931591711938
Epoch 1000, Loss: 0.0014104663860052824, Constraint losses: L1: -1.118134617805481, L2: 0.0, L3: 0.0022639036178588867, L4: 0.0002646974753588438
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9879153966903687, Constraint losses: L1: 4.743617057800293, L2: 0.0, L3: 0.9915866255760193, L4: 0.9915851354598999
Epoch 500, Loss: 0.0021079853177070618, Constraint losses: L1: -1.032958745956421, L2: 0.0, L3: 0.0025696158409118652, L4: 0.0005713281570933759
Epoch 1000, Loss: 0.0013120361836627126, Constraint losses: L1: -1.049509048461914, L2: 0.0, L3: 0.0021805167198181152, L4: 0.0001810285757528618
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 98.70166015625, Losses: L1: 18.023839950561523, L2: 0.007100869435817003, L3: 1.007068395614624, L4: 79.83866882324219, L5: 0.32851120829582214
Epoch 500, Loss: 66.44219207763672, Losses: L1: 15.690997123718262, L2: 1.3198160559113603e-05, L3: 1.0000001192092896, L4: 50.000205993652344, L5: 0.2509787678718567
Epoch 1000, Loss: 13.8422212600708, Losses: L1: 4.558576583862305, L2: 0.5145788788795471, L3: 0.2793627977371216, L4: 8.518311500549316, L5: 0.11107349395751953
Epoch 1500, Loss: 17.87372589111328, Losses: L1: 5.165689468383789, L2: 0.762091338634491, L3: 0.24055874347686768, L4: 11.689227104187012, L5: 0.136439248919487
Epoch 2000, Loss: 4.868049144744873, Losses: L1: 1.8123785257339478, L2: 0.043047040700912476, L3: 0.15054631233215332, L4: 2.9081978797912598, L5: 0.029152248054742813
Epoch 2500, Loss: 3.925527334213257, Losses: L1: 1.4350366592407227, L2: 0.03197234496474266, L3: 0.16457796096801758, L4: 2.3480477333068848, L5: 0.028181860223412514
Epoch 3000, Loss: 2.978774309158325, Losses: L1: 0.9424896836280823, L2: 0.017840532585978508, L3: 0.1463620662689209, L4: 1.9216868877410889, L5: 0.023576341569423676
Epoch 3500, Loss: 2.765838861465454, Losses: L1: 0.8423233032226562, L2: 0.011014187708497047, L3: 0.14361542463302612, L4: 1.8201205730438232, L5: 0.020573044195771217
Epoch 4000, Loss: 2.662621259689331, Losses: L1: 0.8778420686721802, L2: 0.010449732653796673, L3: 0.13842439651489258, L4: 1.6861740350723267, L5: 0.01894327998161316
Epoch 4500, Loss: 2.7317237854003906, Losses: L1: 1.015257716178894, L2: 0.015000161714851856, L3: 0.13311970233917236, L4: 1.6180579662322998, L5: 0.01684819906949997
Epoch 5000, Loss: 2.6732096672058105, Losses: L1: 1.0014511346817017, L2: 0.016090737655758858, L3: 0.1332734227180481, L4: 1.5727195739746094, L5: 0.016311537474393845
Epoch 5500, Loss: 2.6345129013061523, Losses: L1: 0.9954236149787903, L2: 0.017220204696059227, L3: 0.13219279050827026, L4: 1.5394920110702515, L5: 0.016280706971883774
Epoch 6000, Loss: 2.587883234024048, Losses: L1: 0.9705305099487305, L2: 0.019304119050502777, L3: 0.13075846433639526, L4: 1.5165767669677734, L5: 0.016092589125037193
Epoch 6500, Loss: 2.565851926803589, Losses: L1: 0.9664912819862366, L2: 0.020367255434393883, L3: 0.12978053092956543, L4: 1.4980242252349854, L5: 0.01607895828783512
Epoch 7000, Loss: 2.5487821102142334, Losses: L1: 0.9637448191642761, L2: 0.020938772708177567, L3: 0.12931275367736816, L4: 1.4834097623825073, L5: 0.01603243686258793
Epoch 7500, Loss: 2.5355448722839355, Losses: L1: 0.962069034576416, L2: 0.021254295483231544, L3: 0.12901079654693604, L4: 1.4717025756835938, L5: 0.01601371541619301
Epoch 8000, Loss: 2.5251715183258057, Losses: L1: 0.9610878229141235, L2: 0.02144346572458744, L3: 0.1287764310836792, L4: 1.4622386693954468, L5: 0.016013430431485176
Epoch 8500, Loss: 2.5173661708831787, Losses: L1: 0.9603253602981567, L2: 0.02155223861336708, L3: 0.12858903408050537, L4: 1.4551823139190674, L5: 0.01601167768239975
Epoch 9000, Loss: 2.511385440826416, Losses: L1: 0.9598484635353088, L2: 0.021609889343380928, L3: 0.1284245252609253, L4: 1.4496970176696777, L5: 0.016017800197005272
Epoch 9500, Loss: 2.50705885887146, Losses: L1: 0.9595032334327698, L2: 0.021622024476528168, L3: 0.12829136848449707, L4: 1.4457638263702393, L5: 0.01602417789399624
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0192999839782715, Constraint losses: L1: 18.42068099975586, L2: 0.00029307525255717337, L3: 1.0002930164337158, L4: 1.0002931356430054
Epoch 500, Loss: 0.0023673567920923233, Constraint losses: L1: -1.0350825786590576, L2: 0.0, L3: 0.002700209617614746, L4: 0.000702229852322489
Epoch 1000, Loss: 0.0013068432454019785, Constraint losses: L1: -1.113095760345459, L2: 0.0, L3: 0.0022096633911132812, L4: 0.00021027569891884923
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0199458599090576, Constraint losses: L1: 18.42068099975586, L2: 0.0005083422875031829, L3: 1.0005083084106445, L4: 1.0005085468292236
Epoch 500, Loss: 0.0024460661225020885, Constraint losses: L1: -1.0397461652755737, L2: 0.0, L3: 0.002741992473602295, L4: 0.0007438199245370924
Epoch 1000, Loss: 0.0014376519247889519, Constraint losses: L1: -1.0504385232925415, L2: 0.0, L3: 0.00224381685256958, L4: 0.0002442736295051873
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 80.84588623046875, Losses: L1: 7.822951793670654, L2: 0.0008398149511776865, L3: 0.9946271777153015, L4: 71.97771453857422, L5: 0.2735319435596466
Epoch 500, Loss: 1.9794607162475586, Losses: L1: 0.2596680819988251, L2: 0.06924299150705338, L3: 0.06667685508728027, L4: 1.5636796951293945, L5: 0.02676577679812908
Epoch 1000, Loss: 2.4647817611694336, Losses: L1: 0.21311353147029877, L2: 0.07461681962013245, L3: 0.07078760862350464, L4: 2.1196515560150146, L5: 0.011003019288182259
Epoch 1500, Loss: 1.1731107234954834, Losses: L1: 0.22019289433956146, L2: 0.07305706292390823, L3: 0.06925356388092041, L4: 0.8327966928482056, L5: 0.006218667142093182
Epoch 2000, Loss: 1.4402694702148438, Losses: L1: 0.36885881423950195, L2: 0.060817550867795944, L3: 0.08513897657394409, L4: 0.9439264535903931, L5: 0.012048576958477497
Epoch 2500, Loss: 1.066834807395935, Losses: L1: 0.30961963534355164, L2: 0.05758220702409744, L3: 0.07599532604217529, L4: 0.6445213556289673, L5: 0.008556974120438099
Epoch 3000, Loss: 0.9757180213928223, Losses: L1: 0.2665078341960907, L2: 0.05416673421859741, L3: 0.07155954837799072, L4: 0.6031244993209839, L5: 0.008069571107625961
Epoch 3500, Loss: 0.7866466641426086, Losses: L1: 0.24754320085048676, L2: 0.05117727816104889, L3: 0.07023203372955322, L4: 0.43899309635162354, L5: 0.0069085354916751385
Epoch 4000, Loss: 0.741898238658905, Losses: L1: 0.24181489646434784, L2: 0.04926804080605507, L3: 0.06979703903198242, L4: 0.4032450318336487, L5: 0.006335895974189043
Epoch 4500, Loss: 0.7248961329460144, Losses: L1: 0.23649750649929047, L2: 0.04873640462756157, L3: 0.06922125816345215, L4: 0.39291810989379883, L5: 0.006066742818802595
Epoch 5000, Loss: 0.7128198742866516, Losses: L1: 0.2334507405757904, L2: 0.04818931594491005, L3: 0.06884992122650146, L4: 0.38497984409332275, L5: 0.005887513514608145
Epoch 5500, Loss: 0.7047526240348816, Losses: L1: 0.23125547170639038, L2: 0.04783262684941292, L3: 0.0685538649559021, L4: 0.37987637519836426, L5: 0.005755597725510597
Epoch 6000, Loss: 0.6986700892448425, Losses: L1: 0.22965650260448456, L2: 0.04758269712328911, L3: 0.06830155849456787, L4: 0.3759099245071411, L5: 0.005685104057192802
Epoch 6500, Loss: 0.6944864392280579, Losses: L1: 0.22881880402565002, L2: 0.047258321195840836, L3: 0.06817018985748291, L4: 0.3730687201023102, L5: 0.005627748556435108
Epoch 7000, Loss: 0.6911378502845764, Losses: L1: 0.22802861034870148, L2: 0.047126296907663345, L3: 0.0680234432220459, L4: 0.3707713484764099, L5: 0.005599940195679665
Epoch 7500, Loss: 0.6888279914855957, Losses: L1: 0.2274330109357834, L2: 0.04701146110892296, L3: 0.06793642044067383, L4: 0.3692774772644043, L5: 0.005568917375057936
Epoch 8000, Loss: 0.6873277425765991, Losses: L1: 0.2271130532026291, L2: 0.04689342528581619, L3: 0.06788170337677002, L4: 0.3682747781276703, L5: 0.005552825517952442
Epoch 8500, Loss: 0.6862672567367554, Losses: L1: 0.2268703579902649, L2: 0.046825747936964035, L3: 0.06783413887023926, L4: 0.36756157875061035, L5: 0.005546282045543194
Epoch 9000, Loss: 0.6853951215744019, Losses: L1: 0.2267223596572876, L2: 0.046790581196546555, L3: 0.06780332326889038, L4: 0.3669109642505646, L5: 0.005534754600375891
Epoch 9500, Loss: 0.6849390864372253, Losses: L1: 0.2266169637441635, L2: 0.04675610736012459, L3: 0.06778430938720703, L4: 0.3666132092475891, L5: 0.005530327092856169
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0058090686798096, Constraint losses: L1: 7.234648704528809, L2: 0.0, L3: 0.9992872476577759, L4: 0.9992871880531311
Epoch 500, Loss: 0.00221007177606225, Constraint losses: L1: -1.0943776369094849, L2: 0.0, L3: 0.0026513338088989258, L4: 0.0006531157996505499
Epoch 1000, Loss: 0.001298236777074635, Constraint losses: L1: -1.1183112859725952, L2: 0.0, L3: 0.002207934856414795, L4: 0.00020861320081166923
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0305402278900146, Constraint losses: L1: 18.42068099975586, L2: 0.004039755091071129, L3: 1.0040397644042969, L4: 1.004040002822876
Epoch 500, Loss: 0.002475217916071415, Constraint losses: L1: -0.9928048849105835, L2: 0.0, L3: 0.0027329325675964355, L4: 0.0007350902305915952
Epoch 1000, Loss: 0.0014098234241828322, Constraint losses: L1: -1.0504392385482788, L2: 0.0, L3: 0.0022298097610473633, L4: 0.00023045294801704586
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 157.1075897216797, Losses: L1: 4.873233795166016, L2: 1.6359194887627382e-06, L3: 0.9918551445007324, L4: 75.79513549804688, L5: 0.29633238911628723
Epoch 500, Loss: 14.19133186340332, Losses: L1: 4.530566692352295, L2: 0.6897382140159607, L3: 0.1929560899734497, L4: 4.4226579666137695, L5: 0.058465298265218735
Epoch 1000, Loss: 13.878369331359863, Losses: L1: 4.228846549987793, L2: 0.5576090216636658, L3: 0.15393030643463135, L4: 4.485423564910889, L5: 0.08820092678070068
Epoch 1500, Loss: 106.80956268310547, Losses: L1: 6.186460018157959, L2: 0.025784390047192574, L3: 1.0021758079528809, L4: 49.98563003540039, L5: 0.24993403255939484
Epoch 2000, Loss: 9.166638374328613, Losses: L1: 2.2444281578063965, L2: 0.38798221945762634, L3: 0.11948221921920776, L4: 3.210007667541504, L5: 0.1089446172118187
Epoch 2500, Loss: 3.9584319591522217, Losses: L1: 1.7749865055084229, L2: 0.2480449229478836, L3: 0.11979389190673828, L4: 0.9178056120872498, L5: 0.07978469878435135
Epoch 3000, Loss: 3.660696506500244, Losses: L1: 1.7047820091247559, L2: 0.22461117804050446, L3: 0.11410826444625854, L4: 0.8179202079772949, L5: 0.07681743055582047
Epoch 3500, Loss: 3.879000425338745, Losses: L1: 1.6786404848098755, L2: 0.231561541557312, L3: 0.1151549220085144, L4: 0.9382361173629761, L5: 0.06949778646230698
Epoch 4000, Loss: 3.267139196395874, Losses: L1: 1.631382942199707, L2: 0.2100428193807602, L3: 0.10525470972061157, L4: 0.6686547994613647, L5: 0.07155279815196991
Epoch 4500, Loss: 2.9908549785614014, Losses: L1: 1.4734398126602173, L2: 0.20266501605510712, L3: 0.10181856155395508, L4: 0.6145784854888916, L5: 0.06936801970005035
Epoch 5000, Loss: 2.929932117462158, Losses: L1: 1.4524822235107422, L2: 0.19819539785385132, L3: 0.10120630264282227, L4: 0.5972294807434082, L5: 0.06838463991880417
Epoch 5500, Loss: 2.8724422454833984, Losses: L1: 1.4247061014175415, L2: 0.19220858812332153, L3: 0.10060328245162964, L4: 0.5858758091926575, L5: 0.06694821268320084
Epoch 6000, Loss: 2.848306894302368, Losses: L1: 1.4144554138183594, L2: 0.1914065182209015, L3: 0.10011327266693115, L4: 0.5795518755912781, L5: 0.06656867265701294
Epoch 6500, Loss: 2.8324995040893555, Losses: L1: 1.405181884765625, L2: 0.19045357406139374, L3: 0.09976857900619507, L4: 0.5769360065460205, L5: 0.06621546298265457
Epoch 7000, Loss: 2.8218467235565186, Losses: L1: 1.3983937501907349, L2: 0.18957319855690002, L3: 0.0995025634765625, L4: 0.575600802898407, L5: 0.06585373729467392
Epoch 7500, Loss: 2.8136038780212402, Losses: L1: 1.3938298225402832, L2: 0.18892432749271393, L3: 0.0993393063545227, L4: 0.5741969347000122, L5: 0.0655728355050087
Epoch 8000, Loss: 2.8080756664276123, Losses: L1: 1.3907476663589478, L2: 0.18842776119709015, L3: 0.0992051362991333, L4: 0.5733031034469604, L5: 0.06538315117359161
Epoch 8500, Loss: 2.803917646408081, Losses: L1: 1.3886778354644775, L2: 0.18811705708503723, L3: 0.0991138219833374, L4: 0.5724694728851318, L5: 0.06525395065546036
Epoch 9000, Loss: 2.8011326789855957, Losses: L1: 1.3872913122177124, L2: 0.1878882646560669, L3: 0.0990365743637085, L4: 0.5719243884086609, L5: 0.06517208367586136
Epoch 9500, Loss: 2.7991902828216553, Losses: L1: 1.3863333463668823, L2: 0.18771687150001526, L3: 0.09899157285690308, L4: 0.5715441703796387, L5: 0.06511179357767105
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0320699214935303, Constraint losses: L1: 18.42068099975586, L2: 0.004549285396933556, L3: 1.004549264907837, L4: 1.0045506954193115
Epoch 500, Loss: 0.0023124851286411285, Constraint losses: L1: -1.0989410877227783, L2: 0.0, L3: 0.002704799175262451, L4: 0.0007066271500661969
Epoch 1000, Loss: 0.0013430049875751138, Constraint losses: L1: -1.118611454963684, L2: 0.0, L3: 0.002230525016784668, L4: 0.00023109152971301228
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0189692974090576, Constraint losses: L1: 16.193086624145508, L2: 0.0011488426243886352, L3: 1.0008141994476318, L4: 1.0008131265640259
Epoch 500, Loss: 0.002419387921690941, Constraint losses: L1: -1.0135173797607422, L2: 0.0, L3: 0.0027155280113220215, L4: 0.0007173772901296616
Epoch 1000, Loss: 0.0014032293111085892, Constraint losses: L1: -1.0480161905288696, L2: 0.0, L3: 0.0022252798080444336, L4: 0.00022596580674871802
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 186.26473999023438, Losses: L1: 18.364477157592773, L2: 0.003804732346907258, L3: 1.0038033723831177, L4: 83.51980590820312, L5: 0.35495397448539734
Epoch 500, Loss: 14.011438369750977, Losses: L1: 4.786453723907471, L2: 0.5565952062606812, L3: 0.17300212383270264, L4: 4.247842788696289, L5: 0.08620244264602661
Epoch 1000, Loss: 8.862738609313965, Losses: L1: 3.4567205905914307, L2: 0.28617510199546814, L3: 0.15526485443115234, L4: 2.4904167652130127, L5: 0.061377719044685364
Epoch 1500, Loss: 10.046347618103027, Losses: L1: 3.2881388664245605, L2: 0.26459774374961853, L3: 0.16925829648971558, L4: 3.1907832622528076, L5: 0.027414944022893906
Epoch 2000, Loss: 8.514180183410645, Losses: L1: 0.9882821440696716, L2: 0.1252547800540924, L3: 0.10618257522583008, L4: 3.6593453884124756, L5: 0.028861239552497864
Epoch 2500, Loss: 4.322630882263184, Losses: L1: 1.0732544660568237, L2: 0.10255187749862671, L3: 0.12142980098724365, L4: 1.5223482847213745, L5: 0.041413284838199615
Epoch 3000, Loss: 3.6224873065948486, Losses: L1: 1.0261250734329224, L2: 0.09140701591968536, L3: 0.10902822017669678, L4: 1.2042906284332275, L5: 0.04185986891388893
Epoch 3500, Loss: 8.109965324401855, Losses: L1: 1.3601670265197754, L2: 0.10293147712945938, L3: 0.1675814390182495, L4: 3.266299247741699, L5: 0.03047765977680683
Epoch 4000, Loss: 4.638518333435059, Losses: L1: 1.0215108394622803, L2: 0.0926743745803833, L3: 0.12411952018737793, L4: 1.7143125534057617, L5: 0.0336485356092453
Epoch 4500, Loss: 4.149233818054199, Losses: L1: 1.047006368637085, L2: 0.09189386665821075, L3: 0.11656129360198975, L4: 1.4559590816497803, L5: 0.04013458266854286
Epoch 5000, Loss: 3.88159441947937, Losses: L1: 1.0200281143188477, L2: 0.08860569447278976, L3: 0.11304032802581787, L4: 1.3372451066970825, L5: 0.04195033013820648
Epoch 5500, Loss: 3.74747896194458, Losses: L1: 1.0303477048873901, L2: 0.08692371845245361, L3: 0.11178255081176758, L4: 1.2651822566986084, L5: 0.043951813131570816
Epoch 6000, Loss: 3.6555371284484863, Losses: L1: 1.0366301536560059, L2: 0.0856168195605278, L3: 0.11075741052627563, L4: 1.216369867324829, L5: 0.04517181217670441
Epoch 6500, Loss: 3.5705578327178955, Losses: L1: 1.0259040594100952, L2: 0.0843699499964714, L3: 0.10973381996154785, L4: 1.1796948909759521, L5: 0.046027109026908875
Epoch 7000, Loss: 3.509915828704834, Losses: L1: 1.0267388820648193, L2: 0.08342934399843216, L3: 0.10875117778778076, L4: 1.1494719982147217, L5: 0.04642805829644203
Epoch 7500, Loss: 3.4260900020599365, Losses: L1: 0.9960512518882751, L2: 0.08245992660522461, L3: 0.10764831304550171, L4: 1.1235668659210205, L5: 0.046620823442935944
Epoch 8000, Loss: 3.378061532974243, Losses: L1: 0.9909053444862366, L2: 0.08273719251155853, L3: 0.10627812147140503, L4: 1.1023082733154297, L5: 0.04666343331336975
Epoch 8500, Loss: 3.3470606803894043, Losses: L1: 0.990586519241333, L2: 0.08218389004468918, L3: 0.10566186904907227, L4: 1.0873632431030273, L5: 0.04673292860388756
Epoch 9000, Loss: 3.3262124061584473, Losses: L1: 0.9903109073638916, L2: 0.08171802759170532, L3: 0.10533028841018677, L4: 1.0773892402648926, L5: 0.04674013704061508
Epoch 9500, Loss: 3.312565326690674, Losses: L1: 0.9906281232833862, L2: 0.08143428713083267, L3: 0.10509324073791504, L4: 1.0705634355545044, L5: 0.046829577535390854
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9942129850387573, Constraint losses: L1: 5.177060604095459, L2: 0.0, L3: 0.9945182800292969, L4: 0.9945176243782043
Epoch 500, Loss: 0.00211614603176713, Constraint losses: L1: -1.0624980926513672, L2: 0.0, L3: 0.0025884509086608887, L4: 0.0005901934346184134
Epoch 1000, Loss: 0.0012512581888586283, Constraint losses: L1: -1.1182552576065063, L2: 0.0, L3: 0.0021845102310180664, L4: 0.00018500331498216838
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.004023313522339, Constraint losses: L1: 6.589719295501709, L2: 0.0, L3: 0.9987168908119202, L4: 0.9987166523933411
Epoch 500, Loss: 0.0023545734584331512, Constraint losses: L1: -1.0022937059402466, L2: 0.0, L3: 0.002677440643310547, L4: 0.0006794265354983509
Epoch 1000, Loss: 0.001378754386678338, Constraint losses: L1: -1.0491329431533813, L2: 0.0, L3: 0.002213716506958008, L4: 0.000214170926483348
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 171.80645751953125, Losses: L1: 18.42068099975586, L2: 0.0027662604115903378, L3: 1.0027662515640259, L4: 76.13827514648438, L5: 0.30253535509109497
Epoch 500, Loss: 6.100994110107422, Losses: L1: 0.6708313822746277, L2: 0.17235419154167175, L3: 0.07373988628387451, L4: 2.5636141300201416, L5: 0.04685509204864502
Epoch 1000, Loss: 2.8070528507232666, Losses: L1: 0.5732340216636658, L2: 0.054996952414512634, L3: 0.07795530557632446, L4: 1.0497701168060303, L5: 0.020151957869529724
Epoch 1500, Loss: 22.985387802124023, Losses: L1: 5.834015846252441, L2: 0.7106454968452454, L3: 0.3516298532485962, L4: 8.040971755981445, L5: 0.09148381650447845
Epoch 2000, Loss: 6.341242790222168, Losses: L1: 3.3506364822387695, L2: 0.2321087121963501, L3: 0.11422884464263916, L4: 1.2842824459075928, L5: 0.06640902161598206
Epoch 2500, Loss: 15.643172264099121, Losses: L1: 6.465827465057373, L2: 1.1988455057144165, L3: 0.2404630184173584, L4: 3.8506760597229004, L5: 0.07845781743526459
Epoch 3000, Loss: 10.597796440124512, Losses: L1: 4.96636962890625, L2: 0.8543594479560852, L3: 0.13430774211883545, L4: 2.2985565662384033, L5: 0.056399766355752945
Epoch 3500, Loss: 7.108645915985107, Losses: L1: 4.322027206420898, L2: 0.667893648147583, L3: 0.12004458904266357, L4: 0.9704046249389648, L5: 0.0589468739926815
Epoch 4000, Loss: 6.685657501220703, Losses: L1: 4.1111369132995605, L2: 0.6284993290901184, L3: 0.1178736686706543, L4: 0.8845036029815674, L5: 0.0590384379029274
Epoch 4500, Loss: 6.5419769287109375, Losses: L1: 4.065174102783203, L2: 0.6045852899551392, L3: 0.11671602725982666, L4: 0.848178505897522, L5: 0.05875104293227196
Epoch 5000, Loss: 6.466373920440674, Losses: L1: 4.045829772949219, L2: 0.5855317115783691, L3: 0.11565983295440674, L4: 0.8301822543144226, L5: 0.05840897560119629
Epoch 5500, Loss: 6.380550384521484, Losses: L1: 4.006381988525391, L2: 0.5734710097312927, L3: 0.11523354053497314, L4: 0.8131198287010193, L5: 0.05842045694589615
Epoch 6000, Loss: 6.34489631652832, Losses: L1: 3.9989771842956543, L2: 0.5649937391281128, L3: 0.11499989032745361, L4: 0.8033980131149292, L5: 0.058314818888902664
Epoch 6500, Loss: 6.3194756507873535, Losses: L1: 3.993673086166382, L2: 0.5582666397094727, L3: 0.11481916904449463, L4: 0.7968645095825195, L5: 0.05819849669933319
Epoch 7000, Loss: 6.301270484924316, Losses: L1: 3.9891276359558105, L2: 0.5526432394981384, L3: 0.11479061841964722, L4: 0.7929506301879883, L5: 0.05810150131583214
Epoch 7500, Loss: 6.284927845001221, Losses: L1: 3.9878933429718018, L2: 0.5479061603546143, L3: 0.11444973945617676, L4: 0.7878414392471313, L5: 0.058110546320676804
Epoch 8000, Loss: 6.245562553405762, Losses: L1: 3.9596219062805176, L2: 0.5425315499305725, L3: 0.11416041851043701, L4: 0.7850180268287659, L5: 0.05814651399850845
Epoch 8500, Loss: 6.237395286560059, Losses: L1: 3.957937479019165, L2: 0.5405089855194092, L3: 0.1141054630279541, L4: 0.782831072807312, L5: 0.0581168569624424
Epoch 9000, Loss: 6.232098579406738, Losses: L1: 3.9565303325653076, L2: 0.5388452410697937, L3: 0.11414659023284912, L4: 0.7817254066467285, L5: 0.058099400252103806
Epoch 9500, Loss: 6.228327751159668, Losses: L1: 3.9555699825286865, L2: 0.5375990271568298, L3: 0.1141747236251831, L4: 0.7809487581253052, L5: 0.058086950331926346
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0258803367614746, Constraint losses: L1: 18.42068099975586, L2: 0.002486339071765542, L3: 1.0024863481521606, L4: 1.0024868249893188
Epoch 500, Loss: 0.0021314388141036034, Constraint losses: L1: -1.0716946125030518, L2: 0.0, L3: 0.0026006102561950684, L4: 0.0006025230977684259
Epoch 1000, Loss: 0.0012567657977342606, Constraint losses: L1: -1.1173933744430542, L2: 0.0, L3: 0.0021867752075195312, L4: 0.00018738397920969874
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.008371353149414, Constraint losses: L1: 8.736028671264648, L2: 0.0, L3: 0.9998176693916321, L4: 0.9998176693916321
Epoch 500, Loss: 0.0023182681761682034, Constraint losses: L1: -1.0105079412460327, L2: 0.0, L3: 0.00266343355178833, L4: 0.0006653427262790501
Epoch 1000, Loss: 0.0013732854276895523, Constraint losses: L1: -1.049866795539856, L2: 0.0, L3: 0.002211272716522217, L4: 0.00021187956735957414
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 47.44485855102539, Losses: L1: 10.7925443649292, L2: 0.0011768100084736943, L3: 0.998923122882843, L4: 71.02938842773438, L5: 0.27504289150238037
Epoch 500, Loss: 9.005373001098633, Losses: L1: 4.401558876037598, L2: 0.23147128522396088, L3: 0.2718561887741089, L4: 8.127628326416016, L5: 0.07334563136100769
Epoch 1000, Loss: 9.420461654663086, Losses: L1: 3.8798668384552, L2: 0.07252875715494156, L3: 0.2508903741836548, L4: 10.378852844238281, L5: 0.05549808219075203
Epoch 1500, Loss: 39.00178909301758, Losses: L1: 12.8762845993042, L2: 3.4995071018784074e-06, L3: 0.9999908208847046, L4: 50.00012969970703, L5: 0.25089624524116516
Epoch 2000, Loss: 25.326990127563477, Losses: L1: 3.807694435119629, L2: 0.27706843614578247, L3: 1.0125023126602173, L4: 40.28789520263672, L5: 0.17155270278453827
Epoch 2500, Loss: 9.162088394165039, Losses: L1: 4.161278247833252, L2: 0.5551228523254395, L3: 0.270230770111084, L4: 8.2130126953125, L5: 0.13790175318717957
Epoch 3000, Loss: 6.590271949768066, Losses: L1: 3.783673048019409, L2: 0.2515839636325836, L3: 0.1709098219871521, L4: 4.678241729736328, L5: 0.08996879309415817
Epoch 3500, Loss: 4.7327752113342285, Losses: L1: 1.7689608335494995, L2: 0.0642954409122467, L3: 0.16550993919372559, L4: 5.429041862487793, L5: 0.03897611424326897
Epoch 4000, Loss: 5.596728801727295, Losses: L1: 1.6636006832122803, L2: 0.04183090850710869, L3: 0.2897603511810303, L4: 7.154636383056641, L5: 0.04843701049685478
Epoch 4500, Loss: 5.184712886810303, Losses: L1: 1.4969710111618042, L2: 0.035593584179878235, L3: 0.266212522983551, L4: 6.727562427520752, L5: 0.04430900886654854
Epoch 5000, Loss: 5.065536975860596, Losses: L1: 1.472738265991211, L2: 0.034422893077135086, L3: 0.2597482204437256, L4: 6.553225517272949, L5: 0.044030170887708664
Epoch 5500, Loss: 4.989256858825684, Losses: L1: 1.4558510780334473, L2: 0.03383432701230049, L3: 0.25807034969329834, L4: 6.439582347869873, L5: 0.04342001676559448
Epoch 6000, Loss: 4.935708522796631, Losses: L1: 1.4453104734420776, L2: 0.03337179496884346, L3: 0.25700831413269043, L4: 6.356928825378418, L5: 0.043106622993946075
Epoch 6500, Loss: 4.881592273712158, Losses: L1: 1.4261422157287598, L2: 0.032728541642427444, L3: 0.2554960250854492, L4: 6.291438102722168, L5: 0.04301271215081215
Epoch 7000, Loss: 4.841339588165283, Losses: L1: 1.4131709337234497, L2: 0.03159099072217941, L3: 0.25283902883529663, L4: 6.244966983795166, L5: 0.042510345578193665
Epoch 7500, Loss: 4.82623815536499, Losses: L1: 1.40859055519104, L2: 0.03174203261733055, L3: 0.25323182344436646, L4: 6.222778797149658, L5: 0.04256946220993996
Epoch 8000, Loss: 4.815116882324219, Losses: L1: 1.405682921409607, L2: 0.03181182220578194, L3: 0.253409743309021, L4: 6.205849647521973, L5: 0.04257466271519661
Epoch 8500, Loss: 4.806957244873047, Losses: L1: 1.4035181999206543, L2: 0.031754717230796814, L3: 0.2532392740249634, L4: 6.194377899169922, L5: 0.042511675506830215
Epoch 9000, Loss: 4.800900459289551, Losses: L1: 1.4020992517471313, L2: 0.03169982507824898, L3: 0.25310391187667847, L4: 6.185547828674316, L5: 0.04244719445705414
Epoch 9500, Loss: 4.796477794647217, Losses: L1: 1.401206135749817, L2: 0.03166554123163223, L3: 0.25298696756362915, L4: 6.178827285766602, L5: 0.04241086170077324
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.99941086769104, Constraint losses: L1: 5.742384433746338, L2: 0.0, L3: 0.9968344569206238, L4: 0.9968339800834656
Epoch 500, Loss: 0.002211867831647396, Constraint losses: L1: -1.0956238508224487, L2: 0.0, L3: 0.002652883529663086, L4: 0.000654608360491693
Epoch 1000, Loss: 0.0013021820923313498, Constraint losses: L1: -1.116974949836731, L2: 0.0, L3: 0.002209305763244629, L4: 0.00020985132141504437
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0035994052886963, Constraint losses: L1: 6.5188469886779785, L2: 0.0, L3: 0.9985404014587402, L4: 0.9985401630401611
Epoch 500, Loss: 0.002660512225702405, Constraint losses: L1: -0.9715374112129211, L2: 0.0, L3: 0.002814769744873047, L4: 0.0008172799134626985
Epoch 1000, Loss: 0.0014683124609291553, Constraint losses: L1: -1.0472344160079956, L2: 0.0, L3: 0.00225752592086792, L4: 0.0002580210566520691
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 45.09904479980469, Losses: L1: 5.11386251449585, L2: 0.0, L3: 0.9934727549552917, L4: 77.36164855957031, L5: 0.31088677048683167
Epoch 500, Loss: 30.49761962890625, Losses: L1: 3.229434013366699, L2: 0.0, L3: 0.9479270577430725, L4: 52.1545295715332, L5: 0.24299432337284088
Epoch 1000, Loss: 30.467041015625, Losses: L1: 3.2027480602264404, L2: 0.0, L3: 0.9462780952453613, L4: 52.14965057373047, L5: 0.24319103360176086
Epoch 1500, Loss: 30.173095703125, Losses: L1: 3.0562777519226074, L2: 0.0, L3: 0.9396632313728333, L4: 51.865699768066406, L5: 0.24430422484874725
Epoch 2000, Loss: 30.46119499206543, Losses: L1: 3.197249174118042, L2: 0.0, L3: 0.9447734951972961, L4: 52.15235900878906, L5: 0.2429918646812439
Epoch 2500, Loss: 30.44623374938965, Losses: L1: 3.1829185485839844, L2: 0.0, L3: 0.9446046352386475, L4: 52.15129852294922, L5: 0.2430606186389923
Epoch 3000, Loss: 30.437232971191406, Losses: L1: 3.1753344535827637, L2: 0.0, L3: 0.9440808892250061, L4: 52.14946746826172, L5: 0.2430839240550995
Epoch 3500, Loss: 30.431215286254883, Losses: L1: 3.1707804203033447, L2: 0.0, L3: 0.9435952305793762, L4: 52.147491455078125, L5: 0.24309328198432922
Epoch 4000, Loss: 30.4268856048584, Losses: L1: 3.1677849292755127, L2: 0.0, L3: 0.9432041049003601, L4: 52.14560317993164, L5: 0.24309518933296204
Epoch 4500, Loss: 30.42365837097168, Losses: L1: 3.1656668186187744, L2: 0.0, L3: 0.9429053664207458, L4: 52.143985748291016, L5: 0.2430933117866516
Epoch 5000, Loss: 30.42120933532715, Losses: L1: 3.164111375808716, L2: 0.0, L3: 0.9426826238632202, L4: 52.14265060424805, L5: 0.24308976531028748
Epoch 5500, Loss: 30.419336318969727, Losses: L1: 3.1629414558410645, L2: 0.0, L3: 0.9425166249275208, L4: 52.14158630371094, L5: 0.24308568239212036
Epoch 6000, Loss: 30.41789436340332, Losses: L1: 3.1620588302612305, L2: 0.0, L3: 0.9423924088478088, L4: 52.140724182128906, L5: 0.24308203160762787
Epoch 6500, Loss: 30.416784286499023, Losses: L1: 3.1613833904266357, L2: 0.0, L3: 0.9422988891601562, L4: 52.14004898071289, L5: 0.24307897686958313
Epoch 7000, Loss: 30.415925979614258, Losses: L1: 3.160828113555908, L2: 0.0, L3: 0.9422260522842407, L4: 52.139591217041016, L5: 0.24307604134082794
Epoch 7500, Loss: 30.41526222229004, Losses: L1: 3.160456657409668, L2: 0.0, L3: 0.9421751499176025, L4: 52.13911437988281, L5: 0.24307367205619812
Epoch 8000, Loss: 30.414751052856445, Losses: L1: 3.1600899696350098, L2: 0.0, L3: 0.9421322345733643, L4: 52.138916015625, L5: 0.2430712878704071
Epoch 8500, Loss: 30.41435432434082, Losses: L1: 3.1598477363586426, L2: 0.0, L3: 0.9421005249023438, L4: 52.138671875, L5: 0.24306988716125488
Epoch 9000, Loss: 30.414047241210938, Losses: L1: 3.159717321395874, L2: 0.0, L3: 0.9420804977416992, L4: 52.138362884521484, L5: 0.2430688887834549
Epoch 9500, Loss: 30.41381072998047, Losses: L1: 3.1596949100494385, L2: 0.0, L3: 0.942070484161377, L4: 52.13795471191406, L5: 0.24306818842887878
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.031447649002075, Constraint losses: L1: 18.42068099975586, L2: 0.004342022351920605, L3: 1.0043420791625977, L4: 1.0043429136276245
Epoch 500, Loss: 0.0024230247363448143, Constraint losses: L1: -1.0622445344924927, L2: 0.0, L3: 0.002741515636444092, L4: 0.0007437537424266338
Epoch 1000, Loss: 0.0013503311201930046, Constraint losses: L1: -1.1183720827102661, L2: 0.0, L3: 0.0022341012954711914, L4: 0.00023460185911972076
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0008327960968018, Constraint losses: L1: 5.91654634475708, L2: 0.0, L3: 0.9974584579467773, L4: 0.9974578022956848
Epoch 500, Loss: 0.002548506483435631, Constraint losses: L1: -1.0132074356079102, L2: 0.0, L3: 0.0027799010276794434, L4: 0.0007818130543455482
Epoch 1000, Loss: 0.001468323403969407, Constraint losses: L1: -1.0423533916473389, L2: 0.0, L3: 0.002254962921142578, L4: 0.000255713879596442
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 57.29741287231445, Losses: L1: 13.689543724060059, L2: 0.0011523565044626594, L3: 1.000801920890808, L4: 83.7901382446289, L5: 0.35542231798171997
Epoch 500, Loss: 10.340182304382324, Losses: L1: 1.7414277791976929, L2: 0.20222263038158417, L3: 0.2088896632194519, L4: 15.985271453857422, L5: 0.09750311076641083
Epoch 1000, Loss: 35.820640563964844, Losses: L1: 9.321990013122559, L2: 0.00016523395606782287, L3: 0.9997736215591431, L4: 49.99266052246094, L5: 0.2511908710002899
Epoch 1500, Loss: 30.688020706176758, Losses: L1: 4.703691482543945, L2: 0.07000619918107986, L3: 0.8787194490432739, L4: 49.27870178222656, L5: 0.19812658429145813
Epoch 2000, Loss: 6.488912582397461, Losses: L1: 2.4881763458251953, L2: 0.03693729639053345, L3: 0.1900695562362671, L4: 7.392626762390137, L5: 0.03870785981416702
Epoch 2500, Loss: 2.807027578353882, Losses: L1: 0.747164785861969, L2: 0.01624484546482563, L3: 0.17856037616729736, L4: 3.5980160236358643, L5: 0.03302481770515442
Epoch 3000, Loss: 2.474456548690796, Losses: L1: 0.7069329023361206, L2: 0.026703234761953354, L3: 0.16039973497390747, L4: 3.0171334743499756, L5: 0.03592692315578461
Epoch 3500, Loss: 2.1279280185699463, Losses: L1: 0.6323496103286743, L2: 0.021935326978564262, L3: 0.15152227878570557, L4: 2.506221055984497, L5: 0.034505125135183334
Epoch 4000, Loss: 2.0168442726135254, Losses: L1: 0.6202729344367981, L2: 0.020904986187815666, L3: 0.14715361595153809, L4: 2.3251845836639404, L5: 0.03296024724841118
Epoch 4500, Loss: 1.9528889656066895, Losses: L1: 0.6110342741012573, L2: 0.020287735387682915, L3: 0.14467430114746094, L4: 2.2244796752929688, L5: 0.032326407730579376
Epoch 5000, Loss: 1.91070556640625, Losses: L1: 0.6050267815589905, L2: 0.01985698565840721, L3: 0.1433643102645874, L4: 2.1597213745117188, L5: 0.03129841759800911
Epoch 5500, Loss: 1.8493458032608032, Losses: L1: 0.5719127655029297, L2: 0.017577113583683968, L3: 0.1426132321357727, L4: 2.1116676330566406, L5: 0.03070446476340294
Epoch 6000, Loss: 1.8281900882720947, Losses: L1: 0.5689288377761841, L2: 0.01745188608765602, L3: 0.1415879726409912, L4: 2.078519582748413, L5: 0.030480822548270226
Epoch 6500, Loss: 1.8131595849990845, Losses: L1: 0.5668564438819885, L2: 0.017376210540533066, L3: 0.1408112645149231, L4: 2.0551419258117676, L5: 0.0302723441272974
Epoch 7000, Loss: 1.8022736310958862, Losses: L1: 0.5653432607650757, L2: 0.017350157722830772, L3: 0.14015883207321167, L4: 2.038170576095581, L5: 0.030168041586875916
Epoch 7500, Loss: 1.7942092418670654, Losses: L1: 0.5640977621078491, L2: 0.017326531931757927, L3: 0.13975316286087036, L4: 2.025956630706787, L5: 0.030026748776435852
Epoch 8000, Loss: 1.7883182764053345, Losses: L1: 0.5632069706916809, L2: 0.017304586246609688, L3: 0.13945484161376953, L4: 2.0170609951019287, L5: 0.02991071157157421
Epoch 8500, Loss: 1.7840510606765747, Losses: L1: 0.5624973177909851, L2: 0.017301717773079872, L3: 0.1392521858215332, L4: 2.0107126235961914, L5: 0.02982177585363388
Epoch 9000, Loss: 1.7810951471328735, Losses: L1: 0.5621653199195862, L2: 0.017314821481704712, L3: 0.13904666900634766, L4: 2.0060105323791504, L5: 0.029781535267829895
Epoch 9500, Loss: 1.7790169715881348, Losses: L1: 0.5619120001792908, L2: 0.017320116981863976, L3: 0.1389148235321045, L4: 2.002656936645508, L5: 0.029770812019705772
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.001255989074707, Constraint losses: L1: 5.983279228210449, L2: 0.0, L3: 0.9976366758346558, L4: 0.997636079788208
Epoch 500, Loss: 0.00215133186429739, Constraint losses: L1: -1.0407246351242065, L2: 0.0, L3: 0.0025951266288757324, L4: 0.0005969299236312509
Epoch 1000, Loss: 0.001251149456948042, Constraint losses: L1: -1.1163676977157593, L2: 0.0, L3: 0.0021834373474121094, L4: 0.000184079835889861
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0193684101104736, Constraint losses: L1: 18.42068099975586, L2: 0.00031575586763210595, L3: 1.00031578540802, L4: 1.0003161430358887
Epoch 500, Loss: 0.0024063079617917538, Constraint losses: L1: -0.9934603571891785, L2: 0.0, L3: 0.0026987791061401367, L4: 0.0007009892724454403
Epoch 1000, Loss: 0.0013946833787485957, Constraint losses: L1: -1.0512028932571411, L2: 0.0, L3: 0.0022226572036743164, L4: 0.00022322917357087135
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 89.08379364013672, Losses: L1: 11.773103713989258, L2: 0.001153887016698718, L3: 0.9998251795768738, L4: 76.16009521484375, L5: 0.29922300577163696
Epoch 500, Loss: 2.3413970470428467, Losses: L1: 0.5330057740211487, L2: 0.05669379606842995, L3: 0.11509829759597778, L4: 1.629605770111084, L5: 0.013987165875732899
Epoch 1000, Loss: 18.480812072753906, Losses: L1: 4.383699893951416, L2: 0.6894801259040833, L3: 0.36389029026031494, L4: 12.972238540649414, L5: 0.14300578832626343
Epoch 1500, Loss: 4.258590221405029, Losses: L1: 1.5256036520004272, L2: 0.12472601979970932, L3: 0.12893307209014893, L4: 2.4447336196899414, L5: 0.0691884458065033
Epoch 2000, Loss: 2.354224681854248, Losses: L1: 0.8113201260566711, L2: 0.0863024890422821, L3: 0.12108033895492554, L4: 1.3154734373092651, L5: 0.040096405893564224
Epoch 2500, Loss: 1.8718483448028564, Losses: L1: 0.5074553489685059, L2: 0.07028830796480179, L3: 0.11171388626098633, L4: 1.1707236766815186, L5: 0.023334302008152008
Epoch 3000, Loss: 1.5801174640655518, Losses: L1: 0.5203890800476074, L2: 0.06689190864562988, L3: 0.0994255542755127, L4: 0.8825680613517761, L5: 0.02168552577495575
Epoch 3500, Loss: 1.4817231893539429, Losses: L1: 0.4509575366973877, L2: 0.06153197959065437, L3: 0.0949242115020752, L4: 0.8631665706634521, L5: 0.022285697981715202
Epoch 4000, Loss: 1.371142864227295, Losses: L1: 0.4408433735370636, L2: 0.05911261960864067, L3: 0.09398746490478516, L4: 0.7669084072113037, L5: 0.020581936463713646
Epoch 4500, Loss: 1.3339608907699585, Losses: L1: 0.4343242943286896, L2: 0.05792444944381714, L3: 0.09295547008514404, L4: 0.7385820746421814, L5: 0.020349180325865746
Epoch 5000, Loss: 1.3088233470916748, Losses: L1: 0.430489718914032, L2: 0.05698682740330696, L3: 0.0920877456665039, L4: 0.7191112041473389, L5: 0.020295729860663414
Epoch 5500, Loss: 1.289795160293579, Losses: L1: 0.4273134469985962, L2: 0.05678102746605873, L3: 0.09135317802429199, L4: 0.7042428255081177, L5: 0.02020939812064171
Epoch 6000, Loss: 1.2613590955734253, Losses: L1: 0.4111449420452118, L2: 0.056048434227705, L3: 0.09083378314971924, L4: 0.6932187080383301, L5: 0.020226430147886276
Epoch 6500, Loss: 1.2500717639923096, Losses: L1: 0.4083280563354492, L2: 0.056573253124952316, L3: 0.09001356363296509, L4: 0.6850409507751465, L5: 0.020231865346431732
Epoch 7000, Loss: 1.2420016527175903, Losses: L1: 0.4068189561367035, L2: 0.056638266891241074, L3: 0.08955776691436768, L4: 0.678850531578064, L5: 0.020272154361009598
Epoch 7500, Loss: 1.2212934494018555, Losses: L1: 0.3924730718135834, L2: 0.05538608133792877, L3: 0.08964931964874268, L4: 0.6736359000205994, L5: 0.02029789611697197
Epoch 8000, Loss: 1.2164820432662964, Losses: L1: 0.39162489771842957, L2: 0.05534707009792328, L3: 0.08938229084014893, L4: 0.6699727773666382, L5: 0.020310133695602417
Epoch 8500, Loss: 1.2130788564682007, Losses: L1: 0.39094746112823486, L2: 0.055481310933828354, L3: 0.08912801742553711, L4: 0.6673609018325806, L5: 0.02032240480184555
Epoch 9000, Loss: 1.2106573581695557, Losses: L1: 0.39043259620666504, L2: 0.05561406537890434, L3: 0.08894681930541992, L4: 0.6654980778694153, L5: 0.020331621170043945
Epoch 9500, Loss: 1.2088911533355713, Losses: L1: 0.39007872343063354, L2: 0.05572843924164772, L3: 0.08879399299621582, L4: 0.6641175746917725, L5: 0.020344819873571396
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023771286010742, Constraint losses: L1: 18.42068099975586, L2: 0.0017837814521044493, L3: 1.0017837285995483, L4: 1.0017832517623901
Epoch 500, Loss: 0.0019481380004435778, Constraint losses: L1: -1.1136664152145386, L2: 0.0, L3: 0.002530217170715332, L4: 0.0005315872258506715
Epoch 1000, Loss: 0.0012337233638390899, Constraint losses: L1: -1.1187846660614014, L2: 0.0, L3: 0.002176046371459961, L4: 0.00017646176274865866
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.027041435241699, Constraint losses: L1: 18.42068099975586, L2: 0.0028734069783240557, L3: 1.002873420715332, L4: 1.0028740167617798
Epoch 500, Loss: 0.0023067251313477755, Constraint losses: L1: -0.9903226494789124, L2: 0.0, L3: 0.0026475191116333008, L4: 0.0006495286361314356
Epoch 1000, Loss: 0.0013530347496271133, Constraint losses: L1: -1.050506353378296, L2: 0.0, L3: 0.0022014975547790527, L4: 0.0002020436222665012
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.69127655029297, Losses: L1: 13.166590690612793, L2: 0.0013099107891321182, L3: 1.0004775524139404, L4: 73.24295043945312, L5: 0.2799430191516876
Epoch 500, Loss: 15.82911491394043, Losses: L1: 4.751577377319336, L2: 0.5336558222770691, L3: 0.2918635606765747, L4: 10.199984550476074, L5: 0.05203426256775856
Epoch 1000, Loss: 20.645200729370117, Losses: L1: 5.120574474334717, L2: 0.6021182537078857, L3: 0.09051811695098877, L4: 14.68989372253418, L5: 0.14209574460983276
Epoch 1500, Loss: 1.4577887058258057, Losses: L1: 0.38646912574768066, L2: 0.036282096058130264, L3: 0.08178573846817017, L4: 0.9376605749130249, L5: 0.015591165982186794
Epoch 2000, Loss: 1.3037790060043335, Losses: L1: 0.3467440903186798, L2: 0.036591894924640656, L3: 0.07635343074798584, L4: 0.830679714679718, L5: 0.013409829698503017
Epoch 2500, Loss: 1.2272766828536987, Losses: L1: 0.3482957184314728, L2: 0.035185545682907104, L3: 0.07324719429016113, L4: 0.7553779482841492, L5: 0.015170249156653881
Epoch 3000, Loss: 1.1171704530715942, Losses: L1: 0.33332106471061707, L2: 0.03349529206752777, L3: 0.07353609800338745, L4: 0.6632254123687744, L5: 0.013592565432190895
Epoch 3500, Loss: 1.0722302198410034, Losses: L1: 0.32226061820983887, L2: 0.03408035635948181, L3: 0.07237136363983154, L4: 0.6303508281707764, L5: 0.013166982680559158
Epoch 4000, Loss: 1.0301892757415771, Losses: L1: 0.3173477351665497, L2: 0.03326665610074997, L3: 0.07227528095245361, L4: 0.5947165489196777, L5: 0.012583076022565365
Epoch 4500, Loss: 1.000639796257019, Losses: L1: 0.3146325349807739, L2: 0.03356575593352318, L3: 0.07164502143859863, L4: 0.5683834552764893, L5: 0.012412979267537594
Epoch 5000, Loss: 0.981971800327301, Losses: L1: 0.31205886602401733, L2: 0.034063927829265594, L3: 0.07098639011383057, L4: 0.5526271462440491, L5: 0.012235472910106182
Epoch 5500, Loss: 0.9683004021644592, Losses: L1: 0.3102189004421234, L2: 0.03403603285551071, L3: 0.0707404613494873, L4: 0.5412424802780151, L5: 0.012062480673193932
Epoch 6000, Loss: 0.9592664241790771, Losses: L1: 0.3087460398674011, L2: 0.03396124020218849, L3: 0.07059800624847412, L4: 0.5341021418571472, L5: 0.011858979240059853
Epoch 6500, Loss: 0.9531412720680237, Losses: L1: 0.30781975388526917, L2: 0.03392980620265007, L3: 0.07044249773025513, L4: 0.5291591882705688, L5: 0.011790008284151554
Epoch 7000, Loss: 0.9485857486724854, Losses: L1: 0.30697405338287354, L2: 0.0338645800948143, L3: 0.07036072015762329, L4: 0.5256751775741577, L5: 0.011711220256984234
Epoch 7500, Loss: 0.9454926252365112, Losses: L1: 0.30671876668930054, L2: 0.03378736600279808, L3: 0.07030582427978516, L4: 0.5230058431625366, L5: 0.011674835346639156
Epoch 8000, Loss: 0.9429340362548828, Losses: L1: 0.30630531907081604, L2: 0.033833328634500504, L3: 0.07021665573120117, L4: 0.5209213495254517, L5: 0.011657352559268475
Epoch 8500, Loss: 0.9411059021949768, Losses: L1: 0.3060750961303711, L2: 0.03381417691707611, L3: 0.07018136978149414, L4: 0.5194038152694702, L5: 0.011631431058049202
Epoch 9000, Loss: 0.9398239254951477, Losses: L1: 0.3059670329093933, L2: 0.033773910254240036, L3: 0.07016468048095703, L4: 0.5183029174804688, L5: 0.011615407653152943
Epoch 9500, Loss: 0.9388850927352905, Losses: L1: 0.3058447539806366, L2: 0.03377177566289902, L3: 0.07013857364654541, L4: 0.5175243616104126, L5: 0.011605643667280674
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0200767517089844, Constraint losses: L1: 18.42068099975586, L2: 0.0005520652630366385, L3: 1.0005520582199097, L4: 1.0005520582199097
Epoch 500, Loss: 0.0023962613195180893, Constraint losses: L1: -1.1012964248657227, L2: 0.0, L3: 0.0027478933334350586, L4: 0.0007496644975617528
Epoch 1000, Loss: 0.0013723046286031604, Constraint losses: L1: -1.1185166835784912, L2: 0.0, L3: 0.0022450685501098633, L4: 0.0002457528607919812
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0258374214172363, Constraint losses: L1: 18.42068099975586, L2: 0.002472059102728963, L3: 1.0024720430374146, L4: 1.0024726390838623
Epoch 500, Loss: 0.0025679103564471006, Constraint losses: L1: -0.9198015332221985, L2: 0.0, L3: 0.0027425289154052734, L4: 0.0007451830897480249
Epoch 1000, Loss: 0.0013983087847009301, Constraint losses: L1: -1.0480372905731201, L2: 0.0, L3: 0.002222895622253418, L4: 0.00022345043544191867
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 77.34928131103516, Losses: L1: 5.61942720413208, L2: 0.0, L3: 0.996027410030365, L4: 70.2098617553711, L5: 0.2619818449020386
Epoch 500, Loss: 11.366442680358887, Losses: L1: 3.0510387420654297, L2: 0.29904285073280334, L3: 0.15514826774597168, L4: 7.756413459777832, L5: 0.052399493753910065
Epoch 1000, Loss: 1.9388231039047241, Losses: L1: 0.38826894760131836, L2: 0.08080361038446426, L3: 0.09109807014465332, L4: 1.3497974872589111, L5: 0.014427470043301582
Epoch 1500, Loss: 1.8512823581695557, Losses: L1: 0.24712252616882324, L2: 0.040613722056150436, L3: 0.06788468360900879, L4: 1.4625120162963867, L5: 0.016574740409851074
Epoch 2000, Loss: 0.8773775696754456, Losses: L1: 0.2369946539402008, L2: 0.037512894719839096, L3: 0.06377518177032471, L4: 0.5190545916557312, L5: 0.010020101442933083
Epoch 2500, Loss: 3.436622381210327, Losses: L1: 0.736046552658081, L2: 0.05946690961718559, L3: 0.13149607181549072, L4: 2.471676826477051, L5: 0.018967974931001663
Epoch 3000, Loss: 1.6533211469650269, Losses: L1: 0.4626150131225586, L2: 0.053940366953611374, L3: 0.09897106885910034, L4: 1.0098990201950073, L5: 0.01394786685705185
Epoch 3500, Loss: 1.3726328611373901, Losses: L1: 0.46535927057266235, L2: 0.04954669624567032, L3: 0.09102755784988403, L4: 0.7374672293663025, L5: 0.014616054482758045
Epoch 4000, Loss: 1.4599294662475586, Losses: L1: 0.4031028151512146, L2: 0.0370132140815258, L3: 0.08662092685699463, L4: 0.9063491821289062, L5: 0.013421677984297276
Epoch 4500, Loss: 1.1230508089065552, Losses: L1: 0.3767316937446594, L2: 0.04213429614901543, L3: 0.08216696977615356, L4: 0.5927296876907349, L5: 0.014644082635641098
Epoch 5000, Loss: 1.0819065570831299, Losses: L1: 0.37692078948020935, L2: 0.04246510565280914, L3: 0.08101797103881836, L4: 0.5521972179412842, L5: 0.01465272344648838
Epoch 5500, Loss: 1.070088267326355, Losses: L1: 0.37407997250556946, L2: 0.04283739998936653, L3: 0.0800013542175293, L4: 0.5445982813835144, L5: 0.014285639859735966
Epoch 6000, Loss: 1.0575487613677979, Losses: L1: 0.371144562959671, L2: 0.04286129027605057, L3: 0.07966125011444092, L4: 0.5355734825134277, L5: 0.014154061675071716
Epoch 6500, Loss: 1.0503039360046387, Losses: L1: 0.37007758021354675, L2: 0.042744193226099014, L3: 0.07938390970230103, L4: 0.5300742983818054, L5: 0.01401195302605629
Epoch 7000, Loss: 1.0458648204803467, Losses: L1: 0.36883997917175293, L2: 0.042694419622421265, L3: 0.07923173904418945, L4: 0.5273938775062561, L5: 0.013852444477379322
Epoch 7500, Loss: 1.0422691106796265, Losses: L1: 0.36805713176727295, L2: 0.04268953576683998, L3: 0.0790758728981018, L4: 0.5248285531997681, L5: 0.013809005729854107
Epoch 8000, Loss: 1.039844274520874, Losses: L1: 0.3675744831562042, L2: 0.04271141067147255, L3: 0.07895398139953613, L4: 0.5231360197067261, L5: 0.013734249398112297
Epoch 8500, Loss: 1.03805410861969, Losses: L1: 0.3672086000442505, L2: 0.042739562690258026, L3: 0.07887011766433716, L4: 0.5218430757522583, L5: 0.013696381822228432
Epoch 9000, Loss: 1.0367988348007202, Losses: L1: 0.3670550584793091, L2: 0.04274606332182884, L3: 0.07880371809005737, L4: 0.5208728313446045, L5: 0.013660624623298645
Epoch 9500, Loss: 1.0218759775161743, Losses: L1: 0.3526477813720703, L2: 0.042409446090459824, L3: 0.07892221212387085, L4: 0.5206043720245361, L5: 0.013646087609231472
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.018803596496582, Constraint losses: L1: 18.211463928222656, L2: 0.0002555895480327308, L3: 1.0001682043075562, L4: 1.0001683235168457
Epoch 500, Loss: 0.002180452225729823, Constraint losses: L1: -1.0209466218948364, L2: 0.0, L3: 0.002599656581878662, L4: 0.0006017423002049327
Epoch 1000, Loss: 0.0012430764036253095, Constraint losses: L1: -1.1167420148849487, L2: 0.0, L3: 0.0021796226501464844, L4: 0.0001801957841962576
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9972480535507202, Constraint losses: L1: 5.47882604598999, L2: 0.0, L3: 0.9958848357200623, L4: 0.9958844184875488
Epoch 500, Loss: 0.0019631613977253437, Constraint losses: L1: -1.0368356704711914, L2: 0.0, L3: 0.0024992823600769043, L4: 0.0005007146392017603
Epoch 1000, Loss: 0.0012708723079413176, Constraint losses: L1: -1.047196865081787, L2: 0.0, L3: 0.0021587610244750977, L4: 0.000159308168804273
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 168.34788513183594, Losses: L1: 18.324514389038086, L2: 0.006111381575465202, L3: 1.0061097145080566, L4: 74.43180847167969, L5: 0.2950710952281952
Epoch 500, Loss: 7.975584030151367, Losses: L1: 0.48767971992492676, L2: 0.03167515993118286, L3: 0.08228254318237305, L4: 3.6745195388793945, L5: 0.04981478303670883
Epoch 1000, Loss: 16.911001205444336, Losses: L1: 3.7625603675842285, L2: 0.15042652189731598, L3: 0.23027122020721436, L4: 6.363442897796631, L5: 0.08171641826629639
Epoch 1500, Loss: 8.768744468688965, Losses: L1: 3.142186164855957, L2: 0.14239850640296936, L3: 0.11022257804870605, L4: 2.6729393005371094, L5: 0.05611611157655716
Epoch 2000, Loss: 9.473352432250977, Losses: L1: 4.716619491577148, L2: 0.3921454846858978, L3: 0.16743212938308716, L4: 2.0848405361175537, L5: 0.05494610592722893
Epoch 2500, Loss: 9.817333221435547, Losses: L1: 4.7547287940979, L2: 0.2801424264907837, L3: 0.14836496114730835, L4: 2.3030717372894287, L5: 0.05590766295790672
Epoch 3000, Loss: 6.607792854309082, Losses: L1: 3.7241053581237793, L2: 0.09704586118459702, L3: 0.134879469871521, L4: 1.3130712509155273, L5: 0.05123890936374664
Epoch 3500, Loss: 14.196465492248535, Losses: L1: 6.5048041343688965, L2: 0.386496901512146, L3: 0.10994875431060791, L4: 3.5784692764282227, L5: 0.07655458897352219
Epoch 4000, Loss: 5.728355407714844, Losses: L1: 3.1301827430725098, L2: 0.11244439333677292, L3: 0.1315401792526245, L4: 1.1646004915237427, L5: 0.04997461289167404
Epoch 4500, Loss: 5.081606864929199, Losses: L1: 2.8629143238067627, L2: 0.10461276769638062, L3: 0.12603598833084106, L4: 0.9817632436752319, L5: 0.04903370887041092
Epoch 5000, Loss: 4.999711513519287, Losses: L1: 2.8546714782714844, L2: 0.1008327454328537, L3: 0.12337380647659302, L4: 0.9480785727500916, L5: 0.04935234785079956
Epoch 5500, Loss: 4.946384429931641, Losses: L1: 2.8606202602386475, L2: 0.0984070673584938, L3: 0.12132710218429565, L4: 0.9206210374832153, L5: 0.04957575723528862
Epoch 6000, Loss: 4.907819747924805, Losses: L1: 2.868577241897583, L2: 0.09651124477386475, L3: 0.12008285522460938, L4: 0.8989036083221436, L5: 0.049682993441820145
Epoch 6500, Loss: 4.879080295562744, Losses: L1: 2.8773810863494873, L2: 0.09522996842861176, L3: 0.1192084550857544, L4: 0.8811960220336914, L5: 0.04973773658275604
Epoch 7000, Loss: 4.831413745880127, Losses: L1: 2.8578848838806152, L2: 0.09325629472732544, L3: 0.11878705024719238, L4: 0.868313193321228, L5: 0.04971744865179062
Epoch 7500, Loss: 4.812478065490723, Losses: L1: 2.862489938735962, L2: 0.09312912076711655, L3: 0.11803001165390015, L4: 0.8569929003715515, L5: 0.049686498939991
Epoch 8000, Loss: 4.79939079284668, Losses: L1: 2.8663742542266846, L2: 0.09266652911901474, L3: 0.11761486530303955, L4: 0.8489493131637573, L5: 0.04967265576124191
Epoch 8500, Loss: 4.78957986831665, Losses: L1: 2.8690173625946045, L2: 0.09237091988325119, L3: 0.11725258827209473, L4: 0.8430542349815369, L5: 0.04966084286570549
Epoch 9000, Loss: 4.782155513763428, Losses: L1: 2.8710854053497314, L2: 0.09215224534273148, L3: 0.11699509620666504, L4: 0.8385487198829651, L5: 0.04965054988861084
Epoch 9500, Loss: 4.776569843292236, Losses: L1: 2.872713804244995, L2: 0.09201276302337646, L3: 0.11679553985595703, L4: 0.8351150155067444, L5: 0.049636099487543106
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0064697265625, Constraint losses: L1: 7.555773735046387, L2: 0.0, L3: 0.9994569420814514, L4: 0.9994571208953857
Epoch 500, Loss: 0.002057541161775589, Constraint losses: L1: -1.0686994791030884, L2: 0.0, L3: 0.002562284469604492, L4: 0.0005639560986310244
Epoch 1000, Loss: 0.0012259853538125753, Constraint losses: L1: -1.1161078214645386, L2: 0.0, L3: 0.002170741558074951, L4: 0.00017135171219706535
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.021414041519165, Constraint losses: L1: 18.42068099975586, L2: 0.0009987426456063986, L3: 1.0009973049163818, L4: 1.0009973049163818
Epoch 500, Loss: 0.0024780845269560814, Constraint losses: L1: -1.0057259798049927, L2: 0.0, L3: 0.002740919589996338, L4: 0.0007428908720612526
Epoch 1000, Loss: 0.0014180762227624655, Constraint losses: L1: -1.049991250038147, L2: 0.0, L3: 0.002233743667602539, L4: 0.00023432396119460464
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 162.90444946289062, Losses: L1: 8.824618339538574, L2: 0.00028001650935038924, L3: 0.9983082413673401, L4: 76.38699340820312, L5: 0.3072543144226074
Epoch 500, Loss: 6.718029975891113, Losses: L1: 0.42213478684425354, L2: 0.06729349493980408, L3: 0.06769406795501709, L4: 3.06620454788208, L5: 0.028498662635684013
Epoch 1000, Loss: 3.389472723007202, Losses: L1: 0.2067670375108719, L2: 0.023691928014159203, L3: 0.06869590282440186, L4: 1.5409345626831055, L5: 0.008448758162558079
Epoch 1500, Loss: 1.054033875465393, Losses: L1: 0.20232157409191132, L2: 0.034978341311216354, L3: 0.05418109893798828, L4: 0.3777124285697937, L5: 0.007128014229238033
Epoch 2000, Loss: 1.3472822904586792, Losses: L1: 0.16321125626564026, L2: 0.044015634804964066, L3: 0.07299137115478516, L4: 0.5296242833137512, L5: 0.007815456949174404
Epoch 2500, Loss: 1.178491234779358, Losses: L1: 0.1031000092625618, L2: 0.04101987183094025, L3: 0.058759987354278564, L4: 0.48388296365737915, L5: 0.007845424115657806
Epoch 3000, Loss: 1.0282649993896484, Losses: L1: 0.09028052538633347, L2: 0.031000902876257896, L3: 0.050999462604522705, L4: 0.4252932071685791, L5: 0.005397662986069918
Epoch 3500, Loss: 1.1193419694900513, Losses: L1: 0.07555096596479416, L2: 0.03167116269469261, L3: 0.04890906810760498, L4: 0.47863563895225525, L5: 0.005939507856965065
Epoch 4000, Loss: 0.38263508677482605, Losses: L1: 0.08094695210456848, L2: 0.02694413997232914, L3: 0.049169301986694336, L4: 0.11012591421604156, L5: 0.005322878714650869
Epoch 4500, Loss: 0.3674582540988922, Losses: L1: 0.07781795412302017, L2: 0.027670614421367645, L3: 0.048976898193359375, L4: 0.10382570326328278, L5: 0.005341373849660158
Epoch 5000, Loss: 0.354703426361084, Losses: L1: 0.07642661035060883, L2: 0.027811016887426376, L3: 0.04875075817108154, L4: 0.0981723964214325, L5: 0.005370273254811764
Epoch 5500, Loss: 0.3469476103782654, Losses: L1: 0.07507269084453583, L2: 0.02756962552666664, L3: 0.04857349395751953, L4: 0.0951806902885437, L5: 0.005370424594730139
Epoch 6000, Loss: 0.34258490800857544, Losses: L1: 0.07450424879789352, L2: 0.02744966372847557, L3: 0.048396289348602295, L4: 0.09342651069164276, L5: 0.005381707567721605
Epoch 6500, Loss: 0.3381419777870178, Losses: L1: 0.07389649003744125, L2: 0.027447374537587166, L3: 0.048283159732818604, L4: 0.09156274795532227, L5: 0.005389457568526268
Epoch 7000, Loss: 0.3352718651294708, Losses: L1: 0.07360246777534485, L2: 0.027424601837992668, L3: 0.048195064067840576, L4: 0.09032674133777618, L5: 0.0053962524980306625
Epoch 7500, Loss: 0.33337387442588806, Losses: L1: 0.07334352284669876, L2: 0.027417993173003197, L3: 0.04813265800476074, L4: 0.08954000473022461, L5: 0.005399664398282766
Epoch 8000, Loss: 0.332090824842453, Losses: L1: 0.07321471720933914, L2: 0.027396928519010544, L3: 0.04808562994003296, L4: 0.08899520337581635, L5: 0.005403117276728153
Epoch 8500, Loss: 0.3310526907444, Losses: L1: 0.07314350455999374, L2: 0.02734576351940632, L3: 0.04805588722229004, L4: 0.08855131268501282, L5: 0.0054049319587647915
Epoch 9000, Loss: 0.3304251432418823, Losses: L1: 0.07308867573738098, L2: 0.02733509987592697, L3: 0.048030972480773926, L4: 0.0882815569639206, L5: 0.005407270509749651
Epoch 9500, Loss: 0.3298989236354828, Losses: L1: 0.07304634153842926, L2: 0.02732589654624462, L3: 0.048015594482421875, L4: 0.08805146813392639, L5: 0.005408141762018204
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020735740661621, Constraint losses: L1: 18.42068099975586, L2: 0.0007721548317931592, L3: 1.0007721185684204, L4: 1.0007708072662354
Epoch 500, Loss: 0.0023585520684719086, Constraint losses: L1: -1.1072773933410645, L2: 0.0, L3: 0.0027319788932800293, L4: 0.0007338506984524429
Epoch 1000, Loss: 0.001360022695735097, Constraint losses: L1: -1.118640422821045, L2: 0.0, L3: 0.0022391080856323242, L4: 0.00023955517099238932
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0209274291992188, Constraint losses: L1: 18.42068099975586, L2: 0.0008355114841833711, L3: 1.0008355379104614, L4: 1.000835657119751
Epoch 500, Loss: 0.0023117857053875923, Constraint losses: L1: -0.8886188268661499, L2: 0.0, L3: 0.002599179744720459, L4: 0.0006012249505147338
Epoch 1000, Loss: 0.0012928431387990713, Constraint losses: L1: -1.0496546030044556, L2: 0.0, L3: 0.0021709799766540527, L4: 0.00017151780775748193
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 154.44956970214844, Losses: L1: 5.462149620056152, L2: 4.102291495655663e-05, L3: 0.9918434023857117, L4: 73.71438598632812, L5: 0.2833821177482605
Epoch 500, Loss: 6.570939540863037, Losses: L1: 1.7075324058532715, L2: 0.03848056495189667, L3: 0.10500037670135498, L4: 2.348602294921875, L5: 0.011360827833414078
Epoch 1000, Loss: 4.610002040863037, Losses: L1: 0.283761203289032, L2: 0.07201991975307465, L3: 0.07617902755737305, L4: 2.077402114868164, L5: 0.011618832126259804
Epoch 1500, Loss: 1.6566054821014404, Losses: L1: 0.24904471635818481, L2: 0.05959831550717354, L3: 0.05642592906951904, L4: 0.6352081298828125, L5: 0.010560139082372189
Epoch 2000, Loss: 1.0545716285705566, Losses: L1: 0.18936555087566376, L2: 0.043722186237573624, L3: 0.0557173490524292, L4: 0.37584930658340454, L5: 0.00703395577147603
Epoch 2500, Loss: 1.6387827396392822, Losses: L1: 0.1703183650970459, L2: 0.03721429035067558, L3: 0.054964303970336914, L4: 0.6813275814056396, L5: 0.0068153273314237595
Epoch 3000, Loss: 0.6868708729743958, Losses: L1: 0.15047648549079895, L2: 0.03746053948998451, L3: 0.05317282676696777, L4: 0.21731795370578766, L5: 0.00556257925927639
Epoch 3500, Loss: 0.6798160672187805, Losses: L1: 0.1456971913576126, L2: 0.03471117466688156, L3: 0.05282551050186157, L4: 0.21787771582603455, L5: 0.005413374397903681
Epoch 4000, Loss: 0.5855416059494019, Losses: L1: 0.14146076142787933, L2: 0.033696725964546204, L3: 0.05237936973571777, L4: 0.17363408207893372, L5: 0.005368304904550314
Epoch 4500, Loss: 0.555389940738678, Losses: L1: 0.14029818773269653, L2: 0.03250652551651001, L3: 0.05217832326889038, L4: 0.15991681814193726, L5: 0.005286622326821089
Epoch 5000, Loss: 0.4953414499759674, Losses: L1: 0.13836240768432617, L2: 0.0320960208773613, L3: 0.05197793245315552, L4: 0.1312781125307083, L5: 0.005174428690224886
Epoch 5500, Loss: 0.46751323342323303, Losses: L1: 0.12058766186237335, L2: 0.032633472234010696, L3: 0.051519155502319336, L4: 0.12625299394130707, L5: 0.005133483558893204
Epoch 6000, Loss: 0.45998260378837585, Losses: L1: 0.11941217631101608, L2: 0.032551780343055725, L3: 0.05135691165924072, L4: 0.123225137591362, L5: 0.005105738528072834
Epoch 6500, Loss: 0.43874454498291016, Losses: L1: 0.10297555476427078, L2: 0.032831061631441116, L3: 0.051120758056640625, L4: 0.12085798382759094, L5: 0.005050600506365299
Epoch 7000, Loss: 0.4339401125907898, Losses: L1: 0.10150306671857834, L2: 0.03300926089286804, L3: 0.05096924304962158, L4: 0.11918257176876068, L5: 0.005046695936471224
Epoch 7500, Loss: 0.4307868480682373, Losses: L1: 0.10095369070768356, L2: 0.033066410571336746, L3: 0.05087745189666748, L4: 0.11791323870420456, L5: 0.0050314078107476234
Epoch 8000, Loss: 0.42863571643829346, Losses: L1: 0.10053537040948868, L2: 0.03311753273010254, L3: 0.05081462860107422, L4: 0.11706513166427612, L5: 0.005018964875489473
Epoch 8500, Loss: 0.4271469712257385, Losses: L1: 0.1003633439540863, L2: 0.03305797651410103, L3: 0.05078911781311035, L4: 0.11645582318305969, L5: 0.00501245865598321
Epoch 9000, Loss: 0.42599380016326904, Losses: L1: 0.10026346147060394, L2: 0.03301381692290306, L3: 0.05077075958251953, L4: 0.11596659570932388, L5: 0.005006284918636084
Epoch 9500, Loss: 0.4252680540084839, Losses: L1: 0.10019702464342117, L2: 0.03297827020287514, L3: 0.050759077072143555, L4: 0.1156630888581276, L5: 0.005003742873668671
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0196821689605713, Constraint losses: L1: 18.42068099975586, L2: 0.00042071210918948054, L3: 1.0004206895828247, L4: 1.000420093536377
Epoch 500, Loss: 0.0024256384931504726, Constraint losses: L1: -1.0804308652877808, L2: 0.0, L3: 0.0027520060539245605, L4: 0.0007540633087046444
Epoch 1000, Loss: 0.0013568379217758775, Constraint losses: L1: -1.1182607412338257, L2: 0.0, L3: 0.002237260341644287, L4: 0.0002378383360337466
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005676746368408, Constraint losses: L1: 7.184327125549316, L2: 0.0, L3: 0.9992462396621704, L4: 0.9992461204528809
Epoch 500, Loss: 0.002330952789634466, Constraint losses: L1: -0.9151262044906616, L2: 0.0, L3: 0.0026220083236694336, L4: 0.0006240707589313388
Epoch 1000, Loss: 0.0013334248214960098, Constraint losses: L1: -1.0425834655761719, L2: 0.0, L3: 0.002187669277191162, L4: 0.00018833903595805168
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 48.191524505615234, Losses: L1: 6.70989465713501, L2: 0.00039544590981677175, L3: 0.9940617084503174, L4: 78.66822814941406, L5: 0.31799155473709106
Epoch 500, Loss: 39.34974670410156, Losses: L1: 12.19768238067627, L2: 0.0, L3: 0.9999899864196777, L4: 50.06751251220703, L5: 0.23665934801101685
Epoch 1000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.8388745116459243e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 1500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.8386675645562511e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 2000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.8384959895624553e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 2500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838343388106678e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 3000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.8382889069475106e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 3500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.8382468941133268e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 4000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.8382084049362035e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 4500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.8381944458332328e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 5000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838180215679719e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 5500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 6000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 6500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 7000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 7500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 8000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 8500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 9000, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Epoch 9500, Loss: 45.54623031616211, Losses: L1: 18.42068099975586, L2: 1.838171271011796e-13, L3: 1.0, L4: 50.00001907348633, L5: 0.2510782778263092
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0299742221832275, Constraint losses: L1: 18.42068099975586, L2: 0.0038512060418725014, L3: 1.0038511753082275, L4: 1.0038511753082275
Epoch 500, Loss: 0.002390363020822406, Constraint losses: L1: -1.0936038494110107, L2: 0.0, L3: 0.0027410387992858887, L4: 0.0007429281249642372
Epoch 1000, Loss: 0.001361807226203382, Constraint losses: L1: -1.1181116104125977, L2: 0.0, L3: 0.0022396445274353027, L4: 0.0002402743266429752
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0034074783325195, Constraint losses: L1: 6.497896671295166, L2: 0.0, L3: 0.9984548091888428, L4: 0.9984546899795532
Epoch 500, Loss: 0.0022582283709198236, Constraint losses: L1: -1.0329805612564087, L2: 0.0, L3: 0.0026447176933288574, L4: 0.00064649130217731
Epoch 1000, Loss: 0.0013616130454465747, Constraint losses: L1: -1.0510516166687012, L2: 0.0, L3: 0.0022060275077819824, L4: 0.00020663716713897884
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.146541595458984, Losses: L1: 16.266759872436523, L2: 0.0015900427242740989, L3: 1.0014113187789917, L4: 67.26205444335938, L5: 0.24434156715869904
Epoch 500, Loss: 11.73100471496582, Losses: L1: 4.180626392364502, L2: 0.036259111016988754, L3: 0.3367801904678345, L4: 13.557843208312988, L5: 0.061638299375772476
Epoch 1000, Loss: 45.67184829711914, Losses: L1: 18.42064666748047, L2: 1.67026579335006e-14, L3: 1.0, L4: 50.000614166259766, L5: 0.2508983314037323
Epoch 1500, Loss: 45.671852111816406, Losses: L1: 18.42064666748047, L2: 1.603742366771549e-14, L3: 1.0, L4: 50.0006103515625, L5: 0.2508990466594696
Epoch 2000, Loss: 45.671852111816406, Losses: L1: 18.420644760131836, L2: 1.548076716730712e-14, L3: 1.0, L4: 50.0006103515625, L5: 0.25089961290359497
Epoch 2500, Loss: 45.671844482421875, Losses: L1: 18.420642852783203, L2: 1.5068231628808174e-14, L3: 1.0, L4: 50.00060272216797, L5: 0.2509000301361084
Epoch 3000, Loss: 45.671844482421875, Losses: L1: 18.420642852783203, L2: 1.4716433434825045e-14, L3: 1.0, L4: 50.000606536865234, L5: 0.25090041756629944
Epoch 3500, Loss: 45.671844482421875, Losses: L1: 18.420642852783203, L2: 1.445477648708872e-14, L3: 1.0, L4: 50.000606536865234, L5: 0.2509006857872009
Epoch 4000, Loss: 45.671844482421875, Losses: L1: 18.420642852783203, L2: 1.423143592175439e-14, L3: 1.0, L4: 50.00060272216797, L5: 0.25090089440345764
Epoch 4500, Loss: 45.671844482421875, Losses: L1: 18.42064094543457, L2: 1.4067946704473047e-14, L3: 1.0, L4: 50.00060272216797, L5: 0.25090107321739197
Epoch 5000, Loss: 45.67184066772461, Losses: L1: 18.42064094543457, L2: 1.3952563876398066e-14, L3: 1.0, L4: 50.0005989074707, L5: 0.2509011924266815
Epoch 5500, Loss: 45.67184066772461, Losses: L1: 18.42064094543457, L2: 1.387449539074848e-14, L3: 1.0, L4: 50.0005989074707, L5: 0.2509012818336487
Epoch 6000, Loss: 45.671836853027344, Losses: L1: 18.42064094543457, L2: 1.3779528597801169e-14, L3: 1.0, L4: 50.00059509277344, L5: 0.25090137124061584
Epoch 6500, Loss: 45.67184066772461, Losses: L1: 18.42064094543457, L2: 1.3736492547817072e-14, L3: 1.0, L4: 50.0005989074707, L5: 0.250901460647583
Epoch 7000, Loss: 45.67184066772461, Losses: L1: 18.42064094543457, L2: 1.3683759664652809e-14, L3: 1.0, L4: 50.0005989074707, L5: 0.2509015202522278
Epoch 7500, Loss: 45.67184066772461, Losses: L1: 18.42064094543457, L2: 1.3646225093661129e-14, L3: 1.0, L4: 50.0005989074707, L5: 0.2509015202522278
Epoch 8000, Loss: 45.67184066772461, Losses: L1: 18.42064094543457, L2: 1.3645756684441297e-14, L3: 1.0, L4: 50.0005989074707, L5: 0.2509015202522278
Epoch 8500, Loss: 45.67184066772461, Losses: L1: 18.42064094543457, L2: 1.3619862887243733e-14, L3: 1.0, L4: 50.0005989074707, L5: 0.25090157985687256
Epoch 9000, Loss: 45.671836853027344, Losses: L1: 18.42064094543457, L2: 1.3607719822911896e-14, L3: 1.0, L4: 50.00059509277344, L5: 0.25090157985687256
Epoch 9500, Loss: 45.671836853027344, Losses: L1: 18.42064094543457, L2: 1.3594941483869617e-14, L3: 1.0, L4: 50.00059509277344, L5: 0.25090157985687256
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9979373216629028, Constraint losses: L1: 5.5494465827941895, L2: 0.0, L3: 0.9961941838264465, L4: 0.9961936473846436
Epoch 500, Loss: 0.002363455481827259, Constraint losses: L1: -1.08919095993042, L2: 0.0, L3: 0.00272524356842041, L4: 0.0007274029776453972
Epoch 1000, Loss: 0.001353199128061533, Constraint losses: L1: -1.1181252002716064, L2: 0.0, L3: 0.0022352933883666992, L4: 0.0002360309736104682
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005021333694458, Constraint losses: L1: 6.949695587158203, L2: 0.0, L3: 0.9990357756614685, L4: 0.9990357756614685
Epoch 500, Loss: 0.0022839840967208147, Constraint losses: L1: -1.0329746007919312, L2: 0.0, L3: 0.002657651901245117, L4: 0.0006593068828806281
Epoch 1000, Loss: 0.0013773611281067133, Constraint losses: L1: -1.0512654781341553, L2: 0.0, L3: 0.00221407413482666, L4: 0.00021455244859680533
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.98073196411133, Losses: L1: 12.359169006347656, L2: 0.0008334522135555744, L3: 1.0002543926239014, L4: 83.81209564208984, L5: 0.3570857346057892
Epoch 500, Loss: 1.4069114923477173, Losses: L1: 0.22627155482769012, L2: 0.07661256939172745, L3: 0.05246514081954956, L4: 1.9437165260314941, L5: 0.013619408942759037
Epoch 1000, Loss: 0.9948254227638245, Losses: L1: 0.10056350380182266, L2: 0.03022686019539833, L3: 0.052684903144836426, L4: 1.479243278503418, L5: 0.009521806612610817
Epoch 1500, Loss: 0.9727197885513306, Losses: L1: 0.09030140936374664, L2: 0.016954027116298676, L3: 0.05166506767272949, L4: 1.4863498210906982, L5: 0.009479654021561146
Epoch 2000, Loss: 0.8784389495849609, Losses: L1: 0.07298965007066727, L2: 0.021799230948090553, L3: 0.04742544889450073, L4: 1.3337191343307495, L5: 0.010969803668558598
Epoch 2500, Loss: 0.5001163482666016, Losses: L1: 0.039509162306785583, L2: 0.035033512860536575, L3: 0.0448075532913208, L4: 0.6506695747375488, L5: 0.005311900749802589
Epoch 3000, Loss: 0.37151768803596497, Losses: L1: 0.05296577885746956, L2: 0.02706061862409115, L3: 0.04534178972244263, L4: 0.37697774171829224, L5: 0.006159418728202581
Epoch 3500, Loss: 0.2753297984600067, Losses: L1: 0.04983161762356758, L2: 0.028690386563539505, L3: 0.04495823383331299, L4: 0.19274096190929413, L5: 0.0052604228258132935
Epoch 4000, Loss: 0.2441128045320511, Losses: L1: 0.04925166070461273, L2: 0.02851477637887001, L3: 0.0448453426361084, L4: 0.1320265233516693, L5: 0.005321215372532606
Epoch 4500, Loss: 0.24566347897052765, Losses: L1: 0.05047674849629402, L2: 0.02823757566511631, L3: 0.044803738594055176, L4: 0.13353917002677917, L5: 0.005286048632115126
Epoch 5000, Loss: 0.23279955983161926, Losses: L1: 0.051643453538417816, L2: 0.027977196499705315, L3: 0.04475682973861694, L4: 0.10595262795686722, L5: 0.005344467703253031
Epoch 5500, Loss: 0.2314348816871643, Losses: L1: 0.05225485563278198, L2: 0.027888281270861626, L3: 0.04472392797470093, L4: 0.10225662589073181, L5: 0.005357788875699043
Epoch 6000, Loss: 0.23046623170375824, Losses: L1: 0.05227673053741455, L2: 0.028061946853995323, L3: 0.044668614864349365, L4: 0.1001402735710144, L5: 0.005360092036426067
Epoch 6500, Loss: 0.2301127165555954, Losses: L1: 0.05234327167272568, L2: 0.028051283210515976, L3: 0.04465222358703613, L4: 0.09941272437572479, L5: 0.005353681277483702
Epoch 7000, Loss: 0.22957655787467957, Losses: L1: 0.05248362943530083, L2: 0.027984434738755226, L3: 0.04464155435562134, L4: 0.09821486473083496, L5: 0.005358980968594551
Epoch 7500, Loss: 0.22933700680732727, Losses: L1: 0.052498720586299896, L2: 0.027974754571914673, L3: 0.044632911682128906, L4: 0.09776481986045837, L5: 0.005357643123716116
Epoch 8000, Loss: 0.22912542521953583, Losses: L1: 0.052513543516397476, L2: 0.027970610186457634, L3: 0.04462391138076782, L4: 0.09735939651727676, L5: 0.005356876645237207
Epoch 8500, Loss: 0.22898517549037933, Losses: L1: 0.052506498992443085, L2: 0.027956971898674965, L3: 0.04461944103240967, L4: 0.09714485704898834, L5: 0.005355199333280325
Epoch 9000, Loss: 0.22887687385082245, Losses: L1: 0.05251313000917435, L2: 0.027949422597885132, L3: 0.044614970684051514, L4: 0.09695175290107727, L5: 0.005354254972189665
Epoch 9500, Loss: 0.22880610823631287, Losses: L1: 0.052518878132104874, L2: 0.02794279158115387, L3: 0.04461187124252319, L4: 0.09682577848434448, L5: 0.005353907588869333
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021794319152832, Constraint losses: L1: 18.42068099975586, L2: 0.0011243873741477728, L3: 1.001124382019043, L4: 1.0011247396469116
Epoch 500, Loss: 0.0021490587387233973, Constraint losses: L1: -1.1060848236083984, L2: 0.0, L3: 0.0026267170906066895, L4: 0.0006284265546128154
Epoch 1000, Loss: 0.0012937126448377967, Constraint losses: L1: -1.1186609268188477, L2: 0.0, L3: 0.0022060275077819824, L4: 0.0002063461288344115
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0184309482574463, Constraint losses: L1: 17.829957962036133, L2: 0.0002237571607111022, L3: 1.0001885890960693, L4: 1.0001885890960693
Epoch 500, Loss: 0.0021360479295253754, Constraint losses: L1: -1.0318031311035156, L2: 0.0, L3: 0.0025830864906311035, L4: 0.0005847645225003362
Epoch 1000, Loss: 0.0013339894358068705, Constraint losses: L1: -1.0503193140029907, L2: 0.0, L3: 0.0021918416023254395, L4: 0.0001924672833411023
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 95.46255493164062, Losses: L1: 18.42068099975586, L2: 0.0034205641131848097, L3: 1.0034205913543701, L4: 74.88365173339844, L5: 0.2959287464618683
Epoch 500, Loss: 9.394242286682129, Losses: L1: 3.7729506492614746, L2: 0.5925315618515015, L3: 0.12552225589752197, L4: 4.729592800140381, L5: 0.0962463989853859
Epoch 1000, Loss: 2.6446735858917236, Losses: L1: 0.5952577590942383, L2: 0.08702973276376724, L3: 0.10640406608581543, L4: 1.728834629058838, L5: 0.04148652404546738
Epoch 1500, Loss: 2.819880962371826, Losses: L1: 0.3586420714855194, L2: 0.07243789732456207, L3: 0.0683056116104126, L4: 2.234025716781616, L5: 0.03632824867963791
Epoch 2000, Loss: 1.1074175834655762, Losses: L1: 0.27822601795196533, L2: 0.047230083495378494, L3: 0.07057768106460571, L4: 0.629989743232727, L5: 0.021632619202136993
Epoch 2500, Loss: 0.8134872317314148, Losses: L1: 0.26246848702430725, L2: 0.04829570651054382, L3: 0.06509208679199219, L4: 0.3623749315738678, L5: 0.020327961072325706
Epoch 3000, Loss: 0.9116852283477783, Losses: L1: 0.2434425950050354, L2: 0.04824050888419151, L3: 0.06384754180908203, L4: 0.4830250144004822, L5: 0.018563980236649513
Epoch 3500, Loss: 0.7211827635765076, Losses: L1: 0.23003357648849487, L2: 0.04462708905339241, L3: 0.062149882316589355, L4: 0.31234025955200195, L5: 0.019764067605137825
Epoch 4000, Loss: 0.6993522047996521, Losses: L1: 0.22883383929729462, L2: 0.04273664578795433, L3: 0.061653852462768555, L4: 0.29475536942481995, L5: 0.019437361508607864
Epoch 4500, Loss: 0.6773422360420227, Losses: L1: 0.22781014442443848, L2: 0.04176033288240433, L3: 0.061138153076171875, L4: 0.27577969431877136, L5: 0.019431496039032936
Epoch 5000, Loss: 0.6672966480255127, Losses: L1: 0.22670665383338928, L2: 0.04127885028719902, L3: 0.060697317123413086, L4: 0.2682359516620636, L5: 0.019361117854714394
Epoch 5500, Loss: 0.6605939269065857, Losses: L1: 0.22676004469394684, L2: 0.040817078202962875, L3: 0.060389578342437744, L4: 0.2625545263290405, L5: 0.019366206601262093
Epoch 6000, Loss: 0.6552168726921082, Losses: L1: 0.22662781178951263, L2: 0.04037455841898918, L3: 0.060210227966308594, L4: 0.2581667900085449, L5: 0.019254593178629875
Epoch 6500, Loss: 0.6517797112464905, Losses: L1: 0.2267674207687378, L2: 0.040131017565727234, L3: 0.060047149658203125, L4: 0.25514698028564453, L5: 0.019279982894659042
Epoch 7000, Loss: 0.6485679745674133, Losses: L1: 0.22637706995010376, L2: 0.0399828739464283, L3: 0.0599367618560791, L4: 0.25272542238235474, L5: 0.01921812631189823
Epoch 7500, Loss: 0.646712064743042, Losses: L1: 0.22624148428440094, L2: 0.039813920855522156, L3: 0.059878766536712646, L4: 0.25130385160446167, L5: 0.019190551713109016
Epoch 8000, Loss: 0.6453865766525269, Losses: L1: 0.2262161523103714, L2: 0.039721984416246414, L3: 0.059822797775268555, L4: 0.25021666288375854, L5: 0.01917237974703312
Epoch 8500, Loss: 0.6445626616477966, Losses: L1: 0.22625841200351715, L2: 0.03969327732920647, L3: 0.059769630432128906, L4: 0.24948623776435852, L5: 0.019170895218849182
Epoch 9000, Loss: 0.6438198089599609, Losses: L1: 0.22620180249214172, L2: 0.03965524956583977, L3: 0.059739112854003906, L4: 0.2489062249660492, L5: 0.019156722351908684
Epoch 9500, Loss: 0.643404483795166, Losses: L1: 0.22615107893943787, L2: 0.039645787328481674, L3: 0.05971479415893555, L4: 0.2486022561788559, L5: 0.01915152184665203
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0065953731536865, Constraint losses: L1: 7.583434104919434, L2: 0.0, L3: 0.9995059967041016, L4: 0.9995059370994568
Epoch 500, Loss: 0.002286516595631838, Constraint losses: L1: -1.1000608205795288, L2: 0.0, L3: 0.00269240140914917, L4: 0.0006941761821508408
Epoch 1000, Loss: 0.0013266679598018527, Constraint losses: L1: -1.1174086332321167, L2: 0.0, L3: 0.00222170352935791, L4: 0.00022237320081330836
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0061261653900146, Constraint losses: L1: 7.339887619018555, L2: 0.0, L3: 0.9993931651115417, L4: 0.9993930459022522
Epoch 500, Loss: 0.002503753174096346, Constraint losses: L1: -0.9841427803039551, L2: 0.0, L3: 0.0027428865432739258, L4: 0.0007450096309185028
Epoch 1000, Loss: 0.0014219798613339663, Constraint losses: L1: -1.0482676029205322, L2: 0.0, L3: 0.0022347569465637207, L4: 0.00023549060279037803
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 80.28936004638672, Losses: L1: 5.889766216278076, L2: 0.0, L3: 0.997204065322876, L4: 72.130859375, L5: 0.27432680130004883
Epoch 500, Loss: 3.704695463180542, Losses: L1: 0.2264534831047058, L2: 0.07980608195066452, L3: 0.055146217346191406, L4: 3.265839099884033, L5: 0.02230425924062729
Epoch 1000, Loss: 1.70018470287323, Losses: L1: 0.15844178199768066, L2: 0.05808800086379051, L3: 0.05026602745056152, L4: 1.3750756978988647, L5: 0.00804717093706131
Epoch 1500, Loss: 1.5620360374450684, Losses: L1: 0.17624834179878235, L2: 0.119862399995327, L3: 0.05116558074951172, L4: 1.1514261960983276, L5: 0.012167985551059246
Epoch 2000, Loss: 0.9639108777046204, Losses: L1: 0.06464283168315887, L2: 0.033034104853868484, L3: 0.0497589111328125, L4: 0.7603797316551208, L5: 0.006336401682347059
Epoch 2500, Loss: 0.926414430141449, Losses: L1: 0.060171689838171005, L2: 0.02996962144970894, L3: 0.049602627754211426, L4: 0.7308194041252136, L5: 0.006248491816222668
Epoch 3000, Loss: 0.448036253452301, Losses: L1: 0.045337192714214325, L2: 0.032380592077970505, L3: 0.04839205741882324, L4: 0.2688956558704376, L5: 0.004638714715838432
Epoch 3500, Loss: 0.37635427713394165, Losses: L1: 0.04856549948453903, L2: 0.03160812333226204, L3: 0.04806160926818848, L4: 0.19542686641216278, L5: 0.004630552604794502
Epoch 4000, Loss: 0.3311372399330139, Losses: L1: 0.04892714321613312, L2: 0.030999580398201942, L3: 0.047790467739105225, L4: 0.1509391963481903, L5: 0.004690373782068491
Epoch 4500, Loss: 0.3105405569076538, Losses: L1: 0.04838891699910164, L2: 0.03046284429728985, L3: 0.04760599136352539, L4: 0.13179630041122437, L5: 0.004680507350713015
Epoch 5000, Loss: 0.2761422097682953, Losses: L1: 0.04799475148320198, L2: 0.029993651434779167, L3: 0.04746103286743164, L4: 0.09853891283273697, L5: 0.004692821763455868
Epoch 5500, Loss: 0.2738124132156372, Losses: L1: 0.04773787781596184, L2: 0.029729701578617096, L3: 0.04739731550216675, L4: 0.09684059768915176, L5: 0.004709594417363405
Epoch 6000, Loss: 0.27148932218551636, Losses: L1: 0.04759451746940613, L2: 0.02956426702439785, L3: 0.04731076955795288, L4: 0.09499053657054901, L5: 0.004718479700386524
Epoch 6500, Loss: 0.2706829607486725, Losses: L1: 0.047474779188632965, L2: 0.029447557404637337, L3: 0.04728138446807861, L4: 0.09447857737541199, L5: 0.004719273187220097
Epoch 7000, Loss: 0.2693527638912201, Losses: L1: 0.04749954491853714, L2: 0.02932652458548546, L3: 0.04723858833312988, L4: 0.09332499653100967, L5: 0.004724525380879641
Epoch 7500, Loss: 0.2687438130378723, Losses: L1: 0.04743410646915436, L2: 0.02929370105266571, L3: 0.047202348709106445, L4: 0.09288531541824341, L5: 0.00472599919885397
Epoch 8000, Loss: 0.26824095845222473, Losses: L1: 0.0474221296608448, L2: 0.029249101877212524, L3: 0.047179996967315674, L4: 0.09248153120279312, L5: 0.0047282008454203606
Epoch 8500, Loss: 0.2678501009941101, Losses: L1: 0.0474015511572361, L2: 0.029239553958177567, L3: 0.047163963317871094, L4: 0.09215189516544342, L5: 0.004729163367301226
Epoch 9000, Loss: 0.26760801672935486, Losses: L1: 0.04740859940648079, L2: 0.02921772003173828, L3: 0.047149837017059326, L4: 0.0919528603553772, L5: 0.004729168489575386
Epoch 9500, Loss: 0.2674536406993866, Losses: L1: 0.04738365113735199, L2: 0.02921481244266033, L3: 0.047141075134277344, L4: 0.09184364974498749, L5: 0.004729359410703182
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0179827213287354, Constraint losses: L1: 17.494657516479492, L2: 0.00021996146824676543, L3: 1.0001341104507446, L4: 1.000133991241455
Epoch 500, Loss: 0.002264847746118903, Constraint losses: L1: -1.0974231958389282, L2: 0.0, L3: 0.002680182456970215, L4: 0.0006820885464549065
Epoch 1000, Loss: 0.0013210680335760117, Constraint losses: L1: -1.1147925853729248, L2: 0.0, L3: 0.0022176504135131836, L4: 0.000218210305320099
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.023527145385742, Constraint losses: L1: 18.42068099975586, L2: 0.0017020211089402437, L3: 1.001702070236206, L4: 1.0017023086547852
Epoch 500, Loss: 0.00231088325381279, Constraint losses: L1: -1.0199531316757202, L2: 0.0, L3: 0.0026645660400390625, L4: 0.000666270439978689
Epoch 1000, Loss: 0.0013760646106675267, Constraint losses: L1: -1.0511062145233154, L2: 0.0, L3: 0.00221329927444458, L4: 0.00021387157903518528
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 97.61581420898438, Losses: L1: 17.122922897338867, L2: 0.0010691167553886771, L3: 1.0010164976119995, L4: 77.85928344726562, L5: 0.3152529299259186
Epoch 500, Loss: 2.9697957038879395, Losses: L1: 0.28935083746910095, L2: 0.07905184477567673, L3: 0.0811009407043457, L4: 2.4017980098724365, L5: 0.0186964999884367
Epoch 1000, Loss: 2.099322557449341, Losses: L1: 0.34278231859207153, L2: 0.08846266567707062, L3: 0.08359599113464355, L4: 1.470906138420105, L5: 0.014989782124757767
Epoch 1500, Loss: 1.3870846033096313, Losses: L1: 0.2002066671848297, L2: 0.050182268023490906, L3: 0.06843411922454834, L4: 0.9794408082962036, L5: 0.01019327063113451
Epoch 2000, Loss: 2.7077584266662598, Losses: L1: 0.36751672625541687, L2: 0.06403756886720657, L3: 0.0750969648361206, L4: 2.0732593536376953, L5: 0.0263754203915596
Epoch 2500, Loss: 1.4063535928726196, Losses: L1: 0.2964206635951996, L2: 0.060391832143068314, L3: 0.0663079023361206, L4: 0.8850142359733582, L5: 0.015955479815602303
Epoch 3000, Loss: 1.2897226810455322, Losses: L1: 0.26909205317497253, L2: 0.051488738507032394, L3: 0.06845581531524658, L4: 0.803117573261261, L5: 0.014556347392499447
Epoch 3500, Loss: 0.8728306293487549, Losses: L1: 0.2747741937637329, L2: 0.052151184529066086, L3: 0.06668239831924438, L4: 0.3896697163581848, L5: 0.011435394175350666
Epoch 4000, Loss: 0.8285751938819885, Losses: L1: 0.25734829902648926, L2: 0.05116774141788483, L3: 0.0656362771987915, L4: 0.366018682718277, L5: 0.011383984237909317
Epoch 4500, Loss: 0.7982261776924133, Losses: L1: 0.2561856806278229, L2: 0.050306230783462524, L3: 0.06530880928039551, L4: 0.3383096754550934, L5: 0.011403476819396019
Epoch 5000, Loss: 0.7857632637023926, Losses: L1: 0.25660932064056396, L2: 0.049614839255809784, L3: 0.06498360633850098, L4: 0.3271300494670868, L5: 0.011220925487577915
Epoch 5500, Loss: 0.7787221074104309, Losses: L1: 0.2571999430656433, L2: 0.04914801940321922, L3: 0.06464797258377075, L4: 0.32094064354896545, L5: 0.011068801395595074
Epoch 6000, Loss: 0.773829460144043, Losses: L1: 0.2576029300689697, L2: 0.0487709566950798, L3: 0.0644267201423645, L4: 0.3166174590587616, L5: 0.010992337018251419
Epoch 6500, Loss: 0.7705053091049194, Losses: L1: 0.25737249851226807, L2: 0.04858754202723503, L3: 0.06427425146102905, L4: 0.3142184913158417, L5: 0.010889147408306599
Epoch 7000, Loss: 0.7681871056556702, Losses: L1: 0.25735706090927124, L2: 0.04840194806456566, L3: 0.06420594453811646, L4: 0.31224411725997925, L5: 0.010886051692068577
Epoch 7500, Loss: 0.7663543820381165, Losses: L1: 0.2573639154434204, L2: 0.04831862822175026, L3: 0.06412816047668457, L4: 0.3106914460659027, L5: 0.010862020775675774
Epoch 8000, Loss: 0.765279233455658, Losses: L1: 0.257473886013031, L2: 0.048249028623104095, L3: 0.06406599283218384, L4: 0.30975067615509033, L5: 0.010836798697710037
Epoch 8500, Loss: 0.7643668055534363, Losses: L1: 0.25761619210243225, L2: 0.048157088458538055, L3: 0.06404232978820801, L4: 0.30885785818099976, L5: 0.01082549523562193
Epoch 9000, Loss: 0.7637699246406555, Losses: L1: 0.2576777935028076, L2: 0.04811488091945648, L3: 0.06401360034942627, L4: 0.30831557512283325, L5: 0.010817233473062515
Epoch 9500, Loss: 0.7633458375930786, Losses: L1: 0.25769713521003723, L2: 0.04808885231614113, L3: 0.06399071216583252, L4: 0.30796658992767334, L5: 0.010805892758071423
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0340380668640137, Constraint losses: L1: 18.42068099975586, L2: 0.005205471068620682, L3: 1.005205512046814, L4: 1.0052062273025513
Epoch 500, Loss: 0.002281501656398177, Constraint losses: L1: -1.0800548791885376, L2: 0.0, L3: 0.002679884433746338, L4: 0.0006816721870563924
Epoch 1000, Loss: 0.001311772153712809, Constraint losses: L1: -1.1185822486877441, L2: 0.0, L3: 0.002214968204498291, L4: 0.00021538625878747553
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.02199125289917, Constraint losses: L1: 18.42068099975586, L2: 0.0011901156976819038, L3: 1.0011900663375854, L4: 1.0011903047561646
Epoch 500, Loss: 0.0022824269253760576, Constraint losses: L1: -1.0395954847335815, L2: 0.0, L3: 0.002660214900970459, L4: 0.0006618075422011316
Epoch 1000, Loss: 0.00138632592279464, Constraint losses: L1: -1.05099356174469, L2: 0.0, L3: 0.0022183656692504883, L4: 0.00021895380632486194
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 150.84339904785156, Losses: L1: 6.38067102432251, L2: 3.7906305806245655e-05, L3: 0.9971802234649658, L4: 71.16543579101562, L5: 0.274920254945755
Epoch 500, Loss: 24.448280334472656, Losses: L1: 5.33156156539917, L2: 0.21052929759025574, L3: 0.293768048286438, L4: 9.143533706665039, L5: 0.06317250430583954
Epoch 1000, Loss: 4.155206680297852, Losses: L1: 0.8005438446998596, L2: 0.12814964354038239, L3: 0.07714438438415527, L4: 1.5313984155654907, L5: 0.01885543204843998
Epoch 1500, Loss: 4.535321235656738, Losses: L1: 0.7526664137840271, L2: 0.07647203654050827, L3: 0.06427109241485596, L4: 1.7857208251953125, L5: 0.012397832237184048
Epoch 2000, Loss: 2.3726415634155273, Losses: L1: 0.49014967679977417, L2: 0.04249953851103783, L3: 0.06771266460418701, L4: 0.8435736894607544, L5: 0.034838952124118805
Epoch 2500, Loss: 2.5130984783172607, Losses: L1: 0.38281941413879395, L2: 0.043347105383872986, L3: 0.06112515926361084, L4: 0.9737805724143982, L5: 0.03424125909805298
Epoch 3000, Loss: 1.357632040977478, Losses: L1: 0.32972294092178345, L2: 0.04117169231176376, L3: 0.05892527103424072, L4: 0.42728516459465027, L5: 0.028633037582039833
Epoch 3500, Loss: 1.3102325201034546, Losses: L1: 0.2911732494831085, L2: 0.04262244328856468, L3: 0.056980013847351074, L4: 0.4247514307498932, L5: 0.025947758927941322
Epoch 4000, Loss: 1.0954686403274536, Losses: L1: 0.274962842464447, L2: 0.03866737335920334, L3: 0.05702155828475952, L4: 0.32750481367111206, L5: 0.025571255013346672
Epoch 4500, Loss: 1.020398736000061, Losses: L1: 0.2614443004131317, L2: 0.03806258365511894, L3: 0.05666840076446533, L4: 0.2974831461906433, L5: 0.025177594274282455
Epoch 5000, Loss: 0.9899345636367798, Losses: L1: 0.2518385350704193, L2: 0.03784939646720886, L3: 0.056394338607788086, L4: 0.2875843048095703, L5: 0.024578683078289032
Epoch 5500, Loss: 0.9685426354408264, Losses: L1: 0.24563086032867432, L2: 0.03764534741640091, L3: 0.0561983585357666, L4: 0.28040605783462524, L5: 0.024115240201354027
Epoch 6000, Loss: 0.9531768560409546, Losses: L1: 0.24107706546783447, L2: 0.037517793476581573, L3: 0.05604970455169678, L4: 0.27528929710388184, L5: 0.023807965219020844
Epoch 6500, Loss: 0.9416393041610718, Losses: L1: 0.23806652426719666, L2: 0.03741076588630676, L3: 0.055938005447387695, L4: 0.27123814821243286, L5: 0.02361941523849964
Epoch 7000, Loss: 0.9337519407272339, Losses: L1: 0.23548343777656555, L2: 0.03735807165503502, L3: 0.05585688352584839, L4: 0.26874154806137085, L5: 0.02342711016535759
Epoch 7500, Loss: 0.9273691773414612, Losses: L1: 0.23396745324134827, L2: 0.037329912185668945, L3: 0.055782437324523926, L4: 0.26642027497291565, L5: 0.023332765325903893
Epoch 8000, Loss: 0.9227757453918457, Losses: L1: 0.2327367067337036, L2: 0.0373363271355629, L3: 0.05572575330734253, L4: 0.2648155689239502, L5: 0.023240048438310623
Epoch 8500, Loss: 0.9194703102111816, Losses: L1: 0.23186573386192322, L2: 0.03732209652662277, L3: 0.05568724870681763, L4: 0.2636588215827942, L5: 0.023180734366178513
Epoch 9000, Loss: 0.9169940948486328, Losses: L1: 0.23111629486083984, L2: 0.037349339574575424, L3: 0.05565083026885986, L4: 0.26283150911331177, L5: 0.023127565160393715
Epoch 9500, Loss: 0.9152184128761292, Losses: L1: 0.23063740134239197, L2: 0.03734740614891052, L3: 0.05562889575958252, L4: 0.2622148394584656, L5: 0.023092223331332207
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0749926567077637, Constraint losses: L1: 18.42068099975586, L2: 0.01885553076863289, L3: 1.0188555717468262, L4: 1.0188608169555664
Epoch 500, Loss: 0.0023694303818047047, Constraint losses: L1: -1.1146799325942993, L2: 0.0, L3: 0.002741217613220215, L4: 0.0007428928511217237
Epoch 1000, Loss: 0.0013737148838117719, Constraint losses: L1: -1.1184136867523193, L2: 0.0, L3: 0.002245783805847168, L4: 0.0002463448327034712
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0193934440612793, Constraint losses: L1: 18.42068099975586, L2: 0.00032434772583656013, L3: 1.0003243684768677, L4: 1.000324010848999
Epoch 500, Loss: 0.002232171595096588, Constraint losses: L1: -1.010849952697754, L2: 0.0, L3: 0.002620518207550049, L4: 0.0006225034012459219
Epoch 1000, Loss: 0.0013484423980116844, Constraint losses: L1: -1.0503026247024536, L2: 0.0, L3: 0.0021990537643432617, L4: 0.00019969124696217477
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 174.42276000976562, Losses: L1: 9.249484062194824, L2: 0.00033876922680065036, L3: 0.9984341859817505, L4: 81.41886138916016, L5: 0.3383554518222809
Epoch 500, Loss: 20.279226303100586, Losses: L1: 8.048136711120605, L2: 0.8378155827522278, L3: 0.2104724645614624, L4: 5.463376045227051, L5: 0.045575305819511414
Epoch 1000, Loss: 29.50251579284668, Losses: L1: 4.694672107696533, L2: 0.1762857437133789, L3: 0.3313555121421814, L4: 11.953160285949707, L5: 0.06252589821815491
Epoch 1500, Loss: 14.851348876953125, Losses: L1: 1.1948381662368774, L2: 0.02182832919061184, L3: 0.19277268648147583, L4: 6.609343528747559, L5: 0.030449578538537025
Epoch 2000, Loss: 109.84432220458984, Losses: L1: 7.565910339355469, L2: 0.0017017669742926955, L3: 0.9965241551399231, L4: 50.017051696777344, L5: 0.2495594173669815
Epoch 2500, Loss: 33.820068359375, Losses: L1: 6.067285537719727, L2: 0.9486317038536072, L3: 0.3185187578201294, L4: 13.014063835144043, L5: 0.13898508250713348
Epoch 3000, Loss: 22.593231201171875, Losses: L1: 4.577904224395752, L2: 0.6314594745635986, L3: 0.3145805597305298, L4: 8.326001167297363, L5: 0.10270316898822784
Epoch 3500, Loss: 22.59332847595215, Losses: L1: 4.8966965675354, L2: 0.4708600342273712, L3: 0.2462019920349121, L4: 8.31851577758789, L5: 0.09633702039718628
Epoch 4000, Loss: 19.776134490966797, Losses: L1: 4.80618953704834, L2: 0.4913107752799988, L3: 0.29371488094329834, L4: 6.9011664390563965, L5: 0.08887050300836563
Epoch 4500, Loss: 19.036739349365234, Losses: L1: 4.893723964691162, L2: 0.5071635842323303, L3: 0.3062087893486023, L4: 6.465251922607422, L5: 0.09292998164892197
Epoch 5000, Loss: 17.56590461730957, Losses: L1: 4.858147144317627, L2: 0.4783165752887726, L3: 0.29993295669555664, L4: 5.771182060241699, L5: 0.08720950782299042
Epoch 5500, Loss: 16.981149673461914, Losses: L1: 4.805540084838867, L2: 0.527063250541687, L3: 0.2848855257034302, L4: 5.490993499755859, L5: 0.09678862988948822
Epoch 6000, Loss: 16.574975967407227, Losses: L1: 4.724558353424072, L2: 0.5607127547264099, L3: 0.2955477237701416, L4: 5.298779487609863, L5: 0.1010495126247406
Epoch 6500, Loss: 16.378894805908203, Losses: L1: 4.719631195068359, L2: 0.5716521739959717, L3: 0.29297494888305664, L4: 5.199732780456543, L5: 0.1021963357925415
Epoch 7000, Loss: 16.2141170501709, Losses: L1: 4.709053039550781, L2: 0.5810737013816833, L3: 0.29032325744628906, L4: 5.119887828826904, L5: 0.10356666892766953
Epoch 7500, Loss: 16.090068817138672, Losses: L1: 4.700591564178467, L2: 0.5855592489242554, L3: 0.2878074645996094, L4: 5.06224250793457, L5: 0.10381701588630676
Epoch 8000, Loss: 15.973691940307617, Losses: L1: 4.707484722137451, L2: 0.5905511379241943, L3: 0.2874075770378113, L4: 4.998112201690674, L5: 0.10461598634719849
Epoch 8500, Loss: 15.888509750366211, Losses: L1: 4.706281661987305, L2: 0.5943630933761597, L3: 0.28624510765075684, L4: 4.955180644989014, L5: 0.10501307994127274
Epoch 9000, Loss: 15.832231521606445, Losses: L1: 4.705977916717529, L2: 0.5960445404052734, L3: 0.2852383852005005, L4: 4.927256107330322, L5: 0.10521981865167618
Epoch 9500, Loss: 15.798734664916992, Losses: L1: 4.706128120422363, L2: 0.5970278978347778, L3: 0.28447842597961426, L4: 4.910630226135254, L5: 0.10536164045333862
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021172523498535, Constraint losses: L1: 18.42068099975586, L2: 0.0009171843994408846, L3: 1.0009171962738037, L4: 1.0009173154830933
Epoch 500, Loss: 0.002219653222709894, Constraint losses: L1: -1.0030505657196045, L2: 0.0, L3: 0.0026102662086486816, L4: 0.0006124377250671387
Epoch 1000, Loss: 0.0012656085891649127, Constraint losses: L1: -1.1094427108764648, L2: 0.0, L3: 0.002187192440032959, L4: 0.00018785895372275263
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0239992141723633, Constraint losses: L1: 18.42068099975586, L2: 0.0018594120629131794, L3: 1.001859426498413, L4: 1.0018595457077026
Epoch 500, Loss: 0.002169312909245491, Constraint losses: L1: -0.8985261917114258, L2: 0.0, L3: 0.002532780170440674, L4: 0.0005350589053705335
Epoch 1000, Loss: 0.001260257326066494, Constraint losses: L1: -1.0480754375457764, L2: 0.0, L3: 0.0021538734436035156, L4: 0.00015445936878677458
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 168.42332458496094, Losses: L1: 5.3816328048706055, L2: 0.0, L3: 0.9952471256256104, L4: 80.19486999511719, L5: 0.33072391152381897
Epoch 500, Loss: 6.310504913330078, Losses: L1: 0.24745389819145203, L2: 0.038439273834228516, L3: 0.07786834239959717, L4: 2.911119222640991, L5: 0.023318326100707054
Epoch 1000, Loss: 6.516055583953857, Losses: L1: 0.17906096577644348, L2: 0.016345329582691193, L3: 0.06890290975570679, L4: 3.077153444290161, L5: 0.014268497936427593
Epoch 1500, Loss: 3.338195323944092, Losses: L1: 0.23053021728992462, L2: 0.05920154228806496, L3: 0.06628763675689697, L4: 1.43609619140625, L5: 0.021847955882549286
Epoch 2000, Loss: 0.9798129796981812, Losses: L1: 0.12255292385816574, L2: 0.045375436544418335, L3: 0.05672657489776611, L4: 0.343506783246994, L5: 0.005708927288651466
Epoch 2500, Loss: 0.722287118434906, Losses: L1: 0.07114452123641968, L2: 0.03741375729441643, L3: 0.05259197950363159, L4: 0.24859392642974854, L5: 0.005678517743945122
Epoch 3000, Loss: 0.6139271855354309, Losses: L1: 0.06557365506887436, L2: 0.035012487322092056, L3: 0.04985994100570679, L4: 0.2016392946243286, L5: 0.005171259865164757
Epoch 3500, Loss: 0.4768681228160858, Losses: L1: 0.06568089872598648, L2: 0.03282248601317406, L3: 0.04870891571044922, L4: 0.13526004552841187, L5: 0.005213412921875715
Epoch 4000, Loss: 0.4643198251724243, Losses: L1: 0.06418939679861069, L2: 0.03169526532292366, L3: 0.04822981357574463, L4: 0.1309833526611328, L5: 0.005004399921745062
Epoch 4500, Loss: 0.47318458557128906, Losses: L1: 0.06708239763975143, L2: 0.029796693474054337, L3: 0.048027634620666504, L4: 0.1350458264350891, L5: 0.005079283379018307
Epoch 5000, Loss: 0.41208040714263916, Losses: L1: 0.06672550737857819, L2: 0.02965508960187435, L3: 0.047896623611450195, L4: 0.10492706298828125, L5: 0.005026215221732855
Epoch 5500, Loss: 0.3988533318042755, Losses: L1: 0.06701001524925232, L2: 0.02969473786652088, L3: 0.04773229360580444, L4: 0.09830539673566818, L5: 0.005036613438278437
Epoch 6000, Loss: 0.396213173866272, Losses: L1: 0.06705415993928909, L2: 0.029552532359957695, L3: 0.04765629768371582, L4: 0.09710429608821869, L5: 0.00504263723269105
Epoch 6500, Loss: 0.3934515714645386, Losses: L1: 0.06708469986915588, L2: 0.029368914663791656, L3: 0.04762202501296997, L4: 0.0958336740732193, L5: 0.005043289624154568
Epoch 7000, Loss: 0.3918403089046478, Losses: L1: 0.06708364933729172, L2: 0.02928430773317814, L3: 0.047589242458343506, L4: 0.095099076628685, L5: 0.005047855898737907
Epoch 7500, Loss: 0.39059725403785706, Losses: L1: 0.06703848391771317, L2: 0.02926560305058956, L3: 0.047553420066833496, L4: 0.09453880786895752, L5: 0.005054353736341
Epoch 8000, Loss: 0.3896668255329132, Losses: L1: 0.06698508560657501, L2: 0.02925424464046955, L3: 0.047529757022857666, L4: 0.09412511438131332, L5: 0.005058868322521448
Epoch 8500, Loss: 0.38904088735580444, Losses: L1: 0.06694972515106201, L2: 0.029239268973469734, L3: 0.047513723373413086, L4: 0.09384983777999878, L5: 0.00506239291280508
Epoch 9000, Loss: 0.38852107524871826, Losses: L1: 0.06690189242362976, L2: 0.02924305573105812, L3: 0.04750192165374756, L4: 0.09362106770277023, L5: 0.0050650788471102715
Epoch 9500, Loss: 0.38817381858825684, Losses: L1: 0.06689716130495071, L2: 0.029242616146802902, L3: 0.04749119281768799, L4: 0.09345874190330505, L5: 0.005067072808742523
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0346670150756836, Constraint losses: L1: 18.42068099975586, L2: 0.00541515089571476, L3: 1.0054152011871338, L4: 1.0054161548614502
Epoch 500, Loss: 0.00210060877725482, Constraint losses: L1: -1.1141941547393799, L2: 0.0, L3: 0.002606630325317383, L4: 0.0006081725005060434
Epoch 1000, Loss: 0.0012851881328970194, Constraint losses: L1: -1.1173083782196045, L2: 0.0, L3: 0.0022009611129760742, L4: 0.00020153542573098093
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9916234016418457, Constraint losses: L1: 4.942666530609131, L2: 0.0, L3: 0.9933412075042725, L4: 0.993339478969574
Epoch 500, Loss: 0.002345611108466983, Constraint losses: L1: -1.0328043699264526, L2: 0.0, L3: 0.0026882290840148926, L4: 0.000690186396241188
Epoch 1000, Loss: 0.0013907898683100939, Constraint losses: L1: -1.049937129020691, L2: 0.0, L3: 0.0022200345993041992, L4: 0.0002206925128120929
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.621097564697266, Losses: L1: 11.43204116821289, L2: 0.0007083597010932863, L3: 0.9996621012687683, L4: 75.0768814086914, L5: 0.29873499274253845
Epoch 500, Loss: 16.191875457763672, Losses: L1: 1.1333119869232178, L2: 0.05901087448000908, L3: 0.3361334800720215, L4: 29.426647186279297, L5: 0.11830297857522964
Epoch 1000, Loss: 3.641866683959961, Losses: L1: 0.9218053221702576, L2: 0.11582832038402557, L3: 0.12142443656921387, L4: 4.828705310821533, L5: 0.026679906994104385
Epoch 1500, Loss: 3.9261763095855713, Losses: L1: 1.4690132141113281, L2: 0.12227277457714081, L3: 0.14540475606918335, L4: 4.262582778930664, L5: 0.017247674986720085
Epoch 2000, Loss: 1.7330795526504517, Losses: L1: 0.6610848903656006, L2: 0.09032181650400162, L3: 0.11126244068145752, L4: 1.6459534168243408, L5: 0.025486236438155174
Epoch 2500, Loss: 1.5158973932266235, Losses: L1: 0.5611191391944885, L2: 0.0910487100481987, L3: 0.0988430380821228, L4: 1.426628589630127, L5: 0.019890090450644493
Epoch 3000, Loss: 1.358239769935608, Losses: L1: 0.5750664472579956, L2: 0.07698310166597366, L3: 0.09960836172103882, L4: 1.1346102952957153, L5: 0.024195333942770958
Epoch 3500, Loss: 1.3029783964157104, Losses: L1: 0.5812067985534668, L2: 0.0743800699710846, L3: 0.09685087203979492, L4: 1.026780128479004, L5: 0.022392014041543007
Epoch 4000, Loss: 1.2585221529006958, Losses: L1: 0.5891909599304199, L2: 0.07149223983287811, L3: 0.09452778100967407, L4: 0.9346206188201904, L5: 0.023545116186141968
Epoch 4500, Loss: 1.1349432468414307, Losses: L1: 0.49520254135131836, L2: 0.06859443336725235, L3: 0.09177875518798828, L4: 0.8897684812545776, L5: 0.023556578904390335
Epoch 5000, Loss: 1.1146916151046753, Losses: L1: 0.4803760051727295, L2: 0.0681159570813179, L3: 0.08512187004089355, L4: 0.8836051225662231, L5: 0.027440426871180534
Epoch 5500, Loss: 1.0283504724502563, Losses: L1: 0.44440633058547974, L2: 0.0640997663140297, L3: 0.08897942304611206, L4: 0.7978858947753906, L5: 0.02462378516793251
Epoch 6000, Loss: 1.0206621885299683, Losses: L1: 0.4455924928188324, L2: 0.06374401599168777, L3: 0.08804190158843994, L4: 0.7828837633132935, L5: 0.02423756755888462
Epoch 6500, Loss: 1.014038324356079, Losses: L1: 0.44758039712905884, L2: 0.06323123723268509, L3: 0.08757525682449341, L4: 0.7680054903030396, L5: 0.024410292506217957
Epoch 7000, Loss: 1.009765863418579, Losses: L1: 0.4477541744709015, L2: 0.06318078190088272, L3: 0.08716630935668945, L4: 0.7601470947265625, L5: 0.02398688532412052
Epoch 7500, Loss: 1.0050842761993408, Losses: L1: 0.44812148809432983, L2: 0.06305788457393646, L3: 0.08689475059509277, L4: 0.7507327795028687, L5: 0.024066485464572906
Epoch 8000, Loss: 1.0033416748046875, Losses: L1: 0.44800445437431335, L2: 0.06306339055299759, L3: 0.08667492866516113, L4: 0.747765064239502, L5: 0.02398080751299858
Epoch 8500, Loss: 1.0019385814666748, Losses: L1: 0.44793960452079773, L2: 0.06302964687347412, L3: 0.08652108907699585, L4: 0.7453916072845459, L5: 0.023966435343027115
Epoch 9000, Loss: 1.0009877681732178, Losses: L1: 0.44778934121131897, L2: 0.06304404884576797, L3: 0.08640223741531372, L4: 0.7438886165618896, L5: 0.023929838091135025
Epoch 9500, Loss: 1.0003361701965332, Losses: L1: 0.44767752289772034, L2: 0.06304855644702911, L3: 0.0863180160522461, L4: 0.7428975701332092, L5: 0.02390735037624836
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020066738128662, Constraint losses: L1: 18.42068099975586, L2: 0.0005487041780725121, L3: 1.0005487203598022, L4: 1.0005486011505127
Epoch 500, Loss: 0.002384423278272152, Constraint losses: L1: -1.1070884466171265, L2: 0.0, L3: 0.0027446746826171875, L4: 0.000746837118640542
Epoch 1000, Loss: 0.0013703461736440659, Constraint losses: L1: -1.1167268753051758, L2: 0.0, L3: 0.0022431612014770508, L4: 0.00024391181068494916
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0042293071746826, Constraint losses: L1: 6.707632064819336, L2: 0.0, L3: 0.9987608790397644, L4: 0.9987608790397644
Epoch 500, Loss: 0.0022247275337576866, Constraint losses: L1: -0.9931701421737671, L2: 0.0, L3: 0.002608001232147217, L4: 0.0006098963785916567
Epoch 1000, Loss: 0.001332998275756836, Constraint losses: L1: -1.0505633354187012, L2: 0.0, L3: 0.002191483974456787, L4: 0.0001920777722261846
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.55241394042969, Losses: L1: 13.605870246887207, L2: 0.00042788026621565223, L3: 1.000227689743042, L4: 70.3675537109375, L5: 0.26179763674736023
Epoch 500, Loss: 10.764801979064941, Losses: L1: 4.519185543060303, L2: 0.6388371586799622, L3: 0.28539156913757324, L4: 9.473638534545898, L5: 0.08842725306749344
Epoch 1000, Loss: 6.6084771156311035, Losses: L1: 3.171888589859009, L2: 0.2518317699432373, L3: 0.22857201099395752, L4: 5.519139289855957, L5: 0.05906928703188896
Epoch 1500, Loss: 15.920072555541992, Losses: L1: 6.514707565307617, L2: 0.5187327861785889, L3: 0.2675968408584595, L4: 16.310392379760742, L5: 0.07890553027391434
Epoch 2000, Loss: 4.5412983894348145, Losses: L1: 1.5425207614898682, L2: 0.044742122292518616, L3: 0.21280813217163086, L4: 5.521007061004639, L5: 0.04238550737500191
Epoch 2500, Loss: 3.445915460586548, Losses: L1: 1.4585635662078857, L2: 0.036024294793605804, L3: 0.18144965171813965, L4: 3.5736117362976074, L5: 0.037772685289382935
Epoch 3000, Loss: 2.9261343479156494, Losses: L1: 1.44015371799469, L2: 0.028959324583411217, L3: 0.14531195163726807, L4: 2.6531476974487305, L5: 0.02883211523294449
Epoch 3500, Loss: 2.3318710327148438, Losses: L1: 1.003013253211975, L2: 0.02069002203643322, L3: 0.1318492889404297, L4: 2.3942477703094482, L5: 0.024429306387901306
Epoch 4000, Loss: 1.9464290142059326, Losses: L1: 0.8278666138648987, L2: 0.022618526592850685, L3: 0.1258084774017334, L4: 1.9811257123947144, L5: 0.019858205690979958
Epoch 4500, Loss: 1.6306136846542358, Losses: L1: 0.5712398886680603, L2: 0.026444271206855774, L3: 0.12032151222229004, L4: 1.8559129238128662, L5: 0.018368056043982506
Epoch 5000, Loss: 1.5218080282211304, Losses: L1: 0.5375472903251648, L2: 0.02970481477677822, L3: 0.11746996641159058, L4: 1.6989712715148926, L5: 0.01663053222000599
Epoch 5500, Loss: 1.4751611948013306, Losses: L1: 0.5271331667900085, L2: 0.031772270798683167, L3: 0.11534130573272705, L4: 1.6209874153137207, L5: 0.016319159418344498
Epoch 6000, Loss: 1.4435147047042847, Losses: L1: 0.5197054743766785, L2: 0.033326953649520874, L3: 0.11389708518981934, L4: 1.5683157444000244, L5: 0.01604894921183586
Epoch 6500, Loss: 1.4209219217300415, Losses: L1: 0.5145122408866882, L2: 0.034326426684856415, L3: 0.11304700374603271, L4: 1.5307537317276, L5: 0.015856340527534485
Epoch 7000, Loss: 1.4048490524291992, Losses: L1: 0.5109959244728088, L2: 0.03507391735911369, L3: 0.1124112606048584, L4: 1.503600835800171, L5: 0.015699295327067375
Epoch 7500, Loss: 1.3934520483016968, Losses: L1: 0.5077931880950928, L2: 0.035645678639411926, L3: 0.11208438873291016, L4: 1.4855668544769287, L5: 0.015541933476924896
Epoch 8000, Loss: 1.3855571746826172, Losses: L1: 0.5051085352897644, L2: 0.03620370849967003, L3: 0.11179327964782715, L4: 1.4735126495361328, L5: 0.01538819819688797
Epoch 8500, Loss: 1.3799023628234863, Losses: L1: 0.5034505724906921, L2: 0.03658038377761841, L3: 0.11158990859985352, L4: 1.4644334316253662, L5: 0.015279280953109264
Epoch 9000, Loss: 1.3758217096328735, Losses: L1: 0.502335786819458, L2: 0.03685089200735092, L3: 0.11142921447753906, L4: 1.457711935043335, L5: 0.015213560312986374
Epoch 9500, Loss: 1.3728832006454468, Losses: L1: 0.5015926957130432, L2: 0.037068236619234085, L3: 0.1113082766532898, L4: 1.4526736736297607, L5: 0.015163079835474491
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0020029544830322, Constraint losses: L1: 6.137001037597656, L2: 0.0, L3: 0.9979333281517029, L4: 0.9979326128959656
Epoch 500, Loss: 0.001932539395056665, Constraint losses: L1: -1.0821287631988525, L2: 0.0, L3: 0.0025064945220947266, L4: 0.0005081737181171775
Epoch 1000, Loss: 0.001199380960315466, Constraint losses: L1: -1.1178885698318481, L2: 0.0, L3: 0.0021584033966064453, L4: 0.00015886613982729614
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0268959999084473, Constraint losses: L1: 18.42068099975586, L2: 0.0028250371105968952, L3: 1.0028250217437744, L4: 1.002825140953064
Epoch 500, Loss: 0.0022110608406364918, Constraint losses: L1: -1.0159064531326294, L2: 0.0, L3: 0.0026127099990844727, L4: 0.0006142571801319718
Epoch 1000, Loss: 0.0013387958751991391, Constraint losses: L1: -1.0503730773925781, L2: 0.0, L3: 0.002194344997406006, L4: 0.00019482395146042109
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 55.891971588134766, Losses: L1: 17.22209930419922, L2: 0.0018402183195576072, L3: 1.001724362373352, L4: 75.1595687866211, L5: 0.29277318716049194
Epoch 500, Loss: 30.396345138549805, Losses: L1: 4.353348731994629, L2: 0.005559230223298073, L3: 0.9649882912635803, L4: 50.20262145996094, L5: 0.22403623163700104
Epoch 1000, Loss: 32.80100631713867, Losses: L1: 6.715738296508789, L2: 0.05853157117962837, L3: 1.0025440454483032, L4: 49.9607048034668, L5: 0.24329085648059845
Epoch 1500, Loss: 24.40812873840332, Losses: L1: 3.769623279571533, L2: 0.10547951608896255, L3: 0.9941098690032959, L4: 39.29801940917969, L5: 0.14074011147022247
Epoch 2000, Loss: 7.266112327575684, Losses: L1: 2.781383752822876, L2: 0.09112927317619324, L3: 0.28142499923706055, L4: 8.188417434692383, L5: 0.03377443924546242
Epoch 2500, Loss: 25.13053321838379, Losses: L1: 4.9383649826049805, L2: 0.16785861551761627, L3: 1.0003187656402588, L4: 38.069610595703125, L5: 0.16074304282665253
Epoch 3000, Loss: 25.10976219177246, Losses: L1: 4.60179328918457, L2: 0.15460871160030365, L3: 1.0045822858810425, L4: 38.73973083496094, L5: 0.16329734027385712
Epoch 3500, Loss: 25.059432983398438, Losses: L1: 4.503345489501953, L2: 0.16317585110664368, L3: 1.005367636680603, L4: 38.794166564941406, L5: 0.1649843156337738
Epoch 4000, Loss: 25.04473876953125, Losses: L1: 4.482388019561768, L2: 0.16588924825191498, L3: 1.0056655406951904, L4: 38.79632568359375, L5: 0.16478784382343292
Epoch 4500, Loss: 25.036670684814453, Losses: L1: 4.4746575355529785, L2: 0.16716653108596802, L3: 1.0058281421661377, L4: 38.7906494140625, L5: 0.16472016274929047
Epoch 5000, Loss: 25.0317325592041, Losses: L1: 4.470096111297607, L2: 0.16774696111679077, L3: 1.0058937072753906, L4: 38.78794479370117, L5: 0.1646115630865097
Epoch 5500, Loss: 25.028371810913086, Losses: L1: 4.467411518096924, L2: 0.16815751791000366, L3: 1.0059406757354736, L4: 38.784881591796875, L5: 0.16461631655693054
Epoch 6000, Loss: 25.026002883911133, Losses: L1: 4.465464115142822, L2: 0.16836829483509064, L3: 1.0059658288955688, L4: 38.783260345458984, L5: 0.16459497809410095
Epoch 6500, Loss: 25.024246215820312, Losses: L1: 4.46373987197876, L2: 0.16844630241394043, L3: 1.0059669017791748, L4: 38.78303146362305, L5: 0.16455739736557007
Epoch 7000, Loss: 25.022953033447266, Losses: L1: 4.462800979614258, L2: 0.16853007674217224, L3: 1.005974292755127, L4: 38.781959533691406, L5: 0.16456231474876404
Epoch 7500, Loss: 25.021995544433594, Losses: L1: 4.462131023406982, L2: 0.16857849061489105, L3: 1.0059778690338135, L4: 38.78118133544922, L5: 0.16456402838230133
Epoch 8000, Loss: 25.021272659301758, Losses: L1: 4.461593151092529, L2: 0.16859795153141022, L3: 1.0059783458709717, L4: 38.78074645996094, L5: 0.16456030309200287
Epoch 8500, Loss: 25.02073097229004, Losses: L1: 4.461198329925537, L2: 0.1686081439256668, L3: 1.0059782266616821, L4: 38.780418395996094, L5: 0.16455909609794617
Epoch 9000, Loss: 25.020326614379883, Losses: L1: 4.4609293937683105, L2: 0.1686166524887085, L3: 1.005979061126709, L4: 38.78010559082031, L5: 0.16456152498722076
Epoch 9500, Loss: 25.020023345947266, Losses: L1: 4.460658073425293, L2: 0.16860732436180115, L3: 1.0059775114059448, L4: 38.78010559082031, L5: 0.16455456614494324
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.994232177734375, Constraint losses: L1: 5.152929782867432, L2: 0.0, L3: 0.9945402145385742, L4: 0.9945390224456787
Epoch 500, Loss: 0.002684980630874634, Constraint losses: L1: -1.1105774641036987, L2: 0.0, L3: 0.002896726131439209, L4: 0.0008988321060314775
Epoch 1000, Loss: 0.0014762661885470152, Constraint losses: L1: -1.118018627166748, L2: 0.0, L3: 0.0022968053817749023, L4: 0.0002974794479086995
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0196545124053955, Constraint losses: L1: 18.42068099975586, L2: 0.00041133136255666614, L3: 1.0004112720489502, L4: 1.0004112720489502
Epoch 500, Loss: 0.002417751355096698, Constraint losses: L1: -0.9891140460968018, L2: 0.0, L3: 0.0027022957801818848, L4: 0.0007045696256682277
Epoch 1000, Loss: 0.0013941817451268435, Constraint losses: L1: -1.0502121448516846, L2: 0.0, L3: 0.0022218823432922363, L4: 0.00022251161863096058
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 89.08971405029297, Losses: L1: 13.061506271362305, L2: 0.002553171245381236, L3: 1.0002576112747192, L4: 75.37626647949219, L5: 0.29340600967407227
Epoch 500, Loss: 57.74517059326172, Losses: L1: 7.017416477203369, L2: 0.0005342024378478527, L3: 0.9971744418144226, L4: 50.10324478149414, L5: 0.24970956146717072
Epoch 1000, Loss: 58.03841018676758, Losses: L1: 6.648674011230469, L2: 4.5769574796850065e-08, L3: 0.9346125721931458, L4: 50.813472747802734, L5: 0.2179177701473236
Epoch 1500, Loss: 55.686031341552734, Losses: L1: 4.033731460571289, L2: 0.0, L3: 0.9763397574424744, L4: 51.04413604736328, L5: 0.23998768627643585
Epoch 2000, Loss: 15.093506813049316, Losses: L1: 4.67004919052124, L2: 0.2705554664134979, L3: 0.2589237689971924, L4: 9.730570793151855, L5: 0.044627752155065536
Epoch 2500, Loss: 63.38308334350586, Losses: L1: 12.750860214233398, L2: 7.47621413665911e-08, L3: 0.999993622303009, L4: 50.00762939453125, L5: 0.2491905391216278
Epoch 3000, Loss: 50.56964111328125, Losses: L1: 3.106814384460449, L2: 0.0, L3: 0.8673802018165588, L4: 46.91141128540039, L5: 0.23544970154762268
Epoch 3500, Loss: 56.67049789428711, Losses: L1: 6.110713958740234, L2: 7.5518978519539814e-06, L3: 0.9968178272247314, L4: 49.939247131347656, L5: 0.24422821402549744
Epoch 4000, Loss: 14.6145658493042, Losses: L1: 3.178934335708618, L2: 0.13648326694965363, L3: 0.2150784730911255, L4: 11.034448623657227, L5: 0.04135271534323692
Epoch 4500, Loss: 8.991328239440918, Losses: L1: 3.0065505504608154, L2: 0.18261612951755524, L3: 0.21197152137756348, L4: 5.489408493041992, L5: 0.04830450192093849
Epoch 5000, Loss: 8.189323425292969, Losses: L1: 2.9608864784240723, L2: 0.2022571712732315, L3: 0.20391643047332764, L4: 4.695971488952637, L5: 0.051986437290906906
Epoch 5500, Loss: 7.823714733123779, Losses: L1: 2.9522457122802734, L2: 0.19798195362091064, L3: 0.20142704248428345, L4: 4.3486552238464355, L5: 0.052272338420152664
Epoch 6000, Loss: 7.541316986083984, Losses: L1: 2.8919899463653564, L2: 0.19245027005672455, L3: 0.19931399822235107, L4: 4.138837814331055, L5: 0.05186252295970917
Epoch 6500, Loss: 7.35468053817749, Losses: L1: 2.8042349815368652, L2: 0.18251933157444, L3: 0.19958800077438354, L4: 4.058825492858887, L5: 0.05357487499713898
Epoch 7000, Loss: 7.242593765258789, Losses: L1: 2.84865140914917, L2: 0.1846173107624054, L3: 0.1974118947982788, L4: 3.9002819061279297, L5: 0.051439445465803146
Epoch 7500, Loss: 7.165122032165527, Losses: L1: 2.846632957458496, L2: 0.18230986595153809, L3: 0.19692713022232056, L4: 3.8297834396362305, L5: 0.05124437063932419
Epoch 8000, Loss: 7.067811012268066, Losses: L1: 2.797009229660034, L2: 0.17806494235992432, L3: 0.1978885531425476, L4: 3.790330410003662, L5: 0.05079437047243118
Epoch 8500, Loss: 7.026893138885498, Losses: L1: 2.7943177223205566, L2: 0.17687006294727325, L3: 0.19743108749389648, L4: 3.7548182010650635, L5: 0.050602544099092484
Epoch 9000, Loss: 6.998075008392334, Losses: L1: 2.793008804321289, L2: 0.17603106796741486, L3: 0.19713640213012695, L4: 3.7291955947875977, L5: 0.05048072338104248
Epoch 9500, Loss: 6.977929592132568, Losses: L1: 2.7920196056365967, L2: 0.1752244532108307, L3: 0.1971205472946167, L4: 3.7116897106170654, L5: 0.05042160674929619
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9969804286956787, Constraint losses: L1: 5.44655179977417, L2: 0.0, L3: 0.9957670569419861, L4: 0.9957668781280518
Epoch 500, Loss: 0.0018914490938186646, Constraint losses: L1: -1.1133157014846802, L2: 0.0, L3: 0.00250166654586792, L4: 0.0005030984175391495
Epoch 1000, Loss: 0.001214657910168171, Constraint losses: L1: -1.11760413646698, L2: 0.0, L3: 0.002165853977203369, L4: 0.00016640813555568457
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002654552459717, Constraint losses: L1: 6.284084320068359, L2: 0.0, L3: 0.9981853365898132, L4: 0.9981850385665894
Epoch 500, Loss: 0.001964847557246685, Constraint losses: L1: -1.0374443531036377, L2: 0.0, L3: 0.0025005340576171875, L4: 0.0005017580697312951
Epoch 1000, Loss: 0.0012754097115248442, Constraint losses: L1: -1.0506128072738647, L2: 0.0, L3: 0.0021628141403198242, L4: 0.0001632084313314408
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 97.2675552368164, Losses: L1: 18.42068099975586, L2: 0.002715476555749774, L3: 1.0027154684066772, L4: 78.01976013183594, L5: 0.3203269839286804
Epoch 500, Loss: 4.4175615310668945, Losses: L1: 0.2793579399585724, L2: 0.02513337880373001, L3: 0.0786663293838501, L4: 4.027965068817139, L5: 0.020638227462768555
Epoch 1000, Loss: 1.327468752861023, Losses: L1: 0.3432556390762329, L2: 0.01957482285797596, L3: 0.05322134494781494, L4: 0.9095526933670044, L5: 0.008900066837668419
Epoch 1500, Loss: 0.6351915597915649, Losses: L1: 0.0798906609416008, L2: 0.03025488555431366, L3: 0.048751115798950195, L4: 0.46381676197052, L5: 0.006598802749067545
Epoch 2000, Loss: 0.49172016978263855, Losses: L1: 0.07698137313127518, L2: 0.030789965763688087, L3: 0.04826629161834717, L4: 0.3232671320438385, L5: 0.005758569575846195
Epoch 2500, Loss: 0.44559043645858765, Losses: L1: 0.0689711794257164, L2: 0.03050387278199196, L3: 0.046682000160217285, L4: 0.28695443272590637, L5: 0.005316071677953005
Epoch 3000, Loss: 0.3343243896961212, Losses: L1: 0.070318803191185, L2: 0.028165221214294434, L3: 0.04602015018463135, L4: 0.1789863407611847, L5: 0.005678744986653328
Epoch 3500, Loss: 0.32470443844795227, Losses: L1: 0.06767672300338745, L2: 0.027427315711975098, L3: 0.045783817768096924, L4: 0.17378342151641846, L5: 0.005497747100889683
Epoch 4000, Loss: 0.3033682107925415, Losses: L1: 0.06484219431877136, L2: 0.026908453553915024, L3: 0.04568439722061157, L4: 0.15650299191474915, L5: 0.005363925825804472
Epoch 4500, Loss: 0.24673478305339813, Losses: L1: 0.06755208969116211, L2: 0.02552672103047371, L3: 0.04555231332778931, L4: 0.09978453069925308, L5: 0.005568584892898798
Epoch 5000, Loss: 0.23321712017059326, Losses: L1: 0.0670003816485405, L2: 0.025654802098870277, L3: 0.04534709453582764, L4: 0.08670899271965027, L5: 0.005524590145796537
Epoch 5500, Loss: 0.23311765491962433, Losses: L1: 0.06649384647607803, L2: 0.025623761117458344, L3: 0.045233845710754395, L4: 0.08723623305559158, L5: 0.005523135419934988
Epoch 6000, Loss: 0.22754189372062683, Losses: L1: 0.06653894484043121, L2: 0.02533888630568981, L3: 0.0451815128326416, L4: 0.08217231184244156, L5: 0.005562092177569866
Epoch 6500, Loss: 0.22928886115550995, Losses: L1: 0.06592938303947449, L2: 0.02538752183318138, L3: 0.045145273208618164, L4: 0.08447621017694473, L5: 0.005535588134080172
Epoch 7000, Loss: 0.22382406890392303, Losses: L1: 0.06610118597745895, L2: 0.025251714512705803, L3: 0.04510575532913208, L4: 0.07910563051700592, L5: 0.005560950376093388
Epoch 7500, Loss: 0.22304654121398926, Losses: L1: 0.0660049170255661, L2: 0.025204911828041077, L3: 0.045089006423950195, L4: 0.07851961255073547, L5: 0.005567688029259443
Epoch 8000, Loss: 0.22274251282215118, Losses: L1: 0.06595484912395477, L2: 0.025170760229229927, L3: 0.0450742244720459, L4: 0.07833883166313171, L5: 0.005570196080952883
Epoch 8500, Loss: 0.2220531702041626, Losses: L1: 0.0658661276102066, L2: 0.025189906358718872, L3: 0.04505854845046997, L4: 0.07770723849534988, L5: 0.005570705980062485
Epoch 9000, Loss: 0.22180278599262238, Losses: L1: 0.0657825618982315, L2: 0.02520843967795372, L3: 0.04504692554473877, L4: 0.07750754058361053, L5: 0.005572350230067968
Epoch 9500, Loss: 0.2216278612613678, Losses: L1: 0.0657401755452156, L2: 0.025216398760676384, L3: 0.04503816366195679, L4: 0.07736215740442276, L5: 0.005573667120188475
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9960631132125854, Constraint losses: L1: 5.361954212188721, L2: 0.0, L3: 0.9953505396842957, L4: 0.9953505992889404
Epoch 500, Loss: 0.002302078064531088, Constraint losses: L1: -1.0688400268554688, L2: 0.0, L3: 0.0026844143867492676, L4: 0.0006865038303658366
Epoch 1000, Loss: 0.0013203625567257404, Constraint losses: L1: -1.1184682846069336, L2: 0.0, L3: 0.0022191405296325684, L4: 0.00021969035151414573
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0195746421813965, Constraint losses: L1: 18.42068099975586, L2: 0.0003940133028663695, L3: 1.0003799200057983, L4: 1.000380039215088
Epoch 500, Loss: 0.0025791071821004152, Constraint losses: L1: -0.9273067116737366, L2: 0.0, L3: 0.0027518868446350098, L4: 0.0007545269909314811
Epoch 1000, Loss: 0.001407993258908391, Constraint losses: L1: -1.0485106706619263, L2: 0.0, L3: 0.0022279024124145508, L4: 0.00022860166791360825
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 91.406005859375, Losses: L1: 16.452360153198242, L2: 0.0009481391753070056, L3: 1.0007297992706299, L4: 73.87553405761719, L5: 0.28792524337768555
Epoch 500, Loss: 56.17307662963867, Losses: L1: 5.3609747886657715, L2: 0.015874257311224937, L3: 0.9622125029563904, L4: 49.90697479248047, L5: 0.19613613188266754
Epoch 1000, Loss: 11.631829261779785, Losses: L1: 3.9656481742858887, L2: 0.07370773702859879, L3: 0.22732234001159668, L4: 7.2969465255737305, L5: 0.0540783666074276
Epoch 1500, Loss: 4.638707637786865, Losses: L1: 0.6888719201087952, L2: 0.05679655447602272, L3: 0.12220954895019531, L4: 3.7028486728668213, L5: 0.03614453598856926
Epoch 2000, Loss: 1.9489835500717163, Losses: L1: 0.5562466979026794, L2: 0.0670265331864357, L3: 0.10618066787719727, L4: 1.173368215560913, L5: 0.016112633049488068
Epoch 2500, Loss: 1.808538794517517, Losses: L1: 0.5014330744743347, L2: 0.06819435954093933, L3: 0.09283429384231567, L4: 1.0883591175079346, L5: 0.01797037571668625
Epoch 3000, Loss: 1.8907772302627563, Losses: L1: 0.48422980308532715, L2: 0.06206253543496132, L3: 0.09072375297546387, L4: 1.206382155418396, L5: 0.015339219011366367
Epoch 3500, Loss: 1.4101237058639526, Losses: L1: 0.3859553933143616, L2: 0.056030187755823135, L3: 0.087310791015625, L4: 0.8327335119247437, L5: 0.01785954460501671
Epoch 4000, Loss: 1.3151441812515259, Losses: L1: 0.3710080087184906, L2: 0.05564229562878609, L3: 0.08577406406402588, L4: 0.752595841884613, L5: 0.018684329465031624
Epoch 4500, Loss: 1.2847936153411865, Losses: L1: 0.36276277899742126, L2: 0.05552346631884575, L3: 0.08459591865539551, L4: 0.7307301163673401, L5: 0.018977852538228035
Epoch 5000, Loss: 1.2559131383895874, Losses: L1: 0.3582437038421631, L2: 0.05514016002416611, L3: 0.08379983901977539, L4: 0.7063091993331909, L5: 0.019589971750974655
Epoch 5500, Loss: 1.2395946979522705, Losses: L1: 0.3555252254009247, L2: 0.054664257913827896, L3: 0.08332473039627075, L4: 0.693388819694519, L5: 0.019844865426421165
Epoch 6000, Loss: 1.2283283472061157, Losses: L1: 0.3526931405067444, L2: 0.05461446940898895, L3: 0.08300650119781494, L4: 0.6851723194122314, L5: 0.019865361973643303
Epoch 6500, Loss: 1.2200063467025757, Losses: L1: 0.35148823261260986, L2: 0.054442767053842545, L3: 0.0826912522315979, L4: 0.6781278252601624, L5: 0.02007954940199852
Epoch 7000, Loss: 1.2138620615005493, Losses: L1: 0.35029593110084534, L2: 0.05429704487323761, L3: 0.0825396180152893, L4: 0.6735529899597168, L5: 0.020074591040611267
Epoch 7500, Loss: 1.2094587087631226, Losses: L1: 0.34977883100509644, L2: 0.05418533831834793, L3: 0.08239865303039551, L4: 0.6698520183563232, L5: 0.020128924399614334
Epoch 8000, Loss: 1.2062709331512451, Losses: L1: 0.3494672477245331, L2: 0.05408811569213867, L3: 0.08231008052825928, L4: 0.6671743392944336, L5: 0.020149048417806625
Epoch 8500, Loss: 1.204025149345398, Losses: L1: 0.34919068217277527, L2: 0.05402427911758423, L3: 0.08225250244140625, L4: 0.6653079986572266, L5: 0.020175829529762268
Epoch 9000, Loss: 1.2025158405303955, Losses: L1: 0.3490299582481384, L2: 0.05399474874138832, L3: 0.08220887184143066, L4: 0.6639964580535889, L5: 0.020197777077555656
Epoch 9500, Loss: 1.2014223337173462, Losses: L1: 0.3489264249801636, L2: 0.05398780480027199, L3: 0.08217042684555054, L4: 0.6630293130874634, L5: 0.020202888175845146
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0227930545806885, Constraint losses: L1: 18.42068099975586, L2: 0.0014574361266568303, L3: 1.0014574527740479, L4: 1.0014574527740479
Epoch 500, Loss: 0.002295547630637884, Constraint losses: L1: -1.1055271625518799, L2: 0.0, L3: 0.002699613571166992, L4: 0.0007014612201601267
Epoch 1000, Loss: 0.0013367512729018927, Constraint losses: L1: -1.11833918094635, L2: 0.0, L3: 0.0022272467613220215, L4: 0.0002278437023051083
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0196948051452637, Constraint losses: L1: 18.42068099975586, L2: 0.0004246454918757081, L3: 1.0004246234893799, L4: 1.000424861907959
Epoch 500, Loss: 0.0023993616923689842, Constraint losses: L1: -1.0273984670639038, L2: 0.0, L3: 0.002712428569793701, L4: 0.0007143315742723644
Epoch 1000, Loss: 0.0013999282382428646, Constraint losses: L1: -1.050989031791687, L2: 0.0, L3: 0.002225160598754883, L4: 0.0002257566957268864
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.66184997558594, Losses: L1: 11.986680030822754, L2: 0.0020906447898596525, L3: 0.9999290108680725, L4: 77.50614929199219, L5: 0.3174469769001007
Epoch 500, Loss: 8.439372062683105, Losses: L1: 0.26256126165390015, L2: 0.07059715688228607, L3: 0.06663393974304199, L4: 3.995656967163086, L5: 0.021971486508846283
Epoch 1000, Loss: 22.92383575439453, Losses: L1: 5.016529560089111, L2: 0.584732711315155, L3: 0.28145360946655273, L4: 8.278648376464844, L5: 0.07963380217552185
Epoch 1500, Loss: 14.043732643127441, Losses: L1: 2.591928005218506, L2: 0.29889151453971863, L3: 0.13547706604003906, L4: 5.378897666931152, L5: 0.05697348341345787
Epoch 2000, Loss: 5.144467353820801, Losses: L1: 1.567913293838501, L2: 0.17792761325836182, L3: 0.12571460008621216, L4: 1.560691237449646, L5: 0.07291831821203232
Epoch 2500, Loss: 90.32452392578125, Losses: L1: 10.133346557617188, L2: 0.21668066084384918, L3: 1.0011593103408813, L4: 39.593475341796875, L5: 0.1405641883611679
Epoch 3000, Loss: 7.898691654205322, Losses: L1: 2.0485167503356934, L2: 0.19749891757965088, L3: 0.21467846632003784, L4: 2.664365768432617, L5: 0.03821295127272606
Epoch 3500, Loss: 5.680922985076904, Losses: L1: 1.6327259540557861, L2: 0.16457754373550415, L3: 0.15461432933807373, L4: 1.8133187294006348, L5: 0.030194122344255447
Epoch 4000, Loss: 5.183095932006836, Losses: L1: 1.5371813774108887, L2: 0.15005463361740112, L3: 0.14526498317718506, L4: 1.6293854713439941, L5: 0.02880428358912468
Epoch 4500, Loss: 4.818167686462402, Losses: L1: 1.447572946548462, L2: 0.13981059193611145, L3: 0.13953495025634766, L4: 1.503666639328003, L5: 0.02774648740887642
Epoch 5000, Loss: 4.480873107910156, Losses: L1: 1.3197473287582397, L2: 0.12937602400779724, L3: 0.13610845804214478, L4: 1.4105801582336426, L5: 0.026318874210119247
Epoch 5500, Loss: 4.225191593170166, Losses: L1: 1.2328057289123535, L2: 0.12242042273283005, L3: 0.13229691982269287, L4: 1.334391474723816, L5: 0.025227190926671028
Epoch 6000, Loss: 4.030247211456299, Losses: L1: 1.1695027351379395, L2: 0.11858265101909637, L3: 0.12956035137176514, L4: 1.2733697891235352, L5: 0.02411918342113495
Epoch 6500, Loss: 3.822782516479492, Losses: L1: 1.050978660583496, L2: 0.1148710548877716, L3: 0.1273665428161621, L4: 1.2333475351333618, L5: 0.02336694672703743
Epoch 7000, Loss: 3.5204789638519287, Losses: L1: 0.8248940706253052, L2: 0.10954936593770981, L3: 0.1264709234237671, L4: 1.2011064291000366, L5: 0.022075651213526726
Epoch 7500, Loss: 3.4121766090393066, Losses: L1: 0.7707607746124268, L2: 0.1061902567744255, L3: 0.12532007694244385, L4: 1.1778028011322021, L5: 0.021539200097322464
Epoch 8000, Loss: 3.3779096603393555, Losses: L1: 0.7667638659477234, L2: 0.10659388452768326, L3: 0.12412101030349731, L4: 1.1625994443893433, L5: 0.021397607401013374
Epoch 8500, Loss: 3.3547840118408203, Losses: L1: 0.7660813927650452, L2: 0.10589412599802017, L3: 0.12350142002105713, L4: 1.1522578001022339, L5: 0.021295802667737007
Epoch 9000, Loss: 3.3383407592773438, Losses: L1: 0.766062319278717, L2: 0.10535913705825806, L3: 0.12302148342132568, L4: 1.1447169780731201, L5: 0.021230828016996384
Epoch 9500, Loss: 3.3267247676849365, Losses: L1: 0.7661506533622742, L2: 0.1049712747335434, L3: 0.12267357110977173, L4: 1.1393531560897827, L5: 0.021176660433411598
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0203328132629395, Constraint losses: L1: 18.310626983642578, L2: 0.0007881005294620991, L3: 1.0006171464920044, L4: 1.0006170272827148
Epoch 500, Loss: 0.0019138590432703495, Constraint losses: L1: -1.1117637157440186, L2: 0.0, L3: 0.0025121569633483887, L4: 0.0005134657840244472
Epoch 1000, Loss: 0.0012150401016697288, Constraint losses: L1: -1.1160962581634521, L2: 0.0, L3: 0.002165377140045166, L4: 0.00016575920744799078
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.033942699432373, Constraint losses: L1: 18.42068099975586, L2: 0.005174028221517801, L3: 1.0051740407943726, L4: 1.005173921585083
Epoch 500, Loss: 0.002508089179173112, Constraint losses: L1: -0.9203556180000305, L2: 0.0, L3: 0.0027129650115966797, L4: 0.0007154798367992043
Epoch 1000, Loss: 0.0013870315160602331, Constraint losses: L1: -1.0436440706253052, L2: 0.0, L3: 0.0022148489952087402, L4: 0.00021582665794994682
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 173.21505737304688, Losses: L1: 6.159373760223389, L2: 0.0, L3: 0.9978368878364563, L4: 83.10319519042969, L5: 0.35037800669670105
Epoch 500, Loss: 7.3274030685424805, Losses: L1: 2.173783302307129, L2: 0.2828335464000702, L3: 0.10244804620742798, L4: 2.25165057182312, L5: 0.0334271639585495
Epoch 1000, Loss: 11.108588218688965, Losses: L1: 0.42938604950904846, L2: 0.009994125925004482, L3: 0.13750898838043213, L4: 5.283003807067871, L5: 0.024452267214655876
Epoch 1500, Loss: 2.484372615814209, Losses: L1: 0.33089882135391235, L2: 0.07416670769453049, L3: 0.08744287490844727, L4: 0.9749943017959595, L5: 0.01143020112067461
Epoch 2000, Loss: 4.768407344818115, Losses: L1: 0.33151087164878845, L2: 0.06390152126550674, L3: 0.07013911008834839, L4: 2.1272034645080566, L5: 0.01961715891957283
Epoch 2500, Loss: 1.3566555976867676, Losses: L1: 0.3014736473560333, L2: 0.05461461469531059, L3: 0.06997120380401611, L4: 0.4508218765258789, L5: 0.00932333804666996
Epoch 3000, Loss: 1.8432538509368896, Losses: L1: 0.2691195011138916, L2: 0.04945070669054985, L3: 0.06514954566955566, L4: 0.715976357460022, L5: 0.01070545706897974
Epoch 3500, Loss: 1.0243865251541138, Losses: L1: 0.261769562959671, L2: 0.04192544147372246, L3: 0.06463789939880371, L4: 0.3186507225036621, L5: 0.00914566870778799
Epoch 4000, Loss: 0.9735133647918701, Losses: L1: 0.25251710414886475, L2: 0.04015960916876793, L3: 0.06372052431106567, L4: 0.3000071048736572, L5: 0.008802533149719238
Epoch 4500, Loss: 0.941103458404541, Losses: L1: 0.24751365184783936, L2: 0.03905729576945305, L3: 0.06307756900787354, L4: 0.28763943910598755, L5: 0.008657578378915787
Epoch 5000, Loss: 0.9187449812889099, Losses: L1: 0.24381794035434723, L2: 0.03871440514922142, L3: 0.06257188320159912, L4: 0.278839647769928, L5: 0.008532986976206303
Epoch 5500, Loss: 0.9035627841949463, Losses: L1: 0.24179673194885254, L2: 0.0382547527551651, L3: 0.06223165988922119, L4: 0.27284735441207886, L5: 0.00844595581293106
Epoch 6000, Loss: 0.8915421366691589, Losses: L1: 0.2399362027645111, L2: 0.03802832216024399, L3: 0.06195545196533203, L4: 0.26808154582977295, L5: 0.00840850081294775
Epoch 6500, Loss: 0.8833144903182983, Losses: L1: 0.23884843289852142, L2: 0.03771370276808739, L3: 0.06175339221954346, L4: 0.2648983895778656, L5: 0.008365153335034847
Epoch 7000, Loss: 0.8767160773277283, Losses: L1: 0.23797504603862762, L2: 0.03756954148411751, L3: 0.06159085035324097, L4: 0.262233167886734, L5: 0.008340194821357727
Epoch 7500, Loss: 0.8721519112586975, Losses: L1: 0.23726101219654083, L2: 0.037448521703481674, L3: 0.06147313117980957, L4: 0.2604679465293884, L5: 0.008321387693285942
Epoch 8000, Loss: 0.8689136505126953, Losses: L1: 0.23680780827999115, L2: 0.03735828027129173, L3: 0.061391353607177734, L4: 0.25919413566589355, L5: 0.008305288851261139
Epoch 8500, Loss: 0.8666131496429443, Losses: L1: 0.23644068837165833, L2: 0.03731168434023857, L3: 0.06132936477661133, L4: 0.25829458236694336, L5: 0.008295266889035702
Epoch 9000, Loss: 0.8648779392242432, Losses: L1: 0.23619578778743744, L2: 0.0372689887881279, L3: 0.06128746271133423, L4: 0.25760579109191895, L5: 0.00828887801617384
Epoch 9500, Loss: 0.8637481927871704, Losses: L1: 0.23601801693439484, L2: 0.037248119711875916, L3: 0.06125366687774658, L4: 0.2571614980697632, L5: 0.008284062147140503
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0051283836364746, Constraint losses: L1: 6.930983543395996, L2: 3.423039015615359e-05, L3: 0.9990818500518799, L4: 0.9990813732147217
Epoch 500, Loss: 0.00234406441450119, Constraint losses: L1: -1.1027724742889404, L2: 0.0, L3: 0.002722501754760742, L4: 0.0007243352010846138
Epoch 1000, Loss: 0.0013590630842372775, Constraint losses: L1: -1.1185250282287598, L2: 0.0, L3: 0.002238452434539795, L4: 0.00023913572658784688
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.015349864959717, Constraint losses: L1: 15.081886291503906, L2: 0.00013016039156354964, L3: 1.00006902217865, L4: 1.0000689029693604
Epoch 500, Loss: 0.002584399189800024, Constraint losses: L1: -0.8953575491905212, L2: 0.0, L3: 0.0027385950088500977, L4: 0.0007411616388708353
Epoch 1000, Loss: 0.001391964266076684, Constraint losses: L1: -1.0506839752197266, L2: 0.0, L3: 0.0022211074829101562, L4: 0.00022154080215841532
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 170.36410522460938, Losses: L1: 14.307340621948242, L2: 0.0028162661474198103, L3: 1.0020124912261963, L4: 77.45503997802734, L5: 0.3200204074382782
Epoch 500, Loss: 14.87503719329834, Losses: L1: 5.329869270324707, L2: 0.9982302188873291, L3: 0.15294551849365234, L4: 3.656620502471924, L5: 0.07949705421924591
Epoch 1000, Loss: 5.576716899871826, Losses: L1: 1.2089076042175293, L2: 0.10165026038885117, L3: 0.10669052600860596, L4: 2.0374510288238525, L5: 0.01813073456287384
Epoch 1500, Loss: 5.287446975708008, Losses: L1: 0.8744515776634216, L2: 0.17796184122562408, L3: 0.08958518505096436, L4: 1.965434193611145, L5: 0.04070527106523514
Epoch 2000, Loss: 3.284045934677124, Losses: L1: 0.44673824310302734, L2: 0.09453471750020981, L3: 0.06622707843780518, L4: 1.2877813577651978, L5: 0.01978098787367344
Epoch 2500, Loss: 2.131188154220581, Losses: L1: 0.36101770401000977, L2: 0.07118422538042068, L3: 0.06462669372558594, L4: 0.7755232453346252, L5: 0.022221030667424202
Epoch 3000, Loss: 1.4441030025482178, Losses: L1: 0.2967231869697571, L2: 0.0557081513106823, L3: 0.06684112548828125, L4: 0.4819299280643463, L5: 0.019341524690389633
Epoch 3500, Loss: 1.345218300819397, Losses: L1: 0.28783485293388367, L2: 0.05177319049835205, L3: 0.06525862216949463, L4: 0.4432307481765747, L5: 0.017373135313391685
Epoch 4000, Loss: 1.2264297008514404, Losses: L1: 0.28927895426750183, L2: 0.04697747528553009, L3: 0.06416100263595581, L4: 0.38858702778816223, L5: 0.016970625147223473
Epoch 4500, Loss: 1.1828936338424683, Losses: L1: 0.292102575302124, L2: 0.043519988656044006, L3: 0.06327956914901733, L4: 0.36930686235427856, L5: 0.016748784109950066
Epoch 5000, Loss: 1.0682373046875, Losses: L1: 0.22703830897808075, L2: 0.04340415075421333, L3: 0.06208604574203491, L4: 0.3458191752433777, L5: 0.015854686498641968
Epoch 5500, Loss: 1.0314347743988037, Losses: L1: 0.2249041348695755, L2: 0.042582809925079346, L3: 0.06159675121307373, L4: 0.3296138644218445, L5: 0.015669450163841248
Epoch 6000, Loss: 0.9999116659164429, Losses: L1: 0.20927517116069794, L2: 0.0418776236474514, L3: 0.061225295066833496, L4: 0.3226608335971832, L5: 0.015473481267690659
Epoch 6500, Loss: 0.9848829507827759, Losses: L1: 0.20864535868167877, L2: 0.04169104993343353, L3: 0.061037302017211914, L4: 0.31593602895736694, L5: 0.015232373960316181
Epoch 7000, Loss: 0.9779543280601501, Losses: L1: 0.20871156454086304, L2: 0.04161014035344124, L3: 0.06084764003753662, L4: 0.3126765489578247, L5: 0.015122808516025543
Epoch 7500, Loss: 0.9729170203208923, Losses: L1: 0.20819340646266937, L2: 0.04164179414510727, L3: 0.06075090169906616, L4: 0.3105097711086273, L5: 0.01502250786870718
Epoch 8000, Loss: 0.9698411822319031, Losses: L1: 0.20786511898040771, L2: 0.04162980988621712, L3: 0.060701727867126465, L4: 0.3092219829559326, L5: 0.01496079657226801
Epoch 8500, Loss: 0.9675589799880981, Losses: L1: 0.20779134333133698, L2: 0.041597623378038406, L3: 0.06065547466278076, L4: 0.3082098960876465, L5: 0.014912429265677929
Epoch 9000, Loss: 0.9662686586380005, Losses: L1: 0.2079170048236847, L2: 0.041541628539562225, L3: 0.06060492992401123, L4: 0.30759763717651367, L5: 0.014885329641401768
Epoch 9500, Loss: 0.9649959802627563, Losses: L1: 0.20786455273628235, L2: 0.04156750813126564, L3: 0.06054699420928955, L4: 0.30701830983161926, L5: 0.014843176119029522
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.025421619415283, Constraint losses: L1: 18.42068099975586, L2: 0.00233371346257627, L3: 1.0023337602615356, L4: 1.0023335218429565
Epoch 500, Loss: 0.0023614466190338135, Constraint losses: L1: -1.0791584253311157, L2: 0.0, L3: 0.0027194619178771973, L4: 0.0007211430929601192
Epoch 1000, Loss: 0.0013365581398829818, Constraint losses: L1: -1.117689609527588, L2: 0.0, L3: 0.0022268295288085938, L4: 0.00022741824795957655
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9995639324188232, Constraint losses: L1: 5.764959335327148, L2: 0.0, L3: 0.9968997240066528, L4: 0.9968991875648499
Epoch 500, Loss: 0.002123842714354396, Constraint losses: L1: -1.0360146760940552, L2: 0.0, L3: 0.0025791525840759277, L4: 0.0005807048873975873
Epoch 1000, Loss: 0.0013255542144179344, Constraint losses: L1: -1.0515488386154175, L2: 0.0, L3: 0.0021883249282836914, L4: 0.0001887781691038981
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.6650276184082, Losses: L1: 4.659419059753418, L2: 0.0, L3: 0.9902424812316895, L4: 81.69023132324219, L5: 0.3405025601387024
Epoch 500, Loss: 26.862716674804688, Losses: L1: 5.760584831237793, L2: 0.13111884891986847, L3: 0.9994960427284241, L4: 39.5222282409668, L5: 0.1585678905248642
Epoch 1000, Loss: 29.422950744628906, Losses: L1: 3.007662296295166, L2: 0.010720472782850266, L3: 0.8418883085250854, L4: 50.92829132080078, L5: 0.17562749981880188
Epoch 1500, Loss: 28.256481170654297, Losses: L1: 4.5900959968566895, L2: 0.5030091404914856, L3: 0.9932265877723694, L4: 43.13276290893555, L5: 0.20151866972446442
Epoch 2000, Loss: 34.56276321411133, Losses: L1: 8.185761451721191, L2: 0.0, L3: 0.9979352951049805, L4: 50.552730560302734, L5: 0.20540602505207062
Epoch 2500, Loss: 28.11553382873535, Losses: L1: 4.404282569885254, L2: 0.08173640817403793, L3: 0.9138384461402893, L4: 45.10959243774414, L5: 0.15828607976436615
Epoch 3000, Loss: 28.51445198059082, Losses: L1: 4.324595928192139, L2: 0.23630496859550476, L3: 0.8677926659584045, L4: 45.54236602783203, L5: 0.1565403789281845
Epoch 3500, Loss: 27.63006591796875, Losses: L1: 4.183823585510254, L2: 0.22683146595954895, L3: 0.9059580564498901, L4: 44.01469039916992, L5: 0.15855523943901062
Epoch 4000, Loss: 27.059085845947266, Losses: L1: 4.113105297088623, L2: 0.2227156162261963, L3: 0.9285585284233093, L4: 42.97901153564453, L5: 0.16496999561786652
Epoch 4500, Loss: 27.048072814941406, Losses: L1: 4.037588119506836, L2: 0.1309640109539032, L3: 0.8774317502975464, L4: 43.57921600341797, L5: 0.1630340963602066
Epoch 5000, Loss: 26.6426944732666, Losses: L1: 4.095507621765137, L2: 0.200545996427536, L3: 0.9333944320678711, L4: 42.257266998291016, L5: 0.16813114285469055
Epoch 5500, Loss: 26.58994483947754, Losses: L1: 4.140892028808594, L2: 0.19439664483070374, L3: 0.9393569231033325, L4: 42.07500076293945, L5: 0.1668059527873993
Epoch 6000, Loss: 26.565773010253906, Losses: L1: 4.14747953414917, L2: 0.1924959123134613, L3: 0.9404385089874268, L4: 42.019126892089844, L5: 0.16659927368164062
Epoch 6500, Loss: 26.550048828125, Losses: L1: 4.147653102874756, L2: 0.19145353138446808, L3: 0.9407218098640442, L4: 41.99102783203125, L5: 0.16650521755218506
Epoch 7000, Loss: 26.538719177246094, Losses: L1: 4.146830081939697, L2: 0.19082455337047577, L3: 0.9408663511276245, L4: 41.972259521484375, L5: 0.16648823022842407
Epoch 7500, Loss: 26.530345916748047, Losses: L1: 4.145497798919678, L2: 0.19042350351810455, L3: 0.9409148097038269, L4: 41.95966339111328, L5: 0.16651204228401184
Epoch 8000, Loss: 26.524139404296875, Losses: L1: 4.144318103790283, L2: 0.19010871648788452, L3: 0.9409317374229431, L4: 41.95081329345703, L5: 0.16653145849704742
Epoch 8500, Loss: 26.51953887939453, Losses: L1: 4.1434125900268555, L2: 0.1898578554391861, L3: 0.9409403800964355, L4: 41.944393157958984, L5: 0.16654519736766815
Epoch 9000, Loss: 26.516128540039062, Losses: L1: 4.14267110824585, L2: 0.1896723359823227, L3: 0.9409353733062744, L4: 41.939788818359375, L5: 0.1665647327899933
Epoch 9500, Loss: 26.51361846923828, Losses: L1: 4.142177104949951, L2: 0.18950717151165009, L3: 0.9409331679344177, L4: 41.9364128112793, L5: 0.1665726900100708
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0181491374969482, Constraint losses: L1: 17.825429916381836, L2: 0.00014284522330854088, L3: 1.000090479850769, L4: 1.0000903606414795
Epoch 500, Loss: 0.002044599037617445, Constraint losses: L1: -1.1031265258789062, L2: 0.0, L3: 0.002573072910308838, L4: 0.0005746528040617704
Epoch 1000, Loss: 0.0012514465488493443, Constraint losses: L1: -1.1172380447387695, L2: 0.0, L3: 0.002184152603149414, L4: 0.00018453202210366726
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0131962299346924, Constraint losses: L1: 12.714495658874512, L2: 0.00019239190442021936, L3: 1.0001449584960938, L4: 1.000144362449646
Epoch 500, Loss: 0.002655850723385811, Constraint losses: L1: -1.0233458280563354, L2: 0.0, L3: 0.002838432788848877, L4: 0.0008407637942582369
Epoch 1000, Loss: 0.0014971914933994412, Constraint losses: L1: -1.0511080026626587, L2: 0.0, L3: 0.002273738384246826, L4: 0.0002745611418504268
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 53.9463996887207, Losses: L1: 12.900836944580078, L2: 0.0004340340383350849, L3: 1.0000773668289185, L4: 79.43110656738281, L5: 0.3290637731552124
Epoch 500, Loss: 7.1879563331604, Losses: L1: 3.0220797061920166, L2: 0.07258462905883789, L3: 0.17002826929092407, L4: 7.586301803588867, L5: 0.057527825236320496
Epoch 1000, Loss: 19.338403701782227, Losses: L1: 6.229309558868408, L2: 0.15609364211559296, L3: 0.5292105674743652, L4: 24.38881492614746, L5: 0.07329061627388
Epoch 1500, Loss: 43.97439956665039, Losses: L1: 17.723560333251953, L2: 1.1916861097915898e-07, L3: 1.0000001192092896, L4: 50.00008010864258, L5: 0.2507955729961395
Epoch 2000, Loss: 37.21112060546875, Losses: L1: 10.960271835327148, L2: 4.955952681484632e-05, L3: 0.9999553561210632, L4: 50.00003433227539, L5: 0.2507774233818054
Epoch 2500, Loss: 36.29507827758789, Losses: L1: 10.044212341308594, L2: 0.00012196630268590525, L3: 0.9998902678489685, L4: 50.00002670288086, L5: 0.2507190406322479
Epoch 3000, Loss: 35.28040313720703, Losses: L1: 9.030139923095703, L2: 1.3036898963036947e-05, L3: 0.9997803568840027, L4: 49.99976348876953, L5: 0.2505752742290497
Epoch 3500, Loss: 34.27268981933594, Losses: L1: 8.023529052734375, L2: 0.00010881847993005067, L3: 0.9995412826538086, L4: 49.99807357788086, L5: 0.2503673732280731
Epoch 4000, Loss: 33.719242095947266, Losses: L1: 7.471615314483643, L2: 0.00019058643374592066, L3: 0.9992206692695618, L4: 49.995941162109375, L5: 0.2500549256801605
Epoch 4500, Loss: 33.294456481933594, Losses: L1: 7.048768997192383, L2: 0.0002972953370772302, L3: 0.9988090991973877, L4: 49.99323654174805, L5: 0.24966591596603394
Epoch 5000, Loss: 32.96711349487305, Losses: L1: 6.723573684692383, L2: 0.0004204159486107528, L3: 0.9983405470848083, L4: 49.990257263183594, L5: 0.24922996759414673
Epoch 5500, Loss: 32.71408462524414, Losses: L1: 6.4727020263671875, L2: 0.0005498341633938253, L3: 0.9978526830673218, L4: 49.9873046875, L5: 0.24878056347370148
Epoch 6000, Loss: 32.51826095581055, Losses: L1: 6.278905391693115, L2: 0.0006764777936041355, L3: 0.9973785281181335, L4: 49.98455047607422, L5: 0.2483467161655426
Epoch 6500, Loss: 32.366817474365234, Losses: L1: 6.1292924880981445, L2: 0.0007937495829537511, L3: 0.9969417452812195, L4: 49.982086181640625, L5: 0.24795009195804596
Epoch 7000, Loss: 32.2500114440918, Losses: L1: 6.014080047607422, L2: 0.0008976181852631271, L3: 0.996556282043457, L4: 49.97996139526367, L5: 0.2476019412279129
Epoch 7500, Loss: 32.144004821777344, Losses: L1: 5.909669876098633, L2: 0.0008538675028830767, L3: 0.9961866140365601, L4: 49.97836685180664, L5: 0.24725556373596191
Epoch 8000, Loss: 32.076663970947266, Losses: L1: 5.843264579772949, L2: 0.0009205389651469886, L3: 0.9959526658058167, L4: 49.97712707519531, L5: 0.24704159796237946
Epoch 8500, Loss: 32.026309967041016, Losses: L1: 5.7936506271362305, L2: 0.0009740993264131248, L3: 0.9957665205001831, L4: 49.97614669799805, L5: 0.2468719631433487
Epoch 9000, Loss: 31.98906135559082, Losses: L1: 5.756969928741455, L2: 0.0010159133234992623, L3: 0.9956223368644714, L4: 49.97539520263672, L5: 0.24674054980278015
Epoch 9500, Loss: 31.961904525756836, Losses: L1: 5.730235576629639, L2: 0.0010472984286025167, L3: 0.9955138564109802, L4: 49.97483825683594, L5: 0.24664178490638733
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0331578254699707, Constraint losses: L1: 18.42068099975586, L2: 0.004912089556455612, L3: 1.0049121379852295, L4: 1.0049128532409668
Epoch 500, Loss: 0.0023865504190325737, Constraint losses: L1: -1.051696538925171, L2: 0.0, L3: 0.002718031406402588, L4: 0.0007202156120911241
Epoch 1000, Loss: 0.0013270857743918896, Constraint losses: L1: -1.1167768239974976, L2: 0.0, L3: 0.0022215843200683594, L4: 0.00022227823501452804
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0033998489379883, Constraint losses: L1: 6.557260036468506, L2: 0.0, L3: 0.9984212517738342, L4: 0.9984214305877686
Epoch 500, Loss: 0.0020273998379707336, Constraint losses: L1: -1.0172374248504639, L2: 0.0, L3: 0.002521514892578125, L4: 0.0005231222603470087
Epoch 1000, Loss: 0.0012783821439370513, Constraint losses: L1: -1.049949049949646, L2: 0.0, L3: 0.0021638870239257812, L4: 0.00016444417997263372
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.28295135498047, Losses: L1: 17.91063117980957, L2: 0.001889227656647563, L3: 1.001867413520813, L4: 69.69893646240234, L5: 0.25860241055488586
Epoch 500, Loss: 31.99957847595215, Losses: L1: 7.873946189880371, L2: 0.1635146588087082, L3: 0.9884980320930481, L4: 44.95149230957031, L5: 0.16718031466007233
Epoch 1000, Loss: 36.1126708984375, Losses: L1: 7.999267101287842, L2: 1.288136172661325e-05, L3: 0.9984837174415588, L4: 53.51954650878906, L5: 0.1775604635477066
Epoch 1500, Loss: 6.903579235076904, Losses: L1: 3.258533239364624, L2: 0.263013631105423, L3: 0.15362071990966797, L4: 5.736289024353027, L5: 0.04862656071782112
Epoch 2000, Loss: 3.113844871520996, Losses: L1: 1.1715354919433594, L2: 0.08426505327224731, L3: 0.1500607132911682, L4: 3.0965685844421387, L5: 0.037717100232839584
Epoch 2500, Loss: 6.131608009338379, Losses: L1: 0.8361377716064453, L2: 0.08305999636650085, L3: 0.15012574195861816, L4: 9.596574783325195, L5: 0.09046836942434311
Epoch 3000, Loss: 6.216022968292236, Losses: L1: 2.5308072566986084, L2: 0.16316449642181396, L3: 0.21616756916046143, L4: 6.116336345672607, L5: 0.04227576032280922
Epoch 3500, Loss: 26.156570434570312, Losses: L1: 2.3107683658599854, L2: 0.0, L3: 0.8674126863479614, L4: 45.21473693847656, L5: 0.18551070988178253
Epoch 4000, Loss: 6.78314208984375, Losses: L1: 1.6356079578399658, L2: 0.08600271493196487, L3: 0.237801194190979, L4: 9.374826431274414, L5: 0.025157248601317406
Epoch 4500, Loss: 5.55295467376709, Losses: L1: 1.708226203918457, L2: 0.11008638888597488, L3: 0.2226201295852661, L4: 6.679112434387207, L5: 0.03118959814310074
Epoch 5000, Loss: 5.1061601638793945, Losses: L1: 1.6528775691986084, L2: 0.10737946629524231, L3: 0.2192389965057373, L4: 5.9163103103637695, L5: 0.030564695596694946
Epoch 5500, Loss: 4.880826950073242, Losses: L1: 1.6679332256317139, L2: 0.11275803297758102, L3: 0.21058738231658936, L4: 5.43018913269043, L5: 0.03084777481853962
Epoch 6000, Loss: 4.748812198638916, Losses: L1: 1.6626836061477661, L2: 0.11744558066129684, L3: 0.20517879724502563, L4: 5.1627197265625, L5: 0.0323493629693985
Epoch 6500, Loss: 4.654726505279541, Losses: L1: 1.6438549757003784, L2: 0.12010351568460464, L3: 0.2016535997390747, L4: 5.004706382751465, L5: 0.03332875296473503
Epoch 7000, Loss: 4.600728511810303, Losses: L1: 1.6423789262771606, L2: 0.12236225605010986, L3: 0.1992126703262329, L4: 4.892081260681152, L5: 0.03418596461415291
Epoch 7500, Loss: 4.5632524490356445, Losses: L1: 1.6413203477859497, L2: 0.12394175678491592, L3: 0.19754236936569214, L4: 4.814090728759766, L5: 0.03473038971424103
Epoch 8000, Loss: 4.537564754486084, Losses: L1: 1.6398968696594238, L2: 0.12515538930892944, L3: 0.19673097133636475, L4: 4.7615251541137695, L5: 0.03493184968829155
Epoch 8500, Loss: 4.5193867683410645, Losses: L1: 1.6387276649475098, L2: 0.12570229172706604, L3: 0.19633245468139648, L4: 4.725833892822266, L5: 0.035002537071704865
Epoch 9000, Loss: 4.506745338439941, Losses: L1: 1.6382675170898438, L2: 0.12629754841327667, L3: 0.19591188430786133, L4: 4.69931697845459, L5: 0.035156309604644775
Epoch 9500, Loss: 4.497908592224121, Losses: L1: 1.6379040479660034, L2: 0.12668253481388092, L3: 0.19561660289764404, L4: 4.681000709533691, L5: 0.035261187702417374
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0025534629821777, Constraint losses: L1: 6.272337436676025, L2: 0.0, L3: 0.9981405138969421, L4: 0.9981404542922974
Epoch 500, Loss: 0.0026184124872088432, Constraint losses: L1: -1.085145115852356, L2: 0.0, L3: 0.002850651741027832, L4: 0.000852906028740108
Epoch 1000, Loss: 0.0014329948462545872, Constraint losses: L1: -1.1157488822937012, L2: 0.0, L3: 0.0022740960121154785, L4: 0.0002746477839536965
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.021223783493042, Constraint losses: L1: 18.42068099975586, L2: 0.0009343745186924934, L3: 1.000934362411499, L4: 1.000934362411499
Epoch 500, Loss: 0.002233372535556555, Constraint losses: L1: -1.02748703956604, L2: 0.0, L3: 0.002629578113555908, L4: 0.000631281640380621
Epoch 1000, Loss: 0.0013556849444285035, Constraint losses: L1: -1.051719307899475, L2: 0.0, L3: 0.0022034645080566406, L4: 0.0002039397368207574
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 89.17044830322266, Losses: L1: 18.42068099975586, L2: 0.01160584855824709, L3: 1.0116058588027954, L4: 69.58599853515625, L5: 0.2579089403152466
Epoch 500, Loss: 8.651023864746094, Losses: L1: 3.0673956871032715, L2: 0.40942347049713135, L3: 0.07227879762649536, L4: 4.66998291015625, L5: 0.045040491968393326
Epoch 1000, Loss: 5.342095851898193, Losses: L1: 2.0672340393066406, L2: 0.16007983684539795, L3: 0.10002261400222778, L4: 2.8422937393188477, L5: 0.024771373718976974
Epoch 1500, Loss: 1.0776969194412231, Losses: L1: 0.15218007564544678, L2: 0.052250657230615616, L3: 0.06293702125549316, L4: 0.7533490657806396, L5: 0.009458741173148155
Epoch 2000, Loss: 1.1564544439315796, Losses: L1: 0.13968707621097565, L2: 0.038871023803949356, L3: 0.0562092661857605, L4: 0.8789207935333252, L5: 0.007790485862642527
Epoch 2500, Loss: 1.3841722011566162, Losses: L1: 0.4840676784515381, L2: 0.05704040452837944, L3: 0.05487334728240967, L4: 0.7269869446754456, L5: 0.008327013812959194
Epoch 3000, Loss: 0.7776374816894531, Losses: L1: 0.07935596257448196, L2: 0.03376425430178642, L3: 0.05025768280029297, L4: 0.5772796273231506, L5: 0.006431355141103268
Epoch 3500, Loss: 0.4068356156349182, Losses: L1: 0.0814233124256134, L2: 0.03102860413491726, L3: 0.04952716827392578, L4: 0.2103751003742218, L5: 0.006905693560838699
Epoch 4000, Loss: 0.36658743023872375, Losses: L1: 0.0821349248290062, L2: 0.028757933527231216, L3: 0.049246788024902344, L4: 0.17410877346992493, L5: 0.007162168622016907
Epoch 4500, Loss: 0.37529587745666504, Losses: L1: 0.08048336207866669, L2: 0.02868691273033619, L3: 0.04881840944290161, L4: 0.1849057972431183, L5: 0.007428979501128197
Epoch 5000, Loss: 0.3507353961467743, Losses: L1: 0.08023443818092346, L2: 0.028081370517611504, L3: 0.04857438802719116, L4: 0.162073016166687, L5: 0.00738164596259594
Epoch 5500, Loss: 0.3456597924232483, Losses: L1: 0.07963123172521591, L2: 0.027864346280694008, L3: 0.04840362071990967, L4: 0.15815392136573792, L5: 0.007484697736799717
Epoch 6000, Loss: 0.3416735529899597, Losses: L1: 0.07926011830568314, L2: 0.027640776708722115, L3: 0.04828512668609619, L4: 0.1550990641117096, L5: 0.007495393976569176
Epoch 6500, Loss: 0.33991071581840515, Losses: L1: 0.07887489348649979, L2: 0.027602624148130417, L3: 0.04817616939544678, L4: 0.1539025902748108, L5: 0.0075036040507256985
Epoch 7000, Loss: 0.33785560727119446, Losses: L1: 0.07880059629678726, L2: 0.02748696506023407, L3: 0.048104047775268555, L4: 0.1522151380777359, L5: 0.007523809559643269
Epoch 7500, Loss: 0.33678779006004333, Losses: L1: 0.07861277461051941, L2: 0.02742789313197136, L3: 0.048053622245788574, L4: 0.15149986743927002, L5: 0.007531436160206795
Epoch 8000, Loss: 0.3359425365924835, Losses: L1: 0.07860353589057922, L2: 0.027347777038812637, L3: 0.04801607131958008, L4: 0.15086111426353455, L5: 0.007532539311796427
Epoch 8500, Loss: 0.3353216052055359, Losses: L1: 0.07853812724351883, L2: 0.027315976098179817, L3: 0.04798543453216553, L4: 0.15039870142936707, L5: 0.007534762378782034
Epoch 9000, Loss: 0.33487534523010254, Losses: L1: 0.07849589735269547, L2: 0.027287553995847702, L3: 0.047963500022888184, L4: 0.1500721275806427, L5: 0.007537448778748512
Epoch 9500, Loss: 0.33456605672836304, Losses: L1: 0.07846564054489136, L2: 0.02726842649281025, L3: 0.04794710874557495, L4: 0.14984671771526337, L5: 0.007539495825767517
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.028013229370117, Constraint losses: L1: 18.42068099975586, L2: 0.003197324927896261, L3: 1.0031973123550415, L4: 1.0031980276107788
Epoch 500, Loss: 0.0020541001576930285, Constraint losses: L1: -1.0841609239578247, L2: 0.0, L3: 0.0025683045387268066, L4: 0.0005699566099792719
Epoch 1000, Loss: 0.001237504999153316, Constraint losses: L1: -1.1178069114685059, L2: 0.0, L3: 0.002177417278289795, L4: 0.00017789473349694163
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002068519592285, Constraint losses: L1: 6.150121212005615, L2: 0.0, L3: 0.9979592561721802, L4: 0.9979590177536011
Epoch 500, Loss: 0.0020303730852901936, Constraint losses: L1: -1.044033408164978, L2: 0.0, L3: 0.002536594867706299, L4: 0.0005378115456551313
Epoch 1000, Loss: 0.0013054037699475884, Constraint losses: L1: -1.0513252019882202, L2: 0.0, L3: 0.002178192138671875, L4: 0.00017853689496405423
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 85.88381958007812, Losses: L1: 6.850931167602539, L2: 0.0, L3: 0.9989253878593445, L4: 77.71833038330078, L5: 0.31563445925712585
Epoch 500, Loss: 53.86922836303711, Losses: L1: 2.9053473472595215, L2: 0.0013758294517174363, L3: 0.9030968546867371, L4: 49.87085723876953, L5: 0.18717558681964874
Epoch 1000, Loss: 13.685335159301758, Losses: L1: 5.331844806671143, L2: 0.11886010318994522, L3: 0.29893958568573, L4: 7.761595249176025, L5: 0.05523465573787689
Epoch 1500, Loss: 55.76190185546875, Losses: L1: 6.08979606628418, L2: 0.38543766736984253, L3: 0.9107894897460938, L4: 47.81557083129883, L5: 0.17487028241157532
Epoch 2000, Loss: 18.950889587402344, Losses: L1: 5.6021528244018555, L2: 0.8353263735771179, L3: 0.31606489419937134, L4: 11.217309951782227, L5: 0.14470882713794708
Epoch 2500, Loss: 18.673446655273438, Losses: L1: 4.749114513397217, L2: 1.0384079217910767, L3: 0.2979797124862671, L4: 11.383203506469727, L5: 0.16633261740207672
Epoch 3000, Loss: 13.822250366210938, Losses: L1: 5.430427074432373, L2: 0.9359957575798035, L3: 0.18537485599517822, L4: 6.2008490562438965, L5: 0.13360834121704102
Epoch 3500, Loss: 17.96333885192871, Losses: L1: 5.096221923828125, L2: 0.8372482061386108, L3: 0.39478689432144165, L4: 10.645740509033203, L5: 0.15209335088729858
Epoch 4000, Loss: 14.560600280761719, Losses: L1: 4.600528717041016, L2: 0.8854234218597412, L3: 0.31869518756866455, L4: 7.721287250518799, L5: 0.14924204349517822
Epoch 4500, Loss: 14.374370574951172, Losses: L1: 4.599025726318359, L2: 0.8981000781059265, L3: 0.3138033151626587, L4: 7.514250755310059, L5: 0.15109077095985413
Epoch 5000, Loss: 14.277511596679688, Losses: L1: 4.589443683624268, L2: 0.899297833442688, L3: 0.3120988607406616, L4: 7.425422191619873, L5: 0.15195129811763763
Epoch 5500, Loss: 14.199542045593262, Losses: L1: 4.592910289764404, L2: 0.8983902335166931, L3: 0.3107961416244507, L4: 7.347200870513916, L5: 0.15185487270355225
Epoch 6000, Loss: 14.048969268798828, Losses: L1: 4.493684768676758, L2: 0.9023035764694214, L3: 0.30543577671051025, L4: 7.29205322265625, L5: 0.15318915247917175
Epoch 6500, Loss: 13.810976028442383, Losses: L1: 4.378353595733643, L2: 0.8949704766273499, L3: 0.30855870246887207, L4: 7.183876991271973, L5: 0.15024608373641968
Epoch 7000, Loss: 13.668265342712402, Losses: L1: 4.334988594055176, L2: 0.892509937286377, L3: 0.308504581451416, L4: 7.0905961990356445, L5: 0.1491558998823166
Epoch 7500, Loss: 13.61740493774414, Losses: L1: 4.323431015014648, L2: 0.8920480012893677, L3: 0.3080402612686157, L4: 7.052433013916016, L5: 0.1494045853614807
Epoch 8000, Loss: 13.582890510559082, Losses: L1: 4.315066814422607, L2: 0.8920952677726746, L3: 0.3075370192527771, L4: 7.02628231048584, L5: 0.14981374144554138
Epoch 8500, Loss: 13.559717178344727, Losses: L1: 4.311847686767578, L2: 0.8921972513198853, L3: 0.3071705102920532, L4: 7.0062255859375, L5: 0.15008008480072021
Epoch 9000, Loss: 13.54612922668457, Losses: L1: 4.311160564422607, L2: 0.8919653296470642, L3: 0.306999146938324, L4: 6.993886947631836, L5: 0.15015244483947754
Epoch 9500, Loss: 13.53830623626709, Losses: L1: 4.310823440551758, L2: 0.8921270370483398, L3: 0.30660480260849, L4: 6.986333847045898, L5: 0.150290846824646
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.028585433959961, Constraint losses: L1: 18.42068099975586, L2: 0.003388108918443322, L3: 1.0033881664276123, L4: 1.0033886432647705
Epoch 500, Loss: 0.0022818930447101593, Constraint losses: L1: -1.0909826755523682, L2: 0.0, L3: 0.002685546875, L4: 0.0006873289821669459
Epoch 1000, Loss: 0.0013244301080703735, Constraint losses: L1: -1.1184349060058594, L2: 0.0, L3: 0.0022211670875549316, L4: 0.00022169796284288168
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0251951217651367, Constraint losses: L1: 18.42068099975586, L2: 0.0022580905351787806, L3: 1.002258062362671, L4: 1.0022584199905396
Epoch 500, Loss: 0.002349978080019355, Constraint losses: L1: -1.0382977724075317, L2: 0.0, L3: 0.0026932358741760254, L4: 0.0006950399838387966
Epoch 1000, Loss: 0.0014043987030163407, Constraint losses: L1: -1.0477721691131592, L2: 0.0, L3: 0.0022257566452026367, L4: 0.00022641434043180197
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 86.77562713623047, Losses: L1: 5.0405473709106445, L2: 0.0, L3: 0.9934319853782654, L4: 80.08059692382812, L5: 0.33052483201026917
Epoch 500, Loss: 2.684647560119629, Losses: L1: 0.4646623134613037, L2: 0.08391369134187698, L3: 0.07721006870269775, L4: 1.9413179159164429, L5: 0.01681499369442463
Epoch 1000, Loss: 1.8155131340026855, Losses: L1: 0.2626957893371582, L2: 0.04608747363090515, L3: 0.0612485408782959, L4: 1.3684056997299194, L5: 0.015494124963879585
Epoch 1500, Loss: 1.586020827293396, Losses: L1: 0.15094810724258423, L2: 0.038627274334430695, L3: 0.051180243492126465, L4: 1.2889050245285034, L5: 0.00886648427695036
Epoch 2000, Loss: 1.141868233680725, Losses: L1: 0.10181781649589539, L2: 0.023548748344182968, L3: 0.0515323281288147, L4: 0.9205095767974854, L5: 0.010455483570694923
Epoch 2500, Loss: 1.1713916063308716, Losses: L1: 0.07923096418380737, L2: 0.03321586549282074, L3: 0.04785555601119995, L4: 0.9647657871246338, L5: 0.006553769577294588
Epoch 3000, Loss: 0.493499219417572, Losses: L1: 0.08435847610235214, L2: 0.02700895629823208, L3: 0.04813748598098755, L4: 0.2942967414855957, L5: 0.006344310473650694
Epoch 3500, Loss: 0.46551159024238586, Losses: L1: 0.0857861265540123, L2: 0.02558724582195282, L3: 0.04783594608306885, L4: 0.26685258746147156, L5: 0.006931213196367025
Epoch 4000, Loss: 0.4408656060695648, Losses: L1: 0.08488506078720093, L2: 0.02420066110789776, L3: 0.047725141048431396, L4: 0.24624918401241302, L5: 0.0068024578504264355
Epoch 4500, Loss: 0.40302717685699463, Losses: L1: 0.08159323036670685, L2: 0.0247885063290596, L3: 0.04720938205718994, L4: 0.2112751454114914, L5: 0.006686205975711346
Epoch 5000, Loss: 0.39876124262809753, Losses: L1: 0.07894536107778549, L2: 0.02496805600821972, L3: 0.0468677282333374, L4: 0.20984947681427002, L5: 0.006581297144293785
Epoch 5500, Loss: 0.38817358016967773, Losses: L1: 0.07851509749889374, L2: 0.02452085167169571, L3: 0.04675179719924927, L4: 0.20069347321987152, L5: 0.006585745606571436
Epoch 6000, Loss: 0.38538119196891785, Losses: L1: 0.07779041677713394, L2: 0.02454054169356823, L3: 0.0466160774230957, L4: 0.19876910746097565, L5: 0.006562241818755865
Epoch 6500, Loss: 0.3827071189880371, Losses: L1: 0.0772891417145729, L2: 0.02448044903576374, L3: 0.04654276371002197, L4: 0.19677647948265076, L5: 0.006568905431777239
Epoch 7000, Loss: 0.38142192363739014, Losses: L1: 0.07693048566579819, L2: 0.02443891204893589, L3: 0.04649221897125244, L4: 0.19599080085754395, L5: 0.006565296556800604
Epoch 7500, Loss: 0.3805310130119324, Losses: L1: 0.07659842073917389, L2: 0.024420376867055893, L3: 0.04645538330078125, L4: 0.19550971686840057, L5: 0.006563364993780851
Epoch 8000, Loss: 0.379799485206604, Losses: L1: 0.07643568515777588, L2: 0.024413878098130226, L3: 0.04642832279205322, L4: 0.19498774409294128, L5: 0.006560005247592926
Epoch 8500, Loss: 0.37932711839675903, Losses: L1: 0.07633429020643234, L2: 0.024398356676101685, L3: 0.04640895128250122, L4: 0.19466832280158997, L5: 0.006559409201145172
Epoch 9000, Loss: 0.3789975345134735, Losses: L1: 0.07626623660326004, L2: 0.024397030472755432, L3: 0.0463942289352417, L4: 0.19442151486873627, L5: 0.006560751236975193
Epoch 9500, Loss: 0.37876564264297485, Losses: L1: 0.07620856165885925, L2: 0.024397414177656174, L3: 0.04638397693634033, L4: 0.19425542652606964, L5: 0.006561424117535353
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0033414363861084, Constraint losses: L1: 6.4161272048950195, L2: 0.0, L3: 0.9984628558158875, L4: 0.998462438583374
Epoch 500, Loss: 0.002446994883939624, Constraint losses: L1: -1.1132373809814453, L2: 0.0, L3: 0.0027791857719421387, L4: 0.0007810465758666396
Epoch 1000, Loss: 0.001400805776938796, Constraint losses: L1: -1.117807388305664, L2: 0.0, L3: 0.00225907564163208, L4: 0.00025953754084184766
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9978525638580322, Constraint losses: L1: 5.5542893409729, L2: 0.0, L3: 0.996149480342865, L4: 0.9961488246917725
Epoch 500, Loss: 0.002428164705634117, Constraint losses: L1: -1.0183135271072388, L2: 0.0, L3: 0.0027223825454711914, L4: 0.0007240957347676158
Epoch 1000, Loss: 0.0014159989077597857, Constraint losses: L1: -1.0519468784332275, L2: 0.0, L3: 0.002233743667602539, L4: 0.0002342021034564823
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 161.20570373535156, Losses: L1: 17.284019470214844, L2: 0.0009643851080909371, L3: 1.0009268522262573, L4: 71.39134979248047, L5: 0.272232323884964
Epoch 500, Loss: 16.424245834350586, Losses: L1: 4.933506965637207, L2: 0.7921728491783142, L3: 0.18023765087127686, L4: 4.849971771240234, L5: 0.0524238757789135
Epoch 1000, Loss: 8.023771286010742, Losses: L1: 0.9922996163368225, L2: 0.0785074532032013, L3: 0.10958057641983032, L4: 3.374629020690918, L5: 0.031237132847309113
Epoch 1500, Loss: 10.557588577270508, Losses: L1: 3.841297149658203, L2: 0.20520338416099548, L3: 0.14689624309539795, L4: 3.0739388465881348, L5: 0.022220412269234657
Epoch 2000, Loss: 10.342344284057617, Losses: L1: 1.5503970384597778, L2: 0.13470497727394104, L3: 0.11515969038009644, L4: 4.198235988616943, L5: 0.021811097860336304
Epoch 2500, Loss: 4.151646614074707, Losses: L1: 0.9621902108192444, L2: 0.07294187694787979, L3: 0.11563706398010254, L4: 1.4596670866012573, L5: 0.01720258593559265
Epoch 3000, Loss: 3.553419828414917, Losses: L1: 0.8835702538490295, L2: 0.061629727482795715, L3: 0.11514592170715332, L4: 1.211406946182251, L5: 0.017260674387216568
Epoch 3500, Loss: 3.2767839431762695, Losses: L1: 0.8188132643699646, L2: 0.05518052726984024, L3: 0.11090350151062012, L4: 1.1144136190414429, L5: 0.015757625922560692
Epoch 4000, Loss: 3.1512532234191895, Losses: L1: 0.8005998730659485, L2: 0.05280471220612526, L3: 0.10796880722045898, L4: 1.0647203922271729, L5: 0.015268617309629917
Epoch 4500, Loss: 3.036130428314209, Losses: L1: 0.7744221687316895, L2: 0.050033725798130035, L3: 0.10660171508789062, L4: 1.0237970352172852, L5: 0.014890040270984173
Epoch 5000, Loss: 2.8994600772857666, Losses: L1: 0.7193475961685181, L2: 0.04820536822080612, L3: 0.10421836376190186, L4: 0.986289381980896, L5: 0.013809410855174065
Epoch 5500, Loss: 2.8248043060302734, Losses: L1: 0.7087280750274658, L2: 0.04686146602034569, L3: 0.10298633575439453, L4: 0.9564149379730225, L5: 0.013073751702904701
Epoch 6000, Loss: 2.7634150981903076, Losses: L1: 0.7025306224822998, L2: 0.04586245119571686, L3: 0.10195422172546387, L4: 0.9304985404014587, L5: 0.012416410259902477
Epoch 6500, Loss: 2.6980977058410645, Losses: L1: 0.6847636699676514, L2: 0.044949598610401154, L3: 0.10099762678146362, L4: 0.9082409739494324, L5: 0.01191045343875885
Epoch 7000, Loss: 2.6601452827453613, Losses: L1: 0.6830657124519348, L2: 0.04440091550350189, L3: 0.10024845600128174, L4: 0.891096830368042, L5: 0.011670916341245174
Epoch 7500, Loss: 2.6328511238098145, Losses: L1: 0.6814229488372803, L2: 0.04405509680509567, L3: 0.09982132911682129, L4: 0.8788812160491943, L5: 0.011468240059912205
Epoch 8000, Loss: 2.554313898086548, Losses: L1: 0.6234060525894165, L2: 0.042830854654312134, L3: 0.09976696968078613, L4: 0.8699623942375183, L5: 0.011108936741948128
Epoch 8500, Loss: 2.5341897010803223, Losses: L1: 0.6203404664993286, L2: 0.042853567749261856, L3: 0.099276602268219, L4: 0.8616914749145508, L5: 0.010965269058942795
Epoch 9000, Loss: 2.52154541015625, Losses: L1: 0.6191190481185913, L2: 0.04260396584868431, L3: 0.09912109375, L4: 0.8563331365585327, L5: 0.010862219147384167
Epoch 9500, Loss: 2.5131049156188965, Losses: L1: 0.6182758808135986, L2: 0.04253028333187103, L3: 0.09900659322738647, L4: 0.8526807427406311, L5: 0.010800864547491074
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0135085582733154, Constraint losses: L1: 13.46679973602295, L2: 0.00015884090680629015, L3: 0.9999414682388306, L4: 0.9999415278434753
Epoch 500, Loss: 0.0023360829800367355, Constraint losses: L1: -1.0765137672424316, L2: 0.0, L3: 0.0027053356170654297, L4: 0.0007072612643241882
Epoch 1000, Loss: 0.0013209705939516425, Constraint losses: L1: -1.1165391206741333, L2: 0.0, L3: 0.002218484878540039, L4: 0.00021902479056734592
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0099432468414307, Constraint losses: L1: 9.934782028198242, L2: 0.00012384522415231913, L3: 0.999942421913147, L4: 0.9999422430992126
Epoch 500, Loss: 0.002241298323497176, Constraint losses: L1: -0.9256783723831177, L2: 0.0, L3: 0.002582371234893799, L4: 0.0005846054409630597
Epoch 1000, Loss: 0.0012942184694111347, Constraint losses: L1: -1.0503370761871338, L2: 0.0, L3: 0.0021719932556152344, L4: 0.00017256231512874365
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 166.24290466308594, Losses: L1: 7.826097011566162, L2: 1.336837976850802e-05, L3: 0.9993053078651428, L4: 78.54835510253906, L5: 0.3207740783691406
Epoch 500, Loss: 10.271089553833008, Losses: L1: 1.177293300628662, L2: 0.13024921715259552, L3: 0.09934461116790771, L4: 4.3361921310424805, L5: 0.06156916916370392
Epoch 1000, Loss: 18.26348876953125, Losses: L1: 4.058316230773926, L2: 0.6294421553611755, L3: 0.15414810180664062, L4: 6.347280502319336, L5: 0.09757915139198303
Epoch 1500, Loss: 5.054441452026367, Losses: L1: 1.6673414707183838, L2: 0.20906396210193634, L3: 0.10730099678039551, L4: 1.3914905786514282, L5: 0.07868940383195877
Epoch 2000, Loss: 3.114166259765625, Losses: L1: 0.823047399520874, L2: 0.15167412161827087, L3: 0.08101809024810791, L4: 0.9287543892860413, L5: 0.049243614077568054
Epoch 2500, Loss: 3.6540651321411133, Losses: L1: 0.8740577697753906, L2: 0.14458344876766205, L3: 0.08254623413085938, L4: 1.181919813156128, L5: 0.04445461556315422
Epoch 3000, Loss: 2.2742180824279785, Losses: L1: 0.6089124083518982, L2: 0.12059838324785233, L3: 0.07931941747665405, L4: 0.6510281562805176, L5: 0.04273331165313721
Epoch 3500, Loss: 1.9704278707504272, Losses: L1: 0.5390850901603699, L2: 0.10978104919195175, L3: 0.07545244693756104, L4: 0.5496236681938171, L5: 0.03708091005682945
Epoch 4000, Loss: 1.8641895055770874, Losses: L1: 0.49397727847099304, L2: 0.1006021797657013, L3: 0.07415050268173218, L4: 0.5305455923080444, L5: 0.033766187727451324
Epoch 4500, Loss: 1.777984380722046, Losses: L1: 0.4562963843345642, L2: 0.09537994116544724, L3: 0.07328909635543823, L4: 0.5128833055496216, L5: 0.031872425228357315
Epoch 5000, Loss: 1.7123465538024902, Losses: L1: 0.4215145707130432, L2: 0.09127233922481537, L3: 0.07293689250946045, L4: 0.5023590922355652, L5: 0.030632292851805687
Epoch 5500, Loss: 1.6681773662567139, Losses: L1: 0.4021671414375305, L2: 0.08789900690317154, L3: 0.072451651096344, L4: 0.494288831949234, L5: 0.029182936996221542
Epoch 6000, Loss: 1.6332309246063232, Losses: L1: 0.3838099539279938, L2: 0.08558385074138641, L3: 0.07213926315307617, L4: 0.4889656603336334, L5: 0.028182726353406906
Epoch 6500, Loss: 1.6208209991455078, Losses: L1: 0.38277387619018555, L2: 0.08430029451847076, L3: 0.07197356224060059, L4: 0.4848991930484772, L5: 0.02767462097108364
Epoch 7000, Loss: 1.61166250705719, Losses: L1: 0.38152962923049927, L2: 0.08344554901123047, L3: 0.07188308238983154, L4: 0.4820559024810791, L5: 0.027246881276369095
Epoch 7500, Loss: 1.6050273180007935, Losses: L1: 0.38077670335769653, L2: 0.08301212638616562, L3: 0.0717473030090332, L4: 0.4797467291355133, L5: 0.02698557637631893
Epoch 8000, Loss: 1.6000902652740479, Losses: L1: 0.38047224283218384, L2: 0.08249310404062271, L3: 0.07170867919921875, L4: 0.4780758023262024, L5: 0.026771511882543564
Epoch 8500, Loss: 1.5970008373260498, Losses: L1: 0.3801640272140503, L2: 0.08225502818822861, L3: 0.07164549827575684, L4: 0.47703176736831665, L5: 0.026617705821990967
Epoch 9000, Loss: 1.594525933265686, Losses: L1: 0.37999945878982544, L2: 0.08200567215681076, L3: 0.0716281533241272, L4: 0.4761877954006195, L5: 0.026511300355196
Epoch 9500, Loss: 1.5929653644561768, Losses: L1: 0.3799028694629669, L2: 0.08186902850866318, L3: 0.071602463722229, L4: 0.4756486415863037, L5: 0.026424633339047432
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.005880832672119, Constraint losses: L1: 7.277688026428223, L2: 0.0, L3: 0.999301552772522, L4: 0.9993014335632324
Epoch 500, Loss: 0.002378658391535282, Constraint losses: L1: -1.1116913557052612, L2: 0.0, L3: 0.002744317054748535, L4: 0.0007460328051820397
Epoch 1000, Loss: 0.0013767884811386466, Constraint losses: L1: -1.116735816001892, L2: 0.0, L3: 0.0022464394569396973, L4: 0.00024708485580049455
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.006411552429199, Constraint losses: L1: 7.570723533630371, L2: 1.1892077367292586e-07, L3: 0.9994202852249146, L4: 0.9994204044342041
Epoch 500, Loss: 0.0028420635499060154, Constraint losses: L1: -0.9234844446182251, L2: 0.0, L3: 0.0028815269470214844, L4: 0.0008840212831273675
Epoch 1000, Loss: 0.001485705259256065, Constraint losses: L1: -1.0492829084396362, L2: 0.0, L3: 0.002267181873321533, L4: 0.00026780637563206255
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 180.2826385498047, Losses: L1: 15.146051406860352, L2: 0.0020758314058184624, L3: 1.0016549825668335, L4: 81.72175598144531, L5: 0.34363415837287903
Epoch 500, Loss: 11.419322967529297, Losses: L1: 0.8943266868591309, L2: 0.1172013133764267, L3: 0.09125423431396484, L4: 5.060429096221924, L5: 0.03924063965678215
Epoch 1000, Loss: 4.422816753387451, Losses: L1: 0.33502548933029175, L2: 0.053254514932632446, L3: 0.04863786697387695, L4: 1.9511164426803589, L5: 0.015205577947199345
Epoch 1500, Loss: 3.24544095993042, Losses: L1: 0.24098902940750122, L2: 0.04691191390156746, L3: 0.05972015857696533, L4: 1.41015625, L5: 0.015297777950763702
Epoch 2000, Loss: 11.277512550354004, Losses: L1: 2.448878526687622, L2: 0.1410633772611618, L3: 0.24610143899917603, L4: 4.131133079528809, L5: 0.0190702136605978
Epoch 2500, Loss: 3.1973564624786377, Losses: L1: 0.6047142148017883, L2: 0.06658828258514404, L3: 0.10584026575088501, L4: 1.1635926961898804, L5: 0.01321997307240963
Epoch 3000, Loss: 2.4145123958587646, Losses: L1: 0.47021812200546265, L2: 0.05862021446228027, L3: 0.0909503698348999, L4: 0.8565319776535034, L5: 0.011519744992256165
Epoch 3500, Loss: 1.962668776512146, Losses: L1: 0.46779441833496094, L2: 0.05580073222517967, L3: 0.08688551187515259, L4: 0.6353785395622253, L5: 0.012815182097256184
Epoch 4000, Loss: 1.8533308506011963, Losses: L1: 0.4444008469581604, L2: 0.05567479133605957, L3: 0.08411884307861328, L4: 0.5938210487365723, L5: 0.012909742072224617
Epoch 4500, Loss: 1.780601143836975, Losses: L1: 0.4233839213848114, L2: 0.05474252626299858, L3: 0.08320868015289307, L4: 0.5691210627555847, L5: 0.013140655122697353
Epoch 5000, Loss: 1.7436443567276, Losses: L1: 0.4204154908657074, L2: 0.054395757615566254, L3: 0.08274203538894653, L4: 0.552365779876709, L5: 0.01348192524164915
Epoch 5500, Loss: 1.7173140048980713, Losses: L1: 0.41960832476615906, L2: 0.05411678925156593, L3: 0.08225655555725098, L4: 0.5400112271308899, L5: 0.013596509583294392
Epoch 6000, Loss: 1.6992440223693848, Losses: L1: 0.41929665207862854, L2: 0.053661663085222244, L3: 0.08194756507873535, L4: 0.531528115272522, L5: 0.013810131698846817
Epoch 6500, Loss: 1.6868958473205566, Losses: L1: 0.41871973872184753, L2: 0.05356202274560928, L3: 0.0816037654876709, L4: 0.5257872343063354, L5: 0.013936849310994148
Epoch 7000, Loss: 1.6782695055007935, Losses: L1: 0.41811230778694153, L2: 0.05355778709053993, L3: 0.08131629228591919, L4: 0.5218520164489746, L5: 0.014010625891387463
Epoch 7500, Loss: 1.671630620956421, Losses: L1: 0.41759803891181946, L2: 0.0536581389605999, L3: 0.08105069398880005, L4: 0.518733024597168, L5: 0.01409980095922947
Epoch 8000, Loss: 1.6670780181884766, Losses: L1: 0.4173239469528198, L2: 0.053664084523916245, L3: 0.08088052272796631, L4: 0.5166193246841431, L5: 0.0141533762216568
Epoch 8500, Loss: 1.6634314060211182, Losses: L1: 0.4171256422996521, L2: 0.05367268994450569, L3: 0.0807453989982605, L4: 0.5149362087249756, L5: 0.014171225018799305
Epoch 9000, Loss: 1.6609700918197632, Losses: L1: 0.41700953245162964, L2: 0.053673889487981796, L3: 0.08064913749694824, L4: 0.5137858390808105, L5: 0.01419595442712307
Epoch 9500, Loss: 1.6592578887939453, Losses: L1: 0.4169451594352722, L2: 0.053673241287469864, L3: 0.08057785034179688, L4: 0.5129806995391846, L5: 0.014213526621460915
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0057132244110107, Constraint losses: L1: 7.166206359863281, L2: 0.0, L3: 0.9992735981941223, L4: 0.999273419380188
Epoch 500, Loss: 0.002493610605597496, Constraint losses: L1: -0.9024046659469604, L2: 0.0, L3: 0.0026967525482177734, L4: 0.0006992627750150859
Epoch 1000, Loss: 0.0012439321726560593, Constraint losses: L1: -1.1156506538391113, L2: 0.0, L3: 0.0021795034408569336, L4: 0.00018007951439358294
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0033392906188965, Constraint losses: L1: 6.485931873321533, L2: 0.0, L3: 0.9984265565872192, L4: 0.9984267354011536
Epoch 500, Loss: 0.0021741625387221575, Constraint losses: L1: -0.981680691242218, L2: 0.0, L3: 0.0025771260261535645, L4: 0.0005787172704003751
Epoch 1000, Loss: 0.0013040807098150253, Constraint losses: L1: -1.0509785413742065, L2: 0.0, L3: 0.002177298069000244, L4: 0.00017776121967472136
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.82447814941406, Losses: L1: 5.638581275939941, L2: 4.4385848013916984e-05, L3: 0.9938613176345825, L4: 78.08734130859375, L5: 0.308828741312027
Epoch 500, Loss: 36.99037551879883, Losses: L1: 9.866676330566406, L2: 0.002696963958442211, L3: 0.9990737438201904, L4: 49.99045944213867, L5: 0.24985556304454803
Epoch 1000, Loss: 15.348099708557129, Losses: L1: 4.822188854217529, L2: 0.2844201624393463, L3: 0.4674868583679199, L4: 17.979347229003906, L5: 0.06484685838222504
Epoch 1500, Loss: 32.086788177490234, Losses: L1: 3.885659694671631, L2: 0.0003732907644007355, L3: 0.8873888850212097, L4: 52.64397430419922, L5: 0.2072342187166214
Epoch 2000, Loss: 37.80060577392578, Losses: L1: 10.674989700317383, L2: 2.96621165034594e-05, L3: 0.9998315572738647, L4: 50.00153350830078, L5: 0.25024938583374023
Epoch 2500, Loss: 35.024478912353516, Losses: L1: 7.4005656242370605, L2: 0.0, L3: 0.9985429644584656, L4: 51.06060791015625, L5: 0.19304805994033813
Epoch 3000, Loss: 31.09530258178711, Losses: L1: 3.6998419761657715, L2: 0.012596383690834045, L3: 0.8885090351104736, L4: 51.0076789855957, L5: 0.17882344126701355
Epoch 3500, Loss: 30.760589599609375, Losses: L1: 3.6708476543426514, L2: 0.019442500546574593, L3: 0.8777832984924316, L4: 50.41337203979492, L5: 0.17720817029476166
Epoch 4000, Loss: 30.281848907470703, Losses: L1: 3.713052988052368, L2: 0.10445232689380646, L3: 0.8312819004058838, L4: 49.22654724121094, L5: 0.16810421645641327
Epoch 4500, Loss: 29.183259963989258, Losses: L1: 3.8086321353912354, L2: 0.1559351086616516, L3: 0.8277618885040283, L4: 46.653465270996094, L5: 0.1610044240951538
Epoch 5000, Loss: 28.139028549194336, Losses: L1: 4.261604309082031, L2: 0.13144627213478088, L3: 0.8828458189964294, L4: 43.522071838378906, L5: 0.175608828663826
Epoch 5500, Loss: 27.878732681274414, Losses: L1: 4.832644939422607, L2: 0.10596513748168945, L3: 0.9507789611816406, L4: 41.69809341430664, L5: 0.16710834205150604
Epoch 6000, Loss: 27.836593627929688, Losses: L1: 4.824703216552734, L2: 0.10299453139305115, L3: 0.9503520727157593, L4: 41.64360046386719, L5: 0.16679319739341736
Epoch 6500, Loss: 27.8066349029541, Losses: L1: 4.824683666229248, L2: 0.10090983659029007, L3: 0.9500717520713806, L4: 41.593353271484375, L5: 0.16662155091762543
Epoch 7000, Loss: 27.78487777709961, Losses: L1: 4.821130275726318, L2: 0.09997820109128952, L3: 0.9497461318969727, L4: 41.56214904785156, L5: 0.16645213961601257
Epoch 7500, Loss: 27.769058227539062, Losses: L1: 4.818459987640381, L2: 0.09937480092048645, L3: 0.9496251940727234, L4: 41.53891372680664, L5: 0.16628398001194
Epoch 8000, Loss: 27.757299423217773, Losses: L1: 4.816673755645752, L2: 0.09887644648551941, L3: 0.9495468735694885, L4: 41.52137756347656, L5: 0.16617919504642487
Epoch 8500, Loss: 27.74863052368164, Losses: L1: 4.815770626068115, L2: 0.09847273677587509, L3: 0.9495158195495605, L4: 41.50767517089844, L5: 0.16609053313732147
Epoch 9000, Loss: 27.742300033569336, Losses: L1: 4.815196514129639, L2: 0.09814883023500443, L3: 0.9494884014129639, L4: 41.49763488769531, L5: 0.1660231202840805
Epoch 9500, Loss: 27.737741470336914, Losses: L1: 4.8148603439331055, L2: 0.09789277613162994, L3: 0.9494657516479492, L4: 41.4903564453125, L5: 0.16597475111484528
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.006608247756958, Constraint losses: L1: 7.61517333984375, L2: 0.0, L3: 0.9994965195655823, L4: 0.999496579170227
Epoch 500, Loss: 0.0022423542104661465, Constraint losses: L1: -1.070601224899292, L2: 0.0, L3: 0.0026554465293884277, L4: 0.0006575088482350111
Epoch 1000, Loss: 0.0013013717252761126, Constraint losses: L1: -1.1179383993148804, L2: 0.0, L3: 0.0022093653678894043, L4: 0.00020994473015889525
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0298256874084473, Constraint losses: L1: 18.42068099975586, L2: 0.003801436396315694, L3: 1.0038014650344849, L4: 1.0038021802902222
Epoch 500, Loss: 0.0024536591954529285, Constraint losses: L1: -1.0428303480148315, L2: 0.0, L3: 0.00274735689163208, L4: 0.0007491325959563255
Epoch 1000, Loss: 0.0014400840736925602, Constraint losses: L1: -1.051074504852295, L2: 0.0, L3: 0.0022452473640441895, L4: 0.0002459113602526486
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.11107635498047, Losses: L1: 14.081225395202637, L2: 0.001008374965749681, L3: 1.0006784200668335, L4: 75.45043182373047, L5: 0.30126360058784485
Epoch 500, Loss: 14.908278465270996, Losses: L1: 2.5898280143737793, L2: 0.012243962846696377, L3: 0.4046139717102051, L4: 22.795860290527344, L5: 0.08680438250303268
Epoch 1000, Loss: 1.1440449953079224, Losses: L1: 0.24793802201747894, L2: 0.05019728094339371, L3: 0.07031583786010742, L4: 1.2709593772888184, L5: 0.0196010023355484
Epoch 1500, Loss: 1.4173771142959595, Losses: L1: 0.2208462655544281, L2: 0.027116255834698677, L3: 0.0708993673324585, L4: 1.9798356294631958, L5: 0.010581832379102707
Epoch 2000, Loss: 0.7193357348442078, Losses: L1: 0.20141607522964478, L2: 0.031369369477033615, L3: 0.06600189208984375, L4: 0.6324499845504761, L5: 0.006952126044780016
Epoch 2500, Loss: 1.110851526260376, Losses: L1: 0.38513702154159546, L2: 0.05767790228128433, L3: 0.08906948566436768, L4: 0.8500151634216309, L5: 0.0072121755219995975
Epoch 3000, Loss: 0.9137797951698303, Losses: L1: 0.3033599257469177, L2: 0.049967292696237564, L3: 0.07865822315216064, L4: 0.6912685632705688, L5: 0.007534565404057503
Epoch 3500, Loss: 0.8554601073265076, Losses: L1: 0.2869264781475067, L2: 0.04524202272295952, L3: 0.07669323682785034, L4: 0.6337230801582336, L5: 0.0078015704639256
Epoch 4000, Loss: 0.826366126537323, Losses: L1: 0.2868158519268036, L2: 0.04331675544381142, L3: 0.07560032606124878, L4: 0.5862652659416199, L5: 0.008583500981330872
Epoch 4500, Loss: 0.8001991510391235, Losses: L1: 0.2850055992603302, L2: 0.04352148249745369, L3: 0.07422459125518799, L4: 0.5424377918243408, L5: 0.008482514880597591
Epoch 5000, Loss: 0.7745223641395569, Losses: L1: 0.271003395318985, L2: 0.04242488741874695, L3: 0.07370585203170776, L4: 0.5256598591804504, L5: 0.008427536115050316
Epoch 5500, Loss: 0.7531793713569641, Losses: L1: 0.25547000765800476, L2: 0.04119429364800453, L3: 0.07359951734542847, L4: 0.5195262432098389, L5: 0.008358679711818695
Epoch 6000, Loss: 0.7425569891929626, Losses: L1: 0.2540978491306305, L2: 0.041883524507284164, L3: 0.07256418466567993, L4: 0.5023640990257263, L5: 0.008381679654121399
Epoch 6500, Loss: 0.7371487617492676, Losses: L1: 0.2535765469074249, L2: 0.041872430592775345, L3: 0.07214868068695068, L4: 0.49429747462272644, L5: 0.008381275460124016
Epoch 7000, Loss: 0.7332303524017334, Losses: L1: 0.25314629077911377, L2: 0.041866861283779144, L3: 0.07185709476470947, L4: 0.48852846026420593, L5: 0.008371890522539616
Epoch 7500, Loss: 0.7302126884460449, Losses: L1: 0.2529827654361725, L2: 0.04184157773852348, L3: 0.07163280248641968, L4: 0.4837878346443176, L5: 0.008387191221117973
Epoch 8000, Loss: 0.7281022667884827, Losses: L1: 0.2529313564300537, L2: 0.0418131947517395, L3: 0.07145583629608154, L4: 0.48047712445259094, L5: 0.008394325152039528
Epoch 8500, Loss: 0.7266401052474976, Losses: L1: 0.2528790831565857, L2: 0.041803568601608276, L3: 0.07132720947265625, L4: 0.47819820046424866, L5: 0.008400391787290573
Epoch 9000, Loss: 0.7256016135215759, Losses: L1: 0.2527344524860382, L2: 0.04185871034860611, L3: 0.07121193408966064, L4: 0.47665709257125854, L5: 0.008397307246923447
Epoch 9500, Loss: 0.7248955965042114, Losses: L1: 0.2526717782020569, L2: 0.04186008870601654, L3: 0.07114911079406738, L4: 0.4756123721599579, L5: 0.008399223908782005
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0360336303710938, Constraint losses: L1: 18.42068099975586, L2: 0.005870765540748835, L3: 1.0058708190917969, L4: 1.005871295928955
Epoch 500, Loss: 0.002183320466428995, Constraint losses: L1: -1.0675374269485474, L2: 0.0, L3: 0.0026243925094604492, L4: 0.000626465305685997
Epoch 1000, Loss: 0.0012718021171167493, Constraint losses: L1: -1.1178770065307617, L2: 0.0, L3: 0.0021944642066955566, L4: 0.00019521503418218344
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.028047561645508, Constraint losses: L1: 18.42068099975586, L2: 0.003208791371434927, L3: 1.0032087564468384, L4: 1.0032093524932861
Epoch 500, Loss: 0.002186729107052088, Constraint losses: L1: -0.9991114735603333, L2: 0.0, L3: 0.0025919675827026367, L4: 0.0005938730901107192
Epoch 1000, Loss: 0.001324518583714962, Constraint losses: L1: -1.0499753952026367, L2: 0.0, L3: 0.002187013626098633, L4: 0.00018748032744042575
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 51.46087646484375, Losses: L1: 6.060580730438232, L2: 0.0, L3: 0.997670590877533, L4: 85.34087371826172, L5: 0.3672606945037842
Epoch 500, Loss: 19.775917053222656, Losses: L1: 6.484793186187744, L2: 0.5969077348709106, L3: 0.3705812692642212, L4: 22.288650512695312, L5: 0.10591058433055878
Epoch 1000, Loss: 15.8939208984375, Losses: L1: 7.04534912109375, L2: 0.5277994275093079, L3: 0.3639787435531616, L4: 13.692011833190918, L5: 0.10950478166341782
Epoch 1500, Loss: 11.156545639038086, Losses: L1: 4.726151943206787, L2: 0.2619350552558899, L3: 0.22485381364822388, L4: 10.571921348571777, L5: 0.08542771637439728
Epoch 2000, Loss: 32.100189208984375, Losses: L1: 5.624212265014648, L2: 0.35161519050598145, L3: 0.8826611042022705, L4: 47.319793701171875, L5: 0.17376402020454407
Epoch 2500, Loss: 45.50581359863281, Losses: L1: 16.54749870300293, L2: 0.0, L3: 0.999999463558197, L4: 53.20412826538086, L5: 0.17812775075435638
Epoch 3000, Loss: 31.573402404785156, Losses: L1: 3.7187111377716064, L2: 0.001908553414978087, L3: 0.9406861066818237, L4: 51.17430114746094, L5: 0.19117523729801178
Epoch 3500, Loss: 31.278100967407227, Losses: L1: 3.5118653774261475, L2: 0.0016368463402613997, L3: 0.933724582195282, L4: 51.03934097290039, L5: 0.18792018294334412
Epoch 4000, Loss: 31.0999698638916, Losses: L1: 3.4746108055114746, L2: 0.001537366770207882, L3: 0.929888904094696, L4: 50.773048400878906, L5: 0.1879914551973343
Epoch 4500, Loss: 30.8181095123291, Losses: L1: 3.234180212020874, L2: 0.0013130867155268788, L3: 0.9230079054832458, L4: 50.736427307128906, L5: 0.18353675305843353
Epoch 5000, Loss: 30.707565307617188, Losses: L1: 3.180985927581787, L2: 0.001305866171605885, L3: 0.9192765951156616, L4: 50.643253326416016, L5: 0.181893989443779
Epoch 5500, Loss: 30.61907196044922, Losses: L1: 3.146122932434082, L2: 0.001288174418732524, L3: 0.9166921377182007, L4: 50.552093505859375, L5: 0.18047116696834564
Epoch 6000, Loss: 30.54559326171875, Losses: L1: 3.1210386753082275, L2: 0.0012743818806484342, L3: 0.9147893786430359, L4: 50.467933654785156, L5: 0.179229274392128
Epoch 6500, Loss: 30.4847412109375, Losses: L1: 3.102520227432251, L2: 0.0012609603581950068, L3: 0.9133650064468384, L4: 50.393253326416016, L5: 0.17817087471485138
Epoch 7000, Loss: 30.437116622924805, Losses: L1: 3.0927746295928955, L2: 0.0012396785896271467, L3: 0.9126774668693542, L4: 50.32329559326172, L5: 0.17742986977100372
Epoch 7500, Loss: 30.401748657226562, Losses: L1: 3.0887393951416016, L2: 0.0012181163765490055, L3: 0.9124391078948975, L4: 50.26364517211914, L5: 0.17693586647510529
Epoch 8000, Loss: 30.37393569946289, Losses: L1: 3.0847747325897217, L2: 0.0012038137065246701, L3: 0.912157416343689, L4: 50.218788146972656, L5: 0.17652250826358795
Epoch 8500, Loss: 30.352365493774414, Losses: L1: 3.0810418128967285, L2: 0.0011948334285989404, L3: 0.9118599891662598, L4: 50.18567657470703, L5: 0.17618846893310547
Epoch 9000, Loss: 30.33582305908203, Losses: L1: 3.077651262283325, L2: 0.0011896512005478144, L3: 0.9115676283836365, L4: 50.16160583496094, L5: 0.17592720687389374
Epoch 9500, Loss: 30.323291778564453, Losses: L1: 3.0747408866882324, L2: 0.0011869346490129828, L3: 0.9113024473190308, L4: 50.144229888916016, L5: 0.1757284551858902
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0253758430480957, Constraint losses: L1: 18.42068099975586, L2: 0.0023182870354503393, L3: 1.002318263053894, L4: 1.0023185014724731
Epoch 500, Loss: 0.002575238235294819, Constraint losses: L1: -1.1014515161514282, L2: 0.0, L3: 0.002837240695953369, L4: 0.0008394490578211844
Epoch 1000, Loss: 0.0014335695886984468, Constraint losses: L1: -1.1186234951019287, L2: 0.0, L3: 0.0022757649421691895, L4: 0.0002764281816780567
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0012459754943848, Constraint losses: L1: 6.074533462524414, L2: 0.0, L3: 0.9975857138633728, L4: 0.9975858926773071
Epoch 500, Loss: 0.001962619135156274, Constraint losses: L1: -0.9690656065940857, L2: 0.0, L3: 0.002464890480041504, L4: 0.000466794241219759
Epoch 1000, Loss: 0.0012203799560666084, Constraint losses: L1: -1.0502994060516357, L2: 0.0, L3: 0.0021350979804992676, L4: 0.00013558141654357314
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 83.82844543457031, Losses: L1: 16.122478485107422, L2: 0.0018860911950469017, L3: 1.0016640424728394, L4: 65.58312225341797, L5: 0.23149476945400238
Epoch 500, Loss: 63.9149284362793, Losses: L1: 11.766349792480469, L2: 3.980969268013723e-06, L3: 0.9999555945396423, L4: 50.02605056762695, L5: 0.24521960318088531
Epoch 1000, Loss: 61.97526168823242, Losses: L1: 9.837905883789062, L2: 0.0, L3: 0.9999068975448608, L4: 50.014041900634766, L5: 0.24700336158275604
Epoch 1500, Loss: 20.909164428710938, Losses: L1: 5.9725728034973145, L2: 0.28832533955574036, L3: 0.25445932149887085, L4: 13.813812255859375, L5: 0.0744197890162468
Epoch 2000, Loss: 55.58250427246094, Losses: L1: 4.544233322143555, L2: 0.0008782380609773099, L3: 0.9753466844558716, L4: 48.97685623168945, L5: 0.21792440116405487
Epoch 2500, Loss: 15.59906005859375, Losses: L1: 4.754337310791016, L2: 0.032325223088264465, L3: 0.24819862842559814, L4: 10.240413665771484, L5: 0.08652255684137344
Epoch 3000, Loss: 8.53891658782959, Losses: L1: 1.2502812147140503, L2: 0.0045397053472697735, L3: 0.26109105348587036, L4: 6.738448143005371, L5: 0.03785089775919914
Epoch 3500, Loss: 7.851656913757324, Losses: L1: 1.1484166383743286, L2: 0.003573121502995491, L3: 0.2537270188331604, L4: 6.169825077056885, L5: 0.0376303531229496
Epoch 4000, Loss: 7.4366679191589355, Losses: L1: 1.0849438905715942, L2: 0.0027928801719099283, L3: 0.25265806913375854, L4: 5.822093963623047, L5: 0.037456922233104706
Epoch 4500, Loss: 7.79619836807251, Losses: L1: 1.4392876625061035, L2: 0.007289361208677292, L3: 0.2582714557647705, L4: 5.805135726928711, L5: 0.04130677878856659
Epoch 5000, Loss: 7.232983112335205, Losses: L1: 1.063004970550537, L2: 0.002345095155760646, L3: 0.2453731894493103, L4: 5.6547112464904785, L5: 0.03966040536761284
Epoch 5500, Loss: 7.18267297744751, Losses: L1: 1.0537980794906616, L2: 0.0019708408508449793, L3: 0.24825572967529297, L4: 5.609058856964111, L5: 0.038725804537534714
Epoch 6000, Loss: 7.152828216552734, Losses: L1: 1.046173095703125, L2: 0.0017997355898842216, L3: 0.24956834316253662, L4: 5.584780216217041, L5: 0.038277849555015564
Epoch 6500, Loss: 7.108401775360107, Losses: L1: 1.0250523090362549, L2: 0.001581480959430337, L3: 0.25071167945861816, L4: 5.5596771240234375, L5: 0.03817223757505417
Epoch 7000, Loss: 7.084619522094727, Losses: L1: 1.0170143842697144, L2: 0.001545483130030334, L3: 0.2510607838630676, L4: 5.54347038269043, L5: 0.03784480690956116
Epoch 7500, Loss: 7.070446491241455, Losses: L1: 1.0165339708328247, L2: 0.0015139448223635554, L3: 0.2509635090827942, L4: 5.530031204223633, L5: 0.03785189613699913
Epoch 8000, Loss: 7.060176849365234, Losses: L1: 1.0165202617645264, L2: 0.0014954304788261652, L3: 0.2508140802383423, L4: 5.52009916305542, L5: 0.03787662461400032
Epoch 8500, Loss: 7.052340984344482, Losses: L1: 1.0156058073043823, L2: 0.0014851356390863657, L3: 0.2507643699645996, L4: 5.513303756713867, L5: 0.037864964455366135
Epoch 9000, Loss: 7.046522617340088, Losses: L1: 1.0157381296157837, L2: 0.0014795236056670547, L3: 0.25068795680999756, L4: 5.507507801055908, L5: 0.03788331151008606
Epoch 9500, Loss: 7.042230606079102, Losses: L1: 1.0154664516448975, L2: 0.0014749264810234308, L3: 0.25067389011383057, L4: 5.503526210784912, L5: 0.03788134828209877
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0291848182678223, Constraint losses: L1: 18.42068099975586, L2: 0.0035877195186913013, L3: 1.0035877227783203, L4: 1.0035887956619263
Epoch 500, Loss: 0.002293110592290759, Constraint losses: L1: -1.0247408151626587, L2: 0.0, L3: 0.0026578903198242188, L4: 0.0006599610787816346
Epoch 1000, Loss: 0.0012819278053939342, Constraint losses: L1: -1.1163270473480225, L2: 0.0, L3: 0.002198934555053711, L4: 0.00019932040595449507
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.007124900817871, Constraint losses: L1: 7.926825523376465, L2: 0.0, L3: 0.9995989203453064, L4: 0.999599039554596
Epoch 500, Loss: 0.002784138545393944, Constraint losses: L1: -0.8532100915908813, L2: 0.0, L3: 0.0028173327445983887, L4: 0.0008200161391869187
Epoch 1000, Loss: 0.0014234044356271625, Constraint losses: L1: -1.049243450164795, L2: 0.0, L3: 0.002235889434814453, L4: 0.00023675852571614087
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 83.55410766601562, Losses: L1: 9.165842056274414, L2: 4.4027099647792056e-05, L3: 0.9994587898254395, L4: 72.11385345458984, L5: 0.27540576457977295
Epoch 500, Loss: 59.67979431152344, Losses: L1: 7.376379489898682, L2: 0.02326541393995285, L3: 0.9925721883773804, L4: 50.02632522583008, L5: 0.24541498720645905
Epoch 1000, Loss: 11.329305648803711, Losses: L1: 3.6301662921905518, L2: 0.09101741760969162, L3: 0.20818471908569336, L4: 7.065136909484863, L5: 0.03559879958629608
Epoch 1500, Loss: 10.981481552124023, Losses: L1: 3.567592144012451, L2: 0.287421852350235, L3: 0.17590254545211792, L4: 6.417825698852539, L5: 0.06941442936658859
Epoch 2000, Loss: 3.704106092453003, Losses: L1: 1.5737379789352417, L2: 0.06628776341676712, L3: 0.13466793298721313, L4: 1.6970760822296143, L5: 0.0313805527985096
Epoch 2500, Loss: 6.703342437744141, Losses: L1: 1.5874415636062622, L2: 0.1841532438993454, L3: 0.10248255729675293, L4: 4.493704795837402, L5: 0.048924218863248825
Epoch 3000, Loss: 3.30657958984375, Losses: L1: 1.0813965797424316, L2: 0.0938134640455246, L3: 0.11230015754699707, L4: 1.7791705131530762, L5: 0.03378543257713318
Epoch 3500, Loss: 2.953819513320923, Losses: L1: 0.985696017742157, L2: 0.08941693603992462, L3: 0.1133342981338501, L4: 1.5308321714401245, L5: 0.031788818538188934
Epoch 4000, Loss: 2.776995897293091, Losses: L1: 0.9322230815887451, L2: 0.09931665658950806, L3: 0.11694973707199097, L4: 1.3776462078094482, L5: 0.03459373861551285
Epoch 4500, Loss: 2.7264039516448975, Losses: L1: 0.928266167640686, L2: 0.09979133307933807, L3: 0.11604607105255127, L4: 1.3317780494689941, L5: 0.03468484431505203
Epoch 5000, Loss: 2.6915688514709473, Losses: L1: 0.9220536947250366, L2: 0.09908109903335571, L3: 0.11563581228256226, L4: 1.3054819107055664, L5: 0.03459929674863815
Epoch 5500, Loss: 2.667999744415283, Losses: L1: 0.9175950884819031, L2: 0.09861522912979126, L3: 0.1152036190032959, L4: 1.2884328365325928, L5: 0.034334104508161545
Epoch 6000, Loss: 2.6514334678649902, Losses: L1: 0.9131709337234497, L2: 0.09804684668779373, L3: 0.11482560634613037, L4: 1.2783308029174805, L5: 0.03418677672743797
Epoch 6500, Loss: 2.6380984783172607, Losses: L1: 0.9106060266494751, L2: 0.09788569062948227, L3: 0.11444604396820068, L4: 1.2688629627227783, L5: 0.03396615386009216
Epoch 7000, Loss: 2.628800868988037, Losses: L1: 0.9081483483314514, L2: 0.09769397974014282, L3: 0.11432039737701416, L4: 1.2628366947174072, L5: 0.033786971122026443
Epoch 7500, Loss: 2.6218905448913574, Losses: L1: 0.9067816138267517, L2: 0.09743452072143555, L3: 0.11416083574295044, L4: 1.2582097053527832, L5: 0.03370862081646919
Epoch 8000, Loss: 2.6169042587280273, Losses: L1: 0.9054067730903625, L2: 0.09734870493412018, L3: 0.11404484510421753, L4: 1.2550528049468994, L5: 0.03365763649344444
Epoch 8500, Loss: 2.61350154876709, Losses: L1: 0.9045765995979309, L2: 0.0972599983215332, L3: 0.1139480471611023, L4: 1.2528895139694214, L5: 0.0336194708943367
Epoch 9000, Loss: 2.610999822616577, Losses: L1: 0.9038185477256775, L2: 0.09725145995616913, L3: 0.11388963460922241, L4: 1.251319169998169, L5: 0.03358009457588196
Epoch 9500, Loss: 2.6093363761901855, Losses: L1: 0.9034101963043213, L2: 0.09725763648748398, L3: 0.1138189435005188, L4: 1.2502120733261108, L5: 0.03356102854013443
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023214817047119, Constraint losses: L1: 18.42068099975586, L2: 0.0015980550087988377, L3: 1.0015980005264282, L4: 1.0015982389450073
Epoch 500, Loss: 0.002338649006560445, Constraint losses: L1: -1.0668832063674927, L2: 0.0, L3: 0.0027017593383789062, L4: 0.0007037728792056441
Epoch 1000, Loss: 0.001328877522610128, Constraint losses: L1: -1.1181598901748657, L2: 0.0, L3: 0.002223193645477295, L4: 0.00022384384647011757
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.018908739089966, Constraint losses: L1: 17.85141372680664, L2: 0.000509118486661464, L3: 1.0002740621566772, L4: 1.0002741813659668
Epoch 500, Loss: 0.001930068712681532, Constraint losses: L1: -1.0038586854934692, L2: 0.0, L3: 0.002466142177581787, L4: 0.0004677853430621326
Epoch 1000, Loss: 0.001236363430507481, Constraint losses: L1: -1.0509670972824097, L2: 0.0, L3: 0.0021435022354125977, L4: 0.00014382829249370843
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 77.61210632324219, Losses: L1: 6.0337114334106445, L2: 4.7484492824878544e-05, L3: 0.9962242841720581, L4: 69.0707015991211, L5: 0.2575758099555969
Epoch 500, Loss: 8.794291496276855, Losses: L1: 0.5868125557899475, L2: 0.047420453280210495, L3: 0.08858251571655273, L4: 7.818259239196777, L5: 0.0586073100566864
Epoch 1000, Loss: 5.745458602905273, Losses: L1: 1.5426530838012695, L2: 0.023014526814222336, L3: 0.17064499855041504, L4: 3.726487398147583, L5: 0.04449935257434845
Epoch 1500, Loss: 8.645478248596191, Losses: L1: 1.5486124753952026, L2: 0.021642861887812614, L3: 0.16382110118865967, L4: 6.625253200531006, L5: 0.05034206807613373
Epoch 2000, Loss: 64.19050598144531, Losses: L1: 11.57993221282959, L2: 0.0140779297798872, L3: 0.9892558455467224, L4: 50.16925811767578, L5: 0.2173231840133667
Epoch 2500, Loss: 9.418190002441406, Losses: L1: 3.302924871444702, L2: 0.06720566004514694, L3: 0.25987517833709717, L4: 5.343992233276367, L5: 0.05855540558695793
Epoch 3000, Loss: 6.818875312805176, Losses: L1: 1.967593789100647, L2: 0.038411837071180344, L3: 0.214400053024292, L4: 4.280246734619141, L5: 0.03270544484257698
Epoch 3500, Loss: 5.05588436126709, Losses: L1: 1.7149848937988281, L2: 0.042512524873018265, L3: 0.20303493738174438, L4: 2.8055360317230225, L5: 0.022134188562631607
Epoch 4000, Loss: 4.419366836547852, Losses: L1: 1.5983259677886963, L2: 0.04743199422955513, L3: 0.1813042163848877, L4: 2.314413547515869, L5: 0.024577336385846138
Epoch 4500, Loss: 4.146526336669922, Losses: L1: 1.4696069955825806, L2: 0.04629645124077797, L3: 0.1744903326034546, L4: 2.187483787536621, L5: 0.023930992931127548
Epoch 5000, Loss: 4.01923942565918, Losses: L1: 1.457118034362793, L2: 0.049016404896974564, L3: 0.1685272455215454, L4: 2.0793466567993164, L5: 0.023843783885240555
Epoch 5500, Loss: 3.91296648979187, Losses: L1: 1.4431171417236328, L2: 0.05117742717266083, L3: 0.16482126712799072, L4: 1.9907543659210205, L5: 0.023548753932118416
Epoch 6000, Loss: 3.8452141284942627, Losses: L1: 1.4431887865066528, L2: 0.05109994113445282, L3: 0.16244208812713623, L4: 1.9277784824371338, L5: 0.023581378161907196
Epoch 6500, Loss: 3.795711040496826, Losses: L1: 1.438724398612976, L2: 0.05085066705942154, L3: 0.16065454483032227, L4: 1.886826753616333, L5: 0.023574763908982277
Epoch 7000, Loss: 3.933565855026245, Losses: L1: 1.3790115118026733, L2: 0.05792902782559395, L3: 0.15756523609161377, L4: 2.0762088298797607, L5: 0.023678401485085487
Epoch 7500, Loss: 3.668830156326294, Losses: L1: 1.2908344268798828, L2: 0.05166783183813095, L3: 0.16140544414520264, L4: 1.9068572521209717, L5: 0.022496016696095467
Epoch 8000, Loss: 3.6534855365753174, Losses: L1: 1.2929621934890747, L2: 0.05089379847049713, L3: 0.1608583927154541, L4: 1.8916196823120117, L5: 0.022699711844325066
Epoch 8500, Loss: 3.629173755645752, Losses: L1: 1.281263828277588, L2: 0.05040749907493591, L3: 0.16018164157867432, L4: 1.880797028541565, L5: 0.022967297583818436
Epoch 9000, Loss: 3.6222262382507324, Losses: L1: 1.281261920928955, L2: 0.05023918300867081, L3: 0.159837007522583, L4: 1.8746545314788818, L5: 0.02307872474193573
Epoch 9500, Loss: 3.6174416542053223, Losses: L1: 1.2808455228805542, L2: 0.05026773735880852, L3: 0.15963149070739746, L4: 1.870608925819397, L5: 0.023094454780220985
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0198590755462646, Constraint losses: L1: 18.42068099975586, L2: 0.0004895845195278525, L3: 1.0004743337631226, L4: 1.000474452972412
Epoch 500, Loss: 0.00221398682333529, Constraint losses: L1: -1.0830578804016113, L2: 0.0, L3: 0.002647578716278076, L4: 0.0006494660046882927
Epoch 1000, Loss: 0.0012913011014461517, Constraint losses: L1: -1.1181269884109497, L2: 0.0, L3: 0.002204418182373047, L4: 0.00020500998653005809
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.003667116165161, Constraint losses: L1: 6.378907680511475, L2: 0.00012988268281333148, L3: 0.9985796809196472, L4: 0.9985787272453308
Epoch 500, Loss: 0.0020418926142156124, Constraint losses: L1: -0.9549962878227234, L2: 0.0, L3: 0.0024976134300231934, L4: 0.0004992755129933357
Epoch 1000, Loss: 0.001240098150447011, Constraint losses: L1: -1.0508567094802856, L2: 0.0, L3: 0.002145230770111084, L4: 0.00014572417421732098
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 159.9987335205078, Losses: L1: 15.656637191772461, L2: 0.0031976839527487755, L3: 1.002679705619812, L4: 71.09780883789062, L5: 0.26944583654403687
Epoch 500, Loss: 28.349313735961914, Losses: L1: 5.920300483703613, L2: 1.400482177734375, L3: 0.17936086654663086, L4: 9.615139961242676, L5: 0.07809509336948395
Epoch 1000, Loss: 10.25355052947998, Losses: L1: 3.316117763519287, L2: 0.16410236060619354, L3: 0.11206269264221191, L4: 3.1800310611724854, L5: 0.05008196458220482
Epoch 1500, Loss: 14.512933731079102, Losses: L1: 5.144179821014404, L2: 0.5875871777534485, L3: 0.17271637916564941, L4: 3.912944793701172, L5: 0.04451415315270424
Epoch 2000, Loss: 1.6911163330078125, Losses: L1: 0.3153866231441498, L2: 0.0682598426938057, L3: 0.07718133926391602, L4: 0.5377148389816284, L5: 0.018835274502635002
Epoch 2500, Loss: 1.484007716178894, Losses: L1: 0.2273525446653366, L2: 0.05578415468335152, L3: 0.0673035979270935, L4: 0.5017679333686829, L5: 0.013887551613152027
Epoch 3000, Loss: 0.9850387573242188, Losses: L1: 0.2044810652732849, L2: 0.04887877777218819, L3: 0.06353974342346191, L4: 0.2743944823741913, L5: 0.013863296248018742
Epoch 3500, Loss: 1.0762416124343872, Losses: L1: 0.20084238052368164, L2: 0.044971928000450134, L3: 0.06184709072113037, L4: 0.32764434814453125, L5: 0.012944912537932396
Epoch 4000, Loss: 0.8231323957443237, Losses: L1: 0.2006896585226059, L2: 0.042567282915115356, L3: 0.06068575382232666, L4: 0.20449329912662506, L5: 0.013900051824748516
Epoch 4500, Loss: 0.760686457157135, Losses: L1: 0.18759165704250336, L2: 0.04027679190039635, L3: 0.059884846210479736, L4: 0.18286274373531342, L5: 0.014092049561440945
Epoch 5000, Loss: 0.7355304956436157, Losses: L1: 0.18447290360927582, L2: 0.03940626606345177, L3: 0.05936992168426514, L4: 0.1732853353023529, L5: 0.013869073241949081
Epoch 5500, Loss: 0.7121884822845459, Losses: L1: 0.1825604885816574, L2: 0.03888449817895889, L3: 0.05906558036804199, L4: 0.1633756458759308, L5: 0.01395309716463089
Epoch 6000, Loss: 0.7044042348861694, Losses: L1: 0.1811569631099701, L2: 0.03854728117585182, L3: 0.05883204936981201, L4: 0.16075298190116882, L5: 0.013965313322842121
Epoch 6500, Loss: 0.6969717144966125, Losses: L1: 0.18030241131782532, L2: 0.038360465317964554, L3: 0.05864149332046509, L4: 0.15784376859664917, L5: 0.013955740258097649
Epoch 7000, Loss: 0.6924797892570496, Losses: L1: 0.1794397234916687, L2: 0.03822154551744461, L3: 0.05850625038146973, L4: 0.15630783140659332, L5: 0.013937647454440594
Epoch 7500, Loss: 0.6892640590667725, Losses: L1: 0.178813636302948, L2: 0.038123104721307755, L3: 0.058410048484802246, L4: 0.15521639585494995, L5: 0.013902619481086731
Epoch 8000, Loss: 0.6868117451667786, Losses: L1: 0.17841826379299164, L2: 0.03806663677096367, L3: 0.05833578109741211, L4: 0.1543208658695221, L5: 0.013893801718950272
Epoch 8500, Loss: 0.6853212714195251, Losses: L1: 0.17811542749404907, L2: 0.03802700713276863, L3: 0.05828440189361572, L4: 0.15382051467895508, L5: 0.013883890584111214
Epoch 9000, Loss: 0.6841995120048523, Losses: L1: 0.177884042263031, L2: 0.03799830377101898, L3: 0.058248281478881836, L4: 0.15344282984733582, L5: 0.01387326791882515
Epoch 9500, Loss: 0.6834588050842285, Losses: L1: 0.17773711681365967, L2: 0.03797124698758125, L3: 0.05822312831878662, L4: 0.15319985151290894, L5: 0.013866439461708069
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9983609914779663, Constraint losses: L1: 5.544013023376465, L2: 0.0, L3: 0.9964092373847961, L4: 0.9964077472686768
Epoch 500, Loss: 0.0020768563263118267, Constraint losses: L1: -1.0926424264907837, L2: 0.0, L3: 0.0025839805603027344, L4: 0.0005855180788785219
Epoch 1000, Loss: 0.0012595879379659891, Constraint losses: L1: -1.1180566549301147, L2: 0.0, L3: 0.002188563346862793, L4: 0.00018908130005002022
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0055766105651855, Constraint losses: L1: 7.112734317779541, L2: 0.0, L3: 0.9992320537567139, L4: 0.9992319345474243
Epoch 500, Loss: 0.0021108025684952736, Constraint losses: L1: -1.0430186986923218, L2: 0.0, L3: 0.0025760531425476074, L4: 0.0005777680780738592
Epoch 1000, Loss: 0.0013264542212709785, Constraint losses: L1: -1.0516513586044312, L2: 0.0, L3: 0.0021888017654418945, L4: 0.0001893038715934381
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 158.42469787597656, Losses: L1: 7.028047561645508, L2: 0.00013491783465724438, L3: 0.9969705939292908, L4: 74.55320739746094, L5: 0.29602357745170593
Epoch 500, Loss: 20.300220489501953, Losses: L1: 5.546377182006836, L2: 0.6269011497497559, L3: 0.11430215835571289, L4: 6.594239234924316, L5: 0.0829586386680603
Epoch 1000, Loss: 3.8726422786712646, Losses: L1: 0.5332902669906616, L2: 0.06885003298521042, L3: 0.06216847896575928, L4: 1.5271528959274292, L5: 0.0230090394616127
Epoch 1500, Loss: 2.6244497299194336, Losses: L1: 0.154144287109375, L2: 0.03311346471309662, L3: 0.05880868434906006, L4: 1.134982943534851, L5: 0.016495121642947197
Epoch 2000, Loss: 2.6596946716308594, Losses: L1: 0.14353208243846893, L2: 0.03586451709270477, L3: 0.05447244644165039, L4: 1.1594822406768799, L5: 0.016524210572242737
Epoch 2500, Loss: 1.259778380393982, Losses: L1: 0.12025406211614609, L2: 0.03541162982583046, L3: 0.05361366271972656, L4: 0.47465261816978455, L5: 0.012168535962700844
Epoch 3000, Loss: 0.6942521333694458, Losses: L1: 0.10258285701274872, L2: 0.033490244299173355, L3: 0.05227303504943848, L4: 0.20480556786060333, L5: 0.010531526990234852
Epoch 3500, Loss: 0.6339648365974426, Losses: L1: 0.09915632009506226, L2: 0.03223191201686859, L3: 0.05140674114227295, L4: 0.17843715846538544, L5: 0.010656922124326229
Epoch 4000, Loss: 0.5956454277038574, Losses: L1: 0.09488913416862488, L2: 0.0320589542388916, L3: 0.05104076862335205, L4: 0.16192938387393951, L5: 0.01069808378815651
Epoch 4500, Loss: 0.5797843337059021, Losses: L1: 0.09470568597316742, L2: 0.031327467411756516, L3: 0.050817131996154785, L4: 0.1549883782863617, L5: 0.010812722146511078
Epoch 5000, Loss: 0.5564002394676208, Losses: L1: 0.09240880608558655, L2: 0.03108057752251625, L3: 0.05066800117492676, L4: 0.14493253827095032, L5: 0.01062926184386015
Epoch 5500, Loss: 0.54779452085495, Losses: L1: 0.09226948767900467, L2: 0.03086800128221512, L3: 0.05049288272857666, L4: 0.14114251732826233, L5: 0.010518249124288559
Epoch 6000, Loss: 0.5385899543762207, Losses: L1: 0.09099741280078888, L2: 0.03103339858353138, L3: 0.050366103649139404, L4: 0.13714972138404846, L5: 0.010494106449186802
Epoch 6500, Loss: 0.5316836833953857, Losses: L1: 0.09064049273729324, L2: 0.030783995985984802, L3: 0.05030262470245361, L4: 0.134184792637825, L5: 0.010500355623662472
Epoch 7000, Loss: 0.5268293619155884, Losses: L1: 0.09034489840269089, L2: 0.030676214024424553, L3: 0.05025482177734375, L4: 0.13204090297222137, L5: 0.01054059062153101
Epoch 7500, Loss: 0.5231236815452576, Losses: L1: 0.09002828598022461, L2: 0.030617067590355873, L3: 0.05022233724594116, L4: 0.13042792677879333, L5: 0.010560769587755203
Epoch 8000, Loss: 0.5205379128456116, Losses: L1: 0.0898807942867279, L2: 0.03056897222995758, L3: 0.05019998550415039, L4: 0.12928488850593567, L5: 0.01054941676557064
Epoch 8500, Loss: 0.5190989375114441, Losses: L1: 0.08979005366563797, L2: 0.030574122443795204, L3: 0.05017387866973877, L4: 0.12864992022514343, L5: 0.010512983426451683
Epoch 9000, Loss: 0.5180684924125671, Losses: L1: 0.08979479968547821, L2: 0.030556367710232735, L3: 0.050154685974121094, L4: 0.1281818151473999, L5: 0.0104879941791296
Epoch 9500, Loss: 0.5173338651657104, Losses: L1: 0.0897698700428009, L2: 0.030545195564627647, L3: 0.050142526626586914, L4: 0.12786033749580383, L5: 0.010467877611517906
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235  0.40015721]
 [ 0.97873798  2.2408932 ]
 [ 1.86755799 -0.97727788]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0251662731170654, Constraint losses: L1: 18.42068099975586, L2: 0.002248407108709216, L3: 1.0022484064102173, L4: 1.002248764038086
Epoch 500, Loss: 0.0024583167396485806, Constraint losses: L1: -1.0473827123641968, L2: 0.0, L3: 0.0027515292167663574, L4: 0.0007541703525930643
Epoch 1000, Loss: 0.001341585535556078, Constraint losses: L1: -1.1177068948745728, L2: 0.0, L3: 0.00222933292388916, L4: 0.0002299595798831433
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0274970531463623, Constraint losses: L1: 18.42068099975586, L2: 0.003025399288162589, L3: 1.0030254125595093, L4: 1.0030255317687988
Epoch 500, Loss: 0.002580533269792795, Constraint losses: L1: -0.9401986002922058, L2: 0.0, L3: 0.002759099006652832, L4: 0.0007616328075528145
Epoch 1000, Loss: 0.0014150779461488128, Constraint losses: L1: -1.0493875741958618, L2: 0.0, L3: 0.002231895923614502, L4: 0.00023256964050233364
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 172.17300415039062, Losses: L1: 8.789246559143066, L2: 0.0002877542283385992, L3: 0.9982880353927612, L4: 80.35895538330078, L5: 0.3343515992164612
Epoch 500, Loss: 5.43908166885376, Losses: L1: 0.622999906539917, L2: 0.08836762607097626, L3: 0.0723189115524292, L4: 2.1923530101776123, L5: 0.055001188069581985
Epoch 1000, Loss: 2.8647210597991943, Losses: L1: 0.22746679186820984, L2: 0.04867212474346161, L3: 0.06982606649398804, L4: 1.1879528760910034, L5: 0.012175993993878365
Epoch 1500, Loss: 2.7438881397247314, Losses: L1: 0.2681425213813782, L2: 0.03770234435796738, L3: 0.0529102087020874, L4: 1.1211317777633667, L5: 0.026128411293029785
Epoch 2000, Loss: 2.592780351638794, Losses: L1: 0.5066308379173279, L2: 0.07350924611091614, L3: 0.07695567607879639, L4: 0.860629677772522, L5: 0.03198017179965973
Epoch 2500, Loss: 1.4396904706954956, Losses: L1: 0.25133684277534485, L2: 0.0367906354367733, L3: 0.059374213218688965, L4: 0.47609037160873413, L5: 0.021921569481492043
Epoch 3000, Loss: 0.9267613291740417, Losses: L1: 0.18556806445121765, L2: 0.03699713572859764, L3: 0.051655590534210205, L4: 0.2604689598083496, L5: 0.021474923938512802
Epoch 3500, Loss: 1.1564421653747559, Losses: L1: 0.15719595551490784, L2: 0.029843633994460106, L3: 0.05178987979888916, L4: 0.3964930474758148, L5: 0.021496504545211792
Epoch 4000, Loss: 0.7512850165367126, Losses: L1: 0.1502581238746643, L2: 0.030459757894277573, L3: 0.05083966255187988, L4: 0.19909131526947021, L5: 0.020122716203331947
Epoch 4500, Loss: 0.641992449760437, Losses: L1: 0.14619822800159454, L2: 0.029294218868017197, L3: 0.05047130584716797, L4: 0.14882616698741913, L5: 0.019305408000946045
Epoch 5000, Loss: 0.6218425631523132, Losses: L1: 0.14138248562812805, L2: 0.028824670240283012, L3: 0.050295114517211914, L4: 0.14228135347366333, L5: 0.018828902393579483
Epoch 5500, Loss: 0.6024705171585083, Losses: L1: 0.14040426909923553, L2: 0.028610551729798317, L3: 0.04995572566986084, L4: 0.13382452726364136, L5: 0.018642297014594078
Epoch 6000, Loss: 0.5929189920425415, Losses: L1: 0.13904480636119843, L2: 0.028419865295290947, L3: 0.049713850021362305, L4: 0.13035619258880615, L5: 0.01844717748463154
Epoch 6500, Loss: 0.5859328508377075, Losses: L1: 0.13809794187545776, L2: 0.028347337618470192, L3: 0.04953896999359131, L4: 0.12775298953056335, L5: 0.018278149887919426
Epoch 7000, Loss: 0.581123411655426, Losses: L1: 0.13743162155151367, L2: 0.02821735106408596, L3: 0.04941666126251221, L4: 0.12607024610042572, L5: 0.01814165897667408
Epoch 7500, Loss: 0.5773319005966187, Losses: L1: 0.13682910799980164, L2: 0.02819441445171833, L3: 0.049308180809020996, L4: 0.12473098933696747, L5: 0.01801782101392746
Epoch 8000, Loss: 0.5750540494918823, Losses: L1: 0.13646063208580017, L2: 0.02815006673336029, L3: 0.04923814535140991, L4: 0.12396121025085449, L5: 0.017947284504771233
Epoch 8500, Loss: 0.5730487108230591, Losses: L1: 0.13613460958003998, L2: 0.028149334713816643, L3: 0.04918563365936279, L4: 0.1232369989156723, L5: 0.017885100096464157
Epoch 9000, Loss: 0.5719260573387146, Losses: L1: 0.13600540161132812, L2: 0.028132829815149307, L3: 0.049147069454193115, L4: 0.12283207476139069, L5: 0.017848331481218338
Epoch 9500, Loss: 0.571079432964325, Losses: L1: 0.13579905033111572, L2: 0.028137145563960075, L3: 0.04912209510803223, L4: 0.12256062030792236, L5: 0.017820321023464203
Training done
----------------------------------------------------------------------------
######################### Running test with dataset: PosDepWeight ###########
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0195984840393066, Constraint losses: L1: 18.42068099975586, L2: 0.0003925828787032515, L3: 1.0003925561904907, L4: 1.0003925561904907
Epoch 500, Loss: 0.0023804237134754658, Constraint losses: L1: -1.0663849115371704, L2: 0.0, L3: 0.0027222633361816406, L4: 0.0007245454471558332
Epoch 1000, Loss: 0.001341319177299738, Constraint losses: L1: -1.118059515953064, L2: 0.0, L3: 0.0022293925285339355, L4: 0.00022998632630333304
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0246164798736572, Constraint losses: L1: 18.42068099975586, L2: 0.0020650960505008698, L3: 1.0020650625228882, L4: 1.002065658569336
Epoch 500, Loss: 0.0023188386112451553, Constraint losses: L1: -1.0173908472061157, L2: 0.0, L3: 0.0026671290397644043, L4: 0.0006691005546599627
Epoch 1000, Loss: 0.0013459366746246815, Constraint losses: L1: -1.0702871084213257, L2: 0.0, L3: 0.002207815647125244, L4: 0.000208408193429932
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.8968391418457, Losses: L1: 18.42068099975586, L2: 0.014708828181028366, L3: 1.0147019624710083, L4: 75.66172790527344, L5: 0.26117634773254395
Epoch 500, Loss: 8.023139953613281, Losses: L1: 1.7205055952072144, L2: 0.545754075050354, L3: 0.25726211071014404, L4: 11.71877670288086, L5: 0.08347459137439728
Epoch 1000, Loss: 14.818233489990234, Losses: L1: 7.510631084442139, L2: 0.37047210335731506, L3: 0.253664493560791, L4: 13.907176971435547, L5: 0.08389092981815338
Epoch 1500, Loss: 6.552060604095459, Losses: L1: 3.5182716846466064, L2: 0.13274244964122772, L3: 0.19782781600952148, L4: 5.616067409515381, L5: 0.12093980610370636
Epoch 2000, Loss: 6.194374084472656, Losses: L1: 2.999633550643921, L2: 0.11385059356689453, L3: 0.16092360019683838, L4: 5.971118450164795, L5: 0.14358893036842346
Epoch 2500, Loss: 9.887304306030273, Losses: L1: 4.888272762298584, L2: 0.5065872669219971, L3: 0.21079552173614502, L4: 9.124857902526855, L5: 0.15582282841205597
Epoch 3000, Loss: 8.82596206665039, Losses: L1: 4.140229225158691, L2: 0.26378244161605835, L3: 0.2265329360961914, L4: 8.730165481567383, L5: 0.15098629891872406
Epoch 3500, Loss: 32.063209533691406, Losses: L1: 6.457205295562744, L2: 0.0, L3: 0.9979888796806335, L4: 49.914737701416016, L5: 0.29928073287010193
Epoch 4000, Loss: 8.131860733032227, Losses: L1: 4.452114582061768, L2: 0.26989102363586426, L3: 0.22945356369018555, L4: 6.754632949829102, L5: 0.10551422089338303
Epoch 4500, Loss: 7.29884147644043, Losses: L1: 4.2606916427612305, L2: 0.20844149589538574, L3: 0.233223557472229, L4: 5.522179126739502, L5: 0.11245511472225189
Epoch 5000, Loss: 7.113707542419434, Losses: L1: 4.231621265411377, L2: 0.1967606097459793, L3: 0.2311239242553711, L4: 5.22792911529541, L5: 0.1083591878414154
Epoch 5500, Loss: 6.951941013336182, Losses: L1: 4.214341163635254, L2: 0.18884089589118958, L3: 0.22829174995422363, L4: 4.951312065124512, L5: 0.10675519704818726
Epoch 6000, Loss: 6.868156909942627, Losses: L1: 4.2578864097595215, L2: 0.18723666667938232, L3: 0.22460836172103882, L4: 4.702749729156494, L5: 0.10594694316387177
Epoch 6500, Loss: 6.78931188583374, Losses: L1: 4.252630710601807, L2: 0.18282638490200043, L3: 0.22380685806274414, L4: 4.5611724853515625, L5: 0.10555760562419891
Epoch 7000, Loss: 6.735946178436279, Losses: L1: 4.250850200653076, L2: 0.18247291445732117, L3: 0.220694899559021, L4: 4.461122989654541, L5: 0.10590062290430069
Epoch 7500, Loss: 6.698633193969727, Losses: L1: 4.249382019042969, L2: 0.18144375085830688, L3: 0.21924352645874023, L4: 4.391948699951172, L5: 0.105865478515625
Epoch 8000, Loss: 6.672536373138428, Losses: L1: 4.247801303863525, L2: 0.1803838163614273, L3: 0.2184664011001587, L4: 4.344673156738281, L5: 0.10594671219587326
Epoch 8500, Loss: 6.654395580291748, Losses: L1: 4.247056007385254, L2: 0.1796332150697708, L3: 0.21792978048324585, L4: 4.311073303222656, L5: 0.10604312270879745
Epoch 9000, Loss: 6.641785621643066, Losses: L1: 4.246675968170166, L2: 0.17906400561332703, L3: 0.21761083602905273, L4: 4.28743314743042, L5: 0.10611198097467422
Epoch 9500, Loss: 6.633064270019531, Losses: L1: 4.246496200561523, L2: 0.17864269018173218, L3: 0.21741873025894165, L4: 4.270907402038574, L5: 0.10616748034954071
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0250964164733887, Constraint losses: L1: 18.42068099975586, L2: 0.0022250504698604345, L3: 1.0022250413894653, L4: 1.002225637435913
Epoch 500, Loss: 0.0020040415693074465, Constraint losses: L1: -1.1148420572280884, L2: 0.0, L3: 0.0025587081909179688, L4: 0.0005601755110546947
Epoch 1000, Loss: 0.001251145382411778, Constraint losses: L1: -1.1188950538635254, L2: 0.0, L3: 0.002184748649597168, L4: 0.00018529189401306212
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0202348232269287, Constraint losses: L1: 18.42068099975586, L2: 0.0006047592032700777, L3: 1.0006047487258911, L4: 1.0006046295166016
Epoch 500, Loss: 0.002531736623495817, Constraint losses: L1: -1.035010576248169, L2: 0.0, L3: 0.0027824044227600098, L4: 0.0007843429921194911
Epoch 1000, Loss: 0.0014325614320114255, Constraint losses: L1: -1.0710595846176147, L2: 0.0, L3: 0.002251565456390381, L4: 0.000252055557211861
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 53.36294937133789, Losses: L1: 16.38675880432129, L2: 0.0009196375613100827, L3: 1.0008043050765991, L4: 72.46307373046875, L5: 0.2437942624092102
Epoch 500, Loss: 30.83165740966797, Losses: L1: 5.422491550445557, L2: 0.003842755453661084, L3: 0.9905110001564026, L4: 49.259788513183594, L5: 0.2820952534675598
Epoch 1000, Loss: 18.86817741394043, Losses: L1: 10.84013557434082, L2: 2.182708978652954, L3: 0.32548820972442627, L4: 13.268564224243164, L5: 0.13966220617294312
Epoch 1500, Loss: 28.080732345581055, Losses: L1: 5.510153770446777, L2: 1.568109393119812, L3: 1.033501386642456, L4: 42.21588897705078, L5: 0.16182850301265717
Epoch 2000, Loss: 5.6408867835998535, Losses: L1: 1.0777288675308228, L2: 0.2911629378795624, L3: 0.28645503520965576, L4: 8.404592514038086, L5: 0.07205253839492798
Epoch 2500, Loss: 4.359564781188965, Losses: L1: 0.8190165162086487, L2: 0.24646806716918945, L3: 0.2379082441329956, L4: 6.453352928161621, L5: 0.07168377190828323
Epoch 3000, Loss: 3.6540091037750244, Losses: L1: 0.6525383591651917, L2: 0.19432328641414642, L3: 0.22523272037506104, L4: 5.467120170593262, L5: 0.05813264474272728
Epoch 3500, Loss: 3.391007661819458, Losses: L1: 0.627092182636261, L2: 0.16676059365272522, L3: 0.2186284065246582, L4: 5.040472030639648, L5: 0.050985101610422134
Epoch 4000, Loss: 3.2481250762939453, Losses: L1: 0.6287096738815308, L2: 0.14713740348815918, L3: 0.21536362171173096, L4: 4.782848358154297, L5: 0.04674072936177254
Epoch 4500, Loss: 3.152144193649292, Losses: L1: 0.6347302794456482, L2: 0.13469897210597992, L3: 0.2117953896522522, L4: 4.597078323364258, L5: 0.0456276498734951
Epoch 5000, Loss: 3.0926289558410645, Losses: L1: 0.634489893913269, L2: 0.12801390886306763, L3: 0.21053534746170044, L4: 4.490760803222656, L5: 0.043484289199113846
Epoch 5500, Loss: 2.989515781402588, Losses: L1: 0.5884559750556946, L2: 0.11142577975988388, L3: 0.2057066559791565, L4: 4.400624752044678, L5: 0.04218136519193649
Epoch 6000, Loss: 2.959343194961548, Losses: L1: 0.589519202709198, L2: 0.10759150981903076, L3: 0.20444142818450928, L4: 4.3446455001831055, L5: 0.041484735906124115
Epoch 6500, Loss: 2.9380462169647217, Losses: L1: 0.5895923376083374, L2: 0.10519547015428543, L3: 0.20354413986206055, L4: 4.306292533874512, L5: 0.04093767702579498
Epoch 7000, Loss: 2.9221856594085693, Losses: L1: 0.5897392630577087, L2: 0.10361473262310028, L3: 0.20273780822753906, L4: 4.277149200439453, L5: 0.040695417672395706
Epoch 7500, Loss: 2.910945177078247, Losses: L1: 0.5895569324493408, L2: 0.10241950303316116, L3: 0.20229732990264893, L4: 4.257232666015625, L5: 0.04041357338428497
Epoch 8000, Loss: 2.9028983116149902, Losses: L1: 0.5893183350563049, L2: 0.10157597064971924, L3: 0.2020106315612793, L4: 4.243175983428955, L5: 0.040198709815740585
Epoch 8500, Loss: 2.8972384929656982, Losses: L1: 0.5890144109725952, L2: 0.10094323754310608, L3: 0.20190471410751343, L4: 4.233624458312988, L5: 0.039987821131944656
Epoch 9000, Loss: 2.893162488937378, Losses: L1: 0.588799774646759, L2: 0.10060187429189682, L3: 0.20171117782592773, L4: 4.226593971252441, L5: 0.039909057319164276
Epoch 9500, Loss: 2.890385150909424, Losses: L1: 0.588581919670105, L2: 0.10034501552581787, L3: 0.20166325569152832, L4: 4.221968650817871, L5: 0.03981480374932289
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0215485095977783, Constraint losses: L1: 18.42068099975586, L2: 0.0010425159707665443, L3: 1.0010424852371216, L4: 1.0010428428649902
Epoch 500, Loss: 0.0023027013521641493, Constraint losses: L1: -0.981857419013977, L2: 0.0, L3: 0.0026412010192871094, L4: 0.0006433577509596944
Epoch 1000, Loss: 0.0012675339821726084, Constraint losses: L1: -1.113870620727539, L2: 0.0, L3: 0.00219041109085083, L4: 0.00019099347991868854
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9972591400146484, Constraint losses: L1: 5.4703521728515625, L2: 0.0, L3: 0.9958946704864502, L4: 0.9958940744400024
Epoch 500, Loss: 0.0023765787482261658, Constraint losses: L1: -0.9452119469642639, L2: 0.0, L3: 0.0026597976684570312, L4: 0.000661992933601141
Epoch 1000, Loss: 0.001319071277976036, Constraint losses: L1: -1.0654850006103516, L2: 0.0, L3: 0.0021920204162597656, L4: 0.00019253595382906497
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 44.071678161621094, Losses: L1: 4.647777557373047, L2: 0.0, L3: 0.9901990294456482, L4: 76.77607727050781, L5: 0.2703820765018463
Epoch 500, Loss: 30.337074279785156, Losses: L1: 3.224266767501831, L2: 0.0, L3: 0.9275991916656494, L4: 52.11271667480469, L5: 0.29632440209388733
Epoch 1000, Loss: 3.985166549682617, Losses: L1: 0.62187260389328, L2: 0.11156351119279861, L3: 0.11097323894500732, L4: 6.235204696655273, L5: 0.06721165031194687
Epoch 1500, Loss: 4.60312557220459, Losses: L1: 2.5078985691070557, L2: 0.26370707154273987, L3: 0.13493424654006958, L4: 3.6207926273345947, L5: 0.0427548885345459
Epoch 2000, Loss: 1.0902611017227173, Losses: L1: 0.19116267561912537, L2: 0.03718067705631256, L3: 0.11907249689102173, L4: 1.5564286708831787, L5: 0.02137877605855465
Epoch 2500, Loss: 4.6522626876831055, Losses: L1: 2.4694643020629883, L2: 0.4338991641998291, L3: 0.1516183614730835, L4: 3.629793167114258, L5: 0.03757140785455704
Epoch 3000, Loss: 4.434494495391846, Losses: L1: 2.3796069622039795, L2: 0.2705138027667999, L3: 0.15946829319000244, L4: 3.555396556854248, L5: 0.0310991108417511
Epoch 3500, Loss: 3.6005032062530518, Losses: L1: 0.766983151435852, L2: 0.004871336277574301, L3: 0.1408863067626953, L4: 5.334099292755127, L5: 0.04679573327302933
Epoch 4000, Loss: 2.883190631866455, Losses: L1: 0.8899033665657043, L2: 0.006382640451192856, L3: 0.1363094449043274, L4: 3.6714563369750977, L5: 0.043106500059366226
Epoch 4500, Loss: 2.5193467140197754, Losses: L1: 0.8003690838813782, L2: 0.004534106235951185, L3: 0.13286668062210083, L4: 3.1276493072509766, L5: 0.04322625324130058
Epoch 5000, Loss: 2.3692386150360107, Losses: L1: 0.7874682545661926, L2: 0.0042481510899960995, L3: 0.12711501121520996, L4: 2.864623785018921, L5: 0.041888508945703506
Epoch 5500, Loss: 2.3266053199768066, Losses: L1: 0.6851428747177124, L2: 0.0027896251995116472, L3: 0.12442010641098022, L4: 3.0061709880828857, L5: 0.03738603740930557
Epoch 6000, Loss: 2.2630293369293213, Losses: L1: 0.6723921298980713, L2: 0.0026615627575665712, L3: 0.12550365924835205, L4: 2.9096765518188477, L5: 0.03585809841752052
Epoch 6500, Loss: 2.231525421142578, Losses: L1: 0.6740030646324158, L2: 0.0027362704277038574, L3: 0.12481486797332764, L4: 2.844780921936035, L5: 0.03567809611558914
Epoch 7000, Loss: 2.2107460498809814, Losses: L1: 0.6772629618644714, L2: 0.0027834223583340645, L3: 0.12432670593261719, L4: 2.7969815731048584, L5: 0.03571853041648865
Epoch 7500, Loss: 2.1956300735473633, Losses: L1: 0.6791921854019165, L2: 0.0028052525594830513, L3: 0.12411236763000488, L4: 2.7633936405181885, L5: 0.035641148686409
Epoch 8000, Loss: 2.184370279312134, Losses: L1: 0.6804087162017822, L2: 0.002825851086527109, L3: 0.12391948699951172, L4: 2.739140033721924, L5: 0.03550945222377777
Epoch 8500, Loss: 2.175981283187866, Losses: L1: 0.6809137463569641, L2: 0.0028369042556732893, L3: 0.12376296520233154, L4: 2.7219810485839844, L5: 0.03538864105939865
Epoch 9000, Loss: 2.1697583198547363, Losses: L1: 0.6812047958374023, L2: 0.0028456577565521, L3: 0.12362349033355713, L4: 2.7093911170959473, L5: 0.03531164303421974
Epoch 9500, Loss: 2.165286064147949, Losses: L1: 0.6815871000289917, L2: 0.002845173701643944, L3: 0.12342113256454468, L4: 2.6997017860412598, L5: 0.03535746410489082
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.003469228744507, Constraint losses: L1: 6.486236572265625, L2: 0.0, L3: 0.9984914660453796, L4: 0.9984914660453796
Epoch 500, Loss: 0.0023288929369300604, Constraint losses: L1: -1.045165777206421, L2: 0.0, L3: 0.0026860833168029785, L4: 0.00068797537824139
Epoch 1000, Loss: 0.001304703764617443, Constraint losses: L1: -1.116971731185913, L2: 0.0, L3: 0.0022106170654296875, L4: 0.00021105854830238968
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0006227493286133, Constraint losses: L1: 5.930302143096924, L2: 0.0, L3: 0.9973462224006653, L4: 0.9973462820053101
Epoch 500, Loss: 0.002348868176341057, Constraint losses: L1: -0.9655987024307251, L2: 0.0, L3: 0.0026561617851257324, L4: 0.0006583052454516292
Epoch 1000, Loss: 0.0013410223182290792, Constraint losses: L1: -1.0678637027740479, L2: 0.0, L3: 0.0022041797637939453, L4: 0.0002047063026111573
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 100.36593627929688, Losses: L1: 18.249162673950195, L2: 0.004652190022170544, L3: 1.0046513080596924, L4: 81.46192169189453, L5: 0.30039477348327637
Epoch 500, Loss: 61.60458755493164, Losses: L1: 10.944960594177246, L2: 0.0, L3: 0.9998961091041565, L4: 50.0083122253418, L5: 0.30273813009262085
Epoch 1000, Loss: 55.75873947143555, Losses: L1: 4.104841232299805, L2: 0.0, L3: 0.9754434823989868, L4: 51.01742935180664, L5: 0.29748958349227905
Epoch 1500, Loss: 55.41975784301758, Losses: L1: 3.759145736694336, L2: 0.00037876589340157807, L3: 0.9699240326881409, L4: 51.02687072753906, L5: 0.29717981815338135
Epoch 2000, Loss: 55.364498138427734, Losses: L1: 3.708317995071411, L2: 0.0005996365798637271, L3: 0.9699786901473999, L4: 51.02272415161133, L5: 0.2963346242904663
Epoch 2500, Loss: 53.07276916503906, Losses: L1: 2.8123393058776855, L2: 0.016987955197691917, L3: 0.9398409128189087, L4: 49.65082931518555, L5: 0.2623777389526367
Epoch 3000, Loss: 16.004798889160156, Losses: L1: 6.583831310272217, L2: 0.29167863726615906, L3: 0.2519100308418274, L4: 9.10530948638916, L5: 0.08772573620080948
Epoch 3500, Loss: 14.675392150878906, Losses: L1: 6.262060642242432, L2: 0.28915953636169434, L3: 0.25038284063339233, L4: 8.096776008605957, L5: 0.09356913715600967
Epoch 4000, Loss: 13.144885063171387, Losses: L1: 5.864684581756592, L2: 0.24582694470882416, L3: 0.250341534614563, L4: 6.981029510498047, L5: 0.10217522084712982
Epoch 4500, Loss: 12.390323638916016, Losses: L1: 5.6386332511901855, L2: 0.23341497778892517, L3: 0.2427884340286255, L4: 6.4611496925354, L5: 0.10487780719995499
Epoch 5000, Loss: 12.053312301635742, Losses: L1: 5.640000343322754, L2: 0.23189608752727509, L3: 0.24173086881637573, L4: 6.123974323272705, L5: 0.10504965484142303
Epoch 5500, Loss: 11.84168529510498, Losses: L1: 5.641511917114258, L2: 0.23111066222190857, L3: 0.24072062969207764, L4: 5.91161584854126, L5: 0.10528344660997391
Epoch 6000, Loss: 11.653053283691406, Losses: L1: 5.586132049560547, L2: 0.22881552577018738, L3: 0.23772072792053223, L4: 5.779692649841309, L5: 0.10792247951030731
Epoch 6500, Loss: 11.552050590515137, Losses: L1: 5.540421009063721, L2: 0.22895316779613495, L3: 0.23500388860702515, L4: 5.725058078765869, L5: 0.10918711870908737
Epoch 7000, Loss: 11.50366497039795, Losses: L1: 5.539098739624023, L2: 0.22809918224811554, L3: 0.23588907718658447, L4: 5.67809534072876, L5: 0.10895302146673203
Epoch 7500, Loss: 11.471019744873047, Losses: L1: 5.539405345916748, L2: 0.22804498672485352, L3: 0.23654139041900635, L4: 5.6449127197265625, L5: 0.10881540179252625
Epoch 8000, Loss: 11.446833610534668, Losses: L1: 5.539949417114258, L2: 0.22814203798770905, L3: 0.23707294464111328, L4: 5.619966506958008, L5: 0.10862155258655548
Epoch 8500, Loss: 11.428938865661621, Losses: L1: 5.5403361320495605, L2: 0.22819188237190247, L3: 0.23751729726791382, L4: 5.60151481628418, L5: 0.1084645465016365
Epoch 9000, Loss: 11.415816307067871, Losses: L1: 5.540623188018799, L2: 0.22820423543453217, L3: 0.23788833618164062, L4: 5.587975978851318, L5: 0.10834372043609619
Epoch 9500, Loss: 11.40631103515625, Losses: L1: 5.540807723999023, L2: 0.22820131480693817, L3: 0.23818987607955933, L4: 5.578184127807617, L5: 0.1082485094666481
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.019301176071167, Constraint losses: L1: 18.42068099975586, L2: 0.0002934627700597048, L3: 1.000293493270874, L4: 1.000293493270874
Epoch 500, Loss: 0.00266147218644619, Constraint losses: L1: -1.1089426279067993, L2: 0.0, L3: 0.002884089946746826, L4: 0.0008863250259310007
Epoch 1000, Loss: 0.0014640537556260824, Constraint losses: L1: -1.1168913841247559, L2: 0.0, L3: 0.002290070056915283, L4: 0.00029087511938996613
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005835771560669, Constraint losses: L1: 7.346255302429199, L2: 0.0, L3: 0.9992445707321167, L4: 0.9992448687553406
Epoch 500, Loss: 0.002448583720251918, Constraint losses: L1: -0.9394227862358093, L2: 0.0, L3: 0.0026928186416625977, L4: 0.0006951878312975168
Epoch 1000, Loss: 0.0013310260837897658, Constraint losses: L1: -1.0686789751052856, L2: 0.0, L3: 0.0021996498107910156, L4: 0.00020005526312161237
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 101.63681030273438, Losses: L1: 18.42068099975586, L2: 0.00673650810495019, L3: 1.0067365169525146, L4: 82.40147399902344, L5: 0.30792108178138733
Epoch 500, Loss: 15.405143737792969, Losses: L1: 4.215729713439941, L2: 1.2741097211837769, L3: 0.271801233291626, L4: 10.279622077941895, L5: 0.13683722913265228
Epoch 1000, Loss: 6.102705955505371, Losses: L1: 2.1919326782226562, L2: 0.38888368010520935, L3: 0.16138041019439697, L4: 3.573930025100708, L5: 0.061711084097623825
Epoch 1500, Loss: 11.485107421875, Losses: L1: 3.302572011947632, L2: 0.7023357152938843, L3: 0.26141148805618286, L4: 7.620840072631836, L5: 0.07982181012630463
Epoch 2000, Loss: 8.37147331237793, Losses: L1: 2.634464740753174, L2: 1.9945757389068604, L3: 0.25307697057724, L4: 4.49260950088501, L5: 0.12057319283485413
Epoch 2500, Loss: 64.0504379272461, Losses: L1: 13.246086120605469, L2: 6.736197974532843e-05, L3: 0.9999905228614807, L4: 49.99965286254883, L5: 0.3046759068965912
Epoch 3000, Loss: 61.74778747558594, Losses: L1: 10.943563461303711, L2: 0.0001283163292100653, L3: 0.9999872446060181, L4: 49.99949645996094, L5: 0.30467090010643005
Epoch 3500, Loss: 61.49370193481445, Losses: L1: 10.68956470489502, L2: 0.00013160266098566353, L3: 0.9999851584434509, L4: 49.999412536621094, L5: 0.3046688437461853
Epoch 4000, Loss: 61.3054084777832, Losses: L1: 10.501371383666992, L2: 0.00013683948782272637, L3: 0.9999829530715942, L4: 49.99930953979492, L5: 0.3046668767929077
Epoch 4500, Loss: 61.193572998046875, Losses: L1: 10.3895845413208, L2: 0.00014149276830721647, L3: 0.999981701374054, L4: 49.999263763427734, L5: 0.3046655058860779
Epoch 5000, Loss: 61.11872482299805, Losses: L1: 10.314772605895996, L2: 0.00014830072177574039, L3: 0.9999804496765137, L4: 49.99922180175781, L5: 0.3046644330024719
Epoch 5500, Loss: 61.07209014892578, Losses: L1: 10.268168449401855, L2: 0.0001529613946331665, L3: 0.999979555606842, L4: 49.99919128417969, L5: 0.30466365814208984
Epoch 6000, Loss: 61.03828048706055, Losses: L1: 10.234387397766113, L2: 0.0001563367259223014, L3: 0.99997878074646, L4: 49.99916076660156, L5: 0.3046630918979645
Epoch 6500, Loss: 61.012718200683594, Losses: L1: 10.208847045898438, L2: 0.00015902768063824624, L3: 0.9999781847000122, L4: 49.999141693115234, L5: 0.3046625554561615
Epoch 7000, Loss: 60.993003845214844, Losses: L1: 10.1891508102417, L2: 0.00016118743224069476, L3: 0.999977707862854, L4: 49.999122619628906, L5: 0.30466216802597046
Epoch 7500, Loss: 60.97429275512695, Losses: L1: 10.170455932617188, L2: 0.00016410659009125084, L3: 0.9999772906303406, L4: 49.999107360839844, L5: 0.3046618700027466
Epoch 8000, Loss: 60.96150207519531, Losses: L1: 10.157673835754395, L2: 0.00016552807937841862, L3: 0.9999769330024719, L4: 49.99909591674805, L5: 0.3046616315841675
Epoch 8500, Loss: 60.951751708984375, Losses: L1: 10.147934913635254, L2: 0.00016659199900459498, L3: 0.9999766945838928, L4: 49.99908447265625, L5: 0.30466145277023315
Epoch 9000, Loss: 60.92487335205078, Losses: L1: 10.121061325073242, L2: 0.00016653868078719825, L3: 0.999976396560669, L4: 49.999080657958984, L5: 0.3046613037586212
Epoch 9500, Loss: 60.9203987121582, Losses: L1: 10.11659049987793, L2: 0.00016730418428778648, L3: 0.9999762773513794, L4: 49.99907302856445, L5: 0.30466118454933167
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0064401626586914, Constraint losses: L1: 7.567790985107422, L2: 0.0, L3: 0.9994362592697144, L4: 0.9994362592697144
Epoch 500, Loss: 0.002208281308412552, Constraint losses: L1: -1.1063677072525024, L2: 0.0, L3: 0.0026565194129943848, L4: 0.000658129807561636
Epoch 1000, Loss: 0.0013119018403813243, Constraint losses: L1: -1.1181323528289795, L2: 0.0, L3: 0.002214789390563965, L4: 0.00021524479961954057
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0038161277770996, Constraint losses: L1: 6.532873630523682, L2: 0.0, L3: 0.998641848564148, L4: 0.9986413717269897
Epoch 500, Loss: 0.0019385747145861387, Constraint losses: L1: -1.0506248474121094, L2: 0.0, L3: 0.0024939775466918945, L4: 0.0004952220479026437
Epoch 1000, Loss: 0.0012428192421793938, Constraint losses: L1: -1.0715456008911133, L2: 0.0, L3: 0.002156972885131836, L4: 0.0001573919871589169
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 92.53323364257812, Losses: L1: 11.39293384552002, L2: 0.0009692817693576217, L3: 0.9999435544013977, L4: 80.06205749511719, L5: 0.2888936400413513
Epoch 500, Loss: 5.320244312286377, Losses: L1: 0.4339582026004791, L2: 0.06641535460948944, L3: 0.0960654616355896, L4: 4.719025611877441, L5: 0.0430099293589592
Epoch 1000, Loss: 19.757328033447266, Losses: L1: 3.62591814994812, L2: 2.3435192108154297, L3: 0.19197797775268555, L4: 14.529854774475098, L5: 0.1669023633003235
Epoch 1500, Loss: 20.866683959960938, Losses: L1: 2.184138774871826, L2: 0.3579825460910797, L3: 0.2638496160507202, L4: 18.12862205505371, L5: 0.12150421738624573
Epoch 2000, Loss: 38.088680267333984, Losses: L1: 8.681135177612305, L2: 0.7176744341850281, L3: 0.5434960126876831, L4: 28.41912269592285, L5: 0.1789189726114273
Epoch 2500, Loss: 4.90084981918335, Losses: L1: 1.343464732170105, L2: 0.09995938837528229, L3: 0.19288915395736694, L4: 3.3105478286743164, L5: 0.050206419080495834
Epoch 3000, Loss: 4.400328159332275, Losses: L1: 1.2304421663284302, L2: 0.0953332707285881, L3: 0.18676817417144775, L4: 2.935887098312378, L5: 0.04647427052259445
Epoch 3500, Loss: 3.9399900436401367, Losses: L1: 1.1713577508926392, L2: 0.09078842401504517, L3: 0.17206352949142456, L4: 2.543257713317871, L5: 0.04697425290942192
Epoch 4000, Loss: 3.7680094242095947, Losses: L1: 1.1367888450622559, L2: 0.08647186309099197, L3: 0.1649581789970398, L4: 2.4128215312957764, L5: 0.04634196683764458
Epoch 4500, Loss: 3.6587915420532227, Losses: L1: 1.0941792726516724, L2: 0.0825544148683548, L3: 0.16132241487503052, L4: 2.351994514465332, L5: 0.04533974453806877
Epoch 5000, Loss: 3.598249673843384, Losses: L1: 1.0764436721801758, L2: 0.08013668656349182, L3: 0.1588958501815796, L4: 2.3127479553222656, L5: 0.04477086663246155
Epoch 5500, Loss: 3.55777907371521, Losses: L1: 1.0599746704101562, L2: 0.07821628451347351, L3: 0.15759438276290894, L4: 2.291792154312134, L5: 0.04405339062213898
Epoch 6000, Loss: 3.5271546840667725, Losses: L1: 1.0535972118377686, L2: 0.07724609225988388, L3: 0.1565624475479126, L4: 2.269780158996582, L5: 0.043436530977487564
Epoch 6500, Loss: 3.5064845085144043, Losses: L1: 1.0469270944595337, L2: 0.07592829316854477, L3: 0.15574902296066284, L4: 2.2571845054626465, L5: 0.043267179280519485
Epoch 7000, Loss: 3.490791082382202, Losses: L1: 1.0422213077545166, L2: 0.07505295425653458, L3: 0.15492653846740723, L4: 2.2474350929260254, L5: 0.0430724062025547
Epoch 7500, Loss: 3.479686737060547, Losses: L1: 1.0389800071716309, L2: 0.07438015192747116, L3: 0.1543370485305786, L4: 2.2405266761779785, L5: 0.042910754680633545
Epoch 8000, Loss: 3.471813678741455, Losses: L1: 1.0361675024032593, L2: 0.07383566349744797, L3: 0.1539750099182129, L4: 2.236079216003418, L5: 0.04283081740140915
Epoch 8500, Loss: 3.4662864208221436, Losses: L1: 1.0345280170440674, L2: 0.0734567642211914, L3: 0.1536858081817627, L4: 2.2326951026916504, L5: 0.0427459180355072
Epoch 9000, Loss: 3.4624788761138916, Losses: L1: 1.0333354473114014, L2: 0.07317562401294708, L3: 0.15350449085235596, L4: 2.2304067611694336, L5: 0.04269831255078316
Epoch 9500, Loss: 3.4599509239196777, Losses: L1: 1.032481074333191, L2: 0.0729706659913063, L3: 0.1533823013305664, L4: 2.2289440631866455, L5: 0.04267463833093643
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.008875608444214, Constraint losses: L1: 9.054941177368164, L2: 5.2707728173118085e-05, L3: 0.9998840689659119, L4: 0.9998838901519775
Epoch 500, Loss: 0.002089730929583311, Constraint losses: L1: -1.0711206197738647, L2: 0.0, L3: 0.0025795698165893555, L4: 0.0005812817253172398
Epoch 1000, Loss: 0.001234322553500533, Constraint losses: L1: -1.1149200201034546, L2: 0.0, L3: 0.00217437744140625, L4: 0.00017486528668086976
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019056558609009, Constraint losses: L1: 18.42068099975586, L2: 0.00021207588724792004, L3: 1.0002120733261108, L4: 1.0002117156982422
Epoch 500, Loss: 0.0024549467489123344, Constraint losses: L1: -0.9423106908798218, L2: 0.0, L3: 0.0026975274085998535, L4: 0.0006997300079092383
Epoch 1000, Loss: 0.001339977141469717, Constraint losses: L1: -1.070613980293274, L2: 0.0, L3: 0.0022050142288208008, L4: 0.00020557703101076186
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.54257202148438, Losses: L1: 5.7506632804870605, L2: 0.0, L3: 0.996738851070404, L4: 80.57270812988281, L5: 0.2962355613708496
Epoch 500, Loss: 20.15546989440918, Losses: L1: 5.421436786651611, L2: 1.1008790731430054, L3: 0.17030727863311768, L4: 7.027770519256592, L5: 0.08579791337251663
Epoch 1000, Loss: 32.0126838684082, Losses: L1: 5.362262725830078, L2: 0.43866756558418274, L3: 0.2743411064147949, L4: 13.125696182250977, L5: 0.08504581451416016
Epoch 1500, Loss: 4.004357814788818, Losses: L1: 0.6735439896583557, L2: 0.09165911376476288, L3: 0.11252081394195557, L4: 1.6098817586898804, L5: 0.017920447513461113
Epoch 2000, Loss: 2.7507874965667725, Losses: L1: 0.662248432636261, L2: 0.09519219398498535, L3: 0.09727132320404053, L4: 0.9916346669197083, L5: 0.0180757287889719
Epoch 2500, Loss: 2.9982686042785645, Losses: L1: 0.48186391592025757, L2: 0.13814757764339447, L3: 0.092002272605896, L4: 1.1942806243896484, L5: 0.02553725242614746
Epoch 3000, Loss: 2.143563985824585, Losses: L1: 0.33806154131889343, L2: 0.06243721768260002, L3: 0.09153974056243896, L4: 0.8590027093887329, L5: 0.021017251536250114
Epoch 3500, Loss: 1.515527606010437, Losses: L1: 0.16216352581977844, L2: 0.0657322034239769, L3: 0.0919417142868042, L4: 0.6325945854187012, L5: 0.018675897270441055
Epoch 4000, Loss: 1.359513521194458, Losses: L1: 0.1517108678817749, L2: 0.0685947984457016, L3: 0.0902184247970581, L4: 0.5593860745429993, L5: 0.019247787073254585
Epoch 4500, Loss: 1.3172427415847778, Losses: L1: 0.14762799441814423, L2: 0.06898649781942368, L3: 0.0900689959526062, L4: 0.5402708649635315, L5: 0.019090496003627777
Epoch 5000, Loss: 1.3162791728973389, Losses: L1: 0.143644317984581, L2: 0.0683627650141716, L3: 0.08983540534973145, L4: 0.542026698589325, L5: 0.018964752554893494
Epoch 5500, Loss: 1.2716761827468872, Losses: L1: 0.1434106081724167, L2: 0.06876401603221893, L3: 0.0896986722946167, L4: 0.5197370052337646, L5: 0.019120419397950172
Epoch 6000, Loss: 1.2556391954421997, Losses: L1: 0.14284826815128326, L2: 0.06911741942167282, L3: 0.0896790623664856, L4: 0.5119324922561646, L5: 0.019055265933275223
Epoch 6500, Loss: 1.248639464378357, Losses: L1: 0.14213827252388, L2: 0.06905462592840195, L3: 0.08960223197937012, L4: 0.5088251829147339, L5: 0.01904476247727871
Epoch 7000, Loss: 1.2434983253479004, Losses: L1: 0.14171360433101654, L2: 0.06901045143604279, L3: 0.08955252170562744, L4: 0.5064985752105713, L5: 0.019012203440070152
Epoch 7500, Loss: 1.2399991750717163, Losses: L1: 0.14140145480632782, L2: 0.06898172199726105, L3: 0.0894852876663208, L4: 0.5049324631690979, L5: 0.01899852603673935
Epoch 8000, Loss: 1.2372080087661743, Losses: L1: 0.14118318259716034, L2: 0.06897494941949844, L3: 0.08942753076553345, L4: 0.5036642551422119, L5: 0.01899016462266445
Epoch 8500, Loss: 1.23530912399292, Losses: L1: 0.14100217819213867, L2: 0.06897274404764175, L3: 0.08939623832702637, L4: 0.5028160810470581, L5: 0.018980441614985466
Epoch 9000, Loss: 1.2339165210723877, Losses: L1: 0.14089590311050415, L2: 0.0689704492688179, L3: 0.0893700122833252, L4: 0.5021802186965942, L5: 0.018979929387569427
Epoch 9500, Loss: 1.2329515218734741, Losses: L1: 0.1407829374074936, L2: 0.06897081434726715, L3: 0.08934855461120605, L4: 0.5017592310905457, L5: 0.018980829045176506
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0444283485412598, Constraint losses: L1: 18.42068099975586, L2: 0.008668320253491402, L3: 1.008668303489685, L4: 1.0086710453033447
Epoch 500, Loss: 0.0022345620673149824, Constraint losses: L1: -1.0568797588348389, L2: 0.0, L3: 0.0026447176933288574, L4: 0.000646724074613303
Epoch 1000, Loss: 0.0012816224480047822, Constraint losses: L1: -1.1177181005477905, L2: 0.0, L3: 0.0021993517875671387, L4: 0.00019998883362859488
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0194461345672607, Constraint losses: L1: 18.42068099975586, L2: 0.000341797829605639, L3: 1.000341773033142, L4: 1.0003418922424316
Epoch 500, Loss: 0.00202367571182549, Constraint losses: L1: -1.056299090385437, L2: 0.0, L3: 0.002539336681365967, L4: 0.0005406382260844111
Epoch 1000, Loss: 0.0012841194402426481, Constraint losses: L1: -1.0703089237213135, L2: 0.0, L3: 0.002176940441131592, L4: 0.00017748793470673263
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 154.8898468017578, Losses: L1: 5.122485637664795, L2: 0.0, L3: 0.9932111501693726, L4: 74.50829315185547, L5: 0.2541716694831848
Epoch 500, Loss: 8.280848503112793, Losses: L1: 1.2847634553909302, L2: 0.10351420938968658, L3: 0.06864601373672485, L4: 3.4369471073150635, L5: 0.036110758781433105
Epoch 1000, Loss: 8.621943473815918, Losses: L1: 1.2295840978622437, L2: 0.20067636668682098, L3: 0.05877107381820679, L4: 3.6187868118286133, L5: 0.025061139836907387
Epoch 1500, Loss: 13.18863296508789, Losses: L1: 6.300316333770752, L2: 1.5208532810211182, L3: 0.11557352542877197, L4: 3.0017640590667725, L5: 0.06657504290342331
Epoch 2000, Loss: 7.198235511779785, Losses: L1: 4.578203201293945, L2: 0.9195780754089355, L3: 0.11477017402648926, L4: 1.00587797164917, L5: 0.09110219776630402
Epoch 2500, Loss: 10.233538627624512, Losses: L1: 5.843693733215332, L2: 1.113674521446228, L3: 0.13374245166778564, L4: 1.8346824645996094, L5: 0.09677211940288544
Epoch 3000, Loss: 12.989066123962402, Losses: L1: 6.359035491943359, L2: 1.316359043121338, L3: 0.14547091722488403, L4: 2.9164319038391113, L5: 0.06625299155712128
Epoch 3500, Loss: 10.797215461730957, Losses: L1: 5.941514015197754, L2: 1.1205153465270996, L3: 0.14730864763259888, L4: 2.0823259353637695, L5: 0.0571378692984581
Epoch 4000, Loss: 10.692737579345703, Losses: L1: 6.060081958770752, L2: 1.2633768320083618, L3: 0.1318192481994629, L4: 1.9366685152053833, L5: 0.061720822006464005
Epoch 4500, Loss: 9.162470817565918, Losses: L1: 5.452972888946533, L2: 1.2920056581497192, L3: 0.13647353649139404, L4: 1.467657208442688, L5: 0.05994432047009468
Epoch 5000, Loss: 8.877066612243652, Losses: L1: 5.360843181610107, L2: 1.3298368453979492, L3: 0.1301645040512085, L4: 1.361375093460083, L5: 0.063472680747509
Epoch 5500, Loss: 8.770746231079102, Losses: L1: 5.380450248718262, L2: 1.3438712358474731, L3: 0.12800097465515137, L4: 1.2939248085021973, L5: 0.06651032716035843
Epoch 6000, Loss: 8.65965461730957, Losses: L1: 5.333064556121826, L2: 1.3429181575775146, L3: 0.1263793706893921, L4: 1.2618093490600586, L5: 0.06832324713468552
Epoch 6500, Loss: 8.625597953796387, Losses: L1: 5.335041046142578, L2: 1.3332937955856323, L3: 0.12569528818130493, L4: 1.245903730392456, L5: 0.06925524771213531
Epoch 7000, Loss: 8.5601224899292, Losses: L1: 5.2933173179626465, L2: 1.3231630325317383, L3: 0.12489080429077148, L4: 1.2362298965454102, L5: 0.07031828165054321
Epoch 7500, Loss: 8.54257869720459, Losses: L1: 5.293503284454346, L2: 1.3161847591400146, L3: 0.12479758262634277, L4: 1.2288676500320435, L5: 0.07084805518388748
Epoch 8000, Loss: 8.529987335205078, Losses: L1: 5.2938761711120605, L2: 1.3113120794296265, L3: 0.12464070320129395, L4: 1.2234861850738525, L5: 0.07116285711526871
Epoch 8500, Loss: 8.521339416503906, Losses: L1: 5.294417381286621, L2: 1.3077949285507202, L3: 0.12452679872512817, L4: 1.2196943759918213, L5: 0.07137341052293777
Epoch 9000, Loss: 8.500802040100098, Losses: L1: 5.280219078063965, L2: 1.306444525718689, L3: 0.12422585487365723, L4: 1.2168269157409668, L5: 0.07159414887428284
Epoch 9500, Loss: 8.496118545532227, Losses: L1: 5.279901027679443, L2: 1.3050975799560547, L3: 0.12421965599060059, L4: 1.2149596214294434, L5: 0.07163992524147034
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.007755994796753, Constraint losses: L1: 8.279340744018555, L2: 0.0, L3: 0.9997382760047913, L4: 0.9997383952140808
Epoch 500, Loss: 0.0023362787906080484, Constraint losses: L1: -1.0831797122955322, L2: 0.0, L3: 0.0027087926864624023, L4: 0.0007106658304110169
Epoch 1000, Loss: 0.001340215909294784, Constraint losses: L1: -1.1185660362243652, L2: 0.0, L3: 0.002229154109954834, L4: 0.00022962794173508883
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0271036624908447, Constraint losses: L1: 18.42068099975586, L2: 0.002894199686124921, L3: 1.0028941631317139, L4: 1.002894639968872
Epoch 500, Loss: 0.0021990612149238586, Constraint losses: L1: -1.0386137962341309, L2: 0.0, L3: 0.002617955207824707, L4: 0.0006197198526933789
Epoch 1000, Loss: 0.0013277619145810604, Constraint losses: L1: -1.0707297325134277, L2: 0.0, L3: 0.002198934555053711, L4: 0.00019955712195951492
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 147.886962890625, Losses: L1: 11.652168273925781, L2: 0.0008228103397414088, L3: 0.9996140599250793, L4: 67.6463851928711, L5: 0.22090409696102142
Epoch 500, Loss: 4.381317615509033, Losses: L1: 0.24443493783473969, L2: 0.018699193373322487, L3: 0.08883428573608398, L4: 2.01945161819458, L5: 0.022106366232037544
Epoch 1000, Loss: 3.9766809940338135, Losses: L1: 0.4174051880836487, L2: 0.33078762888908386, L3: 0.08895331621170044, L4: 1.639338493347168, L5: 0.03536413237452507
Epoch 1500, Loss: 4.823309421539307, Losses: L1: 0.8073822855949402, L2: 0.22725863754749298, L3: 0.0818282961845398, L4: 1.8986716270446777, L5: 0.032020311802625656
Epoch 2000, Loss: 3.2928929328918457, Losses: L1: 0.9058493971824646, L2: 0.07189302891492844, L3: 0.08028805255889893, L4: 1.1403712034225464, L5: 0.015105238184332848
Epoch 2500, Loss: 2.0800676345825195, Losses: L1: 0.7700793743133545, L2: 0.07938870042562485, L3: 0.07416772842407227, L4: 0.603796124458313, L5: 0.01280886773020029
Epoch 3000, Loss: 2.4422013759613037, Losses: L1: 0.8765929341316223, L2: 0.05261148512363434, L3: 0.08361667394638062, L4: 0.7174173593521118, L5: 0.031329765915870667
Epoch 3500, Loss: 1.6769778728485107, Losses: L1: 0.675940215587616, L2: 0.07752925157546997, L3: 0.06592059135437012, L4: 0.45155787467956543, L5: 0.013098475523293018
Epoch 4000, Loss: 1.500091791152954, Losses: L1: 0.6527702212333679, L2: 0.07764382660388947, L3: 0.06565189361572266, L4: 0.3745489716529846, L5: 0.01328789908438921
Epoch 4500, Loss: 1.4173471927642822, Losses: L1: 0.6150439381599426, L2: 0.0772133469581604, L3: 0.06415170431137085, L4: 0.35219791531562805, L5: 0.013612386770546436
Epoch 5000, Loss: 1.3506650924682617, Losses: L1: 0.6129253506660461, L2: 0.07770422101020813, L3: 0.06338214874267578, L4: 0.3202846348285675, L5: 0.013313659466803074
Epoch 5500, Loss: 1.3261786699295044, Losses: L1: 0.6101491451263428, L2: 0.07745460420846939, L3: 0.06292229890823364, L4: 0.30968478322029114, L5: 0.013235759921371937
Epoch 6000, Loss: 1.3096503019332886, Losses: L1: 0.6079742312431335, L2: 0.07709890604019165, L3: 0.06263101100921631, L4: 0.30267441272735596, L5: 0.013231072574853897
Epoch 6500, Loss: 1.2977359294891357, Losses: L1: 0.6063452363014221, L2: 0.07696881890296936, L3: 0.06234544515609741, L4: 0.2976827025413513, L5: 0.013184048235416412
Epoch 7000, Loss: 1.2887649536132812, Losses: L1: 0.6049934029579163, L2: 0.0767693743109703, L3: 0.062161803245544434, L4: 0.29399698972702026, L5: 0.01315597165375948
Epoch 7500, Loss: 1.2823970317840576, Losses: L1: 0.6040258407592773, L2: 0.07656827569007874, L3: 0.06205761432647705, L4: 0.2914001941680908, L5: 0.013128933496773243
Epoch 8000, Loss: 1.277785301208496, Losses: L1: 0.6033565402030945, L2: 0.07646133750677109, L3: 0.0619429349899292, L4: 0.2895037829875946, L5: 0.01310957781970501
Epoch 8500, Loss: 1.2747597694396973, Losses: L1: 0.6028901934623718, L2: 0.07634604722261429, L3: 0.061888694763183594, L4: 0.288288414478302, L5: 0.013087664730846882
Epoch 9000, Loss: 1.2727164030075073, Losses: L1: 0.6026467084884644, L2: 0.07629036903381348, L3: 0.061847686767578125, L4: 0.2874283492565155, L5: 0.013071926310658455
Epoch 9500, Loss: 1.2715038061141968, Losses: L1: 0.6024351119995117, L2: 0.07624991238117218, L3: 0.06182861328125, L4: 0.28695347905158997, L5: 0.01306122075766325
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0033626556396484, Constraint losses: L1: 6.483240604400635, L2: 0.0, L3: 0.9984394907951355, L4: 0.9984397888183594
Epoch 500, Loss: 0.002293030731379986, Constraint losses: L1: -1.0836758613586426, L2: 0.0, L3: 0.002687394618988037, L4: 0.000689311942551285
Epoch 1000, Loss: 0.0013250306947156787, Constraint losses: L1: -1.1180105209350586, L2: 0.0, L3: 0.002221226692199707, L4: 0.00022181464009918272
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0051207542419434, Constraint losses: L1: 6.980119705200195, L2: 0.0, L3: 0.9990703463554382, L4: 0.999070405960083
Epoch 500, Loss: 0.002479828428477049, Constraint losses: L1: -1.0589759349822998, L2: 0.0, L3: 0.002768397331237793, L4: 0.0007704069721512496
Epoch 1000, Loss: 0.0014334255829453468, Constraint losses: L1: -1.071587085723877, L2: 0.0, L3: 0.0022521615028381348, L4: 0.00025285116862505674
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 41.92097854614258, Losses: L1: 4.946671485900879, L2: 0.0, L3: 0.9925331473350525, L4: 71.72466278076172, L5: 0.23888039588928223
Epoch 500, Loss: 6.937564849853516, Losses: L1: 1.294354796409607, L2: 0.2816391885280609, L3: 0.18930178880691528, L4: 10.547534942626953, L5: 0.07864207029342651
Epoch 1000, Loss: 3.649129629135132, Losses: L1: 0.7243159413337708, L2: 0.24674879014492035, L3: 0.12464630603790283, L4: 5.329743385314941, L5: 0.02384234219789505
Epoch 1500, Loss: 1.3409587144851685, Losses: L1: -0.09611601382493973, L2: 0.11795944720506668, L3: 0.10799717903137207, L4: 2.518284797668457, L5: 0.02191082574427128
Epoch 2000, Loss: 0.7649555802345276, Losses: L1: -0.03539281710982323, L2: 0.11292023956775665, L3: 0.08461058139801025, L4: 1.2924809455871582, L5: 0.026074426248669624
Epoch 2500, Loss: 0.4876602292060852, Losses: L1: 0.0011143970768898726, L2: 0.11109589785337448, L3: 0.08107709884643555, L4: 0.675173819065094, L5: 0.02466772310435772
Epoch 3000, Loss: 0.4789462983608246, Losses: L1: -0.016422729939222336, L2: 0.12242315709590912, L3: 0.07828813791275024, L4: 0.6865420341491699, L5: 0.025196587666869164
Epoch 3500, Loss: 0.44819536805152893, Losses: L1: -0.025816693902015686, L2: 0.13587312400341034, L3: 0.07377928495407104, L4: 0.6333595514297485, L5: 0.03123287297785282
Epoch 4000, Loss: 0.3779369592666626, Losses: L1: -0.034300483763217926, L2: 0.14099179208278656, L3: 0.07321548461914062, L4: 0.5061066746711731, L5: 0.03094543144106865
Epoch 4500, Loss: 0.3574979603290558, Losses: L1: -0.038304347544908524, L2: 0.14287970960140228, L3: 0.07305586338043213, L4: 0.47233498096466064, L5: 0.03027823381125927
Epoch 5000, Loss: 0.3423726558685303, Losses: L1: -0.0402524396777153, L2: 0.145981103181839, L3: 0.07177102565765381, L4: 0.44392716884613037, L5: 0.03179982677102089
Epoch 5500, Loss: 0.3317869305610657, Losses: L1: -0.04259294271469116, L2: 0.1469774842262268, L3: 0.07138770818710327, L4: 0.4271284341812134, L5: 0.03187839314341545
Epoch 6000, Loss: 0.32588234543800354, Losses: L1: -0.044131241738796234, L2: 0.14761333167552948, L3: 0.07100391387939453, L4: 0.4184187948703766, L5: 0.03198724240064621
Epoch 6500, Loss: 0.32298940420150757, Losses: L1: -0.045359622687101364, L2: 0.14842140674591064, L3: 0.07066798210144043, L4: 0.41475021839141846, L5: 0.032190464437007904
Epoch 7000, Loss: 0.320677250623703, Losses: L1: -0.046606775373220444, L2: 0.14908500015735626, L3: 0.0704185962677002, L4: 0.412280797958374, L5: 0.03236499801278114
Epoch 7500, Loss: 0.3187980651855469, Losses: L1: -0.047469522804021835, L2: 0.1496213674545288, L3: 0.07014060020446777, L4: 0.41011911630630493, L5: 0.03251350671052933
Epoch 8000, Loss: 0.31714802980422974, Losses: L1: -0.04826415330171585, L2: 0.1500219851732254, L3: 0.06993907690048218, L4: 0.40832358598709106, L5: 0.03260064497590065
Epoch 8500, Loss: 0.31583815813064575, Losses: L1: -0.0488484688103199, L2: 0.15031906962394714, L3: 0.06975620985031128, L4: 0.4068649709224701, L5: 0.03267679363489151
Epoch 9000, Loss: 0.3148007392883301, Losses: L1: -0.04932505264878273, L2: 0.15054851770401, L3: 0.06961965560913086, L4: 0.4057312607765198, L5: 0.03273247182369232
Epoch 9500, Loss: 0.3140142858028412, Losses: L1: -0.049668457359075546, L2: 0.15071597695350647, L3: 0.06951338052749634, L4: 0.4048451781272888, L5: 0.032777585089206696
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.019961357116699, Constraint losses: L1: 18.42068099975586, L2: 0.0005179686122573912, L3: 1.0005112886428833, L4: 1.0005112886428833
Epoch 500, Loss: 0.002412024885416031, Constraint losses: L1: -1.0888475179672241, L2: 0.0, L3: 0.0027494430541992188, L4: 0.0007514292374253273
Epoch 1000, Loss: 0.001365547999739647, Constraint losses: L1: -1.1182398796081543, L2: 0.0, L3: 0.002241671085357666, L4: 0.00024211690470110625
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0228281021118164, Constraint losses: L1: 18.42068099975586, L2: 0.001469105831347406, L3: 1.0014691352844238, L4: 1.0014690160751343
Epoch 500, Loss: 0.0022547179833054543, Constraint losses: L1: -0.9787358641624451, L2: 0.0, L3: 0.0026159286499023438, L4: 0.0006175251328386366
Epoch 1000, Loss: 0.0012902823509648442, Constraint losses: L1: -1.0710238218307495, L2: 0.0, L3: 0.0021803975105285645, L4: 0.00018090868252329528
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 57.66817092895508, Losses: L1: 18.32273292541504, L2: 0.001713936566375196, L3: 1.001713752746582, L4: 76.14663696289062, L5: 0.26955029368400574
Epoch 500, Loss: 27.135194778442383, Losses: L1: 4.117271900177002, L2: 0.03357813507318497, L3: 0.8544169068336487, L4: 43.75844955444336, L5: 0.26749157905578613
Epoch 1000, Loss: 7.820091724395752, Losses: L1: 2.7616114616394043, L2: 0.36026516556739807, L3: 0.15710854530334473, L4: 9.236997604370117, L5: 0.10274045169353485
Epoch 1500, Loss: 14.291131973266602, Losses: L1: 4.978322505950928, L2: 1.6864439249038696, L3: 0.27184808254241943, L4: 16.130529403686523, L5: 0.13247519731521606
Epoch 2000, Loss: 2.354929208755493, Losses: L1: 0.3072876036167145, L2: 0.18649418652057648, L3: 0.1553904414176941, L4: 3.526614189147949, L5: 0.0356970876455307
Epoch 2500, Loss: 2.184786081314087, Losses: L1: 0.3885297477245331, L2: 0.09313475340604782, L3: 0.14981216192245483, L4: 3.14189076423645, L5: 0.02893141098320484
Epoch 3000, Loss: 1.4469200372695923, Losses: L1: 0.23343312740325928, L2: 0.08708036690950394, L3: 0.13284540176391602, L4: 2.0145645141601562, L5: 0.029819121584296227
Epoch 3500, Loss: 1.3930954933166504, Losses: L1: 0.22080008685588837, L2: 0.1026788279414177, L3: 0.12680530548095703, L4: 1.9223480224609375, L5: 0.0329766571521759
Epoch 4000, Loss: 1.3410441875457764, Losses: L1: 0.199870303273201, L2: 0.11169575899839401, L3: 0.12238216400146484, L4: 1.8562872409820557, L5: 0.03480027988553047
Epoch 4500, Loss: 1.3103340864181519, Losses: L1: 0.18802472949028015, L2: 0.11516857892274857, L3: 0.12068766355514526, L4: 1.817846655845642, L5: 0.035114023834466934
Epoch 5000, Loss: 1.2882722616195679, Losses: L1: 0.18011832237243652, L2: 0.11696045845746994, L3: 0.11956465244293213, L4: 1.7892215251922607, L5: 0.03549827262759209
Epoch 5500, Loss: 1.272759199142456, Losses: L1: 0.1747826784849167, L2: 0.11816494166851044, L3: 0.11857926845550537, L4: 1.7693469524383545, L5: 0.03564131632447243
Epoch 6000, Loss: 1.2616980075836182, Losses: L1: 0.17026279866695404, L2: 0.11924267560243607, L3: 0.11820030212402344, L4: 1.756188988685608, L5: 0.03551913797855377
Epoch 6500, Loss: 1.2524398565292358, Losses: L1: 0.1670059859752655, L2: 0.12000514566898346, L3: 0.11728638410568237, L4: 1.7446461915969849, L5: 0.03582175076007843
Epoch 7000, Loss: 1.2459787130355835, Losses: L1: 0.16450385749340057, L2: 0.1206793412566185, L3: 0.11678951978683472, L4: 1.7367889881134033, L5: 0.0359511561691761
Epoch 7500, Loss: 1.2419179677963257, Losses: L1: 0.16276153922080994, L2: 0.12114941328763962, L3: 0.11633062362670898, L4: 1.7321510314941406, L5: 0.03617558628320694
Epoch 8000, Loss: 1.237709641456604, Losses: L1: 0.16086405515670776, L2: 0.12143979221582413, L3: 0.11634713411331177, L4: 1.7273657321929932, L5: 0.03609568253159523
Epoch 8500, Loss: 1.2353013753890991, Losses: L1: 0.1596040427684784, L2: 0.1216784119606018, L3: 0.11628538370132446, L4: 1.724905014038086, L5: 0.036120280623435974
Epoch 9000, Loss: 1.2335926294326782, Losses: L1: 0.15877054631710052, L2: 0.12183500826358795, L3: 0.11622416973114014, L4: 1.7230782508850098, L5: 0.0361412949860096
Epoch 9500, Loss: 1.2324023246765137, Losses: L1: 0.15820102393627167, L2: 0.12194032967090607, L3: 0.11616885662078857, L4: 1.721801519393921, L5: 0.036161527037620544
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0006442070007324, Constraint losses: L1: 5.886295318603516, L2: 0.0, L3: 0.9973793029785156, L4: 0.9973787069320679
Epoch 500, Loss: 0.0020213089883327484, Constraint losses: L1: -1.099365472793579, L2: 0.0, L3: 0.0025595426559448242, L4: 0.0005611317465081811
Epoch 1000, Loss: 0.0012370245531201363, Constraint losses: L1: -1.1171164512634277, L2: 0.0, L3: 0.002176821231842041, L4: 0.00017731983098201454
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0226924419403076, Constraint losses: L1: 18.42068099975586, L2: 0.0014239202719181776, L3: 1.001423954963684, L4: 1.0014238357543945
Epoch 500, Loss: 0.0022542192600667477, Constraint losses: L1: -1.0545684099197388, L2: 0.0, L3: 0.0026535391807556152, L4: 0.0006552485283464193
Epoch 1000, Loss: 0.0013579220976680517, Constraint losses: L1: -1.0703176259994507, L2: 0.0, L3: 0.0022138357162475586, L4: 0.00021440404816530645
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.552459716796875, Losses: L1: 16.705028533935547, L2: 0.002235337160527706, L3: 1.0018088817596436, L4: 72.6955337524414, L5: 0.24836865067481995
Epoch 500, Loss: 12.480387687683105, Losses: L1: 3.5026626586914062, L2: 1.9890687465667725, L3: 0.2654401659965515, L4: 14.307838439941406, L5: 0.2819158434867859
Epoch 1000, Loss: 27.079484939575195, Losses: L1: 5.241808891296387, L2: 0.49035483598709106, L3: 0.9758920669555664, L4: 40.608238220214844, L5: 0.1562429964542389
Epoch 1500, Loss: 7.599205017089844, Losses: L1: 2.235879421234131, L2: 0.5519101023674011, L3: 0.14921975135803223, L4: 9.469645500183105, L5: 0.10166415572166443
Epoch 2000, Loss: 2.886260747909546, Losses: L1: 0.2881442606449127, L2: 0.05493688955903053, L3: 0.1473902463912964, L4: 4.704468250274658, L5: 0.035511814057826996
Epoch 2500, Loss: 1.5096408128738403, Losses: L1: 0.21158210933208466, L2: 0.04061383381485939, L3: 0.12584269046783447, L4: 2.2294790744781494, L5: 0.018584784120321274
Epoch 3000, Loss: 1.3850910663604736, Losses: L1: 0.19208720326423645, L2: 0.04309803247451782, L3: 0.12167298793792725, L4: 2.0281789302825928, L5: 0.01784619688987732
Epoch 3500, Loss: 1.2644835710525513, Losses: L1: 0.15902042388916016, L2: 0.04610336199402809, L3: 0.12341755628585815, L4: 1.8507623672485352, L5: 0.01680636964738369
Epoch 4000, Loss: 1.1476408243179321, Losses: L1: 0.12089142203330994, L2: 0.05295131728053093, L3: 0.12229675054550171, L4: 1.6943482160568237, L5: 0.015401403419673443
Epoch 4500, Loss: 1.0384832620620728, Losses: L1: 0.09461075067520142, L2: 0.0411112979054451, L3: 0.11983633041381836, L4: 1.550295114517212, L5: 0.014166478998959064
Epoch 5000, Loss: 0.9618247151374817, Losses: L1: 0.0740579292178154, L2: 0.03373171389102936, L3: 0.11899471282958984, L4: 1.4532784223556519, L5: 0.012633509933948517
Epoch 5500, Loss: 0.9199011921882629, Losses: L1: 0.06456554681062698, L2: 0.028256148099899292, L3: 0.1173776388168335, L4: 1.3996269702911377, L5: 0.012008210644125938
Epoch 6000, Loss: 0.8702444434165955, Losses: L1: 0.03539899364113808, L2: 0.024683598428964615, L3: 0.11689865589141846, L4: 1.3634119033813477, L5: 0.01194952242076397
Epoch 6500, Loss: 0.8583441972732544, Losses: L1: 0.03366556018590927, L2: 0.023917660117149353, L3: 0.11624568700790405, L4: 1.3451573848724365, L5: 0.01194772869348526
Epoch 7000, Loss: 0.8503925204277039, Losses: L1: 0.031101519241929054, L2: 0.023575184866786003, L3: 0.11592322587966919, L4: 1.335944652557373, L5: 0.011803930625319481
Epoch 7500, Loss: 0.8447267413139343, Losses: L1: 0.02942470647394657, L2: 0.023400571197271347, L3: 0.11547696590423584, L4: 1.3292596340179443, L5: 0.01174748782068491
Epoch 8000, Loss: 0.8402541279792786, Losses: L1: 0.028208762407302856, L2: 0.023281453177332878, L3: 0.11528807878494263, L4: 1.3234772682189941, L5: 0.011688986793160439
Epoch 8500, Loss: 0.8372534513473511, Losses: L1: 0.027291828766465187, L2: 0.02316952496767044, L3: 0.11513292789459229, L4: 1.3198946714401245, L5: 0.011648299172520638
Epoch 9000, Loss: 0.8351721167564392, Losses: L1: 0.026666322723031044, L2: 0.023087335750460625, L3: 0.11504137516021729, L4: 1.3173844814300537, L5: 0.011614268645644188
Epoch 9500, Loss: 0.8338353037834167, Losses: L1: 0.026266148313879967, L2: 0.02302778884768486, L3: 0.11498415470123291, L4: 1.3157916069030762, L5: 0.011587641201913357
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0209999084472656, Constraint losses: L1: 18.42068099975586, L2: 0.0008598949061706662, L3: 1.0008598566055298, L4: 1.0008594989776611
Epoch 500, Loss: 0.00207679090090096, Constraint losses: L1: -1.0972564220428467, L2: 0.0, L3: 0.002586185932159424, L4: 0.0005878614028915763
Epoch 1000, Loss: 0.001247673062607646, Constraint losses: L1: -1.118051528930664, L2: 0.0, L3: 0.0021825432777404785, L4: 0.00018318135698791593
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.999186396598816, Constraint losses: L1: 5.703787326812744, L2: 0.0, L3: 0.9967414140701294, L4: 0.9967411756515503
Epoch 500, Loss: 0.002470611361786723, Constraint losses: L1: -0.9469588994979858, L2: 0.0, L3: 0.0027077198028564453, L4: 0.0007098506321199238
Epoch 1000, Loss: 0.0013495974708348513, Constraint losses: L1: -1.0692297220230103, L2: 0.0, L3: 0.0022091269493103027, L4: 0.00020970028708688915
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 83.88644409179688, Losses: L1: 7.751948833465576, L2: 1.204292038892163e-05, L3: 0.9978939294815063, L4: 75.00613403320312, L5: 0.2609182894229889
Epoch 500, Loss: 26.490781784057617, Losses: L1: 9.185811996459961, L2: 0.20557059347629547, L3: 0.4882087707519531, L4: 16.660341262817383, L5: 0.10727053880691528
Epoch 1000, Loss: 56.71509552001953, Losses: L1: 5.676780700683594, L2: 0.013481718488037586, L3: 0.9940162897109985, L4: 49.88977813720703, L5: 0.29556021094322205
Epoch 1500, Loss: 53.74687957763672, Losses: L1: 4.758116245269775, L2: 0.040655650198459625, L3: 0.9663558602333069, L4: 47.872711181640625, L5: 0.2587358355522156
Epoch 2000, Loss: 6.920797824859619, Losses: L1: 0.5414469242095947, L2: 0.11927071213722229, L3: 0.2431703805923462, L4: 6.0587005615234375, L5: 0.035688988864421844
Epoch 2500, Loss: 4.775272846221924, Losses: L1: 0.5654523968696594, L2: 0.029594048857688904, L3: 0.18532180786132812, L4: 3.9975547790527344, L5: 0.024293657392263412
Epoch 3000, Loss: 4.255195617675781, Losses: L1: 0.47522175312042236, L2: 0.02070773020386696, L3: 0.17814332246780396, L4: 3.580289125442505, L5: 0.02237534336745739
Epoch 3500, Loss: 4.0691609382629395, Losses: L1: 0.4632472097873688, L2: 0.017686519771814346, L3: 0.17263716459274292, L4: 3.4130301475524902, L5: 0.02280588261783123
Epoch 4000, Loss: 3.945037841796875, Losses: L1: 0.4469620883464813, L2: 0.01629355363547802, L3: 0.17058014869689941, L4: 3.30778169631958, L5: 0.023134395480155945
Epoch 4500, Loss: 3.884007215499878, Losses: L1: 0.4453779458999634, L2: 0.014739011414349079, L3: 0.1693434715270996, L4: 3.2505416870117188, L5: 0.022749437019228935
Epoch 5000, Loss: 3.7787327766418457, Losses: L1: 0.39455127716064453, L2: 0.012423870153725147, L3: 0.16922545433044434, L4: 3.197488307952881, L5: 0.022511323913931847
Epoch 5500, Loss: 3.746368646621704, Losses: L1: 0.38922610878944397, L2: 0.012139864265918732, L3: 0.16861867904663086, L4: 3.1712851524353027, L5: 0.02233726531267166
Epoch 6000, Loss: 3.723639488220215, Losses: L1: 0.38695406913757324, L2: 0.012073519639670849, L3: 0.16779881715774536, L4: 3.1516482830047607, L5: 0.022403143346309662
Epoch 6500, Loss: 3.6927742958068848, Losses: L1: 0.3763498365879059, L2: 0.011612631380558014, L3: 0.16762560606002808, L4: 3.131788730621338, L5: 0.0224076546728611
Epoch 7000, Loss: 3.6801822185516357, Losses: L1: 0.3742905855178833, L2: 0.011578290723264217, L3: 0.1673080325126648, L4: 3.1215827465057373, L5: 0.022423112764954567
Epoch 7500, Loss: 3.6711795330047607, Losses: L1: 0.3719997704029083, L2: 0.011523894965648651, L3: 0.1672561764717102, L4: 3.1149954795837402, L5: 0.02233210951089859
Epoch 8000, Loss: 3.664111614227295, Losses: L1: 0.37155139446258545, L2: 0.011552241630852222, L3: 0.16689157485961914, L4: 3.1087067127227783, L5: 0.022371752187609673
Epoch 8500, Loss: 3.659099817276001, Losses: L1: 0.37113022804260254, L2: 0.011546463705599308, L3: 0.16671442985534668, L4: 3.104304790496826, L5: 0.022354327142238617
Epoch 9000, Loss: 3.655446767807007, Losses: L1: 0.37100690603256226, L2: 0.011550266295671463, L3: 0.1665148138999939, L4: 3.1009654998779297, L5: 0.022368963807821274
Epoch 9500, Loss: 3.652726173400879, Losses: L1: 0.3709986209869385, L2: 0.011553085409104824, L3: 0.1663604974746704, L4: 3.098397970199585, L5: 0.02238496020436287
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0213394165039062, Constraint losses: L1: 18.42068099975586, L2: 0.0009728362201713026, L3: 1.000972867012024, L4: 1.0009729862213135
Epoch 500, Loss: 0.0024020951241254807, Constraint losses: L1: -1.0947191715240479, L2: 0.0, L3: 0.0027474164962768555, L4: 0.0007493979064747691
Epoch 1000, Loss: 0.001367731369100511, Constraint losses: L1: -1.118161916732788, L2: 0.0, L3: 0.0022426247596740723, L4: 0.00024326857237610966
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.02695894241333, Constraint losses: L1: 18.42068099975586, L2: 0.002846002345904708, L3: 1.0028460025787354, L4: 1.0028462409973145
Epoch 500, Loss: 0.002193327061831951, Constraint losses: L1: -0.9934661388397217, L2: 0.0, L3: 0.0025923848152160645, L4: 0.0005944083677604795
Epoch 1000, Loss: 0.001290051732212305, Constraint losses: L1: -1.0684853792190552, L2: 0.0, L3: 0.0021790266036987305, L4: 0.00017951056361198425
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 102.69688415527344, Losses: L1: 17.106897354125977, L2: 0.0019247760064899921, L3: 1.0019011497497559, L4: 84.27043151855469, L5: 0.3166905641555786
Epoch 500, Loss: 11.271785736083984, Losses: L1: 0.8337736129760742, L2: 0.18211086094379425, L3: 0.09435290098190308, L4: 10.128046989440918, L5: 0.12455679476261139
Epoch 1000, Loss: 4.851018905639648, Losses: L1: 1.660356879234314, L2: 0.16713900864124298, L3: 0.12158191204071045, L4: 2.949124336242676, L5: 0.03638671711087227
Epoch 1500, Loss: 2.864278554916382, Losses: L1: 0.48415297269821167, L2: 0.1065184697508812, L3: 0.11264997720718384, L4: 2.1881461143493652, L5: 0.026070358231663704
Epoch 2000, Loss: 1.8105757236480713, Losses: L1: 0.3993653655052185, L2: 0.12275036424398422, L3: 0.10135024785995483, L4: 1.218415379524231, L5: 0.03006957285106182
Epoch 2500, Loss: 1.6051656007766724, Losses: L1: 0.398373007774353, L2: 0.11867007613182068, L3: 0.09706759452819824, L4: 1.0203067064285278, L5: 0.030083319172263145
Epoch 3000, Loss: 1.5419514179229736, Losses: L1: 0.40769246220588684, L2: 0.11697510629892349, L3: 0.09435313940048218, L4: 0.9519193172454834, L5: 0.02949897013604641
Epoch 3500, Loss: 1.5029325485229492, Losses: L1: 0.40580904483795166, L2: 0.1162387877702713, L3: 0.09311783313751221, L4: 0.9168623685836792, L5: 0.029023827984929085
Epoch 4000, Loss: 1.480450987815857, Losses: L1: 0.40510228276252747, L2: 0.11552686244249344, L3: 0.09253859519958496, L4: 0.8963503837585449, L5: 0.02869630604982376
Epoch 4500, Loss: 1.465208888053894, Losses: L1: 0.4072107672691345, L2: 0.11475642770528793, L3: 0.09157657623291016, L4: 0.8805582523345947, L5: 0.028485063463449478
Epoch 5000, Loss: 1.4548804759979248, Losses: L1: 0.40686851739883423, L2: 0.11432307958602905, L3: 0.09125614166259766, L4: 0.8711234331130981, L5: 0.028470918536186218
Epoch 5500, Loss: 1.4419454336166382, Losses: L1: 0.3899059593677521, L2: 0.11963581293821335, L3: 0.09168338775634766, L4: 0.8717219233512878, L5: 0.02881629578769207
Epoch 6000, Loss: 1.4336962699890137, Losses: L1: 0.3836829960346222, L2: 0.12195314466953278, L3: 0.09137684106826782, L4: 0.8687194585800171, L5: 0.028940483927726746
Epoch 6500, Loss: 1.427646517753601, Losses: L1: 0.3822961747646332, L2: 0.12324773520231247, L3: 0.09092283248901367, L4: 0.8638373613357544, L5: 0.028966344892978668
Epoch 7000, Loss: 1.4232741594314575, Losses: L1: 0.38085201382637024, L2: 0.12405352294445038, L3: 0.09059679508209229, L4: 0.8608137369155884, L5: 0.02898487262427807
Epoch 7500, Loss: 1.4201109409332275, Losses: L1: 0.38022342324256897, L2: 0.12457524240016937, L3: 0.09037989377975464, L4: 0.8582261204719543, L5: 0.028993792831897736
Epoch 8000, Loss: 1.4179461002349854, Losses: L1: 0.379810094833374, L2: 0.12495562434196472, L3: 0.09022927284240723, L4: 0.8564249277114868, L5: 0.02900402806699276
Epoch 8500, Loss: 1.4164494276046753, Losses: L1: 0.3793991506099701, L2: 0.12525923550128937, L3: 0.09012776613235474, L4: 0.8552809953689575, L5: 0.029011882841587067
Epoch 9000, Loss: 1.4154285192489624, Losses: L1: 0.3791533410549164, L2: 0.12545950710773468, L3: 0.09005880355834961, L4: 0.8544716835021973, L5: 0.029014967381954193
Epoch 9500, Loss: 1.4147462844848633, Losses: L1: 0.37901368737220764, L2: 0.12559179961681366, L3: 0.09000402688980103, L4: 0.8539121150970459, L5: 0.02902059257030487
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021589517593384, Constraint losses: L1: 18.42068099975586, L2: 0.0010563023388385773, L3: 1.0010563135147095, L4: 1.00105619430542
Epoch 500, Loss: 0.0024226470850408077, Constraint losses: L1: -0.9657592177391052, L2: 0.0, L3: 0.002692997455596924, L4: 0.0006954089039936662
Epoch 1000, Loss: 0.0012967779766768217, Constraint losses: L1: -1.1078213453292847, L2: 0.0, L3: 0.002201974391937256, L4: 0.00020262491307221353
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022681474685669, Constraint losses: L1: 18.42068099975586, L2: 0.0014201715821400285, L3: 1.0014201402664185, L4: 1.001420497894287
Epoch 500, Loss: 0.002556083258241415, Constraint losses: L1: -1.0149009227752686, L2: 0.0, L3: 0.0027843117713928223, L4: 0.0007866723462939262
Epoch 1000, Loss: 0.001425103284418583, Constraint losses: L1: -1.0707416534423828, L2: 0.0, L3: 0.0022475123405456543, L4: 0.00024833259521983564
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.9991455078125, Losses: L1: 14.138928413391113, L2: 0.0005229489761404693, L3: 1.0001853704452515, L4: 79.2930908203125, L5: 0.2833402752876282
Epoch 500, Loss: 4.5385637283325195, Losses: L1: 0.830382227897644, L2: 0.14659669995307922, L3: 0.13388919830322266, L4: 3.4516308307647705, L5: 0.024681594222784042
Epoch 1000, Loss: 15.25265121459961, Losses: L1: 4.740773677825928, L2: 0.8984866738319397, L3: 0.06608724594116211, L4: 9.873926162719727, L5: 0.061310283839702606
Epoch 1500, Loss: 15.844141960144043, Losses: L1: 3.2284739017486572, L2: 1.0269652605056763, L3: 0.270901620388031, L4: 11.594914436340332, L5: 0.1181846410036087
Epoch 2000, Loss: 4.964818000793457, Losses: L1: 0.40714097023010254, L2: 0.08340027928352356, L3: 0.17466139793395996, L4: 4.304933547973633, L5: 0.01819079928100109
Epoch 2500, Loss: 56.357425689697266, Losses: L1: 5.292344570159912, L2: 0.00035479507641866803, L3: 0.9692368507385254, L4: 49.49941635131836, L5: 0.29812344908714294
Epoch 3000, Loss: 3.485078811645508, Losses: L1: 0.3301921784877777, L2: 0.08725635707378387, L3: 0.14440429210662842, L4: 2.9286723136901855, L5: 0.019090915098786354
Epoch 3500, Loss: 3.3111627101898193, Losses: L1: 0.32133573293685913, L2: 0.08444726467132568, L3: 0.14041835069656372, L4: 2.769364595413208, L5: 0.018910162150859833
Epoch 4000, Loss: 3.209364652633667, Losses: L1: 0.3115255832672119, L2: 0.08156668394804001, L3: 0.13804864883422852, L4: 2.6807682514190674, L5: 0.019119378179311752
Epoch 4500, Loss: 3.1343722343444824, Losses: L1: 0.30695635080337524, L2: 0.0785466879606247, L3: 0.13749295473098755, L4: 2.6131224632263184, L5: 0.01876353658735752
Epoch 5000, Loss: 3.080658435821533, Losses: L1: 0.3068590760231018, L2: 0.07592456787824631, L3: 0.13663846254348755, L4: 2.561779022216797, L5: 0.018709758296608925
Epoch 5500, Loss: 3.042942762374878, Losses: L1: 0.3048650622367859, L2: 0.07424825429916382, L3: 0.1355656385421753, L4: 2.5277109146118164, L5: 0.0188385508954525
Epoch 6000, Loss: 3.013826847076416, Losses: L1: 0.30159515142440796, L2: 0.0731220692396164, L3: 0.1349102258682251, L4: 2.503042459487915, L5: 0.018858985975384712
Epoch 6500, Loss: 2.9931206703186035, Losses: L1: 0.29865479469299316, L2: 0.07240774482488632, L3: 0.13439059257507324, L4: 2.4861483573913574, L5: 0.018861573189496994
Epoch 7000, Loss: 2.978301525115967, Losses: L1: 0.29690036177635193, L2: 0.0719318687915802, L3: 0.13389050960540771, L4: 2.4737420082092285, L5: 0.01890140026807785
Epoch 7500, Loss: 2.9676363468170166, Losses: L1: 0.2954792082309723, L2: 0.0715809017419815, L3: 0.13355636596679688, L4: 2.464974880218506, L5: 0.01891765370965004
Epoch 8000, Loss: 2.960277557373047, Losses: L1: 0.2945546805858612, L2: 0.0713435560464859, L3: 0.13330131769180298, L4: 2.4588963985443115, L5: 0.018926704302430153
Epoch 8500, Loss: 2.955190896987915, Losses: L1: 0.29389575123786926, L2: 0.07119325548410416, L3: 0.13310956954956055, L4: 2.4547064304351807, L5: 0.018941262736916542
Epoch 9000, Loss: 2.951794147491455, Losses: L1: 0.29358112812042236, L2: 0.07109548151493073, L3: 0.13295906782150269, L4: 2.4518065452575684, L5: 0.018949922174215317
Epoch 9500, Loss: 2.9494738578796387, Losses: L1: 0.29328328371047974, L2: 0.07103278487920761, L3: 0.1328638195991516, L4: 2.449904203414917, L5: 0.01895303651690483
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.02146577835083, Constraint losses: L1: 18.42068099975586, L2: 0.0010150561574846506, L3: 1.001015067100525, L4: 1.0010149478912354
Epoch 500, Loss: 0.0024396164808422327, Constraint losses: L1: -1.085055947303772, L2: 0.0, L3: 0.0027613043785095215, L4: 0.0007633680943399668
Epoch 1000, Loss: 0.0013661918928846717, Constraint losses: L1: -1.1181560754776, L2: 0.0, L3: 0.0022419095039367676, L4: 0.00024243853113148361
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9995065927505493, Constraint losses: L1: 5.723397731781006, L2: 0.0, L3: 0.996891975402832, L4: 0.9968912601470947
Epoch 500, Loss: 0.002774310763925314, Constraint losses: L1: -1.0563260316848755, L2: 0.0, L3: 0.0029141902923583984, L4: 0.0009164466755464673
Epoch 1000, Loss: 0.0015281550586223602, Constraint losses: L1: -1.0714296102523804, L2: 0.0, L3: 0.0022994279861450195, L4: 0.00030015682568773627
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 171.05035400390625, Losses: L1: 8.923823356628418, L2: 8.596744009992108e-05, L3: 0.9994613528251648, L4: 80.48992919921875, L5: 0.29435107111930847
Epoch 500, Loss: 3.9863345623016357, Losses: L1: 1.0826815366744995, L2: 0.16629117727279663, L3: 0.06096756458282471, L4: 1.37471604347229, L5: 0.020215636119246483
Epoch 1000, Loss: 14.521215438842773, Losses: L1: 8.149706840515137, L2: 1.41288423538208, L3: 0.1184079647064209, L4: 2.7455530166625977, L5: 0.11110486835241318
Epoch 1500, Loss: 9.467766761779785, Losses: L1: 4.811954498291016, L2: 1.023769736289978, L3: 0.08000719547271729, L4: 2.0222582817077637, L5: 0.038808487355709076
Epoch 2000, Loss: 11.629288673400879, Losses: L1: 4.054817199707031, L2: 0.5309528112411499, L3: 0.08528006076812744, L4: 3.5937769412994385, L5: 0.07232324779033661
Epoch 2500, Loss: 35.02678680419922, Losses: L1: 6.793274879455566, L2: 0.44818249344825745, L3: 0.3590857982635498, L4: 13.800620079040527, L5: 0.09819187968969345
Epoch 3000, Loss: 7.158905982971191, Losses: L1: 1.569913625717163, L2: 0.12869474291801453, L3: 0.18752872943878174, L4: 2.659237861633301, L5: 0.0372813418507576
Epoch 3500, Loss: 5.772287845611572, Losses: L1: 1.3262959718704224, L2: 0.12756922841072083, L3: 0.17071533203125, L4: 2.0974843502044678, L5: 0.03304629400372505
Epoch 4000, Loss: 5.100168704986572, Losses: L1: 1.301324725151062, L2: 0.12664979696273804, L3: 0.15972310304641724, L4: 1.779977798461914, L5: 0.031680382788181305
Epoch 4500, Loss: 4.694723129272461, Losses: L1: 1.2441133260726929, L2: 0.12842203676700592, L3: 0.15297186374664307, L4: 1.6088546514511108, L5: 0.031435027718544006
Epoch 5000, Loss: 4.450995445251465, Losses: L1: 1.235582709312439, L2: 0.1312762051820755, L3: 0.14781105518341064, L4: 1.4931031465530396, L5: 0.03151540458202362
Epoch 5500, Loss: 4.316492080688477, Losses: L1: 1.231225848197937, L2: 0.13179314136505127, L3: 0.14489632844924927, L4: 1.4293678998947144, L5: 0.031474627554416656
Epoch 6000, Loss: 4.220199108123779, Losses: L1: 1.2272869348526, L2: 0.1340813785791397, L3: 0.14299744367599487, L4: 1.3835527896881104, L5: 0.03153711557388306
Epoch 6500, Loss: 4.163053035736084, Losses: L1: 1.2290204763412476, L2: 0.13542592525482178, L3: 0.14194047451019287, L4: 1.3543140888214111, L5: 0.03150186687707901
Epoch 7000, Loss: 4.125549793243408, Losses: L1: 1.2299410104751587, L2: 0.13632817566394806, L3: 0.14111673831939697, L4: 1.3352736234664917, L5: 0.031562235206365585
Epoch 7500, Loss: 4.100098133087158, Losses: L1: 1.230822205543518, L2: 0.1371528059244156, L3: 0.14038968086242676, L4: 1.3222459554672241, L5: 0.0316363200545311
Epoch 8000, Loss: 4.082029342651367, Losses: L1: 1.2304463386535645, L2: 0.13771750032901764, L3: 0.1398795247077942, L4: 1.3135019540786743, L5: 0.03168099373579025
Epoch 8500, Loss: 4.069332599639893, Losses: L1: 1.230655550956726, L2: 0.1380937695503235, L3: 0.13948798179626465, L4: 1.307145357131958, L5: 0.03170284628868103
Epoch 9000, Loss: 4.060359954833984, Losses: L1: 1.2307137250900269, L2: 0.13836170732975006, L3: 0.13919174671173096, L4: 1.302706241607666, L5: 0.031722333282232285
Epoch 9500, Loss: 4.053946018218994, Losses: L1: 1.230594515800476, L2: 0.13856874406337738, L3: 0.13898473978042603, L4: 1.2996065616607666, L5: 0.03173939138650894
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0021145343780518, Constraint losses: L1: 6.178165912628174, L2: 0.0, L3: 0.9979684352874756, L4: 0.9979680180549622
Epoch 500, Loss: 0.002499564550817013, Constraint losses: L1: -1.0826876163482666, L2: 0.0, L3: 0.002790093421936035, L4: 0.0007921586511656642
Epoch 1000, Loss: 0.0013921919744461775, Constraint losses: L1: -1.1184320449829102, L2: 0.0, L3: 0.0022550225257873535, L4: 0.00025560162612237036
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.025587558746338, Constraint losses: L1: 18.42068099975586, L2: 0.0023888202849775553, L3: 1.002388834953308, L4: 1.0023893117904663
Epoch 500, Loss: 0.002199786016717553, Constraint losses: L1: -0.9236744046211243, L2: 0.0, L3: 0.0025606155395507812, L4: 0.0005628448561765254
Epoch 1000, Loss: 0.0012478006538003683, Constraint losses: L1: -1.0692857503890991, L2: 0.0, L3: 0.0021584033966064453, L4: 0.0001586830912856385
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 162.89666748046875, Losses: L1: 10.044754981994629, L2: 2.890507494157646e-05, L3: 0.9993446469306946, L4: 75.79359436035156, L5: 0.26535916328430176
Epoch 500, Loss: 15.238110542297363, Losses: L1: 5.397727966308594, L2: 0.3493669629096985, L3: 0.09729158878326416, L4: 4.764636993408203, L5: 0.03913437947630882
Epoch 1000, Loss: 8.547555923461914, Losses: L1: 1.113877296447754, L2: 0.0698934867978096, L3: 0.06141650676727295, L4: 3.649862766265869, L5: 0.03758964315056801
Epoch 1500, Loss: 4.114130973815918, Losses: L1: 0.9087910652160645, L2: 0.08633653074502945, L3: 0.0670880675315857, L4: 1.5155272483825684, L5: 0.06402929872274399
Epoch 2000, Loss: 3.2367794513702393, Losses: L1: 0.8143860101699829, L2: 0.058358971029520035, L3: 0.05854141712188721, L4: 1.1324573755264282, L5: 0.06975774466991425
Epoch 2500, Loss: 1.8080763816833496, Losses: L1: 0.6522048711776733, L2: 0.046121176332235336, L3: 0.05529916286468506, L4: 0.5094928741455078, L5: 0.05852602422237396
Epoch 3000, Loss: 1.7555853128433228, Losses: L1: 0.6530781984329224, L2: 0.04694650322198868, L3: 0.05270564556121826, L4: 0.48340633511543274, L5: 0.059515610337257385
Epoch 3500, Loss: 1.54842209815979, Losses: L1: 0.6287533044815063, L2: 0.04193577542901039, L3: 0.051576316356658936, L4: 0.39558902382850647, L5: 0.055946554988622665
Epoch 4000, Loss: 3.7490997314453125, Losses: L1: 1.6980737447738647, L2: 0.08401291072368622, L3: 0.09895211458206177, L4: 0.925141453742981, L5: 0.059784408658742905
Epoch 4500, Loss: 3.240929126739502, Losses: L1: 1.519668459892273, L2: 0.07673202455043793, L3: 0.0903427004814148, L4: 0.7645316123962402, L5: 0.06348865479230881
Epoch 5000, Loss: 3.0899980068206787, Losses: L1: 1.5269683599472046, L2: 0.07636746764183044, L3: 0.08711159229278564, L4: 0.6860279440879822, L5: 0.06567829102277756
Epoch 5500, Loss: 2.9805705547332764, Losses: L1: 1.4977885484695435, L2: 0.0735592469573021, L3: 0.08488184213638306, L4: 0.647549033164978, L5: 0.06602229923009872
Epoch 6000, Loss: 2.8882126808166504, Losses: L1: 1.4526357650756836, L2: 0.07090368866920471, L3: 0.08372819423675537, L4: 0.6250182390213013, L5: 0.06636049598455429
Epoch 6500, Loss: 2.8435211181640625, Losses: L1: 1.4466172456741333, L2: 0.07009002566337585, L3: 0.08249843120574951, L4: 0.6063295602798462, L5: 0.06670133769512177
Epoch 7000, Loss: 2.8187668323516846, Losses: L1: 1.4435120820999146, L2: 0.06947160512208939, L3: 0.08174729347229004, L4: 0.595946192741394, L5: 0.06687922030687332
Epoch 7500, Loss: 2.8014180660247803, Losses: L1: 1.440738320350647, L2: 0.06922286003828049, L3: 0.08119451999664307, L4: 0.5889317989349365, L5: 0.06701026111841202
Epoch 8000, Loss: 2.7886531352996826, Losses: L1: 1.4386680126190186, L2: 0.06908256560564041, L3: 0.08079653978347778, L4: 0.5837694406509399, L5: 0.06710849702358246
Epoch 8500, Loss: 2.7794511318206787, Losses: L1: 1.4371682405471802, L2: 0.06899140030145645, L3: 0.08050811290740967, L4: 0.5800504684448242, L5: 0.06717797368764877
Epoch 9000, Loss: 2.773021697998047, Losses: L1: 1.4362925291061401, L2: 0.06892658770084381, L3: 0.08029162883758545, L4: 0.577374279499054, L5: 0.06722564250230789
Epoch 9500, Loss: 2.7685422897338867, Losses: L1: 1.4356526136398315, L2: 0.06889721006155014, L3: 0.08013290166854858, L4: 0.5755277276039124, L5: 0.0672527477145195
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9986995458602905, Constraint losses: L1: 5.655265808105469, L2: 0.0, L3: 0.9965221285820007, L4: 0.9965221881866455
Epoch 500, Loss: 0.0022794653195887804, Constraint losses: L1: -1.0571976900100708, L2: 0.0, L3: 0.002667248249053955, L4: 0.0006694148178212345
Epoch 1000, Loss: 0.001302444376051426, Constraint losses: L1: -1.1174792051315308, L2: 0.0, L3: 0.0022096633911132812, L4: 0.00021026027388870716
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0291171073913574, Constraint losses: L1: 18.42068099975586, L2: 0.003565163817256689, L3: 1.0035651922225952, L4: 1.0035661458969116
Epoch 500, Loss: 0.002255873754620552, Constraint losses: L1: -1.0637383460998535, L2: 0.0, L3: 0.0026590824127197266, L4: 0.0006605296512134373
Epoch 1000, Loss: 0.001365187461487949, Constraint losses: L1: -1.0717949867248535, L2: 0.0, L3: 0.0022182464599609375, L4: 0.00021873597870580852
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 179.3794403076172, Losses: L1: 8.04975700378418, L2: 7.088725396897644e-05, L3: 0.9996519684791565, L4: 84.84361267089844, L5: 0.3213876783847809
Epoch 500, Loss: 18.078901290893555, Losses: L1: 2.2892954349517822, L2: 0.08081620186567307, L3: 0.21829938888549805, L4: 7.650570869445801, L5: 0.11487851291894913
Epoch 1000, Loss: 8.744568824768066, Losses: L1: 1.4563229084014893, L2: 0.15482670068740845, L3: 0.058391451835632324, L4: 3.531341075897217, L5: 0.04487954080104828
Epoch 1500, Loss: 3.3279082775115967, Losses: L1: 0.8659868836402893, L2: 0.11190689355134964, L3: 0.06126868724822998, L4: 1.1281840801239014, L5: 0.04416552931070328
Epoch 2000, Loss: 2.347909688949585, Losses: L1: 0.5673857927322388, L2: 0.04210514575242996, L3: 0.05171114206314087, L4: 0.8009436726570129, L5: 0.05293648689985275
Epoch 2500, Loss: 4.705541610717773, Losses: L1: 1.9228883981704712, L2: 0.12182632833719254, L3: 0.1141207218170166, L4: 1.2673240900039673, L5: 0.0364857092499733
Epoch 3000, Loss: 2.742680311203003, Losses: L1: 1.106777548789978, L2: 0.08178684115409851, L3: 0.07694900035858154, L4: 0.7170393466949463, L5: 0.04199082404375076
Epoch 3500, Loss: 2.1631107330322266, Losses: L1: 0.9832560420036316, L2: 0.07297518104314804, L3: 0.0709492564201355, L4: 0.49128127098083496, L5: 0.044927604496479034
Epoch 4000, Loss: 2.0277230739593506, Losses: L1: 0.9325791597366333, L2: 0.06881055980920792, L3: 0.06746375560760498, L4: 0.4512926936149597, L5: 0.04534471407532692
Epoch 4500, Loss: 1.9555003643035889, Losses: L1: 0.9141098260879517, L2: 0.06558935344219208, L3: 0.06569170951843262, L4: 0.4258904755115509, L5: 0.04556170105934143
Epoch 5000, Loss: 1.9162214994430542, Losses: L1: 0.9107771515846252, L2: 0.06315424293279648, L3: 0.06442362070083618, L4: 0.409294456243515, L5: 0.045427355915308
Epoch 5500, Loss: 1.8861415386199951, Losses: L1: 0.9090824127197266, L2: 0.06173807755112648, L3: 0.06296682357788086, L4: 0.3959369659423828, L5: 0.04567469283938408
Epoch 6000, Loss: 1.8602721691131592, Losses: L1: 0.9070867300033569, L2: 0.060566965490579605, L3: 0.06163191795349121, L4: 0.3849932551383972, L5: 0.04564175009727478
Epoch 6500, Loss: 1.8076235055923462, Losses: L1: 0.8756822943687439, L2: 0.058534543961286545, L3: 0.0606236457824707, L4: 0.3753786087036133, L5: 0.045646537095308304
Epoch 7000, Loss: 1.7901089191436768, Losses: L1: 0.8738906383514404, L2: 0.057149436324834824, L3: 0.05980795621871948, L4: 0.3683340549468994, L5: 0.045583732426166534
Epoch 7500, Loss: 2.274397611618042, Losses: L1: 0.7584049701690674, L2: 0.04685017466545105, L3: 0.06258219480514526, L4: 0.669681966304779, L5: 0.04531075432896614
Epoch 8000, Loss: 1.9888936281204224, Losses: L1: 0.7712384462356567, L2: 0.04996394366025925, L3: 0.06219005584716797, L4: 0.5203209519386292, L5: 0.04492060840129852
Epoch 8500, Loss: 1.962412714958191, Losses: L1: 0.7722119688987732, L2: 0.049608513712882996, L3: 0.0619739294052124, L4: 0.5068485736846924, L5: 0.04486267641186714
Epoch 9000, Loss: 1.945428729057312, Losses: L1: 0.7715350985527039, L2: 0.04950077831745148, L3: 0.06184089183807373, L4: 0.4988206923007965, L5: 0.04483051970601082
Epoch 9500, Loss: 1.9337081909179688, Losses: L1: 0.7711287140846252, L2: 0.049384504556655884, L3: 0.061722517013549805, L4: 0.49330368638038635, L5: 0.04477870464324951
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.008634090423584, Constraint losses: L1: 9.333725929260254, L2: 0.0004068520793225616, L3: 0.9994462728500366, L4: 0.9994471073150635
Epoch 500, Loss: 0.0018830480985343456, Constraint losses: L1: -1.0858559608459473, L2: 0.0, L3: 0.0024837255477905273, L4: 0.00048517860705032945
Epoch 1000, Loss: 0.0011854731710627675, Constraint losses: L1: -1.1182783842086792, L2: 0.0, L3: 0.002151668071746826, L4: 0.00015208355034701526
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0015616416931152, Constraint losses: L1: 6.069262981414795, L2: 0.0, L3: 0.9977463483810425, L4: 0.9977461099624634
Epoch 500, Loss: 0.0026743151247501373, Constraint losses: L1: -0.8772684931755066, L2: 0.0, L3: 0.0027745962142944336, L4: 0.0007769875228404999
Epoch 1000, Loss: 0.0013670288026332855, Constraint losses: L1: -1.070281982421875, L2: 0.0, L3: 0.0022184252738952637, L4: 0.00021888557239435613
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 57.65054702758789, Losses: L1: 18.38850212097168, L2: 0.002500012516975403, L3: 1.0024404525756836, L4: 74.25687408447266, L5: 0.254950612783432
Epoch 500, Loss: 25.55756378173828, Losses: L1: 5.921882152557373, L2: 0.6868150234222412, L3: 1.0183600187301636, L4: 34.35560607910156, L5: 0.1555018275976181
Epoch 1000, Loss: 45.57290267944336, Losses: L1: 18.4204158782959, L2: 6.10340293930034e-12, L3: 1.0, L4: 50.000404357910156, L5: 0.30457621812820435
Epoch 1500, Loss: 45.57230758666992, Losses: L1: 18.419818878173828, L2: 9.912120603472463e-12, L3: 1.0, L4: 50.00040817260742, L5: 0.30457478761672974
Epoch 2000, Loss: 45.57076644897461, Losses: L1: 18.41826057434082, L2: 2.1873306985109586e-11, L3: 1.0, L4: 50.00043487548828, L5: 0.3045700490474701
Epoch 2500, Loss: 45.56095504760742, Losses: L1: 18.40842628479004, L2: 9.886014229465445e-11, L3: 1.0, L4: 50.0004997253418, L5: 0.30455487966537476
Epoch 3000, Loss: 29.791847229003906, Losses: L1: 2.649608612060547, L2: 0.33664780855178833, L3: 0.8728999495506287, L4: 50.23810577392578, L5: 0.2181244045495987
Epoch 3500, Loss: 14.979101181030273, Losses: L1: 6.7004475593566895, L2: 0.47217702865600586, L3: 0.18501436710357666, L4: 15.180813789367676, L5: 0.1642618179321289
Epoch 4000, Loss: 11.611433029174805, Losses: L1: 5.06776762008667, L2: 0.4376116991043091, L3: 0.22561299800872803, L4: 11.620904922485352, L5: 0.12636220455169678
Epoch 4500, Loss: 11.343853950500488, Losses: L1: 5.083444595336914, L2: 0.42219021916389465, L3: 0.23063427209854126, L4: 11.046380043029785, L5: 0.12971073389053345
Epoch 5000, Loss: 11.173956871032715, Losses: L1: 5.056408405303955, L2: 0.40292271971702576, L3: 0.22749656438827515, L4: 10.794412612915039, L5: 0.12777535617351532
Epoch 5500, Loss: 11.051534652709961, Losses: L1: 5.039961338043213, L2: 0.3917781710624695, L3: 0.22427988052368164, L4: 10.60757064819336, L5: 0.12667877972126007
Epoch 6000, Loss: 10.96175479888916, Losses: L1: 5.028740406036377, L2: 0.38231161236763, L3: 0.223038911819458, L4: 10.46555233001709, L5: 0.12600988149642944
Epoch 6500, Loss: 10.89521598815918, Losses: L1: 5.020064830780029, L2: 0.37528741359710693, L3: 0.222154438495636, L4: 10.360947608947754, L5: 0.12545107305049896
Epoch 7000, Loss: 10.845843315124512, Losses: L1: 5.0153584480285645, L2: 0.37089136242866516, L3: 0.22131788730621338, L4: 10.279495239257812, L5: 0.12531019747257233
Epoch 7500, Loss: 10.809372901916504, Losses: L1: 5.012473106384277, L2: 0.3675824999809265, L3: 0.22087568044662476, L4: 10.21743392944336, L5: 0.12527987360954285
Epoch 8000, Loss: 10.782325744628906, Losses: L1: 5.010006427764893, L2: 0.364734947681427, L3: 0.22077453136444092, L4: 10.171588897705078, L5: 0.12521794438362122
Epoch 8500, Loss: 10.762337684631348, Losses: L1: 5.007999420166016, L2: 0.36243388056755066, L3: 0.22081661224365234, L4: 10.137828826904297, L5: 0.12514711916446686
Epoch 9000, Loss: 10.747634887695312, Losses: L1: 5.006385803222656, L2: 0.3606131374835968, L3: 0.22092288732528687, L4: 10.113107681274414, L5: 0.12508605420589447
Epoch 9500, Loss: 10.73692512512207, Losses: L1: 5.005191326141357, L2: 0.3592333495616913, L3: 0.2210482358932495, L4: 10.095014572143555, L5: 0.12502655386924744
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9970113039016724, Constraint losses: L1: 5.434957504272461, L2: 0.0, L3: 0.9957884550094604, L4: 0.9957878589630127
Epoch 500, Loss: 0.0020725480280816555, Constraint losses: L1: -1.0930168628692627, L2: 0.0, L3: 0.0025820136070251465, L4: 0.0005835514748468995
Epoch 1000, Loss: 0.0012470701476559043, Constraint losses: L1: -1.1169500350952148, L2: 0.0, L3: 0.0021817684173583984, L4: 0.0001822517951950431
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001112461090088, Constraint losses: L1: 5.988457202911377, L2: 0.0, L3: 0.9975622296333313, L4: 0.9975618720054626
Epoch 500, Loss: 0.0023326619993895292, Constraint losses: L1: -1.0579338073730469, L2: 0.0, L3: 0.0026944875717163086, L4: 0.0006961082690395415
Epoch 1000, Loss: 0.001387301366776228, Constraint losses: L1: -1.0709699392318726, L2: 0.0, L3: 0.002228856086730957, L4: 0.0002294152363901958
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.353633880615234, Losses: L1: 18.42068099975586, L2: 0.0025121066719293594, L3: 1.002511978149414, L4: 71.37493896484375, L5: 0.23920008540153503
Epoch 500, Loss: 30.650257110595703, Losses: L1: 3.8627374172210693, L2: 9.241355655831285e-06, L3: 0.9542549252510071, L4: 49.189571380615234, L5: 0.2842199206352234
Epoch 1000, Loss: 7.50045108795166, Losses: L1: 2.252220630645752, L2: 0.5959147810935974, L3: 0.2751762270927429, L4: 8.581055641174316, L5: 0.10939255356788635
Epoch 1500, Loss: 7.559202671051025, Losses: L1: 3.1049041748046875, L2: 1.8926665782928467, L3: 0.24038982391357422, L4: 5.82243013381958, L5: 0.11597011238336563
Epoch 2000, Loss: 6.154603481292725, Losses: L1: 3.2095367908477783, L2: 1.5050957202911377, L3: 0.17957329750061035, L4: 3.4250590801239014, L5: 0.12084230780601501
Epoch 2500, Loss: 6.573048114776611, Losses: L1: 3.3685691356658936, L2: 1.596606731414795, L3: 0.17488443851470947, L4: 3.8548264503479004, L5: 0.1289934366941452
Epoch 3000, Loss: 6.159967422485352, Losses: L1: 3.2825186252593994, L2: 1.7549281120300293, L3: 0.18960970640182495, L4: 2.992466688156128, L5: 0.12453166395425797
Epoch 3500, Loss: 5.998867988586426, Losses: L1: 3.1701717376708984, L2: 1.6882296800613403, L3: 0.18109917640686035, L4: 2.9839086532592773, L5: 0.13042883574962616
Epoch 4000, Loss: 5.938111305236816, Losses: L1: 3.5242531299591064, L2: 1.5295095443725586, L3: 0.16827285289764404, L4: 2.3766589164733887, L5: 0.12422731518745422
Epoch 4500, Loss: 5.912408351898193, Losses: L1: 3.522277593612671, L2: 1.521227240562439, L3: 0.1663336157798767, L4: 2.345214605331421, L5: 0.12424212694168091
Epoch 5000, Loss: 5.903232574462891, Losses: L1: 3.5499885082244873, L2: 1.5027341842651367, L3: 0.16572076082229614, L4: 2.293997287750244, L5: 0.123436838388443
Epoch 5500, Loss: 5.888243198394775, Losses: L1: 3.542628049850464, L2: 1.4914661645889282, L3: 0.16779327392578125, L4: 2.2854785919189453, L5: 0.1215561106801033
Epoch 6000, Loss: 5.865855693817139, Losses: L1: 3.5469183921813965, L2: 1.4764829874038696, L3: 0.16431820392608643, L4: 2.259165048599243, L5: 0.1224772185087204
Epoch 6500, Loss: 5.856757640838623, Losses: L1: 3.5452828407287598, L2: 1.472674012184143, L3: 0.16313958168029785, L4: 2.252643346786499, L5: 0.12253662943840027
Epoch 7000, Loss: 5.850430011749268, Losses: L1: 3.5438039302825928, L2: 1.4709410667419434, L3: 0.16214066743850708, L4: 2.248422145843506, L5: 0.12266279011964798
Epoch 7500, Loss: 5.845736026763916, Losses: L1: 3.542553186416626, L2: 1.4697153568267822, L3: 0.16131055355072021, L4: 2.245680570602417, L5: 0.12286356091499329
Epoch 8000, Loss: 5.842203140258789, Losses: L1: 3.541696548461914, L2: 1.4686620235443115, L3: 0.16071349382400513, L4: 2.2435388565063477, L5: 0.12297939509153366
Epoch 8500, Loss: 5.839547634124756, Losses: L1: 3.540978193283081, L2: 1.467861533164978, L3: 0.1602364182472229, L4: 2.242190361022949, L5: 0.12307082116603851
Epoch 9000, Loss: 5.837551116943359, Losses: L1: 3.5404608249664307, L2: 1.4672248363494873, L3: 0.15989577770233154, L4: 2.241121530532837, L5: 0.12312610447406769
Epoch 9500, Loss: 5.836066246032715, Losses: L1: 3.540095329284668, L2: 1.4666954278945923, L3: 0.1596474051475525, L4: 2.2403244972229004, L5: 0.12316621094942093
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.006110906600952, Constraint losses: L1: 7.332342624664307, L2: 0.0, L3: 0.9993893504142761, L4: 0.9993892312049866
Epoch 500, Loss: 0.0023897283244878054, Constraint losses: L1: -1.0908491611480713, L2: 0.0, L3: 0.0027391910552978516, L4: 0.000741386495064944
Epoch 1000, Loss: 0.0013575081247836351, Constraint losses: L1: -1.1177175045013428, L2: 0.0, L3: 0.002237260341644287, L4: 0.00023796531604602933
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.033555030822754, Constraint losses: L1: 18.42068099975586, L2: 0.005044769961386919, L3: 1.0050448179244995, L4: 1.005044937133789
Epoch 500, Loss: 0.0022364933975040913, Constraint losses: L1: -0.9487916827201843, L2: 0.0, L3: 0.002591729164123535, L4: 0.0005935559747740626
Epoch 1000, Loss: 0.001281052129343152, Constraint losses: L1: -1.0689365863800049, L2: 0.0, L3: 0.0021747350692749023, L4: 0.00017525377916172147
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 55.10007858276367, Losses: L1: 15.76489543914795, L2: 0.0011741783237084746, L3: 1.0010732412338257, L4: 73.65599060058594, L5: 0.25222542881965637
Epoch 500, Loss: 14.72935676574707, Losses: L1: 4.940217018127441, L2: 3.813009738922119, L3: 0.3119395971298218, L4: 14.030895233154297, L5: 0.12165401130914688
Epoch 1000, Loss: 4.471724510192871, Losses: L1: 1.0202765464782715, L2: 0.41717538237571716, L3: 0.1895695924758911, L4: 5.49493408203125, L5: 0.058126818388700485
Epoch 1500, Loss: 2.143420934677124, Losses: L1: 0.43477123975753784, L2: 0.11708151549100876, L3: 0.12920844554901123, L4: 2.6760170459747314, L5: 0.026841770857572556
Epoch 2000, Loss: 1.678648591041565, Losses: L1: 0.20158283412456512, L2: 0.12706030905246735, L3: 0.12121367454528809, L4: 2.232154130935669, L5: 0.027515599504113197
Epoch 2500, Loss: 1.4656802415847778, Losses: L1: 0.1458462029695511, L2: 0.13828818500041962, L3: 0.11918151378631592, L4: 1.920403003692627, L5: 0.0260627344250679
Epoch 3000, Loss: 1.317460536956787, Losses: L1: 0.10873853415250778, L2: 0.13397900760173798, L3: 0.11679661273956299, L4: 1.7267885208129883, L5: 0.02237248234450817
Epoch 3500, Loss: 1.2234687805175781, Losses: L1: 0.10123369097709656, L2: 0.13525322079658508, L3: 0.11280292272567749, L4: 1.5675561428070068, L5: 0.022612301632761955
Epoch 4000, Loss: 1.1702276468276978, Losses: L1: 0.0932842269539833, L2: 0.13491998612880707, L3: 0.11233377456665039, L4: 1.4836170673370361, L5: 0.021503711119294167
Epoch 4500, Loss: 1.1347546577453613, Losses: L1: 0.09071618318557739, L2: 0.13457781076431274, L3: 0.1104273796081543, L4: 1.4277117252349854, L5: 0.021019477397203445
Epoch 5000, Loss: 1.10709547996521, Losses: L1: 0.0856943428516388, L2: 0.13439862430095673, L3: 0.10943448543548584, L4: 1.3886189460754395, L5: 0.02051168493926525
Epoch 5500, Loss: 1.0883235931396484, Losses: L1: 0.08463042974472046, L2: 0.13469508290290833, L3: 0.1083037257194519, L4: 1.3579697608947754, L5: 0.020376654341816902
Epoch 6000, Loss: 1.075085997581482, Losses: L1: 0.08287379890680313, L2: 0.13467846810817719, L3: 0.1078079342842102, L4: 1.3380603790283203, L5: 0.02011348493397236
Epoch 6500, Loss: 1.0657134056091309, Losses: L1: 0.08158803731203079, L2: 0.13455255329608917, L3: 0.10744667053222656, L4: 1.3242897987365723, L5: 0.019905434921383858
Epoch 7000, Loss: 1.0591380596160889, Losses: L1: 0.08067066222429276, L2: 0.1344016045331955, L3: 0.10710513591766357, L4: 1.314977765083313, L5: 0.019783757627010345
Epoch 7500, Loss: 1.0544171333312988, Losses: L1: 0.08009297400712967, L2: 0.13435101509094238, L3: 0.10683679580688477, L4: 1.3081246614456177, L5: 0.01970636285841465
Epoch 8000, Loss: 1.0509436130523682, Losses: L1: 0.07947050034999847, L2: 0.13422660529613495, L3: 0.10674691200256348, L4: 1.3033136129379272, L5: 0.01960454136133194
Epoch 8500, Loss: 1.0483274459838867, Losses: L1: 0.0791197419166565, L2: 0.13420706987380981, L3: 0.10659807920455933, L4: 1.299522876739502, L5: 0.019573280587792397
Epoch 9000, Loss: 1.0466305017471313, Losses: L1: 0.07894223183393478, L2: 0.13417309522628784, L3: 0.10651546716690063, L4: 1.2969813346862793, L5: 0.01954006217420101
Epoch 9500, Loss: 1.0454899072647095, Losses: L1: 0.07881081104278564, L2: 0.13415440917015076, L3: 0.10643559694290161, L4: 1.2953588962554932, L5: 0.019525589421391487
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.019094944000244, Constraint losses: L1: 18.42068099975586, L2: 0.00022608126164413989, L3: 1.000223994255066, L4: 1.000224232673645
Epoch 500, Loss: 0.002459924900904298, Constraint losses: L1: -1.0837013721466064, L2: 0.0, L3: 0.002770841121673584, L4: 0.0007727851625531912
Epoch 1000, Loss: 0.001384264905937016, Constraint losses: L1: -1.118301272392273, L2: 0.0, L3: 0.0022510290145874023, L4: 0.00025153718888759613
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0190248489379883, Constraint losses: L1: 18.314664840698242, L2: 0.0002621714666020125, L3: 1.000223994255066, L4: 1.0002238750457764
Epoch 500, Loss: 0.0021157870069146156, Constraint losses: L1: -1.0321646928787231, L2: 0.0, L3: 0.002573072910308838, L4: 0.0005748787662014365
Epoch 1000, Loss: 0.0012860328424721956, Constraint losses: L1: -1.070875883102417, L2: 0.0, L3: 0.002178192138671875, L4: 0.00017871655290946364
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.56389617919922, Losses: L1: 15.339682579040527, L2: 0.0014674667036160827, L3: 1.0008959770202637, L4: 77.08491516113281, L5: 0.27353963255882263
Epoch 500, Loss: 23.562339782714844, Losses: L1: 4.415693759918213, L2: 3.264953374862671, L3: 0.2779872417449951, L4: 16.858829498291016, L5: 0.19873052835464478
Epoch 1000, Loss: 11.471522331237793, Losses: L1: 1.2265762090682983, L2: 0.15324582159519196, L3: 0.2954758405685425, L4: 9.546512603759766, L5: 0.0617181733250618
Epoch 1500, Loss: 8.806428909301758, Losses: L1: 0.6987537145614624, L2: 0.03883986920118332, L3: 0.24819684028625488, L4: 7.565810203552246, L5: 0.0521031953394413
Epoch 2000, Loss: 7.985702037811279, Losses: L1: 0.6045583486557007, L2: 0.028565844520926476, L3: 0.243829607963562, L4: 6.8540730476379395, L5: 0.05025629326701164
Epoch 2500, Loss: 7.390560150146484, Losses: L1: 0.5731953382492065, L2: 0.028694182634353638, L3: 0.24066120386123657, L4: 6.297310829162598, L5: 0.04876936227083206
Epoch 3000, Loss: 7.028222560882568, Losses: L1: 0.6503503918647766, L2: 0.017021799460053444, L3: 0.23668426275253296, L4: 5.870704650878906, L5: 0.05057623237371445
Epoch 3500, Loss: 6.774740219116211, Losses: L1: 0.6661964654922485, L2: 0.011704117059707642, L3: 0.2349696159362793, L4: 5.607418060302734, L5: 0.05066842585802078
Epoch 4000, Loss: 6.7766852378845215, Losses: L1: 0.6616950035095215, L2: 0.013962865807116032, L3: 0.23461508750915527, L4: 5.61402702331543, L5: 0.04950306937098503
Epoch 4500, Loss: 6.697871685028076, Losses: L1: 0.6805131435394287, L2: 0.012188181281089783, L3: 0.2343273162841797, L4: 5.517632484436035, L5: 0.049954287707805634
Epoch 5000, Loss: 6.653582572937012, Losses: L1: 0.6771517395973206, L2: 0.01201200857758522, L3: 0.23325484991073608, L4: 5.478724002838135, L5: 0.05038217082619667
Epoch 5500, Loss: 6.621857166290283, Losses: L1: 0.6812188625335693, L2: 0.011755242012441158, L3: 0.23312807083129883, L4: 5.443478107452393, L5: 0.050052329897880554
Epoch 6000, Loss: 6.597690105438232, Losses: L1: 0.6807266473770142, L2: 0.011489656753838062, L3: 0.23329836130142212, L4: 5.419586181640625, L5: 0.05007189139723778
Epoch 6500, Loss: 6.581116676330566, Losses: L1: 0.6799346208572388, L2: 0.011285949498414993, L3: 0.23355257511138916, L4: 5.403376579284668, L5: 0.05011434108018875
Epoch 7000, Loss: 6.553959369659424, Losses: L1: 0.6801944971084595, L2: 0.010595783591270447, L3: 0.23304522037506104, L4: 5.377138614654541, L5: 0.050476327538490295
Epoch 7500, Loss: 6.543760299682617, Losses: L1: 0.6812931299209595, L2: 0.01057083997875452, L3: 0.23313093185424805, L4: 5.36579704284668, L5: 0.05024495720863342
Epoch 8000, Loss: 6.536942958831787, Losses: L1: 0.6813939809799194, L2: 0.010536239482462406, L3: 0.2331409454345703, L4: 5.35891056060791, L5: 0.05017673596739769
Epoch 8500, Loss: 6.531933784484863, Losses: L1: 0.6810935735702515, L2: 0.010496226139366627, L3: 0.2332078218460083, L4: 5.354099750518799, L5: 0.05015343427658081
Epoch 9000, Loss: 6.5283427238464355, Losses: L1: 0.681399941444397, L2: 0.010485678911209106, L3: 0.23320186138153076, L4: 5.350241661071777, L5: 0.050108496099710464
Epoch 9500, Loss: 6.525798797607422, Losses: L1: 0.6812967658042908, L2: 0.010467292740941048, L3: 0.23323553800582886, L4: 5.347745895385742, L5: 0.050101909786462784
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0057296752929688, Constraint losses: L1: 7.180346965789795, L2: 0.0, L3: 0.9992747902870178, L4: 0.9992746114730835
Epoch 500, Loss: 0.0027335123158991337, Constraint losses: L1: -1.0557427406311035, L2: 0.0, L3: 0.002893209457397461, L4: 0.0008960457053035498
Epoch 1000, Loss: 0.0014527610037475824, Constraint losses: L1: -1.1175298690795898, L2: 0.0, L3: 0.0022847652435302734, L4: 0.0002855256316252053
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0268585681915283, Constraint losses: L1: 18.42068099975586, L2: 0.0028125992976129055, L3: 1.0028126239776611, L4: 1.0028126239776611
Epoch 500, Loss: 0.002225362230092287, Constraint losses: L1: -1.06233811378479, L2: 0.0, L3: 0.0026430487632751465, L4: 0.0006446514744311571
Epoch 1000, Loss: 0.0013513729209080338, Constraint losses: L1: -1.071297526359558, L2: 0.0, L3: 0.0022110939025878906, L4: 0.00021157655282877386
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 88.38439178466797, Losses: L1: 16.471235275268555, L2: 0.0041545843705534935, L3: 1.004071831703186, L4: 69.66925811767578, L5: 0.23367929458618164
Epoch 500, Loss: 3.942979335784912, Losses: L1: 0.9647599458694458, L2: 0.09460719674825668, L3: 0.06520313024520874, L4: 2.7491846084594727, L5: 0.05132492631673813
Epoch 1000, Loss: 5.5354132652282715, Losses: L1: 1.4838377237319946, L2: 0.24213315546512604, L3: 0.055154502391815186, L4: 3.7662200927734375, L5: 0.05397988110780716
Epoch 1500, Loss: 1.9009593725204468, Losses: L1: 0.3443167209625244, L2: 0.035972144454717636, L3: 0.04840564727783203, L4: 1.4025061130523682, L5: 0.03933923691511154
Epoch 2000, Loss: 2.2278666496276855, Losses: L1: 0.5514538288116455, L2: 0.05131428688764572, L3: 0.06862008571624756, L4: 1.5016549825668335, L5: 0.011860580183565617
Epoch 2500, Loss: 2.2759218215942383, Losses: L1: 0.42994409799575806, L2: 0.08859246224164963, L3: 0.11301672458648682, L4: 1.5632225275039673, L5: 0.012425442226231098
Epoch 3000, Loss: 2.631431818008423, Losses: L1: 0.4148062765598297, L2: 0.2677585482597351, L3: 0.1058354377746582, L4: 1.8580081462860107, L5: 0.013067197985947132
Epoch 3500, Loss: 1.4527314901351929, Losses: L1: 0.2364327609539032, L2: 0.02800317294895649, L3: 0.10264742374420166, L4: 0.9878864288330078, L5: 0.009115827269852161
Epoch 4000, Loss: 1.3654558658599854, Losses: L1: 0.22846989333629608, L2: 0.026929454877972603, L3: 0.1017613410949707, L4: 0.9107056260108948, L5: 0.009292985312640667
Epoch 4500, Loss: 1.322601079940796, Losses: L1: 0.20745402574539185, L2: 0.026590922847390175, L3: 0.09993720054626465, L4: 0.8931903839111328, L5: 0.00878683477640152
Epoch 5000, Loss: 1.2837798595428467, Losses: L1: 0.2051152139902115, L2: 0.02605321630835533, L3: 0.09959995746612549, L4: 0.8576415777206421, L5: 0.008796630427241325
Epoch 5500, Loss: 1.268235445022583, Losses: L1: 0.20327875018119812, L2: 0.025709955021739006, L3: 0.09938681125640869, L4: 0.8445931673049927, L5: 0.008734975941479206
Epoch 6000, Loss: 1.2589468955993652, Losses: L1: 0.2019745260477066, L2: 0.02564764954149723, L3: 0.09916913509368896, L4: 0.8370852470397949, L5: 0.008725040592253208
Epoch 6500, Loss: 1.2541245222091675, Losses: L1: 0.20087720453739166, L2: 0.025605160742998123, L3: 0.09898966550827026, L4: 0.833775520324707, L5: 0.00868989434093237
Epoch 7000, Loss: 1.2491347789764404, Losses: L1: 0.2001526802778244, L2: 0.025552617385983467, L3: 0.09885787963867188, L4: 0.829802393913269, L5: 0.008687633089721203
Epoch 7500, Loss: 1.2461961507797241, Losses: L1: 0.199534073472023, L2: 0.02556465193629265, L3: 0.09875345230102539, L4: 0.8276989459991455, L5: 0.008673923090100288
Epoch 8000, Loss: 1.2439249753952026, Losses: L1: 0.19891758263111115, L2: 0.025600457563996315, L3: 0.09869801998138428, L4: 0.8261526226997375, L5: 0.008658560924232006
Epoch 8500, Loss: 1.2422617673873901, Losses: L1: 0.19860774278640747, L2: 0.02560087852180004, L3: 0.098655104637146, L4: 0.8248900175094604, L5: 0.008653308264911175
Epoch 9000, Loss: 1.2411220073699951, Losses: L1: 0.19834011793136597, L2: 0.025621507316827774, L3: 0.09861159324645996, L4: 0.8240978121757507, L5: 0.008650057017803192
Epoch 9500, Loss: 1.2402535676956177, Losses: L1: 0.19816777110099792, L2: 0.025627508759498596, L3: 0.09858548641204834, L4: 0.8234544992446899, L5: 0.008646553382277489
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0248517990112305, Constraint losses: L1: 18.42068099975586, L2: 0.0021437297109514475, L3: 1.0021437406539917, L4: 1.0021437406539917
Epoch 500, Loss: 0.002238542539998889, Constraint losses: L1: -1.0997940301895142, L2: 0.0, L3: 0.0026682615280151367, L4: 0.000670075009111315
Epoch 1000, Loss: 0.001318646827712655, Constraint losses: L1: -1.1186013221740723, L2: 0.0, L3: 0.0022183656692504883, L4: 0.0002188825746998191
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0068130493164062, Constraint losses: L1: 7.685376167297363, L2: 3.121420775187289e-07, L3: 0.9995637536048889, L4: 0.999563455581665
Epoch 500, Loss: 0.002268035663291812, Constraint losses: L1: -1.050323486328125, L2: 0.0, L3: 0.002658367156982422, L4: 0.0006599919288419187
Epoch 1000, Loss: 0.0013534286990761757, Constraint losses: L1: -1.0703880786895752, L2: 0.0, L3: 0.002211630344390869, L4: 0.00021218654001131654
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 95.57655334472656, Losses: L1: 18.42068099975586, L2: 0.002574880374595523, L3: 1.0025749206542969, L4: 74.63074493408203, L5: 0.25934743881225586
Epoch 500, Loss: 17.632678985595703, Losses: L1: 4.041010856628418, L2: 1.5732452869415283, L3: 0.23147356510162354, L4: 12.204415321350098, L5: 0.06884181499481201
Epoch 1000, Loss: 10.116357803344727, Losses: L1: 3.431932210922241, L2: 0.19959858059883118, L3: 0.18264281749725342, L4: 6.135605812072754, L5: 0.04186736419796944
Epoch 1500, Loss: 5.590616703033447, Losses: L1: 0.7113945484161377, L2: 0.15527336299419403, L3: 0.09199821949005127, L4: 4.529055118560791, L5: 0.04426686465740204
Epoch 2000, Loss: 3.025247812271118, Losses: L1: 0.33768612146377563, L2: 0.17699840664863586, L3: 0.14449810981750488, L4: 2.275319814682007, L5: 0.017373235896229744
Epoch 2500, Loss: 1.9884189367294312, Losses: L1: 0.12341021001338959, L2: 0.044849686324596405, L3: 0.12290126085281372, L4: 1.5681554079055786, L5: 0.01431301049888134
Epoch 3000, Loss: 1.3841254711151123, Losses: L1: 0.012337390333414078, L2: 0.045503128319978714, L3: 0.09454959630966187, L4: 1.139722466468811, L5: 0.010107413865625858
Epoch 3500, Loss: 1.1893452405929565, Losses: L1: -0.009634220972657204, L2: 0.043357767164707184, L3: 0.09222531318664551, L4: 0.9719460606575012, L5: 0.010451988317072392
Epoch 4000, Loss: 1.102919578552246, Losses: L1: -0.011879908852279186, L2: 0.04072944074869156, L3: 0.09055769443511963, L4: 0.8927055597305298, L5: 0.010306916199624538
Epoch 4500, Loss: 1.0544700622558594, Losses: L1: -0.014652477577328682, L2: 0.03974655643105507, L3: 0.088969886302948, L4: 0.8507034778594971, L5: 0.01030299998819828
Epoch 5000, Loss: 1.0325263738632202, Losses: L1: -0.01579057238996029, L2: 0.0390472412109375, L3: 0.08811628818511963, L4: 0.831916093826294, L5: 0.010322313755750656
Epoch 5500, Loss: 1.020135760307312, Losses: L1: -0.01689639315009117, L2: 0.038372330367565155, L3: 0.08801424503326416, L4: 0.8213540315628052, L5: 0.010231731459498405
Epoch 6000, Loss: 1.011726975440979, Losses: L1: -0.016783269122242928, L2: 0.037723004817962646, L3: 0.08800745010375977, L4: 0.8131200075149536, L5: 0.010256943292915821
Epoch 6500, Loss: 1.0058207511901855, Losses: L1: -0.01606086455285549, L2: 0.03722688928246498, L3: 0.0878828763961792, L4: 0.8069537878036499, L5: 0.010274308733642101
Epoch 7000, Loss: 1.0012547969818115, Losses: L1: -0.01629943586885929, L2: 0.03696976974606514, L3: 0.08773422241210938, L4: 0.8030480146408081, L5: 0.010276409797370434
Epoch 7500, Loss: 0.9983944892883301, Losses: L1: -0.016533169895410538, L2: 0.036781396716833115, L3: 0.08759522438049316, L4: 0.8007681369781494, L5: 0.010289194993674755
Epoch 8000, Loss: 0.9963841438293457, Losses: L1: -0.016666779294610023, L2: 0.03666665405035019, L3: 0.08753257989883423, L4: 0.7990734577178955, L5: 0.010289477184414864
Epoch 8500, Loss: 0.9948889017105103, Losses: L1: -0.016797959804534912, L2: 0.036596380174160004, L3: 0.08748108148574829, L4: 0.7978365421295166, L5: 0.010294985957443714
Epoch 9000, Loss: 0.9939758777618408, Losses: L1: -0.016914673149585724, L2: 0.0365559458732605, L3: 0.08745121955871582, L4: 0.7971305847167969, L5: 0.01028977520763874
Epoch 9500, Loss: 0.99322110414505, Losses: L1: -0.016922341659665108, L2: 0.03652206063270569, L3: 0.08743423223495483, L4: 0.7964301109313965, L5: 0.010291914455592632
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021644353866577, Constraint losses: L1: 18.42068099975586, L2: 0.001074378378689289, L3: 1.0010744333267212, L4: 1.0010749101638794
Epoch 500, Loss: 0.002097303746268153, Constraint losses: L1: -1.1105769872665405, L2: 0.0, L3: 0.00260317325592041, L4: 0.0006047075730748475
Epoch 1000, Loss: 0.0012803428107872605, Constraint losses: L1: -1.1168264150619507, L2: 0.0, L3: 0.0021982789039611816, L4: 0.00019889030954800546
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019622325897217, Constraint losses: L1: 18.42068099975586, L2: 0.00040060366154648364, L3: 1.0004006624221802, L4: 1.0004003047943115
Epoch 500, Loss: 0.0023930624593049288, Constraint losses: L1: -1.0597246885299683, L2: 0.0, L3: 0.0027254819869995117, L4: 0.0007273051887750626
Epoch 1000, Loss: 0.0014077520463615656, Constraint losses: L1: -1.0710856914520264, L2: 0.0, L3: 0.0022391080856323242, L4: 0.0002397296775598079
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 169.01608276367188, Losses: L1: 12.120573043823242, L2: 0.0013275058008730412, L3: 0.9997957944869995, L4: 77.37947082519531, L5: 0.2726214826107025
Epoch 500, Loss: 4.247313022613525, Losses: L1: 2.0320072174072266, L2: 0.2454087883234024, L3: 0.05832648277282715, L4: 0.9814473390579224, L5: 0.026107054203748703
Epoch 1000, Loss: 3.7402546405792236, Losses: L1: 0.8378581404685974, L2: 0.14725688099861145, L3: 0.05579996109008789, L4: 1.3517934083938599, L5: 0.02716248482465744
Epoch 1500, Loss: 1.9190142154693604, Losses: L1: 0.6034071445465088, L2: 0.15555371344089508, L3: 0.06427478790283203, L4: 0.5515382289886475, L5: 0.012408344075083733
Epoch 2000, Loss: 3.0359103679656982, Losses: L1: 0.9376251101493835, L2: 0.10372685641050339, L3: 0.05531930923461914, L4: 0.9600781798362732, L5: 0.03125316649675369
Epoch 2500, Loss: 1.7230627536773682, Losses: L1: 0.39035695791244507, L2: 0.08519785851240158, L3: 0.05086076259613037, L4: 0.5888774991035461, L5: 0.021260729059576988
Epoch 3000, Loss: 0.8228150606155396, Losses: L1: 0.275995671749115, L2: 0.08307857066392899, L3: 0.04708588123321533, L4: 0.2002110779285431, L5: 0.021372290328145027
Epoch 3500, Loss: 0.8688048720359802, Losses: L1: 0.3022235333919525, L2: 0.07956266403198242, L3: 0.04514414072036743, L4: 0.21372725069522858, L5: 0.018114421516656876
Epoch 4000, Loss: 0.711362361907959, Losses: L1: 0.24905289709568024, L2: 0.07454955577850342, L3: 0.04172855615615845, L4: 0.16615429520606995, L5: 0.018537966534495354
Epoch 4500, Loss: 0.6664428114891052, Losses: L1: 0.24353939294815063, L2: 0.07431717216968536, L3: 0.04133403301239014, L4: 0.1471746861934662, L5: 0.01745479926466942
Epoch 5000, Loss: 0.581576943397522, Losses: L1: 0.24319736659526825, L2: 0.07229398190975189, L3: 0.041095197200775146, L4: 0.10556177794933319, L5: 0.01783733256161213
Epoch 5500, Loss: 0.5707566738128662, Losses: L1: 0.24244824051856995, L2: 0.07112186402082443, L3: 0.04094189405441284, L4: 0.10097984969615936, L5: 0.017807919532060623
Epoch 6000, Loss: 0.5636687874794006, Losses: L1: 0.2418212741613388, L2: 0.0704600140452385, L3: 0.04082691669464111, L4: 0.09804240614175797, L5: 0.017757758498191833
Epoch 6500, Loss: 0.558768630027771, Losses: L1: 0.24115905165672302, L2: 0.07015828043222427, L3: 0.04076409339904785, L4: 0.09606589376926422, L5: 0.017740977928042412
Epoch 7000, Loss: 0.5553097128868103, Losses: L1: 0.24076075851917267, L2: 0.06996005773544312, L3: 0.04071402549743652, L4: 0.09463955461978912, L5: 0.017723489552736282
Epoch 7500, Loss: 0.5527773499488831, Losses: L1: 0.24041172862052917, L2: 0.06980916857719421, L3: 0.04068601131439209, L4: 0.09361938387155533, L5: 0.01770051009953022
Epoch 8000, Loss: 0.5510410666465759, Losses: L1: 0.2402685135602951, L2: 0.06973547488451004, L3: 0.040656447410583496, L4: 0.09287548065185547, L5: 0.017681924626231194
Epoch 8500, Loss: 0.5498142242431641, Losses: L1: 0.24009159207344055, L2: 0.06967933475971222, L3: 0.04063832759857178, L4: 0.0923847034573555, L5: 0.01767386868596077
Epoch 9000, Loss: 0.5488886833190918, Losses: L1: 0.24000826478004456, L2: 0.06966951489448547, L3: 0.04062032699584961, L4: 0.09198613464832306, L5: 0.017665352672338486
Epoch 9500, Loss: 0.5483267903327942, Losses: L1: 0.2399311065673828, L2: 0.0696663036942482, L3: 0.04060804843902588, L4: 0.09175853431224823, L5: 0.017658665776252747
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.000974655151367, Constraint losses: L1: 6.000187873840332, L2: 0.0, L3: 0.9974871873855591, L4: 0.9974873661994934
Epoch 500, Loss: 0.0023794351145625114, Constraint losses: L1: -1.090392827987671, L2: 0.0, L3: 0.0027338266372680664, L4: 0.0007360012969002128
Epoch 1000, Loss: 0.0013455424923449755, Constraint losses: L1: -1.117734670639038, L2: 0.0, L3: 0.002231299877166748, L4: 0.0002319773775525391
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022620677947998, Constraint losses: L1: 18.42068099975586, L2: 0.0014001572271808982, L3: 1.001400113105774, L4: 1.0013998746871948
Epoch 500, Loss: 0.0026604977902024984, Constraint losses: L1: -0.8154842853546143, L2: 0.0, L3: 0.002736806869506836, L4: 0.0007391752442345023
Epoch 1000, Loss: 0.0013555714394897223, Constraint losses: L1: -1.0596394538879395, L2: 0.0, L3: 0.0022072196006774902, L4: 0.00020799139747396111
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 177.64817810058594, Losses: L1: 18.325515747070312, L2: 0.0019114474998787045, L3: 1.0019114017486572, L4: 78.51847076416016, L5: 0.2809479832649231
Epoch 500, Loss: 107.57184600830078, Losses: L1: 4.332382678985596, L2: 0.00019712212088052183, L3: 0.9831830859184265, L4: 50.48849105834961, L5: 0.29601553082466125
Epoch 1000, Loss: 33.317726135253906, Losses: L1: 2.723644971847534, L2: 2.944774866104126, L3: 0.21588873863220215, L4: 14.243903160095215, L5: 0.20210975408554077
Epoch 1500, Loss: 13.870336532592773, Losses: L1: 2.4894068241119385, L2: 0.853169322013855, L3: 0.20821362733840942, L4: 5.231313705444336, L5: 0.07529088854789734
Epoch 2000, Loss: 8.699098587036133, Losses: L1: 2.584272623062134, L2: 0.18404218554496765, L3: 0.14120393991470337, L4: 2.8539938926696777, L5: 0.03240938112139702
Epoch 2500, Loss: 6.789381504058838, Losses: L1: 1.355970025062561, L2: 0.03496137633919716, L3: 0.1495668888092041, L4: 2.544959545135498, L5: 0.02687801979482174
Epoch 3000, Loss: 6.274084091186523, Losses: L1: 0.6371932625770569, L2: 0.03376264125108719, L3: 0.1453995704650879, L4: 2.6515090465545654, L5: 0.02619204670190811
Epoch 3500, Loss: 4.789454460144043, Losses: L1: 0.8231059908866882, L2: 0.033328693360090256, L3: 0.13403302431106567, L4: 1.8292912244796753, L5: 0.02303546480834484
Epoch 4000, Loss: 6.989891052246094, Losses: L1: 0.8918691277503967, L2: 0.02723247930407524, L3: 0.1689373254776001, L4: 2.8600211143493652, L5: 0.026488881558179855
Epoch 4500, Loss: 4.762927055358887, Losses: L1: 0.8162345290184021, L2: 0.03619872406125069, L3: 0.12811040878295898, L4: 1.8244658708572388, L5: 0.023440169170498848
Epoch 5000, Loss: 4.688446998596191, Losses: L1: 0.7962149381637573, L2: 0.036869149655103683, L3: 0.12847435474395752, L4: 1.7969645261764526, L5: 0.02291985973715782
Epoch 5500, Loss: 4.654576778411865, Losses: L1: 0.7863036394119263, L2: 0.03713780269026756, L3: 0.1287611722946167, L4: 1.7847543954849243, L5: 0.022673102095723152
Epoch 6000, Loss: 4.632447242736816, Losses: L1: 0.7780595421791077, L2: 0.037349455058574677, L3: 0.1289951205253601, L4: 1.7776074409484863, L5: 0.02250746823847294
Epoch 6500, Loss: 4.616865158081055, Losses: L1: 0.7760482430458069, L2: 0.03747790679335594, L3: 0.12875807285308838, L4: 1.771036148071289, L5: 0.022489437833428383
Epoch 7000, Loss: 4.606227874755859, Losses: L1: 0.774681568145752, L2: 0.03754005581140518, L3: 0.12866973876953125, L4: 1.7664921283721924, L5: 0.022452337667346
Epoch 7500, Loss: 4.598337650299072, Losses: L1: 0.7745413184165955, L2: 0.03759770840406418, L3: 0.12849688529968262, L4: 1.7627694606781006, L5: 0.022464729845523834
Epoch 8000, Loss: 4.592240810394287, Losses: L1: 0.7736133337020874, L2: 0.03762225806713104, L3: 0.12854421138763428, L4: 1.760145902633667, L5: 0.02243616245687008
Epoch 8500, Loss: 4.587817192077637, Losses: L1: 0.7735348343849182, L2: 0.03764041140675545, L3: 0.12847298383712769, L4: 1.758044719696045, L5: 0.022426370531320572
Epoch 9000, Loss: 4.58449125289917, Losses: L1: 0.7735657095909119, L2: 0.0376562774181366, L3: 0.12845081090927124, L4: 1.7563886642456055, L5: 0.022418489679694176
Epoch 9500, Loss: 4.5821027755737305, Losses: L1: 0.773465633392334, L2: 0.037665098905563354, L3: 0.12843191623687744, L4: 1.7552649974822998, L5: 0.02241075597703457
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.02717924118042, Constraint losses: L1: 18.42068099975586, L2: 0.0029193274676799774, L3: 1.002919316291809, L4: 1.0029199123382568
Epoch 500, Loss: 0.0024267337284982204, Constraint losses: L1: -0.9183989763259888, L2: 0.0, L3: 0.002671360969543457, L4: 0.0006737717194482684
Epoch 1000, Loss: 0.001282659824937582, Constraint losses: L1: -1.108020305633545, L2: 0.0, L3: 0.0021949410438537598, L4: 0.0001957390340976417
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.02044677734375, Constraint losses: L1: 18.42068099975586, L2: 0.0006753799389116466, L3: 1.0006753206253052, L4: 1.0006755590438843
Epoch 500, Loss: 0.00233625085093081, Constraint losses: L1: -1.0291985273361206, L2: 0.0, L3: 0.0026817917823791504, L4: 0.0006836575921624899
Epoch 1000, Loss: 0.0013619842939078808, Constraint losses: L1: -1.0713905096054077, L2: 0.0, L3: 0.002216517925262451, L4: 0.0002168569335481152
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 147.862548828125, Losses: L1: 6.351921081542969, L2: 0.0006977436132729053, L3: 0.9948695302009583, L4: 69.5329818725586, L5: 0.2272895872592926
Epoch 500, Loss: 56.835853576660156, Losses: L1: 10.354148864746094, L2: 1.8675519227981567, L3: 0.042154550552368164, L4: 22.493654251098633, L5: 0.23815590143203735
Epoch 1000, Loss: 4.255704879760742, Losses: L1: 1.3100122213363647, L2: 0.09268875420093536, L3: 0.07433348894119263, L4: 1.3163570165634155, L5: 0.05898360535502434
Epoch 1500, Loss: 3.335416793823242, Losses: L1: 0.40486666560173035, L2: 0.03476985916495323, L3: 0.058992087841033936, L4: 1.3483461141586304, L5: 0.04924444481730461
Epoch 2000, Loss: 3.3617587089538574, Losses: L1: 0.8623747229576111, L2: 0.023127812892198563, L3: 0.11245131492614746, L4: 1.116025686264038, L5: 0.015433127991855145
Epoch 2500, Loss: 3.054110288619995, Losses: L1: 0.752777636051178, L2: 0.017575079575181007, L3: 0.08545458316802979, L4: 1.0423928499221802, L5: 0.018425151705741882
Epoch 3000, Loss: 1.8876135349273682, Losses: L1: 0.7230393290519714, L2: 0.034148119390010834, L3: 0.07347750663757324, L4: 0.4893041253089905, L5: 0.010968447662889957
Epoch 3500, Loss: 1.7333894968032837, Losses: L1: 0.681157112121582, L2: 0.03435874730348587, L3: 0.0696181058883667, L4: 0.4359777867794037, L5: 0.011930633336305618
Epoch 4000, Loss: 1.5792350769042969, Losses: L1: 0.6495009064674377, L2: 0.035225436091423035, L3: 0.06669294834136963, L4: 0.37624043226242065, L5: 0.013127348385751247
Epoch 4500, Loss: 1.5174044370651245, Losses: L1: 0.6326122283935547, L2: 0.03704633563756943, L3: 0.0649266242980957, L4: 0.35469064116477966, L5: 0.01351728942245245
Epoch 5000, Loss: 1.4526079893112183, Losses: L1: 0.598495602607727, L2: 0.03715662658214569, L3: 0.06415688991546631, L4: 0.33982664346694946, L5: 0.013783486559987068
Epoch 5500, Loss: 1.4293444156646729, Losses: L1: 0.5969533920288086, L2: 0.037877555936574936, L3: 0.06322324275970459, L4: 0.32942306995391846, L5: 0.014079827815294266
Epoch 6000, Loss: 1.4132088422775269, Losses: L1: 0.5958259105682373, L2: 0.03811243176460266, L3: 0.06278491020202637, L4: 0.3221915364265442, L5: 0.01418691873550415
Epoch 6500, Loss: 1.4028593301773071, Losses: L1: 0.5949772000312805, L2: 0.038179632276296616, L3: 0.06248807907104492, L4: 0.3176267743110657, L5: 0.01428132876753807
Epoch 7000, Loss: 1.3649771213531494, Losses: L1: 0.5624058842658997, L2: 0.03724999725818634, L3: 0.06262242794036865, L4: 0.31502488255500793, L5: 0.01432579942047596
Epoch 7500, Loss: 1.3584656715393066, Losses: L1: 0.5620142817497253, L2: 0.03752714768052101, L3: 0.06229805946350098, L4: 0.31216663122177124, L5: 0.014379232190549374
Epoch 8000, Loss: 1.3532942533493042, Losses: L1: 0.5615212917327881, L2: 0.03767344728112221, L3: 0.06211036443710327, L4: 0.3098992705345154, L5: 0.01445847749710083
Epoch 8500, Loss: 1.3500639200210571, Losses: L1: 0.5613131523132324, L2: 0.0378275029361248, L3: 0.061954379081726074, L4: 0.3084753453731537, L5: 0.014488760381937027
Epoch 9000, Loss: 1.3477047681808472, Losses: L1: 0.5611113905906677, L2: 0.0379248782992363, L3: 0.061855316162109375, L4: 0.3074575662612915, L5: 0.014502573758363724
Epoch 9500, Loss: 1.3462021350860596, Losses: L1: 0.5609639883041382, L2: 0.03797788545489311, L3: 0.061790406703948975, L4: 0.30681276321411133, L5: 0.014521444216370583
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0197913646698, Constraint losses: L1: 18.42068099975586, L2: 0.00045687970123253763, L3: 1.0004569292068481, L4: 1.0004569292068481
Epoch 500, Loss: 0.002390574663877487, Constraint losses: L1: -1.0438106060028076, L2: 0.0, L3: 0.002716064453125, L4: 0.0007183208363130689
Epoch 1000, Loss: 0.0013325173640623689, Constraint losses: L1: -1.1175708770751953, L2: 0.0, L3: 0.0022246241569519043, L4: 0.00022546411491930485
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005286693572998, Constraint losses: L1: 7.015155792236328, L2: 0.0, L3: 0.9991357922554016, L4: 0.9991357326507568
Epoch 500, Loss: 0.002498925430700183, Constraint losses: L1: -1.0578523874282837, L2: 0.0, L3: 0.002777397632598877, L4: 0.0007793802069500089
Epoch 1000, Loss: 0.0014382862718775868, Constraint losses: L1: -1.0715813636779785, L2: 0.0, L3: 0.0022546052932739258, L4: 0.0002552623918745667
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.01856994628906, Losses: L1: 16.233537673950195, L2: 0.00040541947237215936, L3: 1.0003206729888916, L4: 74.31331634521484, L5: 0.25561878085136414
Epoch 500, Loss: 1.707339882850647, Losses: L1: 0.5328359603881836, L2: 0.08073090016841888, L3: 0.068855881690979, L4: 2.099069356918335, L5: 0.019620710983872414
Epoch 1000, Loss: 7.898794651031494, Losses: L1: 4.254496097564697, L2: 0.4000519812107086, L3: 0.2666980028152466, L4: 6.134294509887695, L5: 0.08750039339065552
Epoch 1500, Loss: 4.417660236358643, Losses: L1: 1.4621529579162598, L2: 0.05521966889500618, L3: 0.1536819338798523, L4: 5.606656551361084, L5: 0.04023630917072296
Epoch 2000, Loss: 2.874746084213257, Losses: L1: 0.34749364852905273, L2: 0.046828027814626694, L3: 0.1225818395614624, L4: 4.799833297729492, L5: 0.038433484733104706
Epoch 2500, Loss: 1.8048441410064697, Losses: L1: 0.2559953033924103, L2: 0.027260320261120796, L3: 0.11077284812927246, L4: 2.91397762298584, L5: 0.018426405265927315
Epoch 3000, Loss: 1.378393292427063, Losses: L1: 0.22546841204166412, L2: 0.029384169727563858, L3: 0.12064504623413086, L4: 2.107577323913574, L5: 0.018859241157770157
Epoch 3500, Loss: 1.092258095741272, Losses: L1: 0.22084254026412964, L2: 0.029502058401703835, L3: 0.11641240119934082, L4: 1.5495920181274414, L5: 0.017822442576289177
Epoch 4000, Loss: 1.021885633468628, Losses: L1: 0.18987445533275604, L2: 0.029439354315400124, L3: 0.11010968685150146, L4: 1.4762234687805176, L5: 0.018810423091053963
Epoch 4500, Loss: 0.9839726090431213, Losses: L1: 0.17978540062904358, L2: 0.03022916242480278, L3: 0.10641610622406006, L4: 1.4226760864257812, L5: 0.018823852762579918
Epoch 5000, Loss: 0.9613449573516846, Losses: L1: 0.178039088845253, L2: 0.0310885738581419, L3: 0.10529053211212158, L4: 1.380241870880127, L5: 0.018902212381362915
Epoch 5500, Loss: 0.9458522796630859, Losses: L1: 0.17764799296855927, L2: 0.031548094004392624, L3: 0.1046176552772522, L4: 1.3497501611709595, L5: 0.018944494426250458
Epoch 6000, Loss: 0.9343432784080505, Losses: L1: 0.17649781703948975, L2: 0.03177923336625099, L3: 0.10432147979736328, L4: 1.3286821842193604, L5: 0.01912875846028328
Epoch 6500, Loss: 0.9249368906021118, Losses: L1: 0.1764359027147293, L2: 0.032086677849292755, L3: 0.10392403602600098, L4: 1.3097456693649292, L5: 0.01915886253118515
Epoch 7000, Loss: 0.9185348749160767, Losses: L1: 0.17641910910606384, L2: 0.032261572778224945, L3: 0.10368484258651733, L4: 1.296832799911499, L5: 0.019190801307559013
Epoch 7500, Loss: 0.9139994978904724, Losses: L1: 0.17659397423267365, L2: 0.03237015753984451, L3: 0.10344445705413818, L4: 1.2873873710632324, L5: 0.019238799810409546
Epoch 8000, Loss: 0.9107947945594788, Losses: L1: 0.1762799471616745, L2: 0.032440055161714554, L3: 0.10336494445800781, L4: 1.2815186977386475, L5: 0.019266054034233093
Epoch 8500, Loss: 0.9084042310714722, Losses: L1: 0.1762842833995819, L2: 0.032519225031137466, L3: 0.10327351093292236, L4: 1.2766520977020264, L5: 0.019275914877653122
Epoch 9000, Loss: 0.9068471193313599, Losses: L1: 0.17623843252658844, L2: 0.03256084397435188, L3: 0.1032213568687439, L4: 1.2735885381698608, L5: 0.0192857775837183
Epoch 9500, Loss: 0.9057929515838623, Losses: L1: 0.1762939989566803, L2: 0.03258724510669708, L3: 0.10315370559692383, L4: 1.271372675895691, L5: 0.01929696835577488
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9993681907653809, Constraint losses: L1: 5.715507507324219, L2: 0.0, L3: 0.9968265891075134, L4: 0.9968260526657104
Epoch 500, Loss: 0.0020779091864824295, Constraint losses: L1: -1.0982844829559326, L2: 0.0, L3: 0.0025873780250549316, L4: 0.0005888156592845917
Epoch 1000, Loss: 0.0012600785121321678, Constraint losses: L1: -1.1181509494781494, L2: 0.0, L3: 0.0021889209747314453, L4: 0.0001893086009658873
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.023049831390381, Constraint losses: L1: 18.42068099975586, L2: 0.0015429341001436114, L3: 1.0015429258346558, L4: 1.0015431642532349
Epoch 500, Loss: 0.002232635160908103, Constraint losses: L1: -1.068164348602295, L2: 0.0, L3: 0.002649664878845215, L4: 0.0006511345854960382
Epoch 1000, Loss: 0.0013561579398810863, Constraint losses: L1: -1.0708868503570557, L2: 0.0, L3: 0.0022133588790893555, L4: 0.0002136858820449561
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.600807189941406, Losses: L1: 5.259503364562988, L2: 0.0, L3: 0.9953252077102661, L4: 81.0892333984375, L5: 0.29902541637420654
Epoch 500, Loss: 6.365224361419678, Losses: L1: 1.497374415397644, L2: 0.37091347575187683, L3: 0.1582019329071045, L4: 8.69439697265625, L5: 0.070637047290802
Epoch 1000, Loss: 1.8622182607650757, Losses: L1: 0.3142373859882355, L2: 0.03351554647088051, L3: 0.1298622488975525, L4: 2.8462448120117188, L5: 0.026411794126033783
Epoch 1500, Loss: 1.0037879943847656, Losses: L1: 0.0785771980881691, L2: 0.014649436809122562, L3: 0.10532999038696289, L4: 1.6792669296264648, L5: 0.01826280727982521
Epoch 2000, Loss: 2.3096840381622314, Losses: L1: 0.3751440942287445, L2: 0.03372781723737717, L3: 0.17969584465026855, L4: 3.5591163635253906, L5: 0.03140592575073242
Epoch 2500, Loss: 0.8135335445404053, Losses: L1: 0.04807625710964203, L2: 0.019164690747857094, L3: 0.10940569639205933, L4: 1.362445592880249, L5: 0.010366953909397125
Epoch 3000, Loss: 0.5622612237930298, Losses: L1: 0.05395872890949249, L2: 0.021643517538905144, L3: 0.09793710708618164, L4: 0.8557883501052856, L5: 0.00979626551270485
Epoch 3500, Loss: 0.5209667086601257, Losses: L1: 0.04570502042770386, L2: 0.02063903957605362, L3: 0.09265774488449097, L4: 0.7974810600280762, L5: 0.0095532750710845
Epoch 4000, Loss: 0.4556064009666443, Losses: L1: 0.040472619235515594, L2: 0.020022839307785034, L3: 0.08903169631958008, L4: 0.6803163886070251, L5: 0.010436898097395897
Epoch 4500, Loss: 0.41660892963409424, Losses: L1: 0.03240333870053291, L2: 0.02003652974963188, L3: 0.08799797296524048, L4: 0.619853675365448, L5: 0.010243231430649757
Epoch 5000, Loss: 0.3985191583633423, Losses: L1: 0.028673434630036354, L2: 0.020094100385904312, L3: 0.08712351322174072, L4: 0.5919861197471619, L5: 0.010196791961789131
Epoch 5500, Loss: 0.3921877145767212, Losses: L1: 0.025575531646609306, L2: 0.020124167203903198, L3: 0.0866590142250061, L4: 0.585988461971283, L5: 0.010164270177483559
Epoch 6000, Loss: 0.38753774762153625, Losses: L1: 0.023110901936888695, L2: 0.020295782014727592, L3: 0.08632099628448486, L4: 0.5814648270606995, L5: 0.010238144546747208
Epoch 6500, Loss: 0.3842099905014038, Losses: L1: 0.021393710747361183, L2: 0.020346051082015038, L3: 0.08611863851547241, L4: 0.5783509612083435, L5: 0.0102354371920228
Epoch 7000, Loss: 0.38142600655555725, Losses: L1: 0.020099187269806862, L2: 0.02039702981710434, L3: 0.08600002527236938, L4: 0.5754075050354004, L5: 0.010226035490632057
Epoch 7500, Loss: 0.3796261250972748, Losses: L1: 0.01917160116136074, L2: 0.020430879667401314, L3: 0.08590269088745117, L4: 0.573697566986084, L5: 0.01022349763661623
Epoch 8000, Loss: 0.3782826364040375, Losses: L1: 0.01858215406537056, L2: 0.0204475075006485, L3: 0.0858074426651001, L4: 0.5722517371177673, L5: 0.010223401710391045
Epoch 8500, Loss: 0.37728023529052734, Losses: L1: 0.018136726692318916, L2: 0.020464306697249413, L3: 0.08574128150939941, L4: 0.571161150932312, L5: 0.010227970778942108
Epoch 9000, Loss: 0.3765326142311096, Losses: L1: 0.01780378259718418, L2: 0.020488999783992767, L3: 0.08569186925888062, L4: 0.5703284740447998, L5: 0.010229636915028095
Epoch 9500, Loss: 0.37599217891693115, Losses: L1: 0.017558030784130096, L2: 0.02050488442182541, L3: 0.08565104007720947, L4: 0.5697505474090576, L5: 0.010228445753455162
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0432796478271484, Constraint losses: L1: 18.42068099975586, L2: 0.008285940624773502, L3: 1.0082859992980957, L4: 1.008286952972412
Epoch 500, Loss: 0.0023027234710752964, Constraint losses: L1: -1.0480886697769165, L2: 0.0, L3: 0.002674400806427002, L4: 0.0006764113204553723
Epoch 1000, Loss: 0.0013044257648289204, Constraint losses: L1: -1.11808180809021, L2: 0.0, L3: 0.0022110342979431152, L4: 0.0002114733069902286
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.00807785987854, Constraint losses: L1: 8.452082633972168, L2: 2.5334390585385336e-08, L3: 0.99981290102005, L4: 0.9998128414154053
Epoch 500, Loss: 0.0025047347880899906, Constraint losses: L1: -1.0594675540924072, L2: 0.0, L3: 0.0027812719345092773, L4: 0.0007829305250197649
Epoch 1000, Loss: 0.0014525142032653093, Constraint losses: L1: -1.0706528425216675, L2: 0.0, L3: 0.0022612810134887695, L4: 0.0002618859871290624
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 50.02350616455078, Losses: L1: 6.253229141235352, L2: 0.0, L3: 0.9979251623153687, L4: 85.25456237792969, L5: 0.32201752066612244
Epoch 500, Loss: 11.822392463684082, Losses: L1: 3.359020233154297, L2: 0.43719470500946045, L3: 0.37778252363204956, L4: 15.269837379455566, L5: 0.10118409991264343
Epoch 1000, Loss: 2.35400390625, Losses: L1: 0.4001635015010834, L2: 0.03908267617225647, L3: 0.16968345642089844, L4: 3.561263084411621, L5: 0.024642260745167732
Epoch 1500, Loss: 1.7378231287002563, Losses: L1: 0.19153796136379242, L2: 0.04806625470519066, L3: 0.1494741439819336, L4: 2.7610154151916504, L5: 0.0214870423078537
Epoch 2000, Loss: 1.4436461925506592, Losses: L1: 0.13427352905273438, L2: 0.04803167283535004, L3: 0.1434076428413391, L4: 2.309147834777832, L5: 0.017531637102365494
Epoch 2500, Loss: 1.299059271812439, Losses: L1: 0.06841237097978592, L2: 0.053114134818315506, L3: 0.14102518558502197, L4: 2.154649019241333, L5: 0.01484780665487051
Epoch 3000, Loss: 1.2117319107055664, Losses: L1: 0.06255325675010681, L2: 0.05197836086153984, L3: 0.1336427927017212, L4: 1.9972001314163208, L5: 0.01588943414390087
Epoch 3500, Loss: 1.1063990592956543, Losses: L1: 0.04220674932003021, L2: 0.04103422909975052, L3: 0.13103985786437988, L4: 1.8537882566452026, L5: 0.015372010879218578
Epoch 4000, Loss: 1.0505964756011963, Losses: L1: 0.028446942567825317, L2: 0.044392503798007965, L3: 0.12896496057510376, L4: 1.7665989398956299, L5: 0.01498755719512701
Epoch 4500, Loss: 1.0137132406234741, Losses: L1: 0.02029106207191944, L2: 0.04760446771979332, L3: 0.1272692084312439, L4: 1.7051405906677246, L5: 0.014806368388235569
Epoch 5000, Loss: 0.9884279370307922, Losses: L1: 0.01639149896800518, L2: 0.04921135678887367, L3: 0.12647831439971924, L4: 1.6605333089828491, L5: 0.014659653417766094
Epoch 5500, Loss: 0.9701548218727112, Losses: L1: 0.013439777307212353, L2: 0.05010068044066429, L3: 0.12570500373840332, L4: 1.6296652555465698, L5: 0.01446462981402874
Epoch 6000, Loss: 0.9568789005279541, Losses: L1: 0.012269898317754269, L2: 0.05054011195898056, L3: 0.12504547834396362, L4: 1.6051757335662842, L5: 0.014479164965450764
Epoch 6500, Loss: 0.9468377232551575, Losses: L1: 0.010756783187389374, L2: 0.050851549953222275, L3: 0.1246764063835144, L4: 1.5880547761917114, L5: 0.014431893825531006
Epoch 7000, Loss: 0.9393258094787598, Losses: L1: 0.01005318108946085, L2: 0.050839006900787354, L3: 0.12446069717407227, L4: 1.5747742652893066, L5: 0.014408080838620663
Epoch 7500, Loss: 0.9338311553001404, Losses: L1: 0.00919530913233757, L2: 0.05083734169602394, L3: 0.1241910457611084, L4: 1.5657254457473755, L5: 0.014420113526284695
Epoch 8000, Loss: 0.9297900795936584, Losses: L1: 0.008477865718305111, L2: 0.05085201933979988, L3: 0.12404239177703857, L4: 1.5592021942138672, L5: 0.014418966136872768
Epoch 8500, Loss: 0.92673259973526, Losses: L1: 0.007941283285617828, L2: 0.050800077617168427, L3: 0.12400448322296143, L4: 1.5543959140777588, L5: 0.014395511709153652
Epoch 9000, Loss: 0.9246584177017212, Losses: L1: 0.007635371293872595, L2: 0.050770580768585205, L3: 0.12397658824920654, L4: 1.5510191917419434, L5: 0.014377295970916748
Epoch 9500, Loss: 0.9232133030891418, Losses: L1: 0.007389809936285019, L2: 0.05076294392347336, L3: 0.12394165992736816, L4: 1.5487154722213745, L5: 0.014365999959409237
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0334396362304688, Constraint losses: L1: 18.42068099975586, L2: 0.005005960818380117, L3: 1.005005955696106, L4: 1.0050069093704224
Epoch 500, Loss: 0.002077831421047449, Constraint losses: L1: -1.0974483489990234, L2: 0.0, L3: 0.002586841583251953, L4: 0.0005884383572265506
Epoch 1000, Loss: 0.0012619238113984466, Constraint losses: L1: -1.1184065341949463, L2: 0.0, L3: 0.0021898746490478516, L4: 0.00019045567023567855
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001560688018799, Constraint losses: L1: 6.075568199157715, L2: 0.0, L3: 0.9977426528930664, L4: 0.9977425336837769
Epoch 500, Loss: 0.002192203886806965, Constraint losses: L1: -1.059409499168396, L2: 0.0, L3: 0.0026250481605529785, L4: 0.0006265653646551073
Epoch 1000, Loss: 0.001340795191936195, Constraint losses: L1: -1.0710551738739014, L2: 0.0, L3: 0.00220566987991333, L4: 0.0002061805280391127
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 78.07453918457031, Losses: L1: 5.512925624847412, L2: 0.0, L3: 0.9953774213790894, L4: 71.94264221191406, L5: 0.2425672858953476
Epoch 500, Loss: 5.87753963470459, Losses: L1: 1.3973054885864258, L2: 0.10004085302352905, L3: 0.052596867084503174, L4: 4.336726188659668, L5: 0.03433670103549957
Epoch 1000, Loss: 51.96998977661133, Losses: L1: 5.441835403442383, L2: 0.09940595179796219, L3: 0.9878568053245544, L4: 45.82917785644531, L5: 0.2112828493118286
Epoch 1500, Loss: 28.808347702026367, Losses: L1: 4.6896653175354, L2: 1.6821651458740234, L3: 0.4687774181365967, L4: 22.13350486755371, L5: 0.13725025951862335
Epoch 2000, Loss: 10.358733177185059, Losses: L1: 2.154165744781494, L2: 0.427573025226593, L3: 0.2702733278274536, L4: 7.598400115966797, L5: 0.0869150459766388
Epoch 2500, Loss: 7.837891101837158, Losses: L1: 1.7870725393295288, L2: 0.10963501036167145, L3: 0.2609211206436157, L4: 5.780762672424316, L5: 0.05992025136947632
Epoch 3000, Loss: 50.08973693847656, Losses: L1: 3.0773732662200928, L2: 0.182271808385849, L3: 0.9079451560974121, L4: 46.2781982421875, L5: 0.19583606719970703
Epoch 3500, Loss: 12.819587707519531, Losses: L1: 4.894048690795898, L2: 0.06537754833698273, L3: 0.23949068784713745, L4: 7.710332870483398, L5: 0.06016520410776138
Epoch 4000, Loss: 6.889383316040039, Losses: L1: 1.2144041061401367, L2: 0.055658359080553055, L3: 0.2436511516571045, L4: 5.471756458282471, L5: 0.05147767812013626
Epoch 4500, Loss: 6.3126678466796875, Losses: L1: 1.2580082416534424, L2: 0.05844154953956604, L3: 0.24201172590255737, L4: 4.850275039672852, L5: 0.04987433925271034
Epoch 5000, Loss: 5.830882549285889, Losses: L1: 1.1990100145339966, L2: 0.04753996804356575, L3: 0.22900080680847168, L4: 4.444888114929199, L5: 0.049888089299201965
Epoch 5500, Loss: 21.452173233032227, Losses: L1: 0.7669156789779663, L2: 0.013827133923768997, L3: 0.33632922172546387, L4: 20.42339515686035, L5: 0.1597418338060379
Epoch 6000, Loss: 5.354669094085693, Losses: L1: 0.9164673686027527, L2: 0.032982293516397476, L3: 0.22028934955596924, L4: 4.271096706390381, L5: 0.047955963760614395
Epoch 6500, Loss: 5.280930519104004, Losses: L1: 0.926561713218689, L2: 0.03143071383237839, L3: 0.22281384468078613, L4: 4.187851905822754, L5: 0.04735897108912468
Epoch 7000, Loss: 5.24653434753418, Losses: L1: 0.933122456073761, L2: 0.03068915568292141, L3: 0.2231307029724121, L4: 4.14745569229126, L5: 0.04740378260612488
Epoch 7500, Loss: 5.222808837890625, Losses: L1: 0.936492383480072, L2: 0.03033408150076866, L3: 0.22304213047027588, L4: 4.120751857757568, L5: 0.047418706119060516
Epoch 8000, Loss: 5.205334663391113, Losses: L1: 0.9386007189750671, L2: 0.03010210581123829, L3: 0.2230718731880188, L4: 4.101400375366211, L5: 0.04739052802324295
Epoch 8500, Loss: 5.192416191101074, Losses: L1: 0.9398972988128662, L2: 0.029942573979496956, L3: 0.223097026348114, L4: 4.087347984313965, L5: 0.0473596416413784
Epoch 9000, Loss: 5.182919502258301, Losses: L1: 0.9406625032424927, L2: 0.029830846935510635, L3: 0.22308677434921265, L4: 4.077214241027832, L5: 0.04733685776591301
Epoch 9500, Loss: 5.175967216491699, Losses: L1: 0.9411922693252563, L2: 0.029757225885987282, L3: 0.2230970859527588, L4: 4.069813251495361, L5: 0.04731158912181854
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020289421081543, Constraint losses: L1: 18.42068099975586, L2: 0.0006373815704137087, L3: 1.0006154775619507, L4: 1.0006157159805298
Epoch 500, Loss: 0.0024030953645706177, Constraint losses: L1: -1.0127239227294922, L2: 0.0, L3: 0.002706766128540039, L4: 0.0007090531289577484
Epoch 1000, Loss: 0.0013018730096518993, Constraint losses: L1: -1.1174488067626953, L2: 0.0, L3: 0.0022093653678894043, L4: 0.00020995648810639977
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.003255605697632, Constraint losses: L1: 6.404909610748291, L2: 0.0, L3: 0.9984254837036133, L4: 0.9984251856803894
Epoch 500, Loss: 0.0027817212976515293, Constraint losses: L1: -0.8630018830299377, L2: 0.0, L3: 0.0028210878372192383, L4: 0.0008236353751271963
Epoch 1000, Loss: 0.0014163405867293477, Constraint losses: L1: -1.067044734954834, L2: 0.0, L3: 0.002241373062133789, L4: 0.00024201229098252952
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 95.93092346191406, Losses: L1: 18.228540420532227, L2: 0.0029301620088517666, L3: 1.0028064250946045, L4: 76.92564392089844, L5: 0.272409588098526
Epoch 500, Loss: 4.289496421813965, Losses: L1: 1.1665667295455933, L2: 0.07464904338121414, L3: 0.09587085247039795, L4: 2.971332311630249, L5: 0.02901271916925907
Epoch 1000, Loss: 3.407811164855957, Losses: L1: 0.37237751483917236, L2: 0.09058018773794174, L3: 0.12569332122802734, L4: 2.8495962619781494, L5: 0.03241069242358208
Epoch 1500, Loss: 17.273149490356445, Losses: L1: 7.25969934463501, L2: 0.38961073756217957, L3: 0.2525888681411743, L4: 9.405439376831055, L5: 0.09210539609193802
Epoch 2000, Loss: 10.519636154174805, Losses: L1: 5.59808874130249, L2: 0.31033679842948914, L3: 0.2456573247909546, L4: 4.35288667678833, L5: 0.13549646735191345
Epoch 2500, Loss: 8.715371131896973, Losses: L1: 5.0368170738220215, L2: 0.31255918741226196, L3: 0.23023343086242676, L4: 3.1140122413635254, L5: 0.13686691224575043
Epoch 3000, Loss: 55.44152069091797, Losses: L1: 5.177138805389404, L2: 0.0, L3: 0.9659029841423035, L4: 49.4781494140625, L5: 0.3032814562320709
Epoch 3500, Loss: 28.700645446777344, Losses: L1: 2.0983433723449707, L2: 0.013883945532143116, L3: 0.3742404580116272, L4: 26.17376708984375, L5: 0.22753123939037323
Epoch 4000, Loss: 7.646792411804199, Losses: L1: 3.830580711364746, L2: 0.15857064723968506, L3: 0.21771490573883057, L4: 3.4421982765197754, L5: 0.10658495873212814
Epoch 4500, Loss: 7.239165306091309, Losses: L1: 3.8256587982177734, L2: 0.15379872918128967, L3: 0.20438611507415771, L4: 3.047961473464966, L5: 0.10955355316400528
Epoch 5000, Loss: 6.879283905029297, Losses: L1: 3.588627815246582, L2: 0.1436982899904251, L3: 0.19486981630325317, L4: 2.9399285316467285, L5: 0.10959447920322418
Epoch 5500, Loss: 6.648386478424072, Losses: L1: 3.4618842601776123, L2: 0.13643832504749298, L3: 0.18908941745758057, L4: 2.8469741344451904, L5: 0.10854485630989075
Epoch 6000, Loss: 6.538971900939941, Losses: L1: 3.443427324295044, L2: 0.132013738155365, L3: 0.18564170598983765, L4: 2.7631773948669434, L5: 0.10753234475851059
Epoch 6500, Loss: 6.438844680786133, Losses: L1: 3.4061617851257324, L2: 0.1282787173986435, L3: 0.18369054794311523, L4: 2.7065927982330322, L5: 0.10596594959497452
Epoch 7000, Loss: 6.3934736251831055, Losses: L1: 3.413156509399414, L2: 0.12571950256824493, L3: 0.18103379011154175, L4: 2.658278226852417, L5: 0.1058025136590004
Epoch 7500, Loss: 6.36422061920166, Losses: L1: 3.418133020401001, L2: 0.12440647929906845, L3: 0.17867416143417358, L4: 2.6265206336975098, L5: 0.10582350939512253
Epoch 8000, Loss: 6.343125820159912, Losses: L1: 3.421377182006836, L2: 0.12342729419469833, L3: 0.1769426465034485, L4: 2.6039721965789795, L5: 0.10587760806083679
Epoch 8500, Loss: 6.327932834625244, Losses: L1: 3.422792434692383, L2: 0.12261959910392761, L3: 0.1759563684463501, L4: 2.588731050491333, L5: 0.10581161826848984
Epoch 9000, Loss: 6.276761054992676, Losses: L1: 3.375596284866333, L2: 0.12059064954519272, L3: 0.17615896463394165, L4: 2.5869410037994385, L5: 0.10555370897054672
Epoch 9500, Loss: 6.264562129974365, Losses: L1: 3.3740150928497314, L2: 0.12068876624107361, L3: 0.17528778314590454, L4: 2.57684326171875, L5: 0.1053708866238594
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0006914138793945, Constraint losses: L1: 5.875817775726318, L2: 0.0, L3: 0.9974082112312317, L4: 0.9974073171615601
Epoch 500, Loss: 0.0023172851651906967, Constraint losses: L1: -1.0606797933578491, L2: 0.0, L3: 0.002687990665435791, L4: 0.0006899742875248194
Epoch 1000, Loss: 0.0013181314570829272, Constraint losses: L1: -1.1182012557983398, L2: 0.0, L3: 0.0022178292274475098, L4: 0.00021850351186003536
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0240519046783447, Constraint losses: L1: 18.42068099975586, L2: 0.0018768272129818797, L3: 1.0018768310546875, L4: 1.0018775463104248
Epoch 500, Loss: 0.001984019298106432, Constraint losses: L1: -1.0665334463119507, L2: 0.0, L3: 0.0025246739387512207, L4: 0.0005258789169602096
Epoch 1000, Loss: 0.0012736044591292739, Constraint losses: L1: -1.0716431140899658, L2: 0.0, L3: 0.002172410488128662, L4: 0.00017283714259974658
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 103.58617401123047, Losses: L1: 18.42068099975586, L2: 0.006253835745155811, L3: 1.0062538385391235, L4: 84.02481842041016, L5: 0.31564873456954956
Epoch 500, Loss: 30.9457950592041, Losses: L1: 4.232088088989258, L2: 0.8412286043167114, L3: 0.602733850479126, L4: 25.362773895263672, L5: 0.10416912287473679
Epoch 1000, Loss: 20.131603240966797, Losses: L1: 2.7059590816497803, L2: 0.8653644323348999, L3: 0.41930997371673584, L4: 16.177085876464844, L5: 0.08676937967538834
Epoch 1500, Loss: 14.322489738464355, Losses: L1: 1.4838911294937134, L2: 0.2466578483581543, L3: 0.35608041286468506, L4: 12.29804801940918, L5: 0.057926006615161896
Epoch 2000, Loss: 13.49824333190918, Losses: L1: 1.881278157234192, L2: 0.14691998064517975, L3: 0.33042359352111816, L4: 11.173681259155273, L5: 0.06557609885931015
Epoch 2500, Loss: 10.378339767456055, Losses: L1: 1.1125648021697998, L2: 0.0573558583855629, L3: 0.3258032202720642, L4: 8.952043533325195, L5: 0.04673667624592781
Epoch 3000, Loss: 9.568122863769531, Losses: L1: 1.1426026821136475, L2: 0.046110332012176514, L3: 0.3057234287261963, L4: 8.129615783691406, L5: 0.048466045409440994
Epoch 3500, Loss: 8.910274505615234, Losses: L1: 0.9771606922149658, L2: 0.04924735054373741, L3: 0.3027839660644531, L4: 7.637986660003662, L5: 0.04724419116973877
Epoch 4000, Loss: 8.575031280517578, Losses: L1: 0.9951992630958557, L2: 0.04580652341246605, L3: 0.29624664783477783, L4: 7.290432929992676, L5: 0.04773467034101486
Epoch 4500, Loss: 8.344117164611816, Losses: L1: 0.9795364737510681, L2: 0.04668905586004257, L3: 0.29194939136505127, L4: 7.077844619750977, L5: 0.04703598469495773
Epoch 5000, Loss: 8.172163009643555, Losses: L1: 0.9560922980308533, L2: 0.04723254218697548, L3: 0.2875547409057617, L4: 6.931243896484375, L5: 0.046908196061849594
Epoch 5500, Loss: 8.028682708740234, Losses: L1: 0.9125565886497498, L2: 0.04667315632104874, L3: 0.2832583785057068, L4: 6.833854675292969, L5: 0.0469847172498703
Epoch 6000, Loss: 7.943767547607422, Losses: L1: 0.9356699585914612, L2: 0.04176739975810051, L3: 0.2783428430557251, L4: 6.731635093688965, L5: 0.047761835157871246
Epoch 6500, Loss: 7.86203670501709, Losses: L1: 0.8892650604248047, L2: 0.04187915101647377, L3: 0.2714361548423767, L4: 6.700222969055176, L5: 0.04747588932514191
Epoch 7000, Loss: 7.808401107788086, Losses: L1: 0.8717811703681946, L2: 0.0419955737888813, L3: 0.26681602001190186, L4: 6.666572570800781, L5: 0.04732178896665573
Epoch 7500, Loss: 7.770132541656494, Losses: L1: 0.8666256666183472, L2: 0.04206664860248566, L3: 0.2647864818572998, L4: 6.634500026702881, L5: 0.04727345332503319
Epoch 8000, Loss: 7.741576194763184, Losses: L1: 0.8647826910018921, L2: 0.04209979251027107, L3: 0.26380884647369385, L4: 6.608288288116455, L5: 0.04725043103098869
Epoch 8500, Loss: 7.720393657684326, Losses: L1: 0.8635556101799011, L2: 0.04209516942501068, L3: 0.26324474811553955, L4: 6.588624000549316, L5: 0.04724816605448723
Epoch 9000, Loss: 7.705007553100586, Losses: L1: 0.8631958961486816, L2: 0.04211081564426422, L3: 0.2628439664840698, L4: 6.573790550231934, L5: 0.04724418744444847
Epoch 9500, Loss: 7.693899631500244, Losses: L1: 0.8632134199142456, L2: 0.04213513806462288, L3: 0.26254504919052124, L4: 6.562797546386719, L5: 0.047240398824214935
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.046992063522339, Constraint losses: L1: 18.42068099975586, L2: 0.009523183107376099, L3: 1.0095231533050537, L4: 1.0095250606536865
Epoch 500, Loss: 0.0023138292599469423, Constraint losses: L1: -1.0771616697311401, L2: 0.0, L3: 0.0026944875717163086, L4: 0.000696503440849483
Epoch 1000, Loss: 0.0013225062284618616, Constraint losses: L1: -1.1173820495605469, L2: 0.0, L3: 0.002219676971435547, L4: 0.0002202112809754908
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.994385004043579, Constraint losses: L1: 5.17410945892334, L2: 0.0, L3: 0.9946060180664062, L4: 0.9946048259735107
Epoch 500, Loss: 0.002266904804855585, Constraint losses: L1: -1.0130237340927124, L2: 0.0, L3: 0.00263899564743042, L4: 0.0006409329362213612
Epoch 1000, Loss: 0.0013302182778716087, Constraint losses: L1: -1.070398211479187, L2: 0.0, L3: 0.002200007438659668, L4: 0.00020060903625562787
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 153.3866729736328, Losses: L1: 9.29580307006836, L2: 0.0005516785313375294, L3: 0.9994626641273499, L4: 71.73515319824219, L5: 0.24058465659618378
Epoch 500, Loss: 11.558831214904785, Losses: L1: 3.1743829250335693, L2: 0.4247753918170929, L3: 0.1555677056312561, L4: 3.9279065132141113, L5: 0.0521521121263504
Epoch 1000, Loss: 319.2655334472656, Losses: L1: 18.4200439453125, L2: 1.6707715397822065e-13, L3: 1.0, L4: 149.99896240234375, L5: 0.6951454877853394
Epoch 1500, Loss: 319.2646789550781, Losses: L1: 18.419214248657227, L2: 2.3201411495157864e-13, L3: 1.0, L4: 149.9989471435547, L5: 0.6951453685760498
Epoch 2000, Loss: 319.2472229003906, Losses: L1: 18.40180778503418, L2: 3.262176770033043e-13, L3: 1.0, L4: 149.99893188476562, L5: 0.695145308971405
Epoch 2500, Loss: 309.96063232421875, Losses: L1: 9.142145156860352, L2: 0.00023917409998830408, L3: 0.9998853802680969, L4: 149.98538208007812, L5: 0.6950827240943909
Epoch 3000, Loss: 301.59521484375, Losses: L1: 4.246973037719727, L2: 0.006164828315377235, L3: 0.9893214106559753, L4: 148.2520294189453, L5: 0.6867145299911499
Epoch 3500, Loss: 17.44256019592285, Losses: L1: 0.8876512050628662, L2: 0.16628064215183258, L3: 0.29405999183654785, L4: 8.107792854309082, L5: 0.05202401056885719
Epoch 4000, Loss: 8.16175651550293, Losses: L1: 0.9542120695114136, L2: 0.0580768845975399, L3: 0.19373011589050293, L4: 3.5182266235351562, L5: 0.032299164682626724
Epoch 4500, Loss: 6.333779811859131, Losses: L1: 1.0834497213363647, L2: 0.05497799068689346, L3: 0.17069482803344727, L4: 2.5466501712799072, L5: 0.03340854123234749
Epoch 5000, Loss: 5.664366245269775, Losses: L1: 1.0848591327667236, L2: 0.0586978979408741, L3: 0.16013354063034058, L4: 2.2122702598571777, L5: 0.03240400180220604
Epoch 5500, Loss: 5.387045383453369, Losses: L1: 1.051898717880249, L2: 0.058975353837013245, L3: 0.15592390298843384, L4: 2.0911858081817627, L5: 0.03167504817247391
Epoch 6000, Loss: 5.25394868850708, Losses: L1: 1.0433228015899658, L2: 0.0592307485640049, L3: 0.15381956100463867, L4: 2.0293877124786377, L5: 0.031420208513736725
Epoch 6500, Loss: 5.165396690368652, Losses: L1: 1.0399900674819946, L2: 0.059762101620435715, L3: 0.1521207094192505, L4: 1.9869575500488281, L5: 0.03133799135684967
Epoch 7000, Loss: 5.104152202606201, Losses: L1: 1.0370630025863647, L2: 0.06006661802530289, L3: 0.15109014511108398, L4: 1.9579188823699951, L5: 0.03127923607826233
Epoch 7500, Loss: 5.0561981201171875, Losses: L1: 1.0205144882202148, L2: 0.05935905501246452, L3: 0.15108346939086914, L4: 1.9426568746566772, L5: 0.030938347801566124
Epoch 8000, Loss: 5.0238494873046875, Losses: L1: 1.013092041015625, L2: 0.05913450941443443, L3: 0.15090316534042358, L4: 1.9304066896438599, L5: 0.030716173350811005
Epoch 8500, Loss: 5.000966548919678, Losses: L1: 1.0080183744430542, L2: 0.05900997295975685, L3: 0.15073907375335693, L4: 1.921642541885376, L5: 0.030567171052098274
Epoch 9000, Loss: 4.984897136688232, Losses: L1: 1.0043202638626099, L2: 0.05894213542342186, L3: 0.15062487125396729, L4: 1.915543794631958, L5: 0.030469244346022606
Epoch 9500, Loss: 4.973823547363281, Losses: L1: 1.001841425895691, L2: 0.05889864265918732, L3: 0.15055596828460693, L4: 1.9113028049468994, L5: 0.030398936942219734
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.000241279602051, Constraint losses: L1: 5.846595764160156, L2: 0.0, L3: 0.9971975684165955, L4: 0.997197151184082
Epoch 500, Loss: 0.0019660377874970436, Constraint losses: L1: -1.1020901203155518, L2: 0.0, L3: 0.002533257007598877, L4: 0.0005348707782104611
Epoch 1000, Loss: 0.0012217224575579166, Constraint losses: L1: -1.1177406311035156, L2: 0.0, L3: 0.002169489860534668, L4: 0.00016997329657897353
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9999754428863525, Constraint losses: L1: 5.786181926727295, L2: 0.0, L3: 0.9970949292182922, L4: 0.9970942735671997
Epoch 500, Loss: 0.001998046413064003, Constraint losses: L1: -1.042529821395874, L2: 0.0, L3: 0.0025194883346557617, L4: 0.0005210877861827612
Epoch 1000, Loss: 0.0012667642440646887, Constraint losses: L1: -1.0698412656784058, L2: 0.0, L3: 0.002168118953704834, L4: 0.00016848655650392175
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 195.4420928955078, Losses: L1: 18.42068099975586, L2: 0.003472194541245699, L3: 1.0034699440002441, L4: 88.0882797241211, L5: 0.3396400511264801
Epoch 500, Loss: 35.512001037597656, Losses: L1: 4.627939701080322, L2: 0.15018236637115479, L3: 0.2508687973022461, L4: 15.217327117919922, L5: 0.17378820478916168
Epoch 1000, Loss: 9.683390617370605, Losses: L1: 1.94593346118927, L2: 0.07414630800485611, L3: 0.15079879760742188, L4: 3.7744064331054688, L5: 0.03909904137253761
Epoch 1500, Loss: 14.91067123413086, Losses: L1: 2.823276996612549, L2: 0.9813680648803711, L3: 0.21872973442077637, L4: 5.445479869842529, L5: 0.10570117086172104
Epoch 2000, Loss: 26.718687057495117, Losses: L1: 3.6187937259674072, L2: 1.3617606163024902, L3: 0.2929999828338623, L4: 10.735892295837402, L5: 0.11984756588935852
Epoch 2500, Loss: 11.980338096618652, Losses: L1: 3.7366116046905518, L2: 1.2732361555099487, L3: 0.15233945846557617, L4: 3.3844645023345947, L5: 0.12539182603359222
Epoch 3000, Loss: 10.919781684875488, Losses: L1: 3.1556217670440674, L2: 0.9580296874046326, L3: 0.16303688287734985, L4: 3.318107843399048, L5: 0.08839565515518188
Epoch 3500, Loss: 8.920592308044434, Losses: L1: 3.408639907836914, L2: 0.8545024991035461, L3: 0.13545560836791992, L4: 2.249894142150879, L5: 0.08993380516767502
Epoch 4000, Loss: 6.675069808959961, Losses: L1: 3.1237051486968994, L2: 0.7746797800064087, L3: 0.13963598012924194, L4: 1.3106751441955566, L5: 0.08551628142595291
Epoch 4500, Loss: 6.241560935974121, Losses: L1: 2.9947760105133057, L2: 0.7625696063041687, L3: 0.1365073323249817, L4: 1.1651315689086914, L5: 0.085698202252388
Epoch 5000, Loss: 6.012062072753906, Losses: L1: 2.9803335666656494, L2: 0.7753979563713074, L3: 0.13118219375610352, L4: 1.051987648010254, L5: 0.08676424622535706
Epoch 5500, Loss: 5.924391746520996, Losses: L1: 3.0070948600769043, L2: 0.7848522067070007, L3: 0.130165696144104, L4: 0.9900678396224976, L5: 0.08722592890262604
Epoch 6000, Loss: 5.782834529876709, Losses: L1: 2.8848440647125244, L2: 0.790490984916687, L3: 0.13043445348739624, L4: 0.9770590662956238, L5: 0.08816410601139069
Epoch 6500, Loss: 5.693495273590088, Losses: L1: 2.841186285018921, L2: 0.7951272130012512, L3: 0.13009238243103027, L4: 0.9519706964492798, L5: 0.08819416165351868
Epoch 7000, Loss: 5.660353183746338, Losses: L1: 2.8396358489990234, L2: 0.8007952570915222, L3: 0.12817347049713135, L4: 0.9336622953414917, L5: 0.08851109445095062
Epoch 7500, Loss: 5.63774299621582, Losses: L1: 2.829803943634033, L2: 0.8030992746353149, L3: 0.1290091872215271, L4: 0.9258608222007751, L5: 0.08861333876848221
Epoch 8000, Loss: 5.628052234649658, Losses: L1: 2.8284668922424316, L2: 0.8041271567344666, L3: 0.12896740436553955, L4: 0.9211370944976807, L5: 0.08870037645101547
Epoch 8500, Loss: 5.621250629425049, Losses: L1: 2.8280625343322754, L2: 0.8046696782112122, L3: 0.1288837194442749, L4: 0.9176609516143799, L5: 0.08875453472137451
Epoch 9000, Loss: 5.616384506225586, Losses: L1: 2.8277904987335205, L2: 0.805057168006897, L3: 0.12880849838256836, L4: 0.9151649475097656, L5: 0.08880234509706497
Epoch 9500, Loss: 5.612789154052734, Losses: L1: 2.827763795852661, L2: 0.8052873611450195, L3: 0.12875908613204956, L4: 0.9132681488990784, L5: 0.08882229775190353
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.002150774002075, Constraint losses: L1: 6.245100021362305, L2: 0.0, L3: 0.9979525208473206, L4: 0.9979531168937683
Epoch 500, Loss: 0.002490503014996648, Constraint losses: L1: -0.9903731942176819, L2: 0.0, L3: 0.0027391910552978516, L4: 0.0007416852167807519
Epoch 1000, Loss: 0.001339098671451211, Constraint losses: L1: -1.1120654344558716, L2: 0.0, L3: 0.002225160598754883, L4: 0.0002260035544168204
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9984793663024902, Constraint losses: L1: 5.57649040222168, L2: 0.0, L3: 0.9964518547058105, L4: 0.9964510202407837
Epoch 500, Loss: 0.0022901222109794617, Constraint losses: L1: -1.0297261476516724, L2: 0.0, L3: 0.002659022808074951, L4: 0.0006608255207538605
Epoch 1000, Loss: 0.001340012764558196, Constraint losses: L1: -1.0708600282669067, L2: 0.0, L3: 0.0022051334381103516, L4: 0.00020573940128087997
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 156.98086547851562, Losses: L1: 10.440534591674805, L2: 0.0009193728910759091, L3: 0.9985965490341187, L4: 72.77476501464844, L5: 0.24529334902763367
Epoch 500, Loss: 8.614441871643066, Losses: L1: 1.0675185918807983, L2: 0.04591219872236252, L3: 0.07034468650817871, L4: 3.6467840671539307, L5: 0.08613521605730057
Epoch 1000, Loss: 13.659887313842773, Losses: L1: 5.524731636047363, L2: 0.6242165565490723, L3: 0.08609551191329956, L4: 3.645219326019287, L5: 0.08872592449188232
Epoch 1500, Loss: 33.79949951171875, Losses: L1: 6.317451477050781, L2: 0.7350932359695435, L3: 0.268246054649353, L4: 13.180463790893555, L5: 0.12595126032829285
Epoch 2000, Loss: 6.467165946960449, Losses: L1: 2.7069859504699707, L2: 0.3635161519050598, L3: 0.16072583198547363, L4: 1.626267433166504, L5: 0.03188309073448181
Epoch 2500, Loss: 5.492229461669922, Losses: L1: 2.745372772216797, L2: 0.38703879714012146, L3: 0.11348015069961548, L4: 1.1156487464904785, L5: 0.03589009866118431
Epoch 3000, Loss: 4.906696319580078, Losses: L1: 2.4610791206359863, L2: 0.36390796303749084, L3: 0.10896813869476318, L4: 0.9804695844650269, L5: 0.03314302861690521
Epoch 3500, Loss: 4.525312423706055, Losses: L1: 2.3095901012420654, L2: 0.36243438720703125, L3: 0.10018575191497803, L4: 0.8689351677894592, L5: 0.03266231715679169
Epoch 4000, Loss: 4.3397393226623535, Losses: L1: 2.176396131515503, L2: 0.3532821834087372, L3: 0.09924232959747314, L4: 0.8485647439956665, L5: 0.03165503591299057
Epoch 4500, Loss: 4.181670665740967, Losses: L1: 2.1389806270599365, L2: 0.3329150676727295, L3: 0.09691643714904785, L4: 0.7984942197799683, L5: 0.03216426819562912
Epoch 5000, Loss: 4.03054141998291, Losses: L1: 2.0632739067077637, L2: 0.30609557032585144, L3: 0.09577763080596924, L4: 0.7745894193649292, L5: 0.03205223008990288
Epoch 5500, Loss: 3.9625208377838135, Losses: L1: 2.060811758041382, L2: 0.2872686982154846, L3: 0.09500491619110107, L4: 0.7515168786048889, L5: 0.03195204958319664
Epoch 6000, Loss: 3.891197919845581, Losses: L1: 2.029895067214966, L2: 0.27237561345100403, L3: 0.09490203857421875, L4: 0.7390279769897461, L5: 0.031710147857666016
Epoch 6500, Loss: 3.855290174484253, Losses: L1: 2.026679277420044, L2: 0.262503057718277, L3: 0.0943034291267395, L4: 0.7279973030090332, L5: 0.031480614095926285
Epoch 7000, Loss: 3.834014415740967, Losses: L1: 2.025423526763916, L2: 0.25592249631881714, L3: 0.09420907497406006, L4: 0.7214947938919067, L5: 0.03128704056143761
Epoch 7500, Loss: 3.8190724849700928, Losses: L1: 2.0249390602111816, L2: 0.251128613948822, L3: 0.09396582841873169, L4: 0.7168515920639038, L5: 0.03115931898355484
Epoch 8000, Loss: 3.808359146118164, Losses: L1: 2.024259090423584, L2: 0.2479037493467331, L3: 0.09385097026824951, L4: 0.7135390639305115, L5: 0.03109620325267315
Epoch 8500, Loss: 3.800875186920166, Losses: L1: 2.0238406658172607, L2: 0.24556352198123932, L3: 0.09372347593307495, L4: 0.7112845778465271, L5: 0.031020164489746094
Epoch 9000, Loss: 3.7955050468444824, Losses: L1: 2.0232415199279785, L2: 0.24383626878261566, L3: 0.09364008903503418, L4: 0.7098212242126465, L5: 0.030982499942183495
Epoch 9500, Loss: 3.791767120361328, Losses: L1: 2.0227506160736084, L2: 0.24261988699436188, L3: 0.09356528520584106, L4: 0.7088575959205627, L5: 0.030949361622333527
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0193119049072266, Constraint losses: L1: 18.42068099975586, L2: 0.00029712170362472534, L3: 1.0002970695495605, L4: 1.0002970695495605
Epoch 500, Loss: 0.002287412527948618, Constraint losses: L1: -1.0656250715255737, L2: 0.0, L3: 0.002675473690032959, L4: 0.0006775640067644417
Epoch 1000, Loss: 0.001313132350333035, Constraint losses: L1: -1.1172237396240234, L2: 0.0, L3: 0.0022149085998535156, L4: 0.0002154475514544174
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0047874450683594, Constraint losses: L1: 6.876763820648193, L2: 0.0, L3: 0.9989553689956665, L4: 0.998955488204956
Epoch 500, Loss: 0.002266569994390011, Constraint losses: L1: -1.0087201595306396, L2: 0.0, L3: 0.0026366710662841797, L4: 0.0006386192399077117
Epoch 1000, Loss: 0.0013308700872585177, Constraint losses: L1: -1.0688831806182861, L2: 0.0, L3: 0.0021995902061462402, L4: 0.00020016312191728503
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.23196792602539, Losses: L1: 11.195427894592285, L2: 0.0002188329235650599, L3: 0.9994515776634216, L4: 83.76154327392578, L5: 0.31219229102134705
Epoch 500, Loss: 19.116783142089844, Losses: L1: 5.871638298034668, L2: 0.04852837324142456, L3: 0.10614603757858276, L4: 25.93838119506836, L5: 0.24256005883216858
Epoch 1000, Loss: 37.135494232177734, Losses: L1: 10.973736763000488, L2: 0.0001847898674895987, L3: 0.9994978904724121, L4: 50.021636962890625, L5: 0.30251091718673706
Epoch 1500, Loss: 10.003870010375977, Losses: L1: 5.187699317932129, L2: 0.15508803725242615, L3: 0.23550868034362793, L4: 8.808624267578125, L5: 0.04252399131655693
Epoch 2000, Loss: 3.86539626121521, Losses: L1: 2.323840618133545, L2: 0.1059950664639473, L3: 0.11542987823486328, L4: 2.596007823944092, L5: 0.044253479689359665
Epoch 2500, Loss: 3.1537227630615234, Losses: L1: 1.860633134841919, L2: 0.085561104118824, L3: 0.10404294729232788, L4: 2.1685333251953125, L5: 0.038437746465206146
Epoch 3000, Loss: 6.016590118408203, Losses: L1: 2.287180185317993, L2: 0.09498308598995209, L3: 0.12244528532028198, L4: 6.980891227722168, L5: 0.043071478605270386
Epoch 3500, Loss: 24.69000816345215, Losses: L1: 2.468144655227661, L2: 0.0791487768292427, L3: 0.8492085933685303, L4: 42.380409240722656, L5: 0.20660266280174255
Epoch 4000, Loss: 29.279264450073242, Losses: L1: 3.8460774421691895, L2: 0.016679350286722183, L3: 0.975010871887207, L4: 48.599700927734375, L5: 0.2832913398742676
Epoch 4500, Loss: 12.899624824523926, Losses: L1: 1.0063550472259521, L2: 0.3312760889530182, L3: 0.5708932280540466, L4: 21.88052749633789, L5: 0.10167260468006134
Epoch 5000, Loss: 8.918614387512207, Losses: L1: 0.9789344072341919, L2: 0.3251877725124359, L3: 0.4145127534866333, L4: 14.315953254699707, L5: 0.0840059146285057
Epoch 5500, Loss: 8.380255699157715, Losses: L1: 0.9847162365913391, L2: 0.3220469355583191, L3: 0.3836730122566223, L4: 13.296724319458008, L5: 0.08291410654783249
Epoch 6000, Loss: 8.079058647155762, Losses: L1: 0.9954303503036499, L2: 0.31261146068573, L3: 0.36700439453125, L4: 12.72810173034668, L5: 0.07992305606603622
Epoch 6500, Loss: 7.854625701904297, Losses: L1: 0.9935550689697266, L2: 0.2978802025318146, L3: 0.35837143659591675, L4: 12.334600448608398, L5: 0.07503656297922134
Epoch 7000, Loss: 7.68721866607666, Losses: L1: 0.9850981831550598, L2: 0.2852691411972046, L3: 0.35295581817626953, L4: 12.05682373046875, L5: 0.07096651196479797
Epoch 7500, Loss: 7.576314926147461, Losses: L1: 0.9964431524276733, L2: 0.27611058950424194, L3: 0.3481687307357788, L4: 11.843355178833008, L5: 0.06782971322536469
Epoch 8000, Loss: 7.496596813201904, Losses: L1: 1.0030016899108887, L2: 0.26979002356529236, L3: 0.34436285495758057, L4: 11.69304084777832, L5: 0.06584395468235016
Epoch 8500, Loss: 7.410882472991943, Losses: L1: 1.0057849884033203, L2: 0.2645743787288666, L3: 0.3412100672721863, L4: 11.535364151000977, L5: 0.06326232105493546
Epoch 9000, Loss: 7.368043422698975, Losses: L1: 1.0093095302581787, L2: 0.2619636058807373, L3: 0.33839863538742065, L4: 11.454245567321777, L5: 0.06249723210930824
Epoch 9500, Loss: 7.336706638336182, Losses: L1: 1.0119363069534302, L2: 0.2591513395309448, L3: 0.3368276357650757, L4: 11.396065711975098, L5: 0.06151706352829933
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0227417945861816, Constraint losses: L1: 18.42068099975586, L2: 0.0014403390232473612, L3: 1.0014402866363525, L4: 1.0014405250549316
Epoch 500, Loss: 0.0022563189268112183, Constraint losses: L1: -1.0833312273025513, L2: 0.0, L3: 0.002669036388397217, L4: 0.0006706139538437128
Epoch 1000, Loss: 0.0013100901851430535, Constraint losses: L1: -1.1184414625167847, L2: 0.0, L3: 0.0022139549255371094, L4: 0.00021457672119140625
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.027235507965088, Constraint losses: L1: 18.42068099975586, L2: 0.0029379057232290506, L3: 1.002937912940979, L4: 1.002938985824585
Epoch 500, Loss: 0.002136537106707692, Constraint losses: L1: -1.0665444135665894, L2: 0.0, L3: 0.0026009082794189453, L4: 0.0006021732115186751
Epoch 1000, Loss: 0.0013344656908884645, Constraint losses: L1: -1.070618748664856, L2: 0.0, L3: 0.0022022128105163574, L4: 0.0002028715971391648
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.0734748840332, Losses: L1: 10.741361618041992, L2: 0.00016957039770204574, L3: 0.9992297887802124, L4: 80.08279418945312, L5: 0.29131627082824707
Epoch 500, Loss: 3.9419424533843994, Losses: L1: 0.3859610855579376, L2: 0.09716583788394928, L3: 0.13161182403564453, L4: 6.553946018218994, L5: 0.05023082718253136
Epoch 1000, Loss: 1.5985583066940308, Losses: L1: 0.09304516762495041, L2: 0.07441367954015732, L3: 0.10572361946105957, L4: 2.5922389030456543, L5: 0.029256481677293777
Epoch 1500, Loss: 0.641852855682373, Losses: L1: -0.07093236595392227, L2: 0.02642594277858734, L3: 0.09634828567504883, L4: 1.152687430381775, L5: 0.013667257502675056
Epoch 2000, Loss: 0.6998897194862366, Losses: L1: -0.017387166619300842, L2: 0.022765036672353745, L3: 0.10556566715240479, L4: 1.154076337814331, L5: 0.01190798170864582
Epoch 2500, Loss: 0.7994735836982727, Losses: L1: -0.03367455303668976, L2: 0.027590617537498474, L3: 0.09517008066177368, L4: 1.3895010948181152, L5: 0.015636853873729706
Epoch 3000, Loss: 0.5503464937210083, Losses: L1: -0.05742007866501808, L2: 0.026368804275989532, L3: 0.09820282459259033, L4: 0.9441413879394531, L5: 0.011124262586236
Epoch 3500, Loss: 0.521818995475769, Losses: L1: -0.06659390777349472, L2: 0.026782795786857605, L3: 0.09643751382827759, L4: 0.9080202579498291, L5: 0.011182465590536594
Epoch 4000, Loss: 0.47351571917533875, Losses: L1: -0.10370875895023346, L2: 0.023570606485009193, L3: 0.09551441669464111, L4: 0.8954825401306152, L5: 0.010398192331194878
Epoch 4500, Loss: 0.4587540924549103, Losses: L1: -0.10909949243068695, L2: 0.02434338815510273, L3: 0.09482866525650024, L4: 0.8766326904296875, L5: 0.010365178808569908
Epoch 5000, Loss: 0.4482870399951935, Losses: L1: -0.11190301179885864, L2: 0.024512290954589844, L3: 0.09389328956604004, L4: 0.8622761964797974, L5: 0.010646378621459007
Epoch 5500, Loss: 0.4388342499732971, Losses: L1: -0.11393489688634872, L2: 0.024621915072202682, L3: 0.09323060512542725, L4: 0.8489024639129639, L5: 0.010465378873050213
Epoch 6000, Loss: 0.43321484327316284, Losses: L1: -0.11557407677173615, L2: 0.024634867906570435, L3: 0.09291958808898926, L4: 0.8416005969047546, L5: 0.010434165596961975
Epoch 6500, Loss: 0.4292071461677551, Losses: L1: -0.11639325320720673, L2: 0.024679886177182198, L3: 0.09242784976959229, L4: 0.8360455632209778, L5: 0.010469892993569374
Epoch 7000, Loss: 0.4261951446533203, Losses: L1: -0.11715681850910187, L2: 0.02471548318862915, L3: 0.09223735332489014, L4: 0.8319886922836304, L5: 0.010404756292700768
Epoch 7500, Loss: 0.42407241463661194, Losses: L1: -0.11751769483089447, L2: 0.024744253605604172, L3: 0.09194725751876831, L4: 0.8289462327957153, L5: 0.010425488464534283
Epoch 8000, Loss: 0.42260637879371643, Losses: L1: -0.11776077002286911, L2: 0.024747725576162338, L3: 0.091793954372406, L4: 0.8268348574638367, L5: 0.01040805783122778
Epoch 8500, Loss: 0.42167991399765015, Losses: L1: -0.11795209348201752, L2: 0.024754665791988373, L3: 0.09169149398803711, L4: 0.8256067037582397, L5: 0.01038250233978033
Epoch 9000, Loss: 0.420918345451355, Losses: L1: -0.117994025349617, L2: 0.02475624345242977, L3: 0.09156811237335205, L4: 0.8244054317474365, L5: 0.01038531493395567
Epoch 9500, Loss: 0.42045748233795166, Losses: L1: -0.11803033947944641, L2: 0.024755381047725677, L3: 0.09149885177612305, L4: 0.8237075209617615, L5: 0.01037982851266861
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0106258392333984, Constraint losses: L1: 10.659553527832031, L2: 0.00014645578630734235, L3: 0.9999099969863892, L4: 0.9999099373817444
Epoch 500, Loss: 0.0020073566120117903, Constraint losses: L1: -1.0537610054016113, L2: 0.0, L3: 0.002529621124267578, L4: 0.0005314965965226293
Epoch 1000, Loss: 0.0012083507608622313, Constraint losses: L1: -1.1173806190490723, L2: 0.0, L3: 0.0021626949310302734, L4: 0.00016303648590110242
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001230239868164, Constraint losses: L1: 6.03327751159668, L2: 0.0, L3: 0.99759840965271, L4: 0.9975986480712891
Epoch 500, Loss: 0.0022227908484637737, Constraint losses: L1: -1.0129313468933105, L2: 0.0, L3: 0.0026169419288635254, L4: 0.0006187802064232528
Epoch 1000, Loss: 0.0013215303188189864, Constraint losses: L1: -1.0680464506149292, L2: 0.0, L3: 0.002194523811340332, L4: 0.00019505308591760695
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.21312713623047, Losses: L1: 5.607840538024902, L2: 0.0, L3: 0.9958086609840393, L4: 78.11648559570312, L5: 0.2756175994873047
Epoch 500, Loss: 3.3616840839385986, Losses: L1: 0.3710683584213257, L2: 0.069427490234375, L3: 0.14339512586593628, L4: 5.4131693840026855, L5: 0.035604264587163925
Epoch 1000, Loss: 3.261322498321533, Losses: L1: 0.3016871511936188, L2: 0.10760460793972015, L3: 0.18972527980804443, L4: 5.2376508712768555, L5: 0.0217400174587965
Epoch 1500, Loss: 27.69508934020996, Losses: L1: 1.7517955303192139, L2: 0.9096010327339172, L3: 0.9157204627990723, L4: 47.528221130371094, L5: 0.17693057656288147
Epoch 2000, Loss: 18.727535247802734, Losses: L1: 1.496118426322937, L2: 0.1500794142484665, L3: 0.7808167338371277, L4: 32.153167724609375, L5: 0.11196833103895187
Epoch 2500, Loss: 3.662296772003174, Losses: L1: 1.7033071517944336, L2: 0.09534105658531189, L3: 0.10188984870910645, L4: 3.373541831970215, L5: 0.03749397397041321
Epoch 3000, Loss: 2.263904094696045, Losses: L1: 1.1765556335449219, L2: 0.06876906007528305, L3: 0.08438277244567871, L4: 1.7649040222167969, L5: 0.02587224915623665
Epoch 3500, Loss: 1.8671211004257202, Losses: L1: 1.0299363136291504, L2: 0.06108052656054497, L3: 0.07631951570510864, L4: 1.31070876121521, L5: 0.022215131670236588
Epoch 4000, Loss: 1.738620400428772, Losses: L1: 1.0067843198776245, L2: 0.05707023665308952, L3: 0.07444709539413452, L4: 1.118044137954712, L5: 0.020648367702960968
Epoch 4500, Loss: 1.6125731468200684, Losses: L1: 0.9425899982452393, L2: 0.05332213640213013, L3: 0.07363235950469971, L4: 1.0063374042510986, L5: 0.01992994360625744
Epoch 5000, Loss: 1.5626031160354614, Losses: L1: 0.9270581603050232, L2: 0.0535668209195137, L3: 0.07263028621673584, L4: 0.9437305927276611, L5: 0.018741263076663017
Epoch 5500, Loss: 1.527907371520996, Losses: L1: 0.9176127314567566, L2: 0.052723344415426254, L3: 0.07175523042678833, L4: 0.8988152146339417, L5: 0.018204232677817345
Epoch 6000, Loss: 1.468566656112671, Losses: L1: 0.8777457475662231, L2: 0.05163871496915817, L3: 0.07086896896362305, L4: 0.8675895929336548, L5: 0.01725926250219345
Epoch 6500, Loss: 1.4498863220214844, Losses: L1: 0.8718266487121582, L2: 0.05218740180134773, L3: 0.06981277465820312, L4: 0.8446236252784729, L5: 0.016873858869075775
Epoch 7000, Loss: 1.438552975654602, Losses: L1: 0.8690436482429504, L2: 0.05204008147120476, L3: 0.0693817138671875, L4: 0.8294336199760437, L5: 0.016685374081134796
Epoch 7500, Loss: 1.430871605873108, Losses: L1: 0.8673801422119141, L2: 0.051966406404972076, L3: 0.06907081604003906, L4: 0.8185297250747681, L5: 0.01659472845494747
Epoch 8000, Loss: 1.425485610961914, Losses: L1: 0.8662340044975281, L2: 0.051932193338871, L3: 0.06885349750518799, L4: 0.8108611702919006, L5: 0.01651766337454319
Epoch 8500, Loss: 1.4216358661651611, Losses: L1: 0.8654537796974182, L2: 0.05181139335036278, L3: 0.06874316930770874, L4: 0.8055533170700073, L5: 0.01642545498907566
Epoch 9000, Loss: 1.4189000129699707, Losses: L1: 0.8649188876152039, L2: 0.051802828907966614, L3: 0.06864213943481445, L4: 0.8015227317810059, L5: 0.016387416049838066
Epoch 9500, Loss: 1.416917324066162, Losses: L1: 0.8645541667938232, L2: 0.051765453070402145, L3: 0.06858909130096436, L4: 0.7987189292907715, L5: 0.0163246002048254
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0302515029907227, Constraint losses: L1: 18.42068099975586, L2: 0.00394367566332221, L3: 1.003943681716919, L4: 1.0039434432983398
Epoch 500, Loss: 0.002166645834222436, Constraint losses: L1: -1.0203464031219482, L2: 0.0, L3: 0.0025925636291503906, L4: 0.0005944286240264773
Epoch 1000, Loss: 0.0012346976436674595, Constraint losses: L1: -1.1175546646118164, L2: 0.0, L3: 0.00217592716217041, L4: 0.00017632526578381658
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0003645420074463, Constraint losses: L1: 5.892171382904053, L2: 0.0, L3: 0.9972361326217651, L4: 0.9972362518310547
Epoch 500, Loss: 0.002322377637028694, Constraint losses: L1: -1.018272042274475, L2: 0.0, L3: 0.002669394016265869, L4: 0.0006712556350976229
Epoch 1000, Loss: 0.0013549148570746183, Constraint losses: L1: -1.0688128471374512, L2: 0.0, L3: 0.002211630344390869, L4: 0.00021209743863437325
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 93.5426254272461, Losses: L1: 18.42068099975586, L2: 0.0014541588025167584, L3: 1.0014389753341675, L4: 73.99214935302734, L5: 0.25380536913871765
Epoch 500, Loss: 46.36397933959961, Losses: L1: 2.096696615219116, L2: 0.00016879753093235195, L3: 0.859001636505127, L4: 43.3226432800293, L5: 0.17093981802463531
Epoch 1000, Loss: 19.274415969848633, Losses: L1: 5.455963134765625, L2: 1.0571316480636597, L3: 0.05650663375854492, L4: 12.630321502685547, L5: 0.14898785948753357
Epoch 1500, Loss: 55.65926742553711, Losses: L1: 3.5727596282958984, L2: 0.00013961699733044952, L3: 0.9624201059341431, L4: 50.976139068603516, L5: 0.2956134080886841
Epoch 2000, Loss: 35.261329650878906, Losses: L1: 3.0283374786376953, L2: 0.28896620869636536, L3: 0.3762642741203308, L4: 31.460649490356445, L5: 0.21422415971755981
Epoch 2500, Loss: 51.56214904785156, Losses: L1: 4.435425758361816, L2: 0.07998984307050705, L3: 0.662912905216217, L4: 46.23541259765625, L5: 0.2968137264251709
Epoch 3000, Loss: 11.709024429321289, Losses: L1: 5.640935897827148, L2: 0.954973042011261, L3: 0.2143072485923767, L4: 4.831912994384766, L5: 0.13378983736038208
Epoch 3500, Loss: 9.806534767150879, Losses: L1: 5.78265380859375, L2: 0.5310923457145691, L3: 0.2005518078804016, L4: 3.2254602909088135, L5: 0.13355287909507751
Epoch 4000, Loss: 9.00586223602295, Losses: L1: 5.487547874450684, L2: 0.44963353872299194, L3: 0.177931547164917, L4: 2.8242363929748535, L5: 0.1330249160528183
Epoch 4500, Loss: 7.377488136291504, Losses: L1: 3.9032180309295654, L2: 0.2261623740196228, L3: 0.2027740478515625, L4: 2.9790430068969727, L5: 0.13258138298988342
Epoch 5000, Loss: 6.858705520629883, Losses: L1: 3.6145718097686768, L2: 0.19277667999267578, L3: 0.19351136684417725, L4: 2.7919647693634033, L5: 0.13176174461841583
Epoch 5500, Loss: 6.706396102905273, Losses: L1: 3.5779337882995605, L2: 0.18554538488388062, L3: 0.18748211860656738, L4: 2.689915180206299, L5: 0.13103869557380676
Epoch 6000, Loss: 6.453741550445557, Losses: L1: 3.369669198989868, L2: 0.17639979720115662, L3: 0.18604278564453125, L4: 2.6566648483276367, L5: 0.12992912530899048
Epoch 6500, Loss: 6.356277942657471, Losses: L1: 3.326115369796753, L2: 0.17079223692417145, L3: 0.18440234661102295, L4: 2.609957456588745, L5: 0.13002079725265503
Epoch 7000, Loss: 6.311963081359863, Losses: L1: 3.325352191925049, L2: 0.1687774658203125, L3: 0.18429982662200928, L4: 2.568582057952881, L5: 0.12990300357341766
Epoch 7500, Loss: 6.278736591339111, Losses: L1: 3.3227169513702393, L2: 0.16760079562664032, L3: 0.18499070405960083, L4: 2.53855037689209, L5: 0.12975624203681946
Epoch 8000, Loss: 6.251553535461426, Losses: L1: 3.323601722717285, L2: 0.16666586697101593, L3: 0.18511474132537842, L4: 2.5113463401794434, L5: 0.1296500265598297
Epoch 8500, Loss: 6.226851940155029, Losses: L1: 3.329261302947998, L2: 0.16091156005859375, L3: 0.18529808521270752, L4: 2.4864296913146973, L5: 0.12990275025367737
Epoch 9000, Loss: 6.199385643005371, Losses: L1: 3.3049559593200684, L2: 0.16500645875930786, L3: 0.18484318256378174, L4: 2.479849100112915, L5: 0.12946142256259918
Epoch 9500, Loss: 6.188164710998535, Losses: L1: 3.30306077003479, L2: 0.16468200087547302, L3: 0.1845751404762268, L4: 2.4711294174194336, L5: 0.12943492829799652
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0222437381744385, Constraint losses: L1: 18.42068099975586, L2: 0.0012745073763653636, L3: 1.0012744665145874, L4: 1.0012741088867188
Epoch 500, Loss: 0.0020743925124406815, Constraint losses: L1: -1.0965558290481567, L2: 0.0, L3: 0.002584695816040039, L4: 0.000586252601351589
Epoch 1000, Loss: 0.0012527138460427523, Constraint losses: L1: -1.1178269386291504, L2: 0.0, L3: 0.002185046672821045, L4: 0.00018549419473856688
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9994306564331055, Constraint losses: L1: 5.707602024078369, L2: 0.0, L3: 0.99686199426651, L4: 0.9968611598014832
Epoch 500, Loss: 0.002066120970994234, Constraint losses: L1: -1.0590150356292725, L2: 0.0, L3: 0.00256192684173584, L4: 0.0005632092361338437
Epoch 1000, Loss: 0.0012994949938729405, Constraint losses: L1: -1.070662498474121, L2: 0.0, L3: 0.0021848678588867188, L4: 0.0001852896821219474
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 83.51724243164062, Losses: L1: 4.607261657714844, L2: 7.994922270881943e-06, L3: 0.9908319115638733, L4: 77.64252471923828, L5: 0.2766193151473999
Epoch 500, Loss: 7.923649787902832, Losses: L1: 2.453334093093872, L2: 0.2880675196647644, L3: 0.10687112808227539, L4: 5.025182723999023, L5: 0.050194431096315384
Epoch 1000, Loss: 56.19549560546875, Losses: L1: 5.529984951019287, L2: 0.022251857444643974, L3: 0.9885500073432922, L4: 49.35887908935547, L5: 0.2958281636238098
Epoch 1500, Loss: 26.769376754760742, Losses: L1: 8.071746826171875, L2: 0.6705279350280762, L3: 0.19490230083465576, L4: 17.646451950073242, L5: 0.18574795126914978
Epoch 2000, Loss: 23.786888122558594, Losses: L1: 10.58896541595459, L2: 0.2640860676765442, L3: 0.32884401082992554, L4: 12.493995666503906, L5: 0.11099578440189362
Epoch 2500, Loss: 9.237752914428711, Losses: L1: 4.641948699951172, L2: 0.18607240915298462, L3: 0.1485518217086792, L4: 4.232378005981445, L5: 0.02880181558430195
Epoch 3000, Loss: 5.911838531494141, Losses: L1: 1.3734339475631714, L2: 0.1109514981508255, L3: 0.18567544221878052, L4: 4.217179298400879, L5: 0.024597909301519394
Epoch 3500, Loss: 5.537231922149658, Losses: L1: 1.321744680404663, L2: 0.11343564093112946, L3: 0.17161208391189575, L4: 3.9064977169036865, L5: 0.023941701278090477
Epoch 4000, Loss: 5.342747688293457, Losses: L1: 1.308335304260254, L2: 0.1096496656537056, L3: 0.16765642166137695, L4: 3.733708143234253, L5: 0.023398570716381073
Epoch 4500, Loss: 5.223202705383301, Losses: L1: 1.3032009601593018, L2: 0.10616286098957062, L3: 0.16504859924316406, L4: 3.625770330429077, L5: 0.023019716143608093
Epoch 5000, Loss: 5.14185094833374, Losses: L1: 1.300320029258728, L2: 0.10333038121461868, L3: 0.16370272636413574, L4: 3.551919460296631, L5: 0.022578278556466103
Epoch 5500, Loss: 5.08428430557251, Losses: L1: 1.3008021116256714, L2: 0.10106600075960159, L3: 0.16259098052978516, L4: 3.4975457191467285, L5: 0.022279219701886177
Epoch 6000, Loss: 5.030087471008301, Losses: L1: 1.2806116342544556, L2: 0.09970039874315262, L3: 0.1617017388343811, L4: 3.465972661972046, L5: 0.022100793197751045
Epoch 6500, Loss: 4.989927768707275, Losses: L1: 1.2670137882232666, L2: 0.098491370677948, L3: 0.1607072353363037, L4: 3.4417223930358887, L5: 0.021993065252900124
Epoch 7000, Loss: 4.960883617401123, Losses: L1: 1.268052101135254, L2: 0.09666861593723297, L3: 0.16089260578155518, L4: 3.413644790649414, L5: 0.021625442430377007
Epoch 7500, Loss: 4.944399833679199, Losses: L1: 1.2678191661834717, L2: 0.09582836925983429, L3: 0.1607046127319336, L4: 3.398550510406494, L5: 0.02149716392159462
Epoch 8000, Loss: 4.933053016662598, Losses: L1: 1.2679729461669922, L2: 0.09528322517871857, L3: 0.16052544116973877, L4: 3.387826442718506, L5: 0.021444791927933693
Epoch 8500, Loss: 4.925068378448486, Losses: L1: 1.2680737972259521, L2: 0.0949084460735321, L3: 0.16042494773864746, L4: 3.3802571296691895, L5: 0.02140357717871666
Epoch 9000, Loss: 4.919490337371826, Losses: L1: 1.2681541442871094, L2: 0.09461858123540878, L3: 0.16035354137420654, L4: 3.374994993209839, L5: 0.02136875130236149
Epoch 9500, Loss: 4.915623188018799, Losses: L1: 1.2682372331619263, L2: 0.09442011266946793, L3: 0.1602964997291565, L4: 3.371320962905884, L5: 0.02134857140481472
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.024510145187378, Constraint losses: L1: 18.42068099975586, L2: 0.0020297314040362835, L3: 1.0020297765731812, L4: 1.0020298957824707
Epoch 500, Loss: 0.0020689370576292276, Constraint losses: L1: -1.1092822551727295, L2: 0.0, L3: 0.002588331699371338, L4: 0.0005898876115679741
Epoch 1000, Loss: 0.0012644935632124543, Constraint losses: L1: -1.1176601648330688, L2: 0.0, L3: 0.002190828323364258, L4: 0.00019132540910504758
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0224854946136475, Constraint losses: L1: 18.42068099975586, L2: 0.001354772481136024, L3: 1.0013548135757446, L4: 1.0013551712036133
Epoch 500, Loss: 0.002128579653799534, Constraint losses: L1: -1.0326356887817383, L2: 0.0, L3: 0.002579808235168457, L4: 0.0005814070464111865
Epoch 1000, Loss: 0.0012873844243586063, Constraint losses: L1: -1.0705523490905762, L2: 0.0, L3: 0.002178788185119629, L4: 0.0001791486283764243
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 81.761474609375, Losses: L1: 5.259637832641602, L2: 0.0, L3: 0.9940197467803955, L4: 74.99089813232422, L5: 0.2584598958492279
Epoch 500, Loss: 3.0595033168792725, Losses: L1: 0.4756823778152466, L2: 0.09911799430847168, L3: 0.11824333667755127, L4: 2.326068162918091, L5: 0.020195666700601578
Epoch 1000, Loss: 11.147237777709961, Losses: L1: 2.535325765609741, L2: 0.4393349885940552, L3: 0.2649076581001282, L4: 7.740662574768066, L5: 0.08350345492362976
Epoch 1500, Loss: 75.6294174194336, Losses: L1: 9.765583992004395, L2: 1.2295953035354614, L3: 1.178570032119751, L4: 62.96971893310547, L5: 0.2429736703634262
Epoch 2000, Loss: 22.02495765686035, Losses: L1: 1.6451712846755981, L2: 0.18824152648448944, L3: 0.4980967044830322, L4: 19.55271339416504, L5: 0.07036688178777695
Epoch 2500, Loss: 11.304152488708496, Losses: L1: 1.052297592163086, L2: 0.12236795574426651, L3: 0.2820189595222473, L4: 9.746427536010742, L5: 0.050520654767751694
Epoch 3000, Loss: 9.835734367370605, Losses: L1: 0.8294144868850708, L2: 0.10414420813322067, L3: 0.24971842765808105, L4: 8.560454368591309, L5: 0.04600149393081665
Epoch 3500, Loss: 8.719985961914062, Losses: L1: 0.6355493068695068, L2: 0.09489098936319351, L3: 0.23175984621047974, L4: 7.674939155578613, L5: 0.041423432528972626
Epoch 4000, Loss: 7.89483642578125, Losses: L1: 0.5150268077850342, L2: 0.08801862597465515, L3: 0.22046446800231934, L4: 6.994481563568115, L5: 0.038422588258981705
Epoch 4500, Loss: 7.3939008712768555, Losses: L1: 0.4575173258781433, L2: 0.08298290520906448, L3: 0.2169421911239624, L4: 6.5632476806640625, L5: 0.03660539910197258
Epoch 5000, Loss: 7.097070217132568, Losses: L1: 0.43851158022880554, L2: 0.07974457740783691, L3: 0.2147693634033203, L4: 6.292609214782715, L5: 0.035717692226171494
Epoch 5500, Loss: 6.928798198699951, Losses: L1: 0.44315096735954285, L2: 0.07799317687749863, L3: 0.21209800243377686, L4: 6.124061107635498, L5: 0.03574744239449501
Epoch 6000, Loss: 6.821861267089844, Losses: L1: 0.4435068666934967, L2: 0.07603466510772705, L3: 0.21147310733795166, L4: 6.020242214202881, L5: 0.03530217334628105
Epoch 6500, Loss: 6.7461981773376465, Losses: L1: 0.44324183464050293, L2: 0.07494261115789413, L3: 0.21092361211776733, L4: 5.947010517120361, L5: 0.035039886832237244
Epoch 7000, Loss: 6.691409587860107, Losses: L1: 0.4455041289329529, L2: 0.07445264607667923, L3: 0.21009016036987305, L4: 5.891424179077148, L5: 0.0349692739546299
Epoch 7500, Loss: 6.636767387390137, Losses: L1: 0.43408113718032837, L2: 0.0726647675037384, L3: 0.2103644609451294, L4: 5.8501081466674805, L5: 0.03477425500750542
Epoch 8000, Loss: 6.609742164611816, Losses: L1: 0.4350355565547943, L2: 0.07265398651361465, L3: 0.20976245403289795, L4: 5.822713851928711, L5: 0.03478819876909256
Epoch 8500, Loss: 6.589892387390137, Losses: L1: 0.43488314747810364, L2: 0.07249340415000916, L3: 0.2096150517463684, L4: 5.803455352783203, L5: 0.03472273796796799
Epoch 9000, Loss: 6.576242923736572, Losses: L1: 0.43505778908729553, L2: 0.07242922484874725, L3: 0.209486722946167, L4: 5.789901256561279, L5: 0.03468386083841324
Epoch 9500, Loss: 6.566722393035889, Losses: L1: 0.43561652302742004, L2: 0.07236471027135849, L3: 0.20938801765441895, L4: 5.780043601989746, L5: 0.03465483337640762
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020197868347168, Constraint losses: L1: 18.42068099975586, L2: 0.0005924631841480732, L3: 1.0005924701690674, L4: 1.0005923509597778
Epoch 500, Loss: 0.002166051883250475, Constraint losses: L1: -1.0440717935562134, L2: 0.0, L3: 0.002604186534881592, L4: 0.0006059370934963226
Epoch 1000, Loss: 0.0012599942274391651, Constraint losses: L1: -1.1157842874526978, L2: 0.0, L3: 0.002187669277191162, L4: 0.00018810940673574805
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.018357753753662, Constraint losses: L1: 17.92824363708496, L2: 0.0002514639054425061, L3: 1.0000886917114258, L4: 1.000089406967163
Epoch 500, Loss: 0.0022029620595276356, Constraint losses: L1: -1.0231683254241943, L2: 0.0, L3: 0.0026121139526367188, L4: 0.0006140164332464337
Epoch 1000, Loss: 0.0013224756112322211, Constraint losses: L1: -1.0674184560775757, L2: 0.0, L3: 0.002194643020629883, L4: 0.00019525105017237365
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 136.86080932617188, Losses: L1: 5.531201362609863, L2: 0.0, L3: 0.9958745241165161, L4: 65.11518859863281, L5: 0.2067365199327469
Epoch 500, Loss: 3.859874963760376, Losses: L1: 0.915571928024292, L2: 0.11712981015443802, L3: 0.06111156940460205, L4: 1.370396375656128, L5: 0.05053766071796417
Epoch 1000, Loss: 7.315189838409424, Losses: L1: 2.675367832183838, L2: 0.10801450163125992, L3: 0.08285832405090332, L4: 2.204812526702881, L5: 0.0786486566066742
Epoch 1500, Loss: 3.814371347427368, Losses: L1: 0.5761804580688477, L2: 0.06741897761821747, L3: 0.05593991279602051, L4: 1.5442739725112915, L5: 0.052568186074495316
Epoch 2000, Loss: 3.1159651279449463, Losses: L1: 0.3796814978122711, L2: 0.04514584690332413, L3: 0.05608320236206055, L4: 1.3120169639587402, L5: 0.022041212767362595
Epoch 2500, Loss: 1.551673412322998, Losses: L1: 0.4525146782398224, L2: 0.055018991231918335, L3: 0.04637110233306885, L4: 0.49191659688949585, L5: 0.027870986610651016
Epoch 3000, Loss: 1.0764816999435425, Losses: L1: 0.35009339451789856, L2: 0.05049974098801613, L3: 0.047446250915527344, L4: 0.30714818835258484, L5: 0.02829197235405445
Epoch 3500, Loss: 0.8659874796867371, Losses: L1: 0.3416503667831421, L2: 0.047288928180933, L3: 0.04761147499084473, L4: 0.20772913098335266, L5: 0.027956875041127205
Epoch 4000, Loss: 0.8067053556442261, Losses: L1: 0.334188848733902, L2: 0.04727216437458992, L3: 0.047254323959350586, L4: 0.18219561874866486, L5: 0.027197550982236862
Epoch 4500, Loss: 0.77400141954422, Losses: L1: 0.3302532434463501, L2: 0.046065863221883774, L3: 0.0472264289855957, L4: 0.16842949390411377, L5: 0.02719375491142273
Epoch 5000, Loss: 0.7422335147857666, Losses: L1: 0.32769763469696045, L2: 0.045425139367580414, L3: 0.047147274017333984, L4: 0.15434643626213074, L5: 0.02654118649661541
Epoch 5500, Loss: 0.7319853901863098, Losses: L1: 0.3264758586883545, L2: 0.04464907944202423, L3: 0.04718327522277832, L4: 0.1502554714679718, L5: 0.026332439854741096
Epoch 6000, Loss: 0.7260611057281494, Losses: L1: 0.32516711950302124, L2: 0.04449976608157158, L3: 0.04709911346435547, L4: 0.1480802297592163, L5: 0.02626936510205269
Epoch 6500, Loss: 0.7206435203552246, Losses: L1: 0.3241215944290161, L2: 0.04431445151567459, L3: 0.04706728458404541, L4: 0.14604288339614868, L5: 0.026108870282769203
Epoch 7000, Loss: 0.7167767286300659, Losses: L1: 0.3236643970012665, L2: 0.044099606573581696, L3: 0.04705381393432617, L4: 0.14446881413459778, L5: 0.026042547076940536
Epoch 7500, Loss: 0.7148830890655518, Losses: L1: 0.3233502209186554, L2: 0.04393992945551872, L3: 0.04703456163406372, L4: 0.14378602802753448, L5: 0.025972649455070496
Epoch 8000, Loss: 0.7126973867416382, Losses: L1: 0.3232080340385437, L2: 0.04383143037557602, L3: 0.0470118522644043, L4: 0.14283215999603271, L5: 0.025963598862290382
Epoch 8500, Loss: 0.7116910815238953, Losses: L1: 0.3230264484882355, L2: 0.04380879923701286, L3: 0.0469895601272583, L4: 0.14244623482227325, L5: 0.02594771608710289
Epoch 9000, Loss: 0.7108821272850037, Losses: L1: 0.32294753193855286, L2: 0.04374990239739418, L3: 0.046977221965789795, L4: 0.14212137460708618, L5: 0.025929497554898262
Epoch 9500, Loss: 0.7103893160820007, Losses: L1: 0.32288259267807007, L2: 0.04372355341911316, L3: 0.04696667194366455, L4: 0.1419273167848587, L5: 0.025923674926161766
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.02707576751709, Constraint losses: L1: 18.42068099975586, L2: 0.002884817309677601, L3: 1.002884864807129, L4: 1.0028854608535767
Epoch 500, Loss: 0.002009062562137842, Constraint losses: L1: -1.1108880043029785, L2: 0.0, L3: 0.0025593042373657227, L4: 0.0005606465274468064
Epoch 1000, Loss: 0.0012544189812615514, Constraint losses: L1: -1.1148655414581299, L2: 0.0, L3: 0.0021843910217285156, L4: 0.00018489363719709218
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.023772954940796, Constraint losses: L1: 18.42068099975586, L2: 0.0017839298816397786, L3: 1.0017839670181274, L4: 1.001784324645996
Epoch 500, Loss: 0.002111375331878662, Constraint losses: L1: -1.0246000289916992, L2: 0.0, L3: 0.002567112445831299, L4: 0.0005688628880307078
Epoch 1000, Loss: 0.001292440458200872, Constraint losses: L1: -1.0709617137908936, L2: 0.0, L3: 0.0021814703941345215, L4: 0.00018193188589066267
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 163.1797637939453, Losses: L1: 14.617385864257812, L2: 0.001754061901010573, L3: 1.001150369644165, L4: 73.65361022949219, L5: 0.252257376909256
Epoch 500, Loss: 6.293437957763672, Losses: L1: 1.0306648015975952, L2: 0.09130685031414032, L3: 0.07582950592041016, L4: 2.5223989486694336, L5: 0.05083904787898064
Epoch 1000, Loss: 6.970994472503662, Losses: L1: 1.7794283628463745, L2: 0.11129502952098846, L3: 0.10715395212173462, L4: 2.4454503059387207, L5: 0.08221660554409027
Epoch 1500, Loss: 95.0492935180664, Losses: L1: 5.8154802322387695, L2: 0.7444573640823364, L3: 0.9915962219238281, L4: 43.66437911987305, L5: 0.1689966320991516
Epoch 2000, Loss: 18.75103187561035, Losses: L1: 2.2646074295043945, L2: 2.358449935913086, L3: 0.21844935417175293, L4: 6.872156143188477, L5: 0.16521301865577698
Epoch 2500, Loss: 7.223373889923096, Losses: L1: 1.5023752450942993, L2: 0.774097204208374, L3: 0.15544939041137695, L4: 2.3637523651123047, L5: 0.06394699960947037
Epoch 3000, Loss: 17.330825805664062, Losses: L1: 1.3217450380325317, L2: 0.9856117963790894, L3: 0.2793823480606079, L4: 7.327165603637695, L5: 0.08975596725940704
Epoch 3500, Loss: 12.026861190795898, Losses: L1: 1.7782493829727173, L2: 0.45988690853118896, L3: 0.201532244682312, L4: 4.768433570861816, L5: 0.050325531512498856
Epoch 4000, Loss: 9.428138732910156, Losses: L1: 1.6416494846343994, L2: 0.47562772035598755, L3: 0.1685270071029663, L4: 3.5480363368988037, L5: 0.046262141317129135
Epoch 4500, Loss: 8.172014236450195, Losses: L1: 1.5460206270217896, L2: 0.5078252553939819, L3: 0.1541544795036316, L4: 2.9590296745300293, L5: 0.045954637229442596
Epoch 5000, Loss: 7.615176677703857, Losses: L1: 1.545365810394287, L2: 0.4761204123497009, L3: 0.1440119743347168, L4: 2.7032382488250732, L5: 0.04320196434855461
Epoch 5500, Loss: 7.253560543060303, Losses: L1: 1.4961093664169312, L2: 0.456131249666214, L3: 0.13901138305664062, L4: 2.560298204421997, L5: 0.04171205312013626
Epoch 6000, Loss: 6.990183353424072, Losses: L1: 1.4488648176193237, L2: 0.43543577194213867, L3: 0.13466018438339233, L4: 2.4652552604675293, L5: 0.040711838752031326
Epoch 6500, Loss: 6.741678237915039, Losses: L1: 1.4200283288955688, L2: 0.40451955795288086, L3: 0.12976610660552979, L4: 2.3742048740386963, L5: 0.03895474225282669
Epoch 7000, Loss: 6.6658525466918945, Losses: L1: 1.4176584482192993, L2: 0.4014681577682495, L3: 0.12940239906311035, L4: 2.3392693996429443, L5: 0.038784924894571304
Epoch 7500, Loss: 6.556406021118164, Losses: L1: 1.368064522743225, L2: 0.3995057940483093, L3: 0.12871038913726807, L4: 2.310739755630493, L5: 0.038645658642053604
Epoch 8000, Loss: 6.491887092590332, Losses: L1: 1.35480535030365, L2: 0.3958522081375122, L3: 0.12773942947387695, L4: 2.2878990173339844, L5: 0.0376921072602272
Epoch 8500, Loss: 6.469747066497803, Losses: L1: 1.3496034145355225, L2: 0.3982381522655487, L3: 0.12782645225524902, L4: 2.2778801918029785, L5: 0.038318634033203125
Epoch 9000, Loss: 6.4206719398498535, Losses: L1: 1.2673308849334717, L2: 0.39380306005477905, L3: 0.1277158260345459, L4: 2.2969048023223877, L5: 0.038012437522411346
Epoch 9500, Loss: 6.369969844818115, Losses: L1: 1.245802879333496, L2: 0.39451804757118225, L3: 0.1287541389465332, L4: 2.2817609310150146, L5: 0.037373073399066925
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0316338539123535, Constraint losses: L1: 18.42068099975586, L2: 0.0044042207300662994, L3: 1.0044041872024536, L4: 1.0044047832489014
Epoch 500, Loss: 0.0023882328532636166, Constraint losses: L1: -1.0912102460861206, L2: 0.0, L3: 0.0027387142181396484, L4: 0.0007407289231196046
Epoch 1000, Loss: 0.001360383816063404, Constraint losses: L1: -1.1178827285766602, L2: 0.0, L3: 0.0022388696670532227, L4: 0.00023939687525853515
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.016836643218994, Constraint losses: L1: 16.0402889251709, L2: 0.0006617208127863705, L3: 1.000067114830017, L4: 1.0000675916671753
Epoch 500, Loss: 0.0022794215474277735, Constraint losses: L1: -1.0481994152069092, L2: 0.0, L3: 0.0026628971099853516, L4: 0.000664723920635879
Epoch 1000, Loss: 0.0013579254737123847, Constraint losses: L1: -1.0706543922424316, L2: 0.0, L3: 0.0022140145301818848, L4: 0.0002145654143532738
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 171.53326416015625, Losses: L1: 9.19040584564209, L2: 2.4692137230886146e-05, L3: 0.9993446469306946, L4: 80.38048553466797, L5: 0.2912610173225403
Epoch 500, Loss: 5.032626152038574, Losses: L1: 1.0172626972198486, L2: 0.07335657626390457, L3: 0.09415054321289062, L4: 1.9103785753250122, L5: 0.01354947779327631
Epoch 1000, Loss: 26.29280662536621, Losses: L1: 3.7086238861083984, L2: 0.28809309005737305, L3: 0.20452988147735596, L4: 10.931427001953125, L5: 0.11435292661190033
Epoch 1500, Loss: 15.289830207824707, Losses: L1: 2.4646964073181152, L2: 0.20446188747882843, L3: 0.13651055097579956, L4: 6.170670032501221, L5: 0.07141067832708359
Epoch 2000, Loss: 6.091563701629639, Losses: L1: 0.7405742406845093, L2: 0.0803423821926117, L3: 0.12242257595062256, L4: 2.5270767211914062, L5: 0.04703545197844505
Epoch 2500, Loss: 17.650060653686523, Losses: L1: 2.89811635017395, L2: 0.7095584869384766, L3: 0.14000177383422852, L4: 6.851589202880859, L5: 0.09960269927978516
Epoch 3000, Loss: 3.1555769443511963, Losses: L1: 0.4475221335887909, L2: 0.08812767267227173, L3: 0.11726200580596924, L4: 1.2229267358779907, L5: 0.028405755758285522
Epoch 3500, Loss: 2.598856210708618, Losses: L1: 0.2907750904560089, L2: 0.07064617425203323, L3: 0.1130075454711914, L4: 1.0356619358062744, L5: 0.026551665738224983
Epoch 4000, Loss: 2.3985908031463623, Losses: L1: 0.2530549466609955, L2: 0.07232008874416351, L3: 0.10806435346603394, L4: 0.9579946398735046, L5: 0.024581070989370346
Epoch 4500, Loss: 2.26051926612854, Losses: L1: 0.22632353007793427, L2: 0.0727248415350914, L3: 0.10596644878387451, L4: 0.9039103388786316, L5: 0.023841800168156624
Epoch 5000, Loss: 2.1652002334594727, Losses: L1: 0.21776802837848663, L2: 0.07343719154596329, L3: 0.10480034351348877, L4: 0.8610368967056274, L5: 0.023560408502817154
Epoch 5500, Loss: 2.098578929901123, Losses: L1: 0.19514095783233643, L2: 0.07388906180858612, L3: 0.10387217998504639, L4: 0.8398258090019226, L5: 0.023012546822428703
Epoch 6000, Loss: 2.0607783794403076, Losses: L1: 0.18871192634105682, L2: 0.07365694642066956, L3: 0.10318803787231445, L4: 0.8250428438186646, L5: 0.022567853331565857
Epoch 6500, Loss: 2.0366370677948, Losses: L1: 0.18536214530467987, L2: 0.07332923263311386, L3: 0.10264086723327637, L4: 0.8153079748153687, L5: 0.022344453260302544
Epoch 7000, Loss: 2.0182483196258545, Losses: L1: 0.18323560059070587, L2: 0.07318396866321564, L3: 0.10219532251358032, L4: 0.8076138496398926, L5: 0.02220289036631584
Epoch 7500, Loss: 2.0064055919647217, Losses: L1: 0.18170195817947388, L2: 0.07305321842432022, L3: 0.10194116830825806, L4: 0.8027186393737793, L5: 0.022136008366942406
Epoch 8000, Loss: 1.998099446296692, Losses: L1: 0.1807275116443634, L2: 0.07294370234012604, L3: 0.10172712802886963, L4: 0.7992721796035767, L5: 0.02207835018634796
Epoch 8500, Loss: 1.9916383028030396, Losses: L1: 0.18012672662734985, L2: 0.07285714149475098, L3: 0.10154402256011963, L4: 0.7965160608291626, L5: 0.022039130330085754
Epoch 9000, Loss: 1.9874290227890015, Losses: L1: 0.17977124452590942, L2: 0.07278410345315933, L3: 0.10140573978424072, L4: 0.7947207689285278, L5: 0.022013168781995773
Epoch 9500, Loss: 1.9844980239868164, Losses: L1: 0.1796271800994873, L2: 0.07269284129142761, L3: 0.10130941867828369, L4: 0.7934420108795166, L5: 0.02199224755167961
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.024322509765625, Constraint losses: L1: 18.42068099975586, L2: 0.00196722405962646, L3: 1.001967191696167, L4: 1.0019675493240356
Epoch 500, Loss: 0.002260094042867422, Constraint losses: L1: -1.0969470739364624, L2: 0.0, L3: 0.0026775598526000977, L4: 0.0006794814253225923
Epoch 1000, Loss: 0.0013132604071870446, Constraint losses: L1: -1.1176146268844604, L2: 0.0, L3: 0.002215087413787842, L4: 0.00021578770247288048
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0084166526794434, Constraint losses: L1: 8.747068405151367, L2: 0.0, L3: 0.9998348355293274, L4: 0.9998347759246826
Epoch 500, Loss: 0.0024108157958835363, Constraint losses: L1: -1.0584620237350464, L2: 0.0, L3: 0.0027337074279785156, L4: 0.0007355704437941313
Epoch 1000, Loss: 0.0014119758270680904, Constraint losses: L1: -1.0717158317565918, L2: 0.0, L3: 0.0022415518760681152, L4: 0.00024213976575993001
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 59.14870071411133, Losses: L1: 18.295188903808594, L2: 0.014130407012999058, L3: 1.0141290426254272, L4: 77.3427963256836, L5: 0.27946069836616516
Epoch 500, Loss: 8.176444053649902, Losses: L1: 1.3836590051651, L2: 0.3029181957244873, L3: 0.2313317060470581, L4: 11.938422203063965, L5: 0.11598427593708038
Epoch 1000, Loss: 5.600856781005859, Losses: L1: 1.0506082773208618, L2: 0.10561437904834747, L3: 0.28383392095565796, L4: 7.69957971572876, L5: 0.05435234308242798
Epoch 1500, Loss: 2.481224536895752, Losses: L1: 0.22036007046699524, L2: 0.023609085008502007, L3: 0.14545422792434692, L4: 3.8646814823150635, L5: 0.02801235020160675
Epoch 2000, Loss: 1.6563694477081299, Losses: L1: 0.22571620345115662, L2: 0.024572527036070824, L3: 0.11163878440856934, L4: 2.3411402702331543, L5: 0.024465978145599365
Epoch 2500, Loss: 1.3561592102050781, Losses: L1: 0.1703301966190338, L2: 0.02107406035065651, L3: 0.11059677600860596, L4: 1.8663841485977173, L5: 0.020738644525408745
Epoch 3000, Loss: 1.236771821975708, Losses: L1: 0.02628631703555584, L2: 0.019313717260956764, L3: 0.10689890384674072, L4: 1.9330116510391235, L5: 0.021736443042755127
Epoch 3500, Loss: 1.0441519021987915, Losses: L1: 0.01047917827963829, L2: 0.016825305297970772, L3: 0.1056641936302185, L4: 1.5942128896713257, L5: 0.016825146973133087
Epoch 4000, Loss: 0.9967974424362183, Losses: L1: 0.002464642748236656, L2: 0.016654370352625847, L3: 0.10350298881530762, L4: 1.523890495300293, L5: 0.01745438203215599
Epoch 4500, Loss: 0.9509682059288025, Losses: L1: -0.006653281394392252, L2: 0.01783987693488598, L3: 0.102597177028656, L4: 1.4523576498031616, L5: 0.016816815361380577
Epoch 5000, Loss: 0.9262493252754211, Losses: L1: -0.011650875210762024, L2: 0.01877450942993164, L3: 0.10164785385131836, L4: 1.415025234222412, L5: 0.01663469523191452
Epoch 5500, Loss: 0.9109367728233337, Losses: L1: -0.014225361868739128, L2: 0.01933201029896736, L3: 0.10058695077896118, L4: 1.3927416801452637, L5: 0.016570819541811943
Epoch 6000, Loss: 0.8978735208511353, Losses: L1: -0.018718115985393524, L2: 0.01984340138733387, L3: 0.10033953189849854, L4: 1.3755762577056885, L5: 0.016562046483159065
Epoch 6500, Loss: 0.8876680731773376, Losses: L1: -0.020822346210479736, L2: 0.0202877689152956, L3: 0.10008502006530762, L4: 1.3595900535583496, L5: 0.01647515594959259
Epoch 7000, Loss: 0.8818394541740417, Losses: L1: -0.022247692570090294, L2: 0.02048257179558277, L3: 0.09982085227966309, L4: 1.3514864444732666, L5: 0.016439376398921013
Epoch 7500, Loss: 0.8780212998390198, Losses: L1: -0.02316148951649666, L2: 0.02058878168463707, L3: 0.09955102205276489, L4: 1.346537470817566, L5: 0.016446474939584732
Epoch 8000, Loss: 0.8750488758087158, Losses: L1: -0.023882366716861725, L2: 0.02063179202377796, L3: 0.09933483600616455, L4: 1.342860460281372, L5: 0.016399115324020386
Epoch 8500, Loss: 0.8729908466339111, Losses: L1: -0.024524586275219917, L2: 0.0206923708319664, L3: 0.09914255142211914, L4: 1.3406713008880615, L5: 0.016404656693339348
Epoch 9000, Loss: 0.8715835213661194, Losses: L1: -0.0249576885253191, L2: 0.02074580267071724, L3: 0.09902113676071167, L4: 1.339097499847412, L5: 0.016408748924732208
Epoch 9500, Loss: 0.8706207871437073, Losses: L1: -0.025279739871621132, L2: 0.020800424739718437, L3: 0.09894514083862305, L4: 1.3380111455917358, L5: 0.016408532857894897
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0207931995391846, Constraint losses: L1: 18.41224479675293, L2: 0.0008373045129701495, L3: 1.00077223777771, L4: 1.000771403312683
Epoch 500, Loss: 0.002661817241460085, Constraint losses: L1: -0.9028997421264648, L2: 0.0, L3: 0.002781212329864502, L4: 0.0007835045689716935
Epoch 1000, Loss: 0.0013289861381053925, Constraint losses: L1: -1.106486439704895, L2: 0.0, L3: 0.002217411994934082, L4: 0.00021806074073538184
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.012620210647583, Constraint losses: L1: 12.640318870544434, L2: 2.5433540940866806e-05, L3: 0.9999772310256958, L4: 0.9999772310256958
Epoch 500, Loss: 0.0026083551347255707, Constraint losses: L1: -1.053125023841858, L2: 0.0, L3: 0.0028298497200012207, L4: 0.0008316305465996265
Epoch 1000, Loss: 0.001470898394472897, Constraint losses: L1: -1.0710152387619019, L2: 0.0, L3: 0.002270638942718506, L4: 0.0002712746791075915
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 45.37605285644531, Losses: L1: 6.071136951446533, L2: 2.001618304348085e-05, L3: 0.9941881895065308, L4: 74.1379623413086, L5: 0.2475399374961853
Epoch 500, Loss: 4.780608654022217, Losses: L1: 1.4648760557174683, L2: 0.16663341224193573, L3: 0.16221296787261963, L4: 5.520005702972412, L5: 0.0646706074476242
Epoch 1000, Loss: 1.4393702745437622, Losses: L1: 0.11103253066539764, L2: 0.09064699709415436, L3: 0.09776872396469116, L4: 2.0108277797698975, L5: 0.03673949092626572
Epoch 1500, Loss: 0.78837651014328, Losses: L1: 0.02959754317998886, L2: 0.08927804976701736, L3: 0.0795518159866333, L4: 0.9756122827529907, L5: 0.02259114570915699
Epoch 2000, Loss: 1.0777908563613892, Losses: L1: 0.11146799474954605, L2: 0.09136906266212463, L3: 0.09940129518508911, L4: 1.3091914653778076, L5: 0.02155555598437786
Epoch 2500, Loss: 1.9989560842514038, Losses: L1: 0.4731255769729614, L2: 0.0824127048254013, L3: 0.1501958966255188, L4: 2.2491116523742676, L5: 0.018470188602805138
Epoch 3000, Loss: 1.308536171913147, Losses: L1: 0.08716686815023422, L2: 0.031108763068914413, L3: 0.13088065385818481, L4: 1.8245137929916382, L5: 0.016242383047938347
Epoch 3500, Loss: 1.1384071111679077, Losses: L1: 0.01597972773015499, L2: 0.02706656977534294, L3: 0.12306571006774902, L4: 1.6661168336868286, L5: 0.01617097482085228
Epoch 4000, Loss: 1.0313271284103394, Losses: L1: -0.02123250998556614, L2: 0.02523806318640709, L3: 0.12066900730133057, L4: 1.539247751235962, L5: 0.016359718516469002
Epoch 4500, Loss: 0.9580073356628418, Losses: L1: -0.0317930243909359, L2: 0.02576553262770176, L3: 0.11691534519195557, L4: 1.427975058555603, L5: 0.016216622665524483
Epoch 5000, Loss: 0.8756713271141052, Losses: L1: -0.049541424959897995, L2: 0.02644105814397335, L3: 0.11398845911026001, L4: 1.3089181184768677, L5: 0.016335714608430862
Epoch 5500, Loss: 0.8139447569847107, Losses: L1: -0.05145496875047684, L2: 0.029121141880750656, L3: 0.11044490337371826, L4: 1.197784185409546, L5: 0.016496691852808
Epoch 6000, Loss: 0.7588194012641907, Losses: L1: -0.05632907152175903, L2: 0.03365476429462433, L3: 0.10748255252838135, L4: 1.100000023841858, L5: 0.016528621315956116
Epoch 6500, Loss: 0.7267159819602966, Losses: L1: -0.061855100095272064, L2: 0.03791315108537674, L3: 0.10665696859359741, L4: 1.0419105291366577, L5: 0.01638874225318432
Epoch 7000, Loss: 0.710447371006012, Losses: L1: -0.06454174965620041, L2: 0.04043735936284065, L3: 0.10610318183898926, L4: 1.0124047994613647, L5: 0.016143018379807472
Epoch 7500, Loss: 0.7023323774337769, Losses: L1: -0.06613115221261978, L2: 0.04199770465493202, L3: 0.10571485757827759, L4: 0.9981160163879395, L5: 0.015978112816810608
Epoch 8000, Loss: 0.6969808340072632, Losses: L1: -0.06706193834543228, L2: 0.04280047491192818, L3: 0.10556924343109131, L4: 0.9885094165802002, L5: 0.015849141404032707
Epoch 8500, Loss: 0.693466305732727, Losses: L1: -0.06751853227615356, L2: 0.043306030333042145, L3: 0.10538673400878906, L4: 0.9822626113891602, L5: 0.015774032101035118
Epoch 9000, Loss: 0.6910521984100342, Losses: L1: -0.06769400835037231, L2: 0.04361417889595032, L3: 0.10523080825805664, L4: 0.9779719114303589, L5: 0.015684472396969795
Epoch 9500, Loss: 0.6894525289535522, Losses: L1: -0.06778392195701599, L2: 0.043804239481687546, L3: 0.10502737760543823, L4: 0.9754742383956909, L5: 0.01564031094312668
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0037147998809814, Constraint losses: L1: 6.543044090270996, L2: 0.0, L3: 0.9985859394073486, L4: 0.9985858798027039
Epoch 500, Loss: 0.0024116032291203737, Constraint losses: L1: -1.112518072128296, L2: 0.0, L3: 0.0027611851692199707, L4: 0.0007629361934959888
Epoch 1000, Loss: 0.001386953517794609, Constraint losses: L1: -1.1166541576385498, L2: 0.0, L3: 0.0022515058517456055, L4: 0.00025210189050994813
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.02016019821167, Constraint losses: L1: 18.42068099975586, L2: 0.0005867098807357252, L3: 1.0005759000778198, L4: 1.0005768537521362
Epoch 500, Loss: 0.002190469531342387, Constraint losses: L1: -1.0479680299758911, L2: 0.0, L3: 0.0026183724403381348, L4: 0.0006200651405379176
Epoch 1000, Loss: 0.001325557241216302, Constraint losses: L1: -1.0718108415603638, L2: 0.0, L3: 0.002198457717895508, L4: 0.00019891036208719015
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 64.27607727050781, Losses: L1: 18.42068099975586, L2: 0.0032572257332503796, L3: 1.0032572746276855, L4: 86.37522888183594, L5: 0.32900306582450867
Epoch 500, Loss: 10.987603187561035, Losses: L1: 4.3593549728393555, L2: 0.5077175498008728, L3: 0.26978516578674316, L4: 10.57508659362793, L5: 0.14670829474925995
Epoch 1000, Loss: 4.410140037536621, Losses: L1: 1.6888309717178345, L2: 0.09706804156303406, L3: 0.10092192888259888, L4: 4.625518798828125, L5: 0.05481892079114914
Epoch 1500, Loss: 6.562393665313721, Losses: L1: 1.072972297668457, L2: 0.14259785413742065, L3: 0.26238834857940674, L4: 9.415483474731445, L5: 0.05715251341462135
Epoch 2000, Loss: 7.902224063873291, Losses: L1: 3.3784637451171875, L2: 0.17701083421707153, L3: 0.2267712950706482, L4: 7.371856689453125, L5: 0.10363930463790894
Epoch 2500, Loss: 45.87067794799805, Losses: L1: 18.366729736328125, L2: 0.012477613054215908, L3: 1.0117443799972534, L4: 49.77561950683594, L5: 0.2900863587856293
Epoch 3000, Loss: 13.313384056091309, Losses: L1: 4.886138916015625, L2: 0.5277596116065979, L3: 0.31653618812561035, L4: 14.092923164367676, L5: 0.10997577756643295
Epoch 3500, Loss: 6.1344451904296875, Losses: L1: 1.082008719444275, L2: 0.2448183000087738, L3: 0.2792346477508545, L4: 8.249285697937012, L5: 0.062252990901470184
Epoch 4000, Loss: 4.103855133056641, Losses: L1: 0.3572095036506653, L2: 0.24298834800720215, L3: 0.2287890911102295, L4: 5.900705814361572, L5: 0.04786296188831329
Epoch 4500, Loss: 3.449366807937622, Losses: L1: 0.32166358828544617, L2: 0.19085343182086945, L3: 0.20723599195480347, L4: 4.888989448547363, L5: 0.03894155099987984
Epoch 5000, Loss: 3.178957462310791, Losses: L1: 0.35537201166152954, L2: 0.16505278646945953, L3: 0.1970440149307251, L4: 4.394654750823975, L5: 0.03355856239795685
Epoch 5500, Loss: 2.999657392501831, Losses: L1: 0.3369329571723938, L2: 0.152518630027771, L3: 0.1922958493232727, L4: 4.120757102966309, L5: 0.03261784836649895
Epoch 6000, Loss: 2.9030776023864746, Losses: L1: 0.33764734864234924, L2: 0.1472369134426117, L3: 0.18842369318008423, L4: 3.9538164138793945, L5: 0.03221898898482323
Epoch 6500, Loss: 2.837308168411255, Losses: L1: 0.3363531827926636, L2: 0.1442994475364685, L3: 0.1856173276901245, L4: 3.841637134552002, L5: 0.03230118378996849
Epoch 7000, Loss: 2.7932379245758057, Losses: L1: 0.3362483084201813, L2: 0.1420617699623108, L3: 0.18390852212905884, L4: 3.765373706817627, L5: 0.03221191465854645
Epoch 7500, Loss: 2.762320041656494, Losses: L1: 0.3350036144256592, L2: 0.14095668494701385, L3: 0.18231791257858276, L4: 3.714658737182617, L5: 0.032197270542383194
Epoch 8000, Loss: 2.7395570278167725, Losses: L1: 0.3343236744403839, L2: 0.14002199470996857, L3: 0.18114817142486572, L4: 3.677011489868164, L5: 0.03220461308956146
Epoch 8500, Loss: 2.722964286804199, Losses: L1: 0.33248597383499146, L2: 0.13969634473323822, L3: 0.1802128553390503, L4: 3.6513590812683105, L5: 0.03233836218714714
Epoch 9000, Loss: 2.7111504077911377, Losses: L1: 0.3317265808582306, L2: 0.13910767436027527, L3: 0.17983484268188477, L4: 3.6317203044891357, L5: 0.03239315003156662
Epoch 9500, Loss: 2.7027370929718018, Losses: L1: 0.331368625164032, L2: 0.1387353390455246, L3: 0.17948311567306519, L4: 3.617793560028076, L5: 0.032384999096393585
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.02398943901062, Constraint losses: L1: 18.42068099975586, L2: 0.0018560594180598855, L3: 1.0018560886383057, L4: 1.0018565654754639
Epoch 500, Loss: 0.0024632872082293034, Constraint losses: L1: -1.0556449890136719, L2: 0.0, L3: 0.0027582645416259766, L4: 0.0007606677827425301
Epoch 1000, Loss: 0.0013636467047035694, Constraint losses: L1: -1.118116021156311, L2: 0.0, L3: 0.002240598201751709, L4: 0.00024116459826473147
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9978234767913818, Constraint losses: L1: 5.511760711669922, L2: 0.0, L3: 0.9961562752723694, L4: 0.9961553812026978
Epoch 500, Loss: 0.0019982820376753807, Constraint losses: L1: -1.0260200500488281, L2: 0.0, L3: 0.0025113821029663086, L4: 0.0005129199707880616
Epoch 1000, Loss: 0.0012479245197027922, Constraint losses: L1: -1.0715484619140625, L2: 0.0, L3: 0.0021595358848571777, L4: 0.0001599372480995953
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 92.07491302490234, Losses: L1: 7.013596057891846, L2: 0.0, L3: 0.9990925192832947, L4: 82.90980529785156, L5: 0.30664968490600586
Epoch 500, Loss: 11.310710906982422, Losses: L1: 3.6435747146606445, L2: 0.29978469014167786, L3: 0.11084973812103271, L4: 7.106647491455078, L5: 0.07800783216953278
Epoch 1000, Loss: 8.688810348510742, Losses: L1: 4.7839202880859375, L2: 0.19252385199069977, L3: 0.12707215547561646, L4: 3.430027723312378, L5: 0.05638914182782173
Epoch 1500, Loss: 20.444570541381836, Losses: L1: 8.319586753845215, L2: 0.3372536897659302, L3: 0.30765289068222046, L4: 11.120376586914062, L5: 0.10409697145223618
Epoch 2000, Loss: 70.57152557373047, Losses: L1: 18.415925979614258, L2: 1.6887684306521322e-10, L3: 1.0, L4: 50.00364685058594, L5: 0.3039076626300812
Epoch 2500, Loss: 70.57048797607422, Losses: L1: 18.414831161499023, L2: 1.632990132005574e-10, L3: 1.0, L4: 50.00370788574219, L5: 0.3038923442363739
Epoch 3000, Loss: 70.56927490234375, Losses: L1: 18.413537979125977, L2: 1.6118750778559843e-10, L3: 1.0, L4: 50.00379943847656, L5: 0.30387255549430847
Epoch 3500, Loss: 70.56786346435547, Losses: L1: 18.412044525146484, L2: 1.6188088369784026e-10, L3: 1.0, L4: 50.0038948059082, L5: 0.30384960770606995
Epoch 4000, Loss: 70.56627655029297, Losses: L1: 18.410364151000977, L2: 1.6430201643657938e-10, L3: 1.0, L4: 50.004005432128906, L5: 0.303824782371521
Epoch 4500, Loss: 70.56453704833984, Losses: L1: 18.408519744873047, L2: 1.679243966101751e-10, L3: 1.0, L4: 50.00411605834961, L5: 0.3037991225719452
Epoch 5000, Loss: 70.56268310546875, Losses: L1: 18.40656852722168, L2: 1.7236603810921736e-10, L3: 1.0, L4: 50.00422668457031, L5: 0.3037736117839813
Epoch 5500, Loss: 70.5607681274414, Losses: L1: 18.404558181762695, L2: 1.7714940625523923e-10, L3: 1.0, L4: 50.00433349609375, L5: 0.30374911427497864
Epoch 6000, Loss: 70.55884552001953, Losses: L1: 18.402551651000977, L2: 1.8199841633759206e-10, L3: 1.0, L4: 50.004432678222656, L5: 0.3037261962890625
Epoch 6500, Loss: 70.55699157714844, Losses: L1: 18.400617599487305, L2: 1.8672131896213529e-10, L3: 1.0, L4: 50.004520416259766, L5: 0.3037053644657135
Epoch 7000, Loss: 70.55524444580078, Losses: L1: 18.398801803588867, L2: 1.912181246677136e-10, L3: 1.0, L4: 50.004600524902344, L5: 0.30368685722351074
Epoch 7500, Loss: 70.55366516113281, Losses: L1: 18.397159576416016, L2: 1.9520496330471815e-10, L3: 1.0, L4: 50.00467300415039, L5: 0.30367085337638855
Epoch 8000, Loss: 70.55225372314453, Losses: L1: 18.39569664001465, L2: 1.9873649947932392e-10, L3: 1.0, L4: 50.00473403930664, L5: 0.3036571145057678
Epoch 8500, Loss: 70.55104064941406, Losses: L1: 18.394433975219727, L2: 2.0168278158649855e-10, L3: 1.0, L4: 50.00477981567383, L5: 0.30364564061164856
Epoch 9000, Loss: 70.54999542236328, Losses: L1: 18.393360137939453, L2: 2.041959656917669e-10, L3: 1.0, L4: 50.00482177734375, L5: 0.3036361634731293
Epoch 9500, Loss: 70.54914093017578, Losses: L1: 18.392465591430664, L2: 2.0630262775878094e-10, L3: 1.0, L4: 50.00485610961914, L5: 0.30362844467163086
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.028337001800537, Constraint losses: L1: 18.42068099975586, L2: 0.003305313643068075, L3: 1.0033053159713745, L4: 1.0033056735992432
Epoch 500, Loss: 0.002283721696585417, Constraint losses: L1: -1.0383950471878052, L2: 0.0, L3: 0.002660036087036133, L4: 0.0006620808271691203
Epoch 1000, Loss: 0.0012821325799450278, Constraint losses: L1: -1.1179753541946411, L2: 0.0, L3: 0.0021997690200805664, L4: 0.00020033898181281984
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002595901489258, Constraint losses: L1: 6.258253574371338, L2: 0.0, L3: 0.9981688857078552, L4: 0.9981685876846313
Epoch 500, Loss: 0.0021964414045214653, Constraint losses: L1: -1.0393837690353394, L2: 0.0, L3: 0.002617061138153076, L4: 0.0006187640829011798
Epoch 1000, Loss: 0.0013266890309751034, Constraint losses: L1: -1.0714616775512695, L2: 0.0, L3: 0.0021988749504089355, L4: 0.00019927576067857444
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 88.27532196044922, Losses: L1: 18.42068099975586, L2: 0.002540028654038906, L3: 1.0025399923324585, L4: 67.62521362304688, L5: 0.22180819511413574
Epoch 500, Loss: 15.020124435424805, Losses: L1: 6.31648588180542, L2: 0.3323114216327667, L3: 0.2914109230041504, L4: 7.696079730987549, L5: 0.09242526441812515
Epoch 1000, Loss: 22.986562728881836, Losses: L1: 2.6437883377075195, L2: 2.578443765640259, L3: 0.35146069526672363, L4: 16.919565200805664, L5: 0.14184296131134033
Epoch 1500, Loss: 63.29510498046875, Losses: L1: 10.995556831359863, L2: 0.00031547684920951724, L3: 1.0000121593475342, L4: 49.994747161865234, L5: 0.304460346698761
Epoch 2000, Loss: 21.874338150024414, Losses: L1: 7.983890056610107, L2: 0.9360588788986206, L3: 0.33375871181488037, L4: 12.16133975982666, L5: 0.12553150951862335
Epoch 2500, Loss: 26.261287689208984, Losses: L1: 5.280386924743652, L2: 1.3775767087936401, L3: 0.030778467655181885, L4: 19.34872055053711, L5: 0.19304579496383667
Epoch 3000, Loss: 6.694995880126953, Losses: L1: 2.8036954402923584, L2: 0.2616509795188904, L3: 0.14957892894744873, L4: 3.2560012340545654, L5: 0.0744907334446907
Epoch 3500, Loss: 5.867214202880859, Losses: L1: 2.8262667655944824, L2: 0.19259464740753174, L3: 0.12226414680480957, L4: 2.5334534645080566, L5: 0.07037138193845749
Epoch 4000, Loss: 5.209259986877441, Losses: L1: 2.460036277770996, L2: 0.1883694976568222, L3: 0.10938429832458496, L4: 2.2691328525543213, L5: 0.07295291870832443
Epoch 4500, Loss: 5.085525035858154, Losses: L1: 2.432095766067505, L2: 0.1887464076280594, L3: 0.10518169403076172, L4: 2.181148052215576, L5: 0.07317100465297699
Epoch 5000, Loss: 5.01870584487915, Losses: L1: 2.416337490081787, L2: 0.18604663014411926, L3: 0.1028357744216919, L4: 2.1376872062683105, L5: 0.07296302914619446
Epoch 5500, Loss: 5.425198554992676, Losses: L1: 2.4982051849365234, L2: 0.1838286966085434, L3: 0.1091352105140686, L4: 2.4476754665374756, L5: 0.07721906900405884
Epoch 6000, Loss: 5.172209739685059, Losses: L1: 2.4660463333129883, L2: 0.18137969076633453, L3: 0.1086651086807251, L4: 2.2312281131744385, L5: 0.07622532546520233
Epoch 6500, Loss: 5.090314865112305, Losses: L1: 2.473493814468384, L2: 0.1813611388206482, L3: 0.10561412572860718, L4: 2.147969961166382, L5: 0.07626162469387054
Epoch 7000, Loss: 5.052789688110352, Losses: L1: 2.479588747024536, L2: 0.18207739293575287, L3: 0.10402828454971313, L4: 2.1066830158233643, L5: 0.07638377696275711
Epoch 7500, Loss: 5.02462911605835, Losses: L1: 2.4665489196777344, L2: 0.1813371628522873, L3: 0.1028096079826355, L4: 2.0946555137634277, L5: 0.07646848261356354
Epoch 8000, Loss: 5.016376495361328, Losses: L1: 2.4682910442352295, L2: 0.18130707740783691, L3: 0.10206973552703857, L4: 2.0860819816589355, L5: 0.0765569806098938
Epoch 8500, Loss: 5.011045932769775, Losses: L1: 2.4697883129119873, L2: 0.1815388947725296, L3: 0.1015978455543518, L4: 2.079918384552002, L5: 0.07660479843616486
Epoch 9000, Loss: 5.0071024894714355, Losses: L1: 2.4709317684173584, L2: 0.18171024322509766, L3: 0.10126709938049316, L4: 2.0752925872802734, L5: 0.07663404196500778
Epoch 9500, Loss: 5.004140377044678, Losses: L1: 2.4717910289764404, L2: 0.18181562423706055, L3: 0.10100436210632324, L4: 2.071871280670166, L5: 0.07665383070707321
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0167951583862305, Constraint losses: L1: 16.680883407592773, L2: 8.007749420357868e-05, L3: 1.0000170469284058, L4: 1.0000170469284058
Epoch 500, Loss: 0.002568292897194624, Constraint losses: L1: -1.0961111783981323, L2: 0.0, L3: 0.00283128023147583, L4: 0.0008331239223480225
Epoch 1000, Loss: 0.0014274315908551216, Constraint losses: L1: -1.1181868314743042, L2: 0.0, L3: 0.0022724270820617676, L4: 0.00027319142827764153
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.998255968093872, Constraint losses: L1: 5.563612937927246, L2: 0.0, L3: 0.9963463544845581, L4: 0.9963459372520447
Epoch 500, Loss: 0.0022165817208588123, Constraint losses: L1: -1.0590107440948486, L2: 0.0, L3: 0.002637028694152832, L4: 0.000638563884422183
Epoch 1000, Loss: 0.0013495705788955092, Constraint losses: L1: -1.071382999420166, L2: 0.0, L3: 0.002210259437561035, L4: 0.0002106941828969866
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 83.22600555419922, Losses: L1: 5.233651638031006, L2: 0.0, L3: 0.9940666556358337, L4: 75.48185729980469, L5: 0.2611820101737976
Epoch 500, Loss: 11.794407844543457, Losses: L1: 1.2411901950836182, L2: 0.0828179121017456, L3: 0.08973288536071777, L4: 10.100356101989746, L5: 0.09528888016939163
Epoch 1000, Loss: 8.903286933898926, Losses: L1: 1.3008012771606445, L2: 0.07913714647293091, L3: 0.18230897188186646, L4: 7.03489351272583, L5: 0.06191859021782875
Epoch 1500, Loss: 4.6696085929870605, Losses: L1: 0.3479682505130768, L2: 0.07844466716051102, L3: 0.1655738353729248, L4: 3.867614507675171, L5: 0.022216806188225746
Epoch 2000, Loss: 51.25138473510742, Losses: L1: 2.413301706314087, L2: 0.16174958646297455, L3: 0.8309895992279053, L4: 46.657081604003906, L5: 0.17863647639751434
Epoch 2500, Loss: 7.560046672821045, Losses: L1: 4.08893346786499, L2: 0.22372335195541382, L3: 0.17214828729629517, L4: 2.629018783569336, L5: 0.13703738152980804
Epoch 3000, Loss: 6.249845027923584, Losses: L1: 3.2609922885894775, L2: 0.15577062964439392, L3: 0.1438823938369751, L4: 2.2720754146575928, L5: 0.13662101328372955
Epoch 3500, Loss: 5.223525047302246, Losses: L1: 2.718634843826294, L2: 0.12310370802879333, L3: 0.13188952207565308, L4: 1.864786148071289, L5: 0.12661071121692657
Epoch 4000, Loss: 4.692744731903076, Losses: L1: 2.5587663650512695, L2: 0.10999242961406708, L3: 0.12744641304016113, L4: 1.5327264070510864, L5: 0.11818334460258484
Epoch 4500, Loss: 4.441511631011963, Losses: L1: 2.450437068939209, L2: 0.10724116116762161, L3: 0.12321615219116211, L4: 1.4114872217178345, L5: 0.1129569560289383
Epoch 5000, Loss: 4.2621636390686035, Losses: L1: 2.3715569972991943, L2: 0.10152482241392136, L3: 0.1205596923828125, L4: 1.3280243873596191, L5: 0.10996901243925095
Epoch 5500, Loss: 4.146884441375732, Losses: L1: 2.3061578273773193, L2: 0.099598728120327, L3: 0.1190805435180664, L4: 1.288567304611206, L5: 0.10719982534646988
Epoch 6000, Loss: 4.0662007331848145, Losses: L1: 2.2693073749542236, L2: 0.09833722561597824, L3: 0.11706078052520752, L4: 1.2536475658416748, L5: 0.10539361089468002
Epoch 6500, Loss: 3.9306838512420654, Losses: L1: 2.164313554763794, L2: 0.09442275017499924, L3: 0.1139061450958252, L4: 1.2360867261886597, L5: 0.10402429103851318
Epoch 7000, Loss: 3.8771331310272217, Losses: L1: 2.136320114135742, L2: 0.0924035906791687, L3: 0.1128692626953125, L4: 1.2159738540649414, L5: 0.10334852337837219
Epoch 7500, Loss: 3.8192813396453857, Losses: L1: 2.091480255126953, L2: 0.09096917510032654, L3: 0.11202108860015869, L4: 1.2071259021759033, L5: 0.10283192992210388
Epoch 8000, Loss: 3.935384750366211, Losses: L1: 1.9903039932250977, L2: 0.0844675749540329, L3: 0.11287903785705566, L4: 1.4255175590515137, L5: 0.10466871410608292
Epoch 8500, Loss: 3.722864866256714, Losses: L1: 1.9986900091171265, L2: 0.08667732775211334, L3: 0.11114442348480225, L4: 1.2102470397949219, L5: 0.10248076170682907
Epoch 9000, Loss: 3.713007926940918, Losses: L1: 1.9921929836273193, L2: 0.08738573640584946, L3: 0.1106947660446167, L4: 1.207456111907959, L5: 0.10229180008172989
Epoch 9500, Loss: 3.70816707611084, Losses: L1: 1.989731788635254, L2: 0.08740024268627167, L3: 0.11055111885070801, L4: 1.2055048942565918, L5: 0.10221396386623383
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0201148986816406, Constraint losses: L1: 18.42068099975586, L2: 0.0005645296769216657, L3: 1.0005645751953125, L4: 1.0005649328231812
Epoch 500, Loss: 0.0021957415156066418, Constraint losses: L1: -1.109128713607788, L2: 0.0, L3: 0.0026516318321228027, L4: 0.0006532383849844337
Epoch 1000, Loss: 0.0013096004258841276, Constraint losses: L1: -1.1182676553726196, L2: 0.0, L3: 0.002213716506958008, L4: 0.00021415154333226383
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0057950019836426, Constraint losses: L1: 7.221915245056152, L2: 0.0, L3: 0.9992867112159729, L4: 0.9992865324020386
Epoch 500, Loss: 0.0024067643098533154, Constraint losses: L1: -1.0428277254104614, L2: 0.0, L3: 0.0027238130569458008, L4: 0.0007257791003212333
Epoch 1000, Loss: 0.0014002642128616571, Constraint losses: L1: -1.070299744606018, L2: 0.0, L3: 0.0022348761558532715, L4: 0.000235687883105129
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 170.86920166015625, Losses: L1: 17.49985694885254, L2: 0.0019472987623885274, L3: 1.0015708208084106, L4: 75.61638641357422, L5: 0.2629687488079071
Epoch 500, Loss: 3.816359281539917, Losses: L1: 1.2224634885787964, L2: 0.08800248801708221, L3: 0.06550472974777222, L4: 1.1768765449523926, L5: 0.04226158931851387
Epoch 1000, Loss: 7.440845012664795, Losses: L1: 1.3020943403244019, L2: 0.12504997849464417, L3: 0.07634544372558594, L4: 2.91953444480896, L5: 0.043880995362997055
Epoch 1500, Loss: 3.2947094440460205, Losses: L1: 0.5458526611328125, L2: 0.08002638816833496, L3: 0.058005452156066895, L4: 1.2643449306488037, L5: 0.04825916513800621
Epoch 2000, Loss: 8.240073204040527, Losses: L1: 3.7983970642089844, L2: 0.43466830253601074, L3: 0.12039065361022949, L4: 1.8624502420425415, L5: 0.08265045285224915
Epoch 2500, Loss: 3.784067392349243, Losses: L1: 1.3987165689468384, L2: 0.09894026070833206, L3: 0.0675438642501831, L4: 1.0611560344696045, L5: 0.05802134796977043
Epoch 3000, Loss: 1.9847222566604614, Losses: L1: 0.665919840335846, L2: 0.053052183240652084, L3: 0.0606006383895874, L4: 0.559523344039917, L5: 0.05100468918681145
Epoch 3500, Loss: 1.7840251922607422, Losses: L1: 0.6357864141464233, L2: 0.048326775431632996, L3: 0.06037193536758423, L4: 0.4782085120677948, L5: 0.04550216719508171
Epoch 4000, Loss: 1.6840227842330933, Losses: L1: 0.6170706748962402, L2: 0.048424821346998215, L3: 0.060231685638427734, L4: 0.4384672939777374, L5: 0.04225848242640495
Epoch 4500, Loss: 1.8564777374267578, Losses: L1: 0.848547101020813, L2: 0.04562006890773773, L3: 0.05892932415008545, L4: 0.4120783805847168, L5: 0.04059017822146416
Epoch 5000, Loss: 1.5616341829299927, Losses: L1: 0.5942209959030151, L2: 0.04745905101299286, L3: 0.059310317039489746, L4: 0.39069417119026184, L5: 0.03989036753773689
Epoch 5500, Loss: 1.531084418296814, Losses: L1: 0.5942642092704773, L2: 0.047758713364601135, L3: 0.05926835536956787, L4: 0.3753661513328552, L5: 0.03958486393094063
Epoch 6000, Loss: 1.5110018253326416, Losses: L1: 0.5936700105667114, L2: 0.04795347899198532, L3: 0.05921173095703125, L4: 0.36563414335250854, L5: 0.03937309607863426
Epoch 6500, Loss: 1.4953265190124512, Losses: L1: 0.5940398573875427, L2: 0.04820922017097473, L3: 0.05915349721908569, L4: 0.35759344696998596, L5: 0.0391668975353241
Epoch 7000, Loss: 1.4831098318099976, Losses: L1: 0.5946564674377441, L2: 0.048311296850442886, L3: 0.059032440185546875, L4: 0.351240873336792, L5: 0.03919098153710365
Epoch 7500, Loss: 1.4743136167526245, Losses: L1: 0.5944207906723022, L2: 0.04834596812725067, L3: 0.05894124507904053, L4: 0.34704694151878357, L5: 0.03914101421833038
Epoch 8000, Loss: 1.4679821729660034, Losses: L1: 0.5939347147941589, L2: 0.04837504401803017, L3: 0.05886363983154297, L4: 0.3441925048828125, L5: 0.03912017121911049
Epoch 8500, Loss: 1.4633915424346924, Losses: L1: 0.5933312773704529, L2: 0.04840933531522751, L3: 0.05881321430206299, L4: 0.3422425389289856, L5: 0.03907874599099159
Epoch 9000, Loss: 1.4602453708648682, Losses: L1: 0.5930027961730957, L2: 0.04844982177019119, L3: 0.05876964330673218, L4: 0.34086376428604126, L5: 0.03905196487903595
Epoch 9500, Loss: 1.458031177520752, Losses: L1: 0.5927613377571106, L2: 0.048478998243808746, L3: 0.05874013900756836, L4: 0.33989769220352173, L5: 0.03903024643659592
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.022019863128662, Constraint losses: L1: 18.42068099975586, L2: 0.0011996373068541288, L3: 1.0011996030807495, L4: 1.0011998414993286
Epoch 500, Loss: 0.0027802460826933384, Constraint losses: L1: -1.0865776538848877, L2: 0.0, L3: 0.0029321908950805664, L4: 0.0009346327860839665
Epoch 1000, Loss: 0.001484688837081194, Constraint losses: L1: -1.1182267665863037, L2: 0.0, L3: 0.002301037311553955, L4: 0.00030187825905159116
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0062174797058105, Constraint losses: L1: 7.484216213226318, L2: 0.0, L3: 0.9993665218353271, L4: 0.9993668794631958
Epoch 500, Loss: 0.0022197868674993515, Constraint losses: L1: -1.0679880380630493, L2: 0.0, L3: 0.002643287181854248, L4: 0.0006444876780733466
Epoch 1000, Loss: 0.0013518958585336804, Constraint losses: L1: -1.0704097747802734, L2: 0.0, L3: 0.0022109150886535645, L4: 0.00021139052114449441
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 163.25477600097656, Losses: L1: 5.568021297454834, L2: 0.0, L3: 0.9964531064033508, L4: 77.7087173461914, L5: 0.2764189839363098
Epoch 500, Loss: 20.48757553100586, Losses: L1: 2.9558327198028564, L2: 0.17671434581279755, L3: 0.19894111156463623, L4: 8.442447662353516, L5: 0.07225014269351959
Epoch 1000, Loss: 12.912008285522461, Losses: L1: 4.66860818862915, L2: 0.45843562483787537, L3: 0.1541411280632019, L4: 3.711717128753662, L5: 0.05324716493487358
Epoch 1500, Loss: 24.088237762451172, Losses: L1: 3.762491464614868, L2: 1.9203104972839355, L3: 0.3230053186416626, L4: 8.806779861450195, L5: 0.14586655795574188
Epoch 2000, Loss: 6.301861763000488, Losses: L1: 1.709734320640564, L2: 0.13155145943164825, L3: 0.14470446109771729, L4: 2.070805311203003, L5: 0.029556114226579666
Epoch 2500, Loss: 21.16132164001465, Losses: L1: 3.994774341583252, L2: 0.5163385272026062, L3: 0.39345282316207886, L4: 7.885900020599365, L5: 0.09150239825248718
Epoch 3000, Loss: 12.585464477539062, Losses: L1: 4.508815288543701, L2: 0.7035943865776062, L3: 0.20822250843048096, L4: 3.4381260871887207, L5: 0.08035791665315628
Epoch 3500, Loss: 13.591704368591309, Losses: L1: 3.454681396484375, L2: 0.5393418073654175, L3: 0.20585960149765015, L4: 4.5604753494262695, L5: 0.0650106817483902
Epoch 4000, Loss: 10.52938461303711, Losses: L1: 3.332089900970459, L2: 0.7377662658691406, L3: 0.18733668327331543, L4: 3.0076851844787598, L5: 0.06948460638523102
Epoch 4500, Loss: 9.455289840698242, Losses: L1: 3.170315980911255, L2: 0.9039464592933655, L3: 0.16921937465667725, L4: 2.48399019241333, L5: 0.07460825145244598
Epoch 5000, Loss: 9.105742454528809, Losses: L1: 3.215756893157959, L2: 0.9151233434677124, L3: 0.16446292400360107, L4: 2.285370111465454, L5: 0.07519643008708954
Epoch 5500, Loss: 8.634269714355469, Losses: L1: 3.18068265914917, L2: 0.9480078816413879, L3: 0.16114068031311035, L4: 2.053619384765625, L5: 0.07605957239866257
Epoch 6000, Loss: 8.201375961303711, Losses: L1: 3.1290831565856934, L2: 0.962317168712616, L3: 0.15739649534225464, L4: 1.8595507144927979, L5: 0.07608146220445633
Epoch 6500, Loss: 7.854519844055176, Losses: L1: 3.0691304206848145, L2: 0.9877861142158508, L3: 0.1565241813659668, L4: 1.7038381099700928, L5: 0.0768786147236824
Epoch 7000, Loss: 7.651196002960205, Losses: L1: 3.0486578941345215, L2: 0.9972171783447266, L3: 0.15456795692443848, L4: 1.6096911430358887, L5: 0.07680264860391617
Epoch 7500, Loss: 7.503246307373047, Losses: L1: 3.034266710281372, L2: 0.9987044930458069, L3: 0.15287232398986816, L4: 1.5440442562103271, L5: 0.07644152641296387
Epoch 8000, Loss: 7.407107830047607, Losses: L1: 3.0360164642333984, L2: 0.9952446818351746, L3: 0.15162861347198486, L4: 1.4982187747955322, L5: 0.07615175098180771
Epoch 8500, Loss: 7.333820819854736, Losses: L1: 3.0382187366485596, L2: 0.9916445016860962, L3: 0.15075260400772095, L4: 1.4632861614227295, L5: 0.07588014006614685
Epoch 9000, Loss: 7.278667449951172, Losses: L1: 3.040135383605957, L2: 0.9886317849159241, L3: 0.15009623765945435, L4: 1.437025547027588, L5: 0.07565707713365555
Epoch 9500, Loss: 7.2396039962768555, Losses: L1: 3.0417912006378174, L2: 0.9860121011734009, L3: 0.14961767196655273, L4: 1.4185504913330078, L5: 0.07546447217464447
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0276360511779785, Constraint losses: L1: 18.42068099975586, L2: 0.0030719453934580088, L3: 1.003071904182434, L4: 1.0030715465545654
Epoch 500, Loss: 0.002027913462370634, Constraint losses: L1: -1.1093909740447998, L2: 0.0, L3: 0.0025679469108581543, L4: 0.0005693575367331505
Epoch 1000, Loss: 0.0012501380406320095, Constraint losses: L1: -1.1175106763839722, L2: 0.0, L3: 0.00218355655670166, L4: 0.00018409223412163556
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0016279220581055, Constraint losses: L1: 6.083743095397949, L2: 0.0, L3: 0.9977721571922302, L4: 0.9977720379829407
Epoch 500, Loss: 0.002568227704614401, Constraint losses: L1: -0.9917423725128174, L2: 0.0, L3: 0.0027788877487182617, L4: 0.0007810823153704405
Epoch 1000, Loss: 0.0014176981057971716, Constraint losses: L1: -1.064967155456543, L2: 0.0, L3: 0.0022410154342651367, L4: 0.00024164986098185182
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 176.16261291503906, Losses: L1: 6.589207172393799, L2: 4.910218922304921e-05, L3: 0.9940373301506042, L4: 83.48678588867188, L5: 0.30585160851478577
Epoch 500, Loss: 8.372761726379395, Losses: L1: 2.877352476119995, L2: 0.6339288949966431, L3: 0.07482326030731201, L4: 2.299787998199463, L5: 0.05612920969724655
Epoch 1000, Loss: 16.2487735748291, Losses: L1: 6.718648910522461, L2: 0.42799443006515503, L3: 0.18348002433776855, L4: 4.3098978996276855, L5: 0.05768689885735512
Epoch 1500, Loss: 4.919479846954346, Losses: L1: 1.493464469909668, L2: 0.058909982442855835, L3: 0.10332494974136353, L4: 1.554294466972351, L5: 0.02593337930738926
Epoch 2000, Loss: 4.6587371826171875, Losses: L1: 1.4826765060424805, L2: 0.037193648517131805, L3: 0.10775500535964966, L4: 1.4361493587493896, L5: 0.025529086589813232
Epoch 2500, Loss: 3.0755438804626465, Losses: L1: 1.0707303285598755, L2: 0.03628107160329819, L3: 0.08207583427429199, L4: 0.8856704235076904, L5: 0.016520075500011444
Epoch 3000, Loss: 2.9095377922058105, Losses: L1: 1.090445876121521, L2: 0.034177280962467194, L3: 0.08030378818511963, L4: 0.7928209900856018, L5: 0.01933252066373825
Epoch 3500, Loss: 2.783247709274292, Losses: L1: 1.0957483053207397, L2: 0.0314602330327034, L3: 0.07995617389678955, L4: 0.7278276681900024, L5: 0.02023569494485855
Epoch 4000, Loss: 2.716665029525757, Losses: L1: 1.1023530960083008, L2: 0.030080365017056465, L3: 0.07874596118927002, L4: 0.6916536092758179, L5: 0.021716224029660225
Epoch 4500, Loss: 2.648552417755127, Losses: L1: 1.0851610898971558, L2: 0.02881750464439392, L3: 0.07832479476928711, L4: 0.6664284467697144, L5: 0.022533660754561424
Epoch 5000, Loss: 2.615471363067627, Losses: L1: 1.0850447416305542, L2: 0.02784213423728943, L3: 0.0779350996017456, L4: 0.6500532031059265, L5: 0.02330402098596096
Epoch 5500, Loss: 2.5894174575805664, Losses: L1: 1.085060477256775, L2: 0.027216890826821327, L3: 0.07759463787078857, L4: 0.6374344825744629, L5: 0.02354094199836254
Epoch 6000, Loss: 2.5436806678771973, Losses: L1: 1.0514485836029053, L2: 0.026405254378914833, L3: 0.07706129550933838, L4: 0.6324699521064758, L5: 0.023382239043712616
Epoch 6500, Loss: 2.528378486633301, Losses: L1: 1.050941824913025, L2: 0.026068780571222305, L3: 0.07687413692474365, L4: 0.6252086162567139, L5: 0.02360118366777897
Epoch 7000, Loss: 2.476396322250366, Losses: L1: 1.0030854940414429, L2: 0.02516450360417366, L3: 0.07678329944610596, L4: 0.6238076686859131, L5: 0.02348220907151699
Epoch 7500, Loss: 2.4698805809020996, Losses: L1: 1.002522587776184, L2: 0.025031326338648796, L3: 0.07672625780105591, L4: 0.6209117770195007, L5: 0.02352519892156124
Epoch 8000, Loss: 2.4648940563201904, Losses: L1: 1.0026404857635498, L2: 0.024918293580412865, L3: 0.07662051916122437, L4: 0.6185132265090942, L5: 0.02353389374911785
Epoch 8500, Loss: 2.461670160293579, Losses: L1: 1.0025970935821533, L2: 0.02483278140425682, L3: 0.0765695571899414, L4: 0.6169613599777222, L5: 0.0235892441123724
Epoch 9000, Loss: 2.4593522548675537, Losses: L1: 1.0025548934936523, L2: 0.02478298917412758, L3: 0.07653641700744629, L4: 0.6158672571182251, L5: 0.023603511974215508
Epoch 9500, Loss: 2.4578089714050293, Losses: L1: 1.0025324821472168, L2: 0.02475152350962162, L3: 0.07650965452194214, L4: 0.6151382923126221, L5: 0.02361452206969261
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.008195638656616, Constraint losses: L1: 8.580260276794434, L2: 0.0, L3: 0.9998076558113098, L4: 0.9998076558113098
Epoch 500, Loss: 0.0026693083345890045, Constraint losses: L1: -1.0387431383132935, L2: 0.0, L3: 0.0028528571128845215, L4: 0.000855194462928921
Epoch 1000, Loss: 0.001420401968061924, Constraint losses: L1: -1.1180258989334106, L2: 0.0, L3: 0.0022689104080200195, L4: 0.0002695174771361053
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0284976959228516, Constraint losses: L1: 18.42068099975586, L2: 0.003358675166964531, L3: 1.0033587217330933, L4: 1.0033595561981201
Epoch 500, Loss: 0.0023952601477503777, Constraint losses: L1: -1.051099181175232, L2: 0.0, L3: 0.0027222633361816406, L4: 0.0007240962004289031
Epoch 1000, Loss: 0.0014028912410140038, Constraint losses: L1: -1.0712215900421143, L2: 0.0, L3: 0.002236783504486084, L4: 0.00023732938279863447
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.73967742919922, Losses: L1: 7.098880290985107, L2: 3.936648226954276e-06, L3: 0.9990649223327637, L4: 78.0054931640625, L5: 0.27702030539512634
Epoch 500, Loss: 5.51113224029541, Losses: L1: 1.4596015214920044, L2: 0.08110769838094711, L3: 0.11413490772247314, L4: 7.611364364624023, L5: 0.05313151702284813
Epoch 1000, Loss: 26.647865295410156, Losses: L1: 3.7082159519195557, L2: 0.37824007868766785, L3: 0.9828792810440063, L4: 43.230552673339844, L5: 0.1529083400964737
Epoch 1500, Loss: 26.353397369384766, Losses: L1: 1.635728359222412, L2: 0.23907215893268585, L3: 0.6829279661178589, L4: 47.59882354736328, L5: 0.19729465246200562
Epoch 2000, Loss: 2.853827714920044, Losses: L1: 0.5329265594482422, L2: 0.04070449247956276, L3: 0.21700960397720337, L4: 4.2310919761657715, L5: 0.03088274784386158
Epoch 2500, Loss: 1.7480167150497437, Losses: L1: 0.27162104845046997, L2: 0.02813592180609703, L3: 0.15436863899230957, L4: 2.6621642112731934, L5: 0.023714857175946236
Epoch 3000, Loss: 1.4212361574172974, Losses: L1: 0.21666419506072998, L2: 0.02662619575858116, L3: 0.1369858980178833, L4: 2.144303321838379, L5: 0.021349899470806122
Epoch 3500, Loss: 1.287583589553833, Losses: L1: 0.19631637632846832, L2: 0.027304355055093765, L3: 0.129131019115448, L4: 1.9237385988235474, L5: 0.02044735848903656
Epoch 4000, Loss: 1.2137138843536377, Losses: L1: 0.18586735427379608, L2: 0.028232140466570854, L3: 0.1247173547744751, L4: 1.797720193862915, L5: 0.02032718062400818
Epoch 4500, Loss: 1.1648292541503906, Losses: L1: 0.17691200971603394, L2: 0.029033184051513672, L3: 0.12227940559387207, L4: 1.7175278663635254, L5: 0.019894693046808243
Epoch 5000, Loss: 1.1336137056350708, Losses: L1: 0.17058920860290527, L2: 0.029664000496268272, L3: 0.12057322263717651, L4: 1.6670851707458496, L5: 0.019734645262360573
Epoch 5500, Loss: 1.1118526458740234, Losses: L1: 0.16453318297863007, L2: 0.03023078478872776, L3: 0.11952954530715942, L4: 1.6345480680465698, L5: 0.01963798515498638
Epoch 6000, Loss: 1.0952973365783691, Losses: L1: 0.15938808023929596, L2: 0.030645018443465233, L3: 0.1187816858291626, L4: 1.6110491752624512, L5: 0.01940743438899517
Epoch 6500, Loss: 1.0833615064620972, Losses: L1: 0.1568559855222702, L2: 0.03095748834311962, L3: 0.1179192066192627, L4: 1.5918376445770264, L5: 0.019424214959144592
Epoch 7000, Loss: 1.0743930339813232, Losses: L1: 0.15441054105758667, L2: 0.031155943870544434, L3: 0.11743205785751343, L4: 1.578566074371338, L5: 0.01934313029050827
Epoch 7500, Loss: 1.0677741765975952, Losses: L1: 0.15283143520355225, L2: 0.031280163675546646, L3: 0.1170508861541748, L4: 1.568400502204895, L5: 0.019313588738441467
Epoch 8000, Loss: 1.0629327297210693, Losses: L1: 0.15153361856937408, L2: 0.03137576952576637, L3: 0.11676734685897827, L4: 1.561232566833496, L5: 0.019295232370495796
Epoch 8500, Loss: 1.059291958808899, Losses: L1: 0.15062281489372253, L2: 0.031435057520866394, L3: 0.11654925346374512, L4: 1.5557576417922974, L5: 0.019291110336780548
Epoch 9000, Loss: 1.0566608905792236, Losses: L1: 0.14997516572475433, L2: 0.03147617727518082, L3: 0.11638003587722778, L4: 1.5517983436584473, L5: 0.01928839460015297
Epoch 9500, Loss: 1.0547802448272705, Losses: L1: 0.14948740601539612, L2: 0.03149743750691414, L3: 0.1162651777267456, L4: 1.5490484237670898, L5: 0.019282257184386253
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0223777294158936, Constraint losses: L1: 18.42068099975586, L2: 0.0013194256462156773, L3: 1.001319408416748, L4: 1.0013182163238525
Epoch 500, Loss: 0.0022102100774645805, Constraint losses: L1: -1.1005064249038696, L2: 0.0, L3: 0.0026544928550720215, L4: 0.0006562236230820417
Epoch 1000, Loss: 0.0013100039213895798, Constraint losses: L1: -1.1184368133544922, L2: 0.0, L3: 0.0022139549255371094, L4: 0.00021448591724038124
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005087375640869, Constraint losses: L1: 6.995702266693115, L2: 0.0, L3: 0.9990456700325012, L4: 0.9990459680557251
Epoch 500, Loss: 0.0021340148523449898, Constraint losses: L1: -1.0654358863830566, L2: 0.0, L3: 0.002599060535430908, L4: 0.0006003902526572347
Epoch 1000, Loss: 0.0013248884351924062, Constraint losses: L1: -1.0714237689971924, L2: 0.0, L3: 0.0021979212760925293, L4: 0.00019839106244035065
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.64791488647461, Losses: L1: 18.42068099975586, L2: 0.004450011532753706, L3: 1.0044499635696411, L4: 74.91069030761719, L5: 0.2607596218585968
Epoch 500, Loss: 8.252997398376465, Losses: L1: 2.111724615097046, L2: 0.1496507227420807, L3: 0.3176419734954834, L4: 11.227657318115234, L5: 0.06932143121957779
Epoch 1000, Loss: 2.5368659496307373, Losses: L1: 0.8132712841033936, L2: 0.03457900136709213, L3: 0.08430182933807373, L4: 3.1694676876068115, L5: 0.027551885694265366
Epoch 1500, Loss: 2.0950775146484375, Losses: L1: 0.5631092190742493, L2: 0.0182179007679224, L3: 0.08726930618286133, L4: 2.827122688293457, L5: 0.03833649680018425
Epoch 2000, Loss: 1.881714940071106, Losses: L1: 0.9379446506500244, L2: 0.013623928651213646, L3: 0.10998916625976562, L4: 1.6989634037017822, L5: 0.012046072632074356
Epoch 2500, Loss: 6.5176682472229, Losses: L1: 4.157674789428711, L2: 0.16948576271533966, L3: 0.15907424688339233, L4: 3.675886631011963, L5: 0.10354162007570267
Epoch 3000, Loss: 6.266618728637695, Losses: L1: 1.2600371837615967, L2: 0.02039426751434803, L3: 0.18552124500274658, L4: 9.582277297973633, L5: 0.08189409226179123
Epoch 3500, Loss: 2.151233673095703, Losses: L1: 1.2918801307678223, L2: 0.028544316068291664, L3: 0.10475361347198486, L4: 1.4556496143341064, L5: 0.022063348442316055
Epoch 4000, Loss: 1.814664602279663, Losses: L1: 1.034399390220642, L2: 0.021746447309851646, L3: 0.09721094369888306, L4: 1.339057445526123, L5: 0.01863817311823368
Epoch 4500, Loss: 1.6675878763198853, Losses: L1: 0.9867744445800781, L2: 0.021442431956529617, L3: 0.09330201148986816, L4: 1.145371675491333, L5: 0.01859181560575962
Epoch 5000, Loss: 1.6230700016021729, Losses: L1: 0.9826066493988037, L2: 0.02238377556204796, L3: 0.09076231718063354, L4: 1.0636216402053833, L5: 0.018503891304135323
Epoch 5500, Loss: 1.5608032941818237, Losses: L1: 0.9475607872009277, L2: 0.0216013602912426, L3: 0.08997118473052979, L4: 1.0137319564819336, L5: 0.01818823255598545
Epoch 6000, Loss: 1.5392236709594727, Losses: L1: 0.9440972208976746, L2: 0.02253294549882412, L3: 0.08827328681945801, L4: 0.9753646850585938, L5: 0.018241621553897858
Epoch 6500, Loss: 1.5242670774459839, Losses: L1: 0.9416103363037109, L2: 0.022869078442454338, L3: 0.08736264705657959, L4: 0.9499685764312744, L5: 0.01825295016169548
Epoch 7000, Loss: 1.5140633583068848, Losses: L1: 0.9397566318511963, L2: 0.023010604083538055, L3: 0.08679735660552979, L4: 0.9332473874092102, L5: 0.01826324500143528
Epoch 7500, Loss: 1.5068531036376953, Losses: L1: 0.9384148716926575, L2: 0.023102179169654846, L3: 0.08642208576202393, L4: 0.9214662313461304, L5: 0.018289517611265182
Epoch 8000, Loss: 1.501702904701233, Losses: L1: 0.9375327825546265, L2: 0.02317880466580391, L3: 0.08614176511764526, L4: 0.9128352403640747, L5: 0.018324056640267372
Epoch 8500, Loss: 1.498043179512024, Losses: L1: 0.9368364214897156, L2: 0.02323835715651512, L3: 0.08593571186065674, L4: 0.9067949056625366, L5: 0.01836473122239113
Epoch 9000, Loss: 1.4954535961151123, Losses: L1: 0.9363288879394531, L2: 0.02330637164413929, L3: 0.08576393127441406, L4: 0.9025007486343384, L5: 0.018379710614681244
Epoch 9500, Loss: 1.493652105331421, Losses: L1: 0.9359728097915649, L2: 0.023360824212431908, L3: 0.08563351631164551, L4: 0.89949631690979, L5: 0.018392689526081085
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.01958966255188, Constraint losses: L1: 18.42068099975586, L2: 0.0004088417626917362, L3: 1.000380039215088, L4: 1.0003801584243774
Epoch 500, Loss: 0.0021330637391656637, Constraint losses: L1: -1.0642564296722412, L2: 0.0, L3: 0.0025977492332458496, L4: 0.0005995710380375385
Epoch 1000, Loss: 0.0012556874426081777, Constraint losses: L1: -1.1179918050765991, L2: 0.0, L3: 0.0021864771842956543, L4: 0.0001872021530289203
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0068249702453613, Constraint losses: L1: 7.717960357666016, L2: 0.0, L3: 0.9995536208152771, L4: 0.9995535612106323
Epoch 500, Loss: 0.002324158325791359, Constraint losses: L1: -1.0589827299118042, L2: 0.0, L3: 0.0026906728744506836, L4: 0.000692468136548996
Epoch 1000, Loss: 0.001387842115946114, Constraint losses: L1: -1.0711060762405396, L2: 0.0, L3: 0.0022292137145996094, L4: 0.00022973456361796707
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 51.57320022583008, Losses: L1: 15.342452049255371, L2: 0.0009979975875467062, L3: 1.0008434057235718, L4: 70.51668548583984, L5: 0.23499438166618347
Epoch 500, Loss: 10.29699993133545, Losses: L1: 3.9354987144470215, L2: 0.6204295754432678, L3: 0.15749764442443848, L4: 9.516972541809082, L5: 0.1417035311460495
Epoch 1000, Loss: 2.478379726409912, Losses: L1: 0.9814373254776001, L2: 0.0459257997572422, L3: 0.09822893142700195, L4: 2.6058497428894043, L5: 0.026525750756263733
Epoch 1500, Loss: 2.520989179611206, Losses: L1: 1.0499341487884521, L2: 0.03101913444697857, L3: 0.08281344175338745, L4: 2.57263445854187, L5: 0.040646422654390335
Epoch 2000, Loss: 1.4918452501296997, Losses: L1: 0.6073209643363953, L2: 0.038279950618743896, L3: 0.061069369316101074, L4: 1.476793885231018, L5: 0.019516389816999435
Epoch 2500, Loss: 1.014556884765625, Losses: L1: 0.4635721445083618, L2: 0.035586755722761154, L3: 0.058683574199676514, L4: 0.8335501551628113, L5: 0.016847165301442146
Epoch 3000, Loss: 1.1337287425994873, Losses: L1: 0.15952175855636597, L2: 0.004399479366838932, L3: 0.07801604270935059, L4: 1.766945242881775, L5: 0.021463671699166298
Epoch 3500, Loss: 0.8343402147293091, Losses: L1: 0.39271560311317444, L2: 0.03211855888366699, L3: 0.05743288993835449, L4: 0.6309108734130859, L5: 0.016607826575636864
Epoch 4000, Loss: 0.8112483024597168, Losses: L1: 0.3910764157772064, L2: 0.03239322453737259, L3: 0.05676746368408203, L4: 0.5879507064819336, L5: 0.016513178125023842
Epoch 4500, Loss: 0.8010225892066956, Losses: L1: 0.38943567872047424, L2: 0.03241501376032829, L3: 0.05635952949523926, L4: 0.5715011358261108, L5: 0.01641327701508999
Epoch 5000, Loss: 0.7912499308586121, Losses: L1: 0.3878648281097412, L2: 0.03238554298877716, L3: 0.05607074499130249, L4: 0.5547382831573486, L5: 0.016604751348495483
Epoch 5500, Loss: 0.7858738303184509, Losses: L1: 0.38712140917778015, L2: 0.03214997798204422, L3: 0.055846452713012695, L4: 0.545932412147522, L5: 0.016781514510512352
Epoch 6000, Loss: 0.7811812162399292, Losses: L1: 0.3866787850856781, L2: 0.032009564340114594, L3: 0.05568420886993408, L4: 0.5383384227752686, L5: 0.0167359858751297
Epoch 6500, Loss: 0.7779135704040527, Losses: L1: 0.38659143447875977, L2: 0.03193134441971779, L3: 0.05549919605255127, L4: 0.5318821668624878, L5: 0.016884390264749527
Epoch 7000, Loss: 0.7755358219146729, Losses: L1: 0.38619643449783325, L2: 0.03188113868236542, L3: 0.055409908294677734, L4: 0.5281529426574707, L5: 0.01689787022769451
Epoch 7500, Loss: 0.7738638520240784, Losses: L1: 0.3860202431678772, L2: 0.0318305604159832, L3: 0.05533921718597412, L4: 0.5255056619644165, L5: 0.01688000187277794
Epoch 8000, Loss: 0.7725006341934204, Losses: L1: 0.38599148392677307, L2: 0.03180788457393646, L3: 0.05527263879776001, L4: 0.5228066444396973, L5: 0.016926893964409828
Epoch 8500, Loss: 0.7715167999267578, Losses: L1: 0.3859340250492096, L2: 0.03179038688540459, L3: 0.055219411849975586, L4: 0.5209755301475525, L5: 0.016952279955148697
Epoch 9000, Loss: 0.7708284258842468, Losses: L1: 0.3858909010887146, L2: 0.031761445105075836, L3: 0.055189430713653564, L4: 0.5198081731796265, L5: 0.01695791445672512
Epoch 9500, Loss: 0.7703406810760498, Losses: L1: 0.3857775628566742, L2: 0.03176238387823105, L3: 0.05516505241394043, L4: 0.5190712213516235, L5: 0.016960125416517258
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.030256748199463, Constraint losses: L1: 18.42068099975586, L2: 0.0039450861513614655, L3: 1.0039451122283936, L4: 1.0039458274841309
Epoch 500, Loss: 0.0022751521319150925, Constraint losses: L1: -1.0946356058120728, L2: 0.0, L3: 0.0026840567588806152, L4: 0.0006857310654595494
Epoch 1000, Loss: 0.0013255615485832095, Constraint losses: L1: -1.1178736686706543, L2: 0.0, L3: 0.0022214651107788086, L4: 0.0002219701709691435
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.011197090148926, Constraint losses: L1: 11.115216255187988, L2: 6.702788232360035e-05, L3: 1.0000075101852417, L4: 1.0000073909759521
Epoch 500, Loss: 0.002187726553529501, Constraint losses: L1: -1.0024592876434326, L2: 0.0, L3: 0.0025941133499145508, L4: 0.0005960724665783346
Epoch 1000, Loss: 0.0013006485532969236, Constraint losses: L1: -1.0692187547683716, L2: 0.0, L3: 0.002184629440307617, L4: 0.0001852380228228867
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 71.367919921875, Losses: L1: 5.582831382751465, L2: 0.0, L3: 0.9964801669120789, L4: 65.18246459960938, L5: 0.2087734341621399
Epoch 500, Loss: 64.2693862915039, Losses: L1: 13.60595703125, L2: 8.911201439332217e-05, L3: 0.9999514818191528, L4: 50.012149810791016, L5: 0.3022400140762329
Epoch 1000, Loss: 60.856597900390625, Losses: L1: 10.255179405212402, L2: 0.0008737606112845242, L3: 0.9991525411605835, L4: 49.94769287109375, L5: 0.30480024218559265
Epoch 1500, Loss: 68.14045715332031, Losses: L1: 17.48794174194336, L2: 1.4144336368815402e-08, L3: 1.0, L4: 50.000022888183594, L5: 0.3049983084201813
Epoch 2000, Loss: 55.337318420410156, Losses: L1: 4.7283124923706055, L2: 7.980856753420085e-05, L3: 0.990972638130188, L4: 49.961734771728516, L5: 0.3032538592815399
Epoch 2500, Loss: 58.88468933105469, Losses: L1: 8.204657554626465, L2: 8.728100510779768e-06, L3: 0.9997877478599548, L4: 50.031864166259766, L5: 0.2965109646320343
Epoch 3000, Loss: 15.094972610473633, Losses: L1: 2.7295405864715576, L2: 0.23902401328086853, L3: 0.3206443190574646, L4: 11.694375991821289, L5: 0.06537244468927383
Epoch 3500, Loss: 10.116097450256348, Losses: L1: 0.8842301368713379, L2: 0.1561063677072525, L3: 0.2606167793273926, L4: 8.760456085205078, L5: 0.057779863476753235
Epoch 4000, Loss: 8.822388648986816, Losses: L1: 0.7616100907325745, L2: 0.11256642639636993, L3: 0.24526852369308472, L4: 7.687849044799805, L5: 0.05032585188746452
Epoch 4500, Loss: 7.991251468658447, Losses: L1: 0.6681112051010132, L2: 0.08903545141220093, L3: 0.23325347900390625, L4: 7.005945205688477, L5: 0.04499531537294388
Epoch 5000, Loss: 7.44661283493042, Losses: L1: 0.6339330673217773, L2: 0.07365606725215912, L3: 0.22763502597808838, L4: 6.53114128112793, L5: 0.04081682488322258
Epoch 5500, Loss: 7.049508571624756, Losses: L1: 0.5984579920768738, L2: 0.06377730518579483, L3: 0.22274959087371826, L4: 6.193099498748779, L5: 0.03804291784763336
Epoch 6000, Loss: 6.7866315841674805, Losses: L1: 0.5767403244972229, L2: 0.0606003999710083, L3: 0.21913152933120728, L4: 5.961153507232666, L5: 0.035942498594522476
Epoch 6500, Loss: 6.595920085906982, Losses: L1: 0.5641306638717651, L2: 0.05847122147679329, L3: 0.216167151927948, L4: 5.789565563201904, L5: 0.03439661115407944
Epoch 7000, Loss: 6.457772731781006, Losses: L1: 0.5549335479736328, L2: 0.05710766464471817, L3: 0.21384668350219727, L4: 5.665053844451904, L5: 0.03329325094819069
Epoch 7500, Loss: 6.358781814575195, Losses: L1: 0.5479846596717834, L2: 0.056111205369234085, L3: 0.21277260780334473, L4: 5.575965404510498, L5: 0.03244616091251373
Epoch 8000, Loss: 6.287796497344971, Losses: L1: 0.5434502959251404, L2: 0.05544979125261307, L3: 0.21191155910491943, L4: 5.5115861892700195, L5: 0.031809817999601364
Epoch 8500, Loss: 6.237618923187256, Losses: L1: 0.540449857711792, L2: 0.05500192567706108, L3: 0.21137595176696777, L4: 5.4658098220825195, L5: 0.03133517503738403
Epoch 9000, Loss: 6.202911376953125, Losses: L1: 0.5385602712631226, L2: 0.05473107844591141, L3: 0.21099936962127686, L4: 5.433887958526611, L5: 0.031003432348370552
Epoch 9500, Loss: 6.17941951751709, Losses: L1: 0.5372700691223145, L2: 0.05456613004207611, L3: 0.21075057983398438, L4: 5.412259101867676, L5: 0.030765844509005547
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0230915546417236, Constraint losses: L1: 18.42068099975586, L2: 0.0015569854294881225, L3: 1.0015569925308228, L4: 1.0015568733215332
Epoch 500, Loss: 0.002850338350981474, Constraint losses: L1: -0.9526644945144653, L2: 0.0, L3: 0.002900063991546631, L4: 0.0009029390057548881
Epoch 1000, Loss: 0.0014071724144741893, Constraint losses: L1: -1.1171377897262573, L2: 0.0, L3: 0.0022617578506469727, L4: 0.00026255237753503025
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.999225378036499, Constraint losses: L1: 5.717810153961182, L2: 0.0, L3: 0.9967539310455322, L4: 0.9967536926269531
Epoch 500, Loss: 0.0025733113288879395, Constraint losses: L1: -1.031646490097046, L2: 0.0, L3: 0.0028014183044433594, L4: 0.0008035395294427872
Epoch 1000, Loss: 0.0014403206296265125, Constraint losses: L1: -1.0714956521987915, L2: 0.0, L3: 0.002255558967590332, L4: 0.00025625733542256057
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 78.34439849853516, Losses: L1: 10.244050979614258, L2: 0.0004634005017578602, L3: 0.9988120794296265, L4: 67.38296508789062, L5: 0.2170456498861313
Epoch 500, Loss: 5.387264728546143, Losses: L1: 2.276214361190796, L2: 0.20770800113677979, L3: 0.08543527126312256, L4: 2.617093324661255, L5: 0.035823479294776917
Epoch 1000, Loss: 2.509026288986206, Losses: L1: 0.6397842764854431, L2: 0.09265373647212982, L3: 0.05303078889846802, L4: 1.639646053314209, L5: 0.017773263156414032
Epoch 1500, Loss: 1.5921103954315186, Losses: L1: 0.530911386013031, L2: 0.06759017705917358, L3: 0.04959845542907715, L4: 0.8799579739570618, L5: 0.021261470392346382
Epoch 2000, Loss: 1.7553114891052246, Losses: L1: 0.6126251220703125, L2: 0.04066569730639458, L3: 0.06031990051269531, L4: 0.9905016422271729, L5: 0.040693387389183044
Epoch 2500, Loss: 1.2463566064834595, Losses: L1: 0.4830716848373413, L2: 0.03754746913909912, L3: 0.056088805198669434, L4: 0.6278619766235352, L5: 0.03228365629911423
Epoch 3000, Loss: 0.9852020144462585, Losses: L1: 0.4203570783138275, L2: 0.038455914705991745, L3: 0.05229753255844116, L4: 0.4337977468967438, L5: 0.02798660844564438
Epoch 3500, Loss: 0.8085161447525024, Losses: L1: 0.3816418945789337, L2: 0.03491314500570297, L3: 0.051860809326171875, L4: 0.30572283267974854, L5: 0.025394756346940994
Epoch 4000, Loss: 0.7334103584289551, Losses: L1: 0.33479753136634827, L2: 0.03509661555290222, L3: 0.05084669589996338, L4: 0.2805386185646057, L5: 0.02245759405195713
Epoch 4500, Loss: 0.6819784641265869, Losses: L1: 0.3071877062320709, L2: 0.034451764076948166, L3: 0.05028343200683594, L4: 0.2602347731590271, L5: 0.02051074244081974
Epoch 5000, Loss: 0.6670145988464355, Losses: L1: 0.300642728805542, L2: 0.034091509878635406, L3: 0.05004364252090454, L4: 0.25384193658828735, L5: 0.01932515762746334
Epoch 5500, Loss: 0.6575221419334412, Losses: L1: 0.29705774784088135, L2: 0.03376699611544609, L3: 0.049813926219940186, L4: 0.24926288425922394, L5: 0.01876058429479599
Epoch 6000, Loss: 0.6525692939758301, Losses: L1: 0.29474011063575745, L2: 0.03368962183594704, L3: 0.04962283372879028, L4: 0.24710632860660553, L5: 0.01853221096098423
Epoch 6500, Loss: 0.648977518081665, Losses: L1: 0.2929031550884247, L2: 0.03372606262564659, L3: 0.049533724784851074, L4: 0.2456846386194229, L5: 0.018170729279518127
Epoch 7000, Loss: 0.6445446014404297, Losses: L1: 0.29210832715034485, L2: 0.03362575173377991, L3: 0.0494457483291626, L4: 0.24230018258094788, L5: 0.018161706626415253
Epoch 7500, Loss: 0.6425197124481201, Losses: L1: 0.2915504276752472, L2: 0.03356393799185753, L3: 0.04939025640487671, L4: 0.24108338356018066, L5: 0.018062898889183998
Epoch 8000, Loss: 0.6412895321846008, Losses: L1: 0.29121115803718567, L2: 0.03351493924856186, L3: 0.0493503212928772, L4: 0.24035625159740448, L5: 0.018017088994383812
Epoch 8500, Loss: 0.6403120756149292, Losses: L1: 0.2909047603607178, L2: 0.03346913307905197, L3: 0.04932934045791626, L4: 0.23981139063835144, L5: 0.01799299567937851
Epoch 9000, Loss: 0.6397103071212769, Losses: L1: 0.2906514108181, L2: 0.033451493829488754, L3: 0.04930746555328369, L4: 0.23954005539417267, L5: 0.017962107434868813
Epoch 9500, Loss: 0.6392400860786438, Losses: L1: 0.2904578149318695, L2: 0.033433519303798676, L3: 0.04929542541503906, L4: 0.23932373523712158, L5: 0.01794378086924553
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9936400651931763, Constraint losses: L1: 5.119636535644531, L2: 0.0, L3: 0.9942606091499329, L4: 0.9942598342895508
Epoch 500, Loss: 0.0020505900029093027, Constraint losses: L1: -1.109662652015686, L2: 0.0, L3: 0.0025793910026550293, L4: 0.0005808617570437491
Epoch 1000, Loss: 0.0012621599016711116, Constraint losses: L1: -1.1182620525360107, L2: 0.0, L3: 0.0021900534629821777, L4: 0.0001903685333672911
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.000521421432495, Constraint losses: L1: 5.868911266326904, L2: 0.0, L3: 0.9973266124725342, L4: 0.9973258972167969
Epoch 500, Loss: 0.002500404603779316, Constraint losses: L1: -0.9753450155258179, L2: 0.0, L3: 0.002736687660217285, L4: 0.0007390618557110429
Epoch 1000, Loss: 0.0013817142462357879, Constraint losses: L1: -1.0704236030578613, L2: 0.0, L3: 0.0022257566452026367, L4: 0.00022638127848040313
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 85.93630981445312, Losses: L1: 5.36724328994751, L2: 0.0, L3: 0.9956192970275879, L4: 79.50068664550781, L5: 0.2852875292301178
Epoch 500, Loss: 3.2005410194396973, Losses: L1: 0.3797535002231598, L2: 0.0326753668487072, L3: 0.10249650478363037, L4: 2.6339924335479736, L5: 0.03509801626205444
Epoch 1000, Loss: 12.878986358642578, Losses: L1: 1.5896685123443604, L2: 0.6771394610404968, L3: 0.254419207572937, L4: 9.629993438720703, L5: 0.0889178067445755
Epoch 1500, Loss: 9.89146900177002, Losses: L1: 0.8127278089523315, L2: 0.11322581768035889, L3: 0.2788681387901306, L4: 8.61955451965332, L5: 0.04665040597319603
Epoch 2000, Loss: 3.663012742996216, Losses: L1: 0.43043920397758484, L2: 0.029255062341690063, L3: 0.15788137912750244, L4: 3.041910171508789, L5: 0.026606176048517227
Epoch 2500, Loss: 2.5650341510772705, Losses: L1: 0.24255159497261047, L2: 0.03218809887766838, L3: 0.14639997482299805, L4: 2.1436831951141357, L5: 0.020611699670553207
Epoch 3000, Loss: 2.1321215629577637, Losses: L1: 0.23688526451587677, L2: 0.03040372207760811, L3: 0.1375533938407898, L4: 1.7264840602874756, L5: 0.019584087654948235
Epoch 3500, Loss: 1.8220436573028564, Losses: L1: 0.21162520349025726, L2: 0.031281717121601105, L3: 0.1210818886756897, L4: 1.4484045505523682, L5: 0.01945478841662407
Epoch 4000, Loss: 1.6901819705963135, Losses: L1: 0.19904589653015137, L2: 0.03190329670906067, L3: 0.1150369644165039, L4: 1.3309235572814941, L5: 0.019443722441792488
Epoch 4500, Loss: 1.6390488147735596, Losses: L1: 0.19800755381584167, L2: 0.030824871733784676, L3: 0.11345654726028442, L4: 1.2837716341018677, L5: 0.01944577880203724
Epoch 5000, Loss: 1.6057624816894531, Losses: L1: 0.19639529287815094, L2: 0.029981054365634918, L3: 0.1129765510559082, L4: 1.254082202911377, L5: 0.01941726915538311
Epoch 5500, Loss: 1.582411527633667, Losses: L1: 0.19561991095542908, L2: 0.02960905060172081, L3: 0.11220073699951172, L4: 1.232452630996704, L5: 0.019510269165039062
Epoch 6000, Loss: 1.566186785697937, Losses: L1: 0.19350981712341309, L2: 0.0295268464833498, L3: 0.11150699853897095, L4: 1.2186174392700195, L5: 0.019626202061772346
Epoch 6500, Loss: 1.5550405979156494, Losses: L1: 0.1907051056623459, L2: 0.02959083393216133, L3: 0.11113333702087402, L4: 1.2102248668670654, L5: 0.019681161269545555
Epoch 7000, Loss: 1.5466054677963257, Losses: L1: 0.1893964260816574, L2: 0.029655590653419495, L3: 0.11051464080810547, L4: 1.2031031847000122, L5: 0.019768673926591873
Epoch 7500, Loss: 1.5406423807144165, Losses: L1: 0.18790683150291443, L2: 0.02969045378267765, L3: 0.11023283004760742, L4: 1.1986641883850098, L5: 0.019787030294537544
Epoch 8000, Loss: 1.5362887382507324, Losses: L1: 0.18688736855983734, L2: 0.02971542254090309, L3: 0.11000245809555054, L4: 1.1953575611114502, L5: 0.019805820658802986
Epoch 8500, Loss: 1.5329556465148926, Losses: L1: 0.18611255288124084, L2: 0.02973560057580471, L3: 0.10985887050628662, L4: 1.1927783489227295, L5: 0.01983203925192356
Epoch 9000, Loss: 1.5306110382080078, Losses: L1: 0.18540900945663452, L2: 0.029738686978816986, L3: 0.10981971025466919, L4: 1.1911838054656982, L5: 0.019815515726804733
Epoch 9500, Loss: 1.5288410186767578, Losses: L1: 0.18504737317562103, L2: 0.029741942882537842, L3: 0.10975253582000732, L4: 1.189802646636963, L5: 0.01981542445719242
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9980647563934326, Constraint losses: L1: 5.542454242706299, L2: 0.0, L3: 0.996261477470398, L4: 0.9962608814239502
Epoch 500, Loss: 0.00222016591578722, Constraint losses: L1: -1.0774115324020386, L2: 0.0, L3: 0.002647995948791504, L4: 0.0006495816633105278
Epoch 1000, Loss: 0.0012887615012004972, Constraint losses: L1: -1.1180171966552734, L2: 0.0, L3: 0.002203226089477539, L4: 0.0002035526849795133
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9991930723190308, Constraint losses: L1: 5.713128566741943, L2: 0.0, L3: 0.9967402815818787, L4: 0.9967396259307861
Epoch 500, Loss: 0.002467901213094592, Constraint losses: L1: -0.9883370995521545, L2: 0.0, L3: 0.002727031707763672, L4: 0.0007292066002264619
Epoch 1000, Loss: 0.0013806521892547607, Constraint losses: L1: -1.0702297687530518, L2: 0.0, L3: 0.002225160598754883, L4: 0.00022572133457288146
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 173.43226623535156, Losses: L1: 10.712102890014648, L2: 0.000424722908064723, L3: 0.9992512464523315, L4: 81.03610229492188, L5: 0.29496634006500244
Epoch 500, Loss: 2.8890509605407715, Losses: L1: 0.8015183210372925, L2: 0.07352793961763382, L3: 0.07258498668670654, L4: 0.9459277987480164, L5: 0.024657296016812325
Epoch 1000, Loss: 4.444860458374023, Losses: L1: 1.2249717712402344, L2: 0.054054904729127884, L3: 0.0922095775604248, L4: 1.5285474061965942, L5: 0.017158184200525284
Epoch 1500, Loss: 9.719382286071777, Losses: L1: 3.290210723876953, L2: 0.4056154489517212, L3: 0.08229660987854004, L4: 2.7747802734375, L5: 0.05446417257189751
Epoch 2000, Loss: 6.786072731018066, Losses: L1: 2.2361061573028564, L2: 0.07249519228935242, L3: 0.1367264986038208, L4: 2.160390853881836, L5: 0.03166204318404198
Epoch 2500, Loss: 4.016077995300293, Losses: L1: 0.5838158130645752, L2: 0.03001296892762184, L3: 0.10851556062698364, L4: 1.6517051458358765, L5: 0.029137084260582924
Epoch 3000, Loss: 2.244569778442383, Losses: L1: 0.39003026485443115, L2: 0.03130607306957245, L3: 0.09840387105941772, L4: 0.864436686038971, L5: 0.02770426869392395
Epoch 3500, Loss: 2.033656120300293, Losses: L1: 0.36566150188446045, L2: 0.026194876059889793, L3: 0.0945814847946167, L4: 0.7774381637573242, L5: 0.026875536888837814
Epoch 4000, Loss: 1.9332146644592285, Losses: L1: 0.34251680970191956, L2: 0.02393534407019615, L3: 0.09265005588531494, L4: 0.7419113516807556, L5: 0.025359010323882103
Epoch 4500, Loss: 1.7655742168426514, Losses: L1: 0.2220318615436554, L2: 0.020277466624975204, L3: 0.09187108278274536, L4: 0.7225043773651123, L5: 0.024086156859993935
Epoch 5000, Loss: 1.7104836702346802, Losses: L1: 0.20259812474250793, L2: 0.018787583336234093, L3: 0.09066832065582275, L4: 0.7067818641662598, L5: 0.022824885323643684
Epoch 5500, Loss: 1.680238962173462, Losses: L1: 0.1898047924041748, L2: 0.01839584857225418, L3: 0.09009742736816406, L4: 0.6988309621810913, L5: 0.021863602101802826
Epoch 6000, Loss: 1.6555445194244385, Losses: L1: 0.18046687543392181, L2: 0.018284622579813004, L3: 0.08964109420776367, L4: 0.6915987730026245, L5: 0.02098061703145504
Epoch 6500, Loss: 1.638838768005371, Losses: L1: 0.1741972118616104, L2: 0.018215114250779152, L3: 0.08932852745056152, L4: 0.6866716742515564, L5: 0.02040744014084339
Epoch 7000, Loss: 1.626745581626892, Losses: L1: 0.16992181539535522, L2: 0.018171517178416252, L3: 0.08908951282501221, L4: 0.6829586029052734, L5: 0.02003750205039978
Epoch 7500, Loss: 1.6185909509658813, Losses: L1: 0.167046919465065, L2: 0.018166225403547287, L3: 0.08882999420166016, L4: 0.6804593205451965, L5: 0.01975594274699688
Epoch 8000, Loss: 1.612566590309143, Losses: L1: 0.16514107584953308, L2: 0.018101701512932777, L3: 0.08871090412139893, L4: 0.6785284876823425, L5: 0.019619518890976906
Epoch 8500, Loss: 1.607816457748413, Losses: L1: 0.16412046551704407, L2: 0.01806783303618431, L3: 0.08860111236572266, L4: 0.6767612099647522, L5: 0.019474640488624573
Epoch 9000, Loss: 1.6047780513763428, Losses: L1: 0.1634225845336914, L2: 0.018031762912869453, L3: 0.08853214979171753, L4: 0.6756616830825806, L5: 0.019404888153076172
Epoch 9500, Loss: 1.6027518510818481, Losses: L1: 0.1629856675863266, L2: 0.018002891913056374, L3: 0.0884697437286377, L4: 0.6749233603477478, L5: 0.019357644021511078
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0190465450286865, Constraint losses: L1: 18.42068099975586, L2: 0.00022398470900952816, L3: 1.000200867652893, L4: 1.0002009868621826
Epoch 500, Loss: 0.0021669387351721525, Constraint losses: L1: -1.0549876689910889, L2: 0.0, L3: 0.0026100873947143555, L4: 0.0006118391756899655
Epoch 1000, Loss: 0.001262621022760868, Constraint losses: L1: -1.1172524690628052, L2: 0.0, L3: 0.0021896958351135254, L4: 0.00019017771410290152
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.021709442138672, Constraint losses: L1: 18.42068099975586, L2: 0.0010960913496091962, L3: 1.0010961294174194, L4: 1.001096487045288
Epoch 500, Loss: 0.002160751959308982, Constraint losses: L1: -1.0546890497207642, L2: 0.0, L3: 0.002606987953186035, L4: 0.0006084530614316463
Epoch 1000, Loss: 0.0013248815666884184, Constraint losses: L1: -1.0709964036941528, L2: 0.0, L3: 0.0021976828575134277, L4: 0.000198195077246055
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 142.7904815673828, Losses: L1: 5.313220500946045, L2: 0.0, L3: 0.9954294562339783, L4: 68.37774658203125, L5: 0.22405365109443665
Epoch 500, Loss: 11.385979652404785, Losses: L1: 3.832658529281616, L2: 0.21080878376960754, L3: 0.12552958726882935, L4: 3.518571138381958, L5: 0.031796474009752274
Epoch 1000, Loss: 15.253908157348633, Losses: L1: 2.4342398643493652, L2: 0.21550734341144562, L3: 0.1500459909439087, L4: 6.1344218254089355, L5: 0.04478676617145538
Epoch 1500, Loss: 11.629415512084961, Losses: L1: 2.077251672744751, L2: 0.1680564433336258, L3: 0.13924002647399902, L4: 4.557895660400391, L5: 0.030639277771115303
Epoch 2000, Loss: 3.932396411895752, Losses: L1: 0.22626352310180664, L2: 0.07989739626646042, L3: 0.11979156732559204, L4: 1.7282441854476929, L5: 0.029953856021165848
Epoch 2500, Loss: 3.182851791381836, Losses: L1: 0.24342286586761475, L2: 0.06270784884691238, L3: 0.10980772972106934, L4: 1.368565320968628, L5: 0.02197878621518612
Epoch 3000, Loss: 2.3446385860443115, Losses: L1: 0.1811283826828003, L2: 0.07076699286699295, L3: 0.10209137201309204, L4: 0.9730207920074463, L5: 0.024888992309570312
Epoch 3500, Loss: 2.0524678230285645, Losses: L1: 0.15213772654533386, L2: 0.07580496370792389, L3: 0.10073971748352051, L4: 0.8369458317756653, L5: 0.024458542466163635
Epoch 4000, Loss: 1.9655401706695557, Losses: L1: 0.1612771451473236, L2: 0.07249904423952103, L3: 0.09781539440155029, L4: 0.7934237122535706, L5: 0.023509785532951355
Epoch 4500, Loss: 1.9162602424621582, Losses: L1: 0.15155881643295288, L2: 0.07329535484313965, L3: 0.09652185440063477, L4: 0.7731143236160278, L5: 0.023621050640940666
Epoch 5000, Loss: 1.8806190490722656, Losses: L1: 0.14439035952091217, L2: 0.07373480498790741, L3: 0.09566199779510498, L4: 0.7586148977279663, L5: 0.02369837649166584
Epoch 5500, Loss: 1.8502016067504883, Losses: L1: 0.13948704302310944, L2: 0.07405900955200195, L3: 0.09494239091873169, L4: 0.7456319332122803, L5: 0.023861542344093323
Epoch 6000, Loss: 1.8272491693496704, Losses: L1: 0.13582971692085266, L2: 0.07415582984685898, L3: 0.09444767236709595, L4: 0.7359672784805298, L5: 0.02394934743642807
Epoch 6500, Loss: 1.8092912435531616, Losses: L1: 0.1332552134990692, L2: 0.07413050532341003, L3: 0.09405207633972168, L4: 0.7283825278282166, L5: 0.023983905091881752
Epoch 7000, Loss: 1.7960773706436157, Losses: L1: 0.1311533898115158, L2: 0.074034184217453, L3: 0.09379154443740845, L4: 0.7229832410812378, L5: 0.02399342507123947
Epoch 7500, Loss: 1.7862257957458496, Losses: L1: 0.1298980861902237, L2: 0.07394373416900635, L3: 0.093569815158844, L4: 0.7188292741775513, L5: 0.02399679459631443
Epoch 8000, Loss: 1.778717041015625, Losses: L1: 0.1287987381219864, L2: 0.07392453402280807, L3: 0.09344792366027832, L4: 0.715675950050354, L5: 0.023993419483304024
Epoch 8500, Loss: 1.773274302482605, Losses: L1: 0.12796354293823242, L2: 0.07390549778938293, L3: 0.09335148334503174, L4: 0.7134078741073608, L5: 0.024008318781852722
Epoch 9000, Loss: 1.769438624382019, Losses: L1: 0.1273912787437439, L2: 0.07388515025377274, L3: 0.09328508377075195, L4: 0.7118086218833923, L5: 0.024017158895730972
Epoch 9500, Loss: 1.7667145729064941, Losses: L1: 0.12700118124485016, L2: 0.07386337965726852, L3: 0.09324002265930176, L4: 0.7106765508651733, L5: 0.0240134596824646
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0274415016174316, Constraint losses: L1: 18.42068099975586, L2: 0.0030064345337450504, L3: 1.0030064582824707, L4: 1.0030078887939453
Epoch 500, Loss: 0.0023976252414286137, Constraint losses: L1: -0.8654767870903015, L2: 0.0, L3: 0.00263059139251709, L4: 0.0006325106369331479
Epoch 1000, Loss: 0.0012247147969901562, Constraint losses: L1: -1.1087080240249634, L2: 0.0, L3: 0.0021663904190063477, L4: 0.00016703252913430333
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.006899118423462, Constraint losses: L1: 7.724606990814209, L2: 0.0, L3: 0.9995872974395752, L4: 0.9995871782302856
Epoch 500, Loss: 0.0022942102514207363, Constraint losses: L1: -1.005781888961792, L2: 0.0, L3: 0.00264894962310791, L4: 0.000651042559184134
Epoch 1000, Loss: 0.0013394564157351851, Constraint losses: L1: -1.0695483684539795, L2: 0.0, L3: 0.002204298973083496, L4: 0.00020470588060561568
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 170.060546875, Losses: L1: 9.238064765930176, L2: 0.0019830306991934776, L3: 0.9989640116691589, L4: 79.86793518066406, L5: 0.2915775179862976
Epoch 500, Loss: 7.804931640625, Losses: L1: 1.6283971071243286, L2: 0.07971455156803131, L3: 0.11098599433898926, L4: 2.9470245838165283, L5: 0.03378164768218994
Epoch 1000, Loss: 7.5641865730285645, Losses: L1: 2.220125198364258, L2: 0.17437689006328583, L3: 0.07169747352600098, L4: 2.3725805282592773, L5: 0.10714893788099289
Epoch 1500, Loss: 7.380343914031982, Losses: L1: 2.359656810760498, L2: 0.11111244559288025, L3: 0.10388118028640747, L4: 2.2542338371276855, L5: 0.11902692914009094
Epoch 2000, Loss: 4.394037246704102, Losses: L1: 1.9223673343658447, L2: 0.07884082198143005, L3: 0.07041442394256592, L4: 1.0371630191802979, L5: 0.10222749412059784
Epoch 2500, Loss: 9.311912536621094, Losses: L1: 2.854401111602783, L2: 0.14310768246650696, L3: 0.09668546915054321, L4: 2.9908642768859863, L5: 0.0706123486161232
Epoch 3000, Loss: 5.413301467895508, Losses: L1: 2.406463384628296, L2: 0.10277155786752701, L3: 0.09128278493881226, L4: 1.2953486442565918, L5: 0.08247794955968857
Epoch 3500, Loss: 7.010651588439941, Losses: L1: 2.0518438816070557, L2: 0.08283932507038116, L3: 0.09150815010070801, L4: 2.2813003063201904, L5: 0.09238716959953308
Epoch 4000, Loss: 5.730269908905029, Losses: L1: 2.091825246810913, L2: 0.11625725030899048, L3: 0.12151336669921875, L4: 1.5855519771575928, L5: 0.08703481405973434
Epoch 4500, Loss: 4.7838134765625, Losses: L1: 1.9268555641174316, L2: 0.09201374650001526, L3: 0.10080075263977051, L4: 1.2186875343322754, L5: 0.09257740527391434
Epoch 5000, Loss: 4.369004726409912, Losses: L1: 1.8757514953613281, L2: 0.0820620059967041, L3: 0.09232616424560547, L4: 1.0450623035430908, L5: 0.09642075002193451
Epoch 5500, Loss: 4.043820858001709, Losses: L1: 1.7681329250335693, L2: 0.07361163198947906, L3: 0.08979856967926025, L4: 0.9453505873680115, L5: 0.09643226861953735
Epoch 6000, Loss: 3.944364547729492, Losses: L1: 1.7899701595306396, L2: 0.06979770958423615, L3: 0.0876694917678833, L4: 0.8890434503555298, L5: 0.09643863886594772
Epoch 6500, Loss: 3.8816370964050293, Losses: L1: 1.80131995677948, L2: 0.06755100190639496, L3: 0.08640557527542114, L4: 0.854530930519104, L5: 0.09647525101900101
Epoch 7000, Loss: 3.8432583808898926, Losses: L1: 1.8081200122833252, L2: 0.0661204382777214, L3: 0.08539515733718872, L4: 0.8337219953536987, L5: 0.09637799113988876
Epoch 7500, Loss: 3.818822145462036, Losses: L1: 1.8146417140960693, L2: 0.06506166607141495, L3: 0.08465969562530518, L4: 0.819441556930542, L5: 0.09642206132411957
Epoch 8000, Loss: 3.8025496006011963, Losses: L1: 1.819045066833496, L2: 0.06435388326644897, L3: 0.08410441875457764, L4: 0.8098868131637573, L5: 0.09648548066616058
Epoch 8500, Loss: 3.7916972637176514, Losses: L1: 1.8219459056854248, L2: 0.063868448138237, L3: 0.08371198177337646, L4: 0.8036127090454102, L5: 0.09646652638912201
Epoch 9000, Loss: 3.783738613128662, Losses: L1: 1.823531150817871, L2: 0.0635485053062439, L3: 0.08340215682983398, L4: 0.799188494682312, L5: 0.09651608765125275
Epoch 9500, Loss: 3.778245687484741, Losses: L1: 1.8244163990020752, L2: 0.06335973739624023, L3: 0.0831613540649414, L4: 0.7962480187416077, L5: 0.09651646763086319
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0252981185913086, Constraint losses: L1: 18.42068099975586, L2: 0.0022923508659005165, L3: 1.0022923946380615, L4: 1.0022926330566406
Epoch 500, Loss: 0.0027116979472339153, Constraint losses: L1: -1.101379632949829, L2: 0.0, L3: 0.0029053688049316406, L4: 0.0009077087743207812
Epoch 1000, Loss: 0.0014814813621342182, Constraint losses: L1: -1.1179730892181396, L2: 0.0, L3: 0.002299368381500244, L4: 0.0003000860451720655
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.011244535446167, Constraint losses: L1: 11.111532211303711, L2: 0.0003160896885674447, L3: 0.9999086856842041, L4: 0.9999082088470459
Epoch 500, Loss: 0.0020055160857737064, Constraint losses: L1: -1.039334774017334, L2: 0.0, L3: 0.0025216341018676758, L4: 0.0005232166731730103
Epoch 1000, Loss: 0.0012484700419008732, Constraint losses: L1: -1.071500539779663, L2: 0.0, L3: 0.002159714698791504, L4: 0.00016025593504309654
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 45.66959762573242, Losses: L1: 5.53926420211792, L2: 4.050783536513336e-05, L3: 0.9964800477027893, L4: 77.9896011352539, L5: 0.2779488265514374
Epoch 500, Loss: 4.834447860717773, Losses: L1: 2.3800125122070312, L2: 0.24864041805267334, L3: 0.09403526782989502, L4: 3.674424409866333, L5: 0.051814060658216476
Epoch 1000, Loss: 4.100372791290283, Losses: L1: 0.5921813249588013, L2: 0.06606384366750717, L3: 0.15194785594940186, L4: 6.397613048553467, L5: 0.05061938986182213
Epoch 1500, Loss: 2.160778284072876, Losses: L1: 0.059546053409576416, L2: 0.008942884393036366, L3: 0.13551050424575806, L4: 3.874234199523926, L5: 0.021437566727399826
Epoch 2000, Loss: 1.337062954902649, Losses: L1: 0.11917801201343536, L2: 0.05388060212135315, L3: 0.11112093925476074, L4: 1.981310486793518, L5: 0.01669517531991005
Epoch 2500, Loss: 0.8998696208000183, Losses: L1: 0.11435559391975403, L2: 0.023832092061638832, L3: 0.09987223148345947, L4: 1.2602030038833618, L5: 0.015752144157886505
Epoch 3000, Loss: 0.8349059820175171, Losses: L1: 0.10238143801689148, L2: 0.024856649339199066, L3: 0.09870612621307373, L4: 1.153525710105896, L5: 0.014684589579701424
Epoch 3500, Loss: 0.8166430592536926, Losses: L1: 0.09414318203926086, L2: 0.025599276646971703, L3: 0.09808015823364258, L4: 1.1323761940002441, L5: 0.014066117815673351
Epoch 4000, Loss: 0.8028203248977661, Losses: L1: 0.08888759464025497, L2: 0.026245424523949623, L3: 0.09710711240768433, L4: 1.1145706176757812, L5: 0.014098851941525936
Epoch 4500, Loss: 0.7933054566383362, Losses: L1: 0.08672332018613815, L2: 0.026576174423098564, L3: 0.09652793407440186, L4: 1.0999428033828735, L5: 0.013860970735549927
Epoch 5000, Loss: 0.7866989970207214, Losses: L1: 0.08403079211711884, L2: 0.026822835206985474, L3: 0.09621167182922363, L4: 1.0917831659317017, L5: 0.013838479295372963
Epoch 5500, Loss: 0.7821436524391174, Losses: L1: 0.08223715424537659, L2: 0.026972511783242226, L3: 0.09602624177932739, L4: 1.0861968994140625, L5: 0.013673555105924606
Epoch 6000, Loss: 0.7786911129951477, Losses: L1: 0.08110227435827255, L2: 0.027118565514683723, L3: 0.09576702117919922, L4: 1.081491231918335, L5: 0.013678171671926975
Epoch 6500, Loss: 0.7761046886444092, Losses: L1: 0.07993756979703903, L2: 0.02717248536646366, L3: 0.09578102827072144, L4: 1.078479528427124, L5: 0.013602785766124725
Epoch 7000, Loss: 0.7741344571113586, Losses: L1: 0.07956114411354065, L2: 0.027231108397245407, L3: 0.09558045864105225, L4: 1.075438380241394, L5: 0.013622915372252464
Epoch 7500, Loss: 0.7727028727531433, Losses: L1: 0.07905915379524231, L2: 0.027274789288640022, L3: 0.09551370143890381, L4: 1.0735690593719482, L5: 0.013591917231678963
Epoch 8000, Loss: 0.7717939615249634, Losses: L1: 0.07859565317630768, L2: 0.02731894701719284, L3: 0.09547489881515503, L4: 1.0725802183151245, L5: 0.01359076052904129
Epoch 8500, Loss: 0.7711015939712524, Losses: L1: 0.07835296541452408, L2: 0.027348442003130913, L3: 0.09542465209960938, L4: 1.0716830492019653, L5: 0.013571170158684254
Epoch 9000, Loss: 0.7705965638160706, Losses: L1: 0.07822712510824203, L2: 0.02736784517765045, L3: 0.09539353847503662, L4: 1.0709278583526611, L5: 0.013552563264966011
Epoch 9500, Loss: 0.7702794075012207, Losses: L1: 0.07812588661909103, L2: 0.027384832501411438, L3: 0.09536069631576538, L4: 1.0704938173294067, L5: 0.013552410528063774
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9971325397491455, Constraint losses: L1: 5.418823719024658, L2: 0.0, L3: 0.9958574175834656, L4: 0.9958562850952148
Epoch 500, Loss: 0.002028553280979395, Constraint losses: L1: -1.0899280309677124, L2: 0.0, L3: 0.002558410167694092, L4: 0.0005600712611339986
Epoch 1000, Loss: 0.0012437909608706832, Constraint losses: L1: -1.1183650493621826, L2: 0.0, L3: 0.002180814743041992, L4: 0.00018134128185920417
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0195975303649902, Constraint losses: L1: 18.42068099975586, L2: 0.00039226553053595126, L3: 1.0003923177719116, L4: 1.0003924369812012
Epoch 500, Loss: 0.002337176352739334, Constraint losses: L1: -1.0092263221740723, L2: 0.0, L3: 0.0026721954345703125, L4: 0.0006742074619978666
Epoch 1000, Loss: 0.0013540840009227395, Constraint losses: L1: -1.071318507194519, L2: 0.0, L3: 0.002212345600128174, L4: 0.00021305694826878607
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 59.77896499633789, Losses: L1: 17.98703956604004, L2: 0.002862286753952503, L3: 1.0027016401290894, L4: 80.97694396972656, L5: 0.2950272262096405
Epoch 500, Loss: 1.5415098667144775, Losses: L1: 0.2643188536167145, L2: 0.06804449111223221, L3: 0.10743933916091919, L4: 2.0356264114379883, L5: 0.015849413350224495
Epoch 1000, Loss: 2.1791837215423584, Losses: L1: 0.4770731031894684, L2: 0.04828496277332306, L3: 0.13827204704284668, L4: 2.8858587741851807, L5: 0.024339262396097183
Epoch 1500, Loss: 0.9476443529129028, Losses: L1: -0.0026063385885208845, L2: 0.010876846499741077, L3: 0.09348070621490479, L4: 1.6342432498931885, L5: 0.017894675955176353
Epoch 2000, Loss: 28.089534759521484, Losses: L1: 1.9330068826675415, L2: 0.24136042594909668, L3: 0.8664453625679016, L4: 49.191650390625, L5: 0.21153588593006134
Epoch 2500, Loss: 26.37873077392578, Losses: L1: 4.695291996002197, L2: 0.20062877237796783, L3: 1.0201177597045898, L4: 40.23774337768555, L5: 0.1431916356086731
Epoch 3000, Loss: 25.32723617553711, Losses: L1: 4.2233781814575195, L2: 0.1951579749584198, L3: 1.010524034500122, L4: 39.119781494140625, L5: 0.14312802255153656
Epoch 3500, Loss: 24.869068145751953, Losses: L1: 3.485261917114258, L2: 0.20453520119190216, L3: 1.0075452327728271, L4: 39.64274215698242, L5: 0.14582040905952454
Epoch 4000, Loss: 24.745031356811523, Losses: L1: 3.8969945907592773, L2: 0.22057926654815674, L3: 1.0024991035461426, L4: 38.504051208496094, L5: 0.152353435754776
Epoch 4500, Loss: 24.566314697265625, Losses: L1: 3.9857590198516846, L2: 0.20766983926296234, L3: 1.005026936531067, L4: 38.01800537109375, L5: 0.15118630230426788
Epoch 5000, Loss: 24.465795516967773, Losses: L1: 3.9009315967559814, L2: 0.21241049468517303, L3: 1.0084782838821411, L4: 37.963134765625, L5: 0.14999832212924957
Epoch 5500, Loss: 24.414854049682617, Losses: L1: 3.875288724899292, L2: 0.21569932997226715, L3: 1.010555386543274, L4: 37.89769744873047, L5: 0.14876367151737213
Epoch 6000, Loss: 24.383745193481445, Losses: L1: 3.861187696456909, L2: 0.2173648625612259, L3: 1.0118827819824219, L4: 37.85612106323242, L5: 0.14788387715816498
Epoch 6500, Loss: 24.364578247070312, Losses: L1: 3.8433053493499756, L2: 0.21844838559627533, L3: 1.0126755237579346, L4: 37.84809112548828, L5: 0.14765635132789612
Epoch 7000, Loss: 24.352218627929688, Losses: L1: 3.8319971561431885, L2: 0.21884672343730927, L3: 1.0130292177200317, L4: 37.84388732910156, L5: 0.14755722880363464
Epoch 7500, Loss: 24.343355178833008, Losses: L1: 3.825132369995117, L2: 0.21900907158851624, L3: 1.0132040977478027, L4: 37.83903121948242, L5: 0.14748568832874298
Epoch 8000, Loss: 24.33671760559082, Losses: L1: 3.820270299911499, L2: 0.21911412477493286, L3: 1.0132999420166016, L4: 37.83495330810547, L5: 0.14744259417057037
Epoch 8500, Loss: 24.331647872924805, Losses: L1: 3.8168962001800537, L2: 0.2191571742296219, L3: 1.0133498907089233, L4: 37.83136749267578, L5: 0.14740395545959473
Epoch 9000, Loss: 24.327783584594727, Losses: L1: 3.8143792152404785, L2: 0.21920038759708405, L3: 1.013378381729126, L4: 37.8284912109375, L5: 0.14737911522388458
Epoch 9500, Loss: 24.3248348236084, Losses: L1: 3.8125061988830566, L2: 0.21922491490840912, L3: 1.013392686843872, L4: 37.82625198364258, L5: 0.1473599523305893
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9909307956695557, Constraint losses: L1: 4.907001495361328, L2: 0.0, L3: 0.9930126070976257, L4: 0.9930112361907959
Epoch 500, Loss: 0.002080613747239113, Constraint losses: L1: -1.0521637201309204, L2: 0.0, L3: 0.002565324306488037, L4: 0.0005674533313140273
Epoch 1000, Loss: 0.0012342761037871242, Constraint losses: L1: -1.117706060409546, L2: 0.0, L3: 0.002175748348236084, L4: 0.0001762338069966063
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0035040378570557, Constraint losses: L1: 6.46737813949585, L2: 0.0, L3: 0.9985184669494629, L4: 0.9985182881355286
Epoch 500, Loss: 0.0020989368204027414, Constraint losses: L1: -0.9689100384712219, L2: 0.0, L3: 0.0025330185890197754, L4: 0.0005348282866179943
Epoch 1000, Loss: 0.0012537522707134485, Constraint losses: L1: -1.0702295303344727, L2: 0.0, L3: 0.002161681652069092, L4: 0.0001623001298867166
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 42.82933044433594, Losses: L1: 4.624820232391357, L2: 0.0, L3: 0.9891893863677979, L4: 73.44559478759766, L5: 0.24626080691814423
Epoch 500, Loss: 4.837210655212402, Losses: L1: 0.6272581815719604, L2: 0.08720681816339493, L3: 0.20271813869476318, L4: 7.452531337738037, L5: 0.05327756330370903
Epoch 1000, Loss: 9.130777359008789, Losses: L1: 3.0218780040740967, L2: 0.20233143866062164, L3: 0.31623077392578125, L4: 10.440193176269531, L5: 0.08395460993051529
Epoch 1500, Loss: 34.45661926269531, Losses: L1: 7.9079813957214355, L2: 0.0, L3: 0.9882622361183167, L4: 49.9456787109375, L5: 0.2937680184841156
Epoch 2000, Loss: 40.139686584472656, Losses: L1: 12.924986839294434, L2: 0.0, L3: 0.9999764561653137, L4: 51.53725051879883, L5: 0.22304926812648773
Epoch 2500, Loss: 22.88800811767578, Losses: L1: 2.8177006244659424, L2: 0.013845098204910755, L3: 0.7846920490264893, L4: 37.9322624206543, L5: 0.14589691162109375
Epoch 3000, Loss: 11.13757610321045, Losses: L1: 4.468109607696533, L2: 0.21753863990306854, L3: 0.24621343612670898, L4: 11.510627746582031, L5: 0.11643068492412567
Epoch 3500, Loss: 26.72097396850586, Losses: L1: 2.379304885864258, L2: 0.0, L3: 0.8086715936660767, L4: 45.9567985534668, L5: 0.27729931473731995
Epoch 4000, Loss: 9.328054428100586, Losses: L1: 4.572488784790039, L2: 0.16391430795192719, L3: 0.2179766297340393, L4: 8.059347152709961, L5: 0.09004363417625427
Epoch 4500, Loss: 8.950204849243164, Losses: L1: 4.570713996887207, L2: 0.15322305262088776, L3: 0.21603715419769287, L4: 7.354768753051758, L5: 0.08981131762266159
Epoch 5000, Loss: 8.728699684143066, Losses: L1: 4.566333293914795, L2: 0.14970730245113373, L3: 0.21096515655517578, L4: 6.944429397583008, L5: 0.08988618850708008
Epoch 5500, Loss: 8.582297325134277, Losses: L1: 4.560138702392578, L2: 0.14674270153045654, L3: 0.20795774459838867, L4: 6.6812896728515625, L5: 0.0900348350405693
Epoch 6000, Loss: 8.482595443725586, Losses: L1: 4.553086757659912, L2: 0.14411121606826782, L3: 0.20567357540130615, L4: 6.5102362632751465, L5: 0.09024730324745178
Epoch 6500, Loss: 8.412145614624023, Losses: L1: 4.546006202697754, L2: 0.14183363318443298, L3: 0.20385539531707764, L4: 6.395961761474609, L5: 0.09031768143177032
Epoch 7000, Loss: 8.223027229309082, Losses: L1: 4.366560935974121, L2: 0.13824573159217834, L3: 0.20235300064086914, L4: 6.383782863616943, L5: 0.09286510944366455
Epoch 7500, Loss: 8.19617748260498, Losses: L1: 4.360471725463867, L2: 0.13815073668956757, L3: 0.20127499103546143, L4: 6.346884727478027, L5: 0.0923437774181366
Epoch 8000, Loss: 8.17679500579834, Losses: L1: 4.3558526039123535, L2: 0.13804581761360168, L3: 0.20049810409545898, L4: 6.320401191711426, L5: 0.09207603335380554
Epoch 8500, Loss: 8.163722038269043, Losses: L1: 4.352457046508789, L2: 0.13804608583450317, L3: 0.1998920440673828, L4: 6.30210018157959, L5: 0.0921153798699379
Epoch 9000, Loss: 8.154485702514648, Losses: L1: 4.3509111404418945, L2: 0.138169527053833, L3: 0.19942694902420044, L4: 6.287342071533203, L5: 0.09206870943307877
Epoch 9500, Loss: 8.147980690002441, Losses: L1: 4.350029468536377, L2: 0.13825194537639618, L3: 0.19912898540496826, L4: 6.2766618728637695, L5: 0.09199342876672745
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021521806716919, Constraint losses: L1: 18.42068099975586, L2: 0.0010337141575291753, L3: 1.0010336637496948, L4: 1.0010337829589844
Epoch 500, Loss: 0.0021043033339083195, Constraint losses: L1: -1.0950967073440552, L2: 0.0, L3: 0.0025989413261413574, L4: 0.0006004589376971126
Epoch 1000, Loss: 0.001271299086511135, Constraint losses: L1: -1.117011547088623, L2: 0.0, L3: 0.0021939873695373535, L4: 0.0001943233364727348
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.997202754020691, Constraint losses: L1: 5.45281982421875, L2: 0.0, L3: 0.9958752393722534, L4: 0.9958746433258057
Epoch 500, Loss: 0.002319654216989875, Constraint losses: L1: -0.9320363402366638, L2: 0.0, L3: 0.0026246309280395508, L4: 0.0006270597223192453
Epoch 1000, Loss: 0.0012895918916910887, Constraint losses: L1: -1.0654796361923218, L2: 0.0, L3: 0.0021772384643554688, L4: 0.0001778331061359495
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.40122985839844, Losses: L1: 9.249588012695312, L2: 0.00020349955593701452, L3: 0.997831404209137, L4: 83.99751281738281, L5: 0.31178420782089233
Epoch 500, Loss: 7.412250995635986, Losses: L1: 0.5212593674659729, L2: 0.12532426416873932, L3: 0.18073666095733643, L4: 6.445298671722412, L5: 0.02861478179693222
Epoch 1000, Loss: 5.222224235534668, Losses: L1: 0.61710125207901, L2: 0.02745997905731201, L3: 0.18066620826721191, L4: 4.347014427185059, L5: 0.04504510015249252
Epoch 1500, Loss: 5.653074264526367, Losses: L1: 0.24635429680347443, L2: 0.22039677202701569, L3: 0.12885844707489014, L4: 4.818125247955322, L5: 0.037885554134845734
Epoch 2000, Loss: 1.3366961479187012, Losses: L1: 0.15587429702281952, L2: 0.017439352348446846, L3: 0.09571290016174316, L4: 1.0423163175582886, L5: 0.01582787185907364
Epoch 2500, Loss: 1.7491408586502075, Losses: L1: 0.08441758900880814, L2: 0.026634905487298965, L3: 0.08724868297576904, L4: 1.5157517194747925, L5: 0.01690608449280262
Epoch 3000, Loss: 0.9627571105957031, Losses: L1: 0.07156997174024582, L2: 0.024257607758045197, L3: 0.09062886238098145, L4: 0.7444553971290588, L5: 0.01517531368881464
Epoch 3500, Loss: 0.9139062762260437, Losses: L1: 0.06647855788469315, L2: 0.02221488580107689, L3: 0.08892130851745605, L4: 0.7067809104919434, L5: 0.014591421000659466
Epoch 4000, Loss: 0.8798977136611938, Losses: L1: 0.0645957663655281, L2: 0.01975364051759243, L3: 0.08817726373672485, L4: 0.6803407669067383, L5: 0.014553261920809746
Epoch 4500, Loss: 0.8668823838233948, Losses: L1: 0.06487642228603363, L2: 0.01788308471441269, L3: 0.08726990222930908, L4: 0.6716948747634888, L5: 0.014550103805959225
Epoch 5000, Loss: 0.8489498496055603, Losses: L1: 0.063428595662117, L2: 0.016415398567914963, L3: 0.08711814880371094, L4: 0.658402681350708, L5: 0.014339270070195198
Epoch 5500, Loss: 0.8397505283355713, Losses: L1: 0.06323947757482529, L2: 0.015473024919629097, L3: 0.08698642253875732, L4: 0.6514256000518799, L5: 0.014305980876088142
Epoch 6000, Loss: 0.8325555324554443, Losses: L1: 0.062685526907444, L2: 0.014861440286040306, L3: 0.08678567409515381, L4: 0.646239697933197, L5: 0.014243435114622116
Epoch 6500, Loss: 0.8268784880638123, Losses: L1: 0.06250201165676117, L2: 0.014385259710252285, L3: 0.08658534288406372, L4: 0.6419249176979065, L5: 0.01419142447412014
Epoch 7000, Loss: 0.823148787021637, Losses: L1: 0.0626523494720459, L2: 0.014092398807406425, L3: 0.08650076389312744, L4: 0.6387170553207397, L5: 0.014187655411660671
Epoch 7500, Loss: 0.8211876749992371, Losses: L1: 0.0627179741859436, L2: 0.013884133659303188, L3: 0.0864800214767456, L4: 0.63712477684021, L5: 0.014193293638527393
Epoch 8000, Loss: 0.8189610242843628, Losses: L1: 0.06223219260573387, L2: 0.01377516146749258, L3: 0.08643734455108643, L4: 0.6356699466705322, L5: 0.01414251048117876
Epoch 8500, Loss: 0.8177084922790527, Losses: L1: 0.062080468982458115, L2: 0.013690239749848843, L3: 0.08639109134674072, L4: 0.6347874402999878, L5: 0.014138028025627136
Epoch 9000, Loss: 0.8168674111366272, Losses: L1: 0.061969976872205734, L2: 0.01363463420420885, L3: 0.0863807201385498, L4: 0.6341838240623474, L5: 0.01412725169211626
Epoch 9500, Loss: 0.8163310289382935, Losses: L1: 0.061902277171611786, L2: 0.013594996184110641, L3: 0.08636283874511719, L4: 0.6338151097297668, L5: 0.01412164606153965
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.001831531524658, Constraint losses: L1: 6.06594181060791, L2: 0.0, L3: 0.9978832006454468, L4: 0.9978824257850647
Epoch 500, Loss: 0.002324305009096861, Constraint losses: L1: -1.007642149925232, L2: 0.0, L3: 0.0026649832725524902, L4: 0.0006669641006737947
Epoch 1000, Loss: 0.001285891281440854, Constraint losses: L1: -1.1174836158752441, L2: 0.0, L3: 0.002201378345489502, L4: 0.00020199666323605925
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0040481090545654, Constraint losses: L1: 6.591330528259277, L2: 0.0, L3: 0.9987286329269409, L4: 0.9987281560897827
Epoch 500, Loss: 0.0023659481666982174, Constraint losses: L1: -1.0572888851165771, L2: 0.0, L3: 0.002710700035095215, L4: 0.0007125369738787413
Epoch 1000, Loss: 0.001390442717820406, Constraint losses: L1: -1.0717483758926392, L2: 0.0, L3: 0.0022307634353637695, L4: 0.00023142767895478755
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 81.87641906738281, Losses: L1: 10.298674583435059, L2: 0.0009354606154374778, L3: 0.9962968826293945, L4: 70.34474182128906, L5: 0.2348300665616989
Epoch 500, Loss: 58.37604904174805, Losses: L1: 6.694490432739258, L2: 0.003426673822104931, L3: 0.9722801446914673, L4: 50.457393646240234, L5: 0.2450304627418518
Epoch 1000, Loss: 56.46724319458008, Losses: L1: 4.911818504333496, L2: 0.0020451261661946774, L3: 0.9237450957298279, L4: 50.40480041503906, L5: 0.22278934717178345
Epoch 1500, Loss: 10.513208389282227, Losses: L1: 0.816957950592041, L2: 0.05026395618915558, L3: 0.27816957235336304, L4: 9.265466690063477, L5: 0.05208545923233032
Epoch 2000, Loss: 14.34897232055664, Losses: L1: 5.9088454246521, L2: 0.07765131443738937, L3: 0.258105993270874, L4: 7.952280044555664, L5: 0.07443822175264359
Epoch 2500, Loss: 7.554980278015137, Losses: L1: 0.8008407354354858, L2: 0.05300503969192505, L3: 0.25100886821746826, L4: 6.344907760620117, L5: 0.05221274122595787
Epoch 3000, Loss: 7.005751609802246, Losses: L1: 0.5991679430007935, L2: 0.03760065138339996, L3: 0.23082369565963745, L4: 6.05324125289917, L5: 0.0473175123333931
Epoch 3500, Loss: 6.417505741119385, Losses: L1: 0.6264552474021912, L2: 0.021792128682136536, L3: 0.22237741947174072, L4: 5.475842475891113, L5: 0.04924643784761429
Epoch 4000, Loss: 6.109960079193115, Losses: L1: 0.5714823007583618, L2: 0.014545522630214691, L3: 0.21961236000061035, L4: 5.240694046020508, L5: 0.04908030107617378
Epoch 4500, Loss: 5.851726531982422, Losses: L1: 0.5809595584869385, L2: 0.012201866135001183, L3: 0.21625781059265137, L4: 4.980890274047852, L5: 0.049215104430913925
Epoch 5000, Loss: 5.677496433258057, Losses: L1: 0.5810632705688477, L2: 0.011286976747214794, L3: 0.21418678760528564, L4: 4.810544967651367, L5: 0.049127571284770966
Epoch 5500, Loss: 5.551851272583008, Losses: L1: 0.5850470662117004, L2: 0.010662795975804329, L3: 0.21265500783920288, L4: 4.683969497680664, L5: 0.04885399714112282
Epoch 6000, Loss: 5.45924711227417, Losses: L1: 0.5837293863296509, L2: 0.010188265703618526, L3: 0.2114800214767456, L4: 4.5946855545043945, L5: 0.048975590616464615
Epoch 6500, Loss: 5.389901638031006, Losses: L1: 0.5810750126838684, L2: 0.009827801957726479, L3: 0.21063625812530518, L4: 4.52940559387207, L5: 0.049129098653793335
Epoch 7000, Loss: 5.3375396728515625, Losses: L1: 0.5804671049118042, L2: 0.009638060815632343, L3: 0.2099754810333252, L4: 4.478738307952881, L5: 0.04908261448144913
Epoch 7500, Loss: 5.298233509063721, Losses: L1: 0.5790137648582458, L2: 0.009480861946940422, L3: 0.20951569080352783, L4: 4.441623687744141, L5: 0.04911866784095764
Epoch 8000, Loss: 5.268478870391846, Losses: L1: 0.578768253326416, L2: 0.009391531348228455, L3: 0.20916569232940674, L4: 4.412699222564697, L5: 0.049062736332416534
Epoch 8500, Loss: 5.246578216552734, Losses: L1: 0.5779459476470947, L2: 0.00931423157453537, L3: 0.20897674560546875, L4: 4.391982078552246, L5: 0.049045123159885406
Epoch 9000, Loss: 5.2302632331848145, Losses: L1: 0.5776891112327576, L2: 0.009278379380702972, L3: 0.2087864875793457, L4: 4.376242160797119, L5: 0.04898883029818535
Epoch 9500, Loss: 5.218690872192383, Losses: L1: 0.5772653818130493, L2: 0.009255435317754745, L3: 0.20867043733596802, L4: 4.365289688110352, L5: 0.04895463585853577
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0011632442474365, Constraint losses: L1: 6.029487609863281, L2: 0.0, L3: 0.9975666999816895, L4: 0.9975669980049133
Epoch 500, Loss: 0.0022248956374824047, Constraint losses: L1: -1.0921626091003418, L2: 0.0, L3: 0.0026577115058898926, L4: 0.0006593469297513366
Epoch 1000, Loss: 0.001307970262132585, Constraint losses: L1: -1.1183805465698242, L2: 0.0, L3: 0.0022128820419311523, L4: 0.00021346876746974885
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.024515390396118, Constraint losses: L1: 18.42068099975586, L2: 0.0020315730944275856, L3: 1.0020315647125244, L4: 1.0020315647125244
Epoch 500, Loss: 0.0022991537116467953, Constraint losses: L1: -1.012711763381958, L2: 0.0, L3: 0.002655029296875, L4: 0.0006568363169208169
Epoch 1000, Loss: 0.0013294401578605175, Constraint losses: L1: -1.0713459253311157, L2: 0.0, L3: 0.0022001266479492188, L4: 0.0002006595314014703
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 98.89812469482422, Losses: L1: 16.4019832611084, L2: 0.006370027549564838, L3: 1.0061662197113037, L4: 80.87594604492188, L5: 0.30064570903778076
Epoch 500, Loss: 19.777950286865234, Losses: L1: 3.3663225173950195, L2: 0.04701446741819382, L3: 0.29050201177597046, L4: 15.761347770690918, L5: 0.13287407159805298
Epoch 1000, Loss: 58.454925537109375, Losses: L1: 6.385326862335205, L2: 0.22112323343753815, L3: 1.0112547874450684, L4: 50.0334358215332, L5: 0.2913304567337036
Epoch 1500, Loss: 70.05752563476562, Losses: L1: 18.420635223388672, L2: 1.5611949066851594e-08, L3: 1.0, L4: 50.0506477355957, L5: 0.2931228578090668
Epoch 2000, Loss: 70.0486831665039, Losses: L1: 18.420652389526367, L2: 1.068616839461356e-08, L3: 1.0, L4: 50.034297943115234, L5: 0.296869158744812
Epoch 2500, Loss: 70.04484558105469, Losses: L1: 18.4206600189209, L2: 8.50786019412908e-09, L3: 1.0, L4: 50.02717590332031, L5: 0.2985043227672577
Epoch 3000, Loss: 70.04276275634766, Losses: L1: 18.420663833618164, L2: 7.3166956937598115e-09, L3: 1.0, L4: 50.0233154296875, L5: 0.2993914484977722
Epoch 3500, Loss: 70.04149627685547, Losses: L1: 18.420665740966797, L2: 6.588057210876741e-09, L3: 1.0, L4: 50.02096939086914, L5: 0.299932062625885
Epoch 4000, Loss: 70.04066467285156, Losses: L1: 18.420669555664062, L2: 6.110037809037294e-09, L3: 1.0, L4: 50.01942825317383, L5: 0.30028584599494934
Epoch 4500, Loss: 70.04010009765625, Losses: L1: 18.42066764831543, L2: 5.7817151066785755e-09, L3: 1.0, L4: 50.018375396728516, L5: 0.30052849650382996
Epoch 5000, Loss: 70.0396957397461, Losses: L1: 18.420669555664062, L2: 5.54875301261859e-09, L3: 1.0, L4: 50.01762390136719, L5: 0.30070042610168457
Epoch 5500, Loss: 70.0394058227539, Losses: L1: 18.420669555664062, L2: 5.379530154669965e-09, L3: 1.0, L4: 50.01708221435547, L5: 0.30082520842552185
Epoch 6000, Loss: 70.03919982910156, Losses: L1: 18.420669555664062, L2: 5.254611856742031e-09, L3: 1.0, L4: 50.01668930053711, L5: 0.30091726779937744
Epoch 6500, Loss: 70.03903198242188, Losses: L1: 18.420669555664062, L2: 5.16116838156222e-09, L3: 1.0, L4: 50.016387939453125, L5: 0.30098608136177063
Epoch 7000, Loss: 70.03890991210938, Losses: L1: 18.420669555664062, L2: 5.090599497492576e-09, L3: 1.0, L4: 50.01616668701172, L5: 0.3010379672050476
Epoch 7500, Loss: 70.038818359375, Losses: L1: 18.420669555664062, L2: 5.036780770240057e-09, L3: 1.0, L4: 50.0159912109375, L5: 0.30107739567756653
Epoch 8000, Loss: 70.03874969482422, Losses: L1: 18.420669555664062, L2: 4.9956390135719175e-09, L3: 1.0, L4: 50.01586151123047, L5: 0.30110758543014526
Epoch 8500, Loss: 70.0386962890625, Losses: L1: 18.420671463012695, L2: 4.96417751350009e-09, L3: 1.0, L4: 50.0157585144043, L5: 0.3011306822299957
Epoch 9000, Loss: 70.03865051269531, Losses: L1: 18.420669555664062, L2: 4.939943121229362e-09, L3: 1.0, L4: 50.015682220458984, L5: 0.3011484742164612
Epoch 9500, Loss: 70.03861999511719, Losses: L1: 18.420669555664062, L2: 4.921100416055424e-09, L3: 1.0, L4: 50.015625, L5: 0.3011622428894043
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.009150743484497, Constraint losses: L1: 9.265602111816406, L2: 1.2331220204941928e-05, L3: 0.9999365210533142, L4: 0.9999364018440247
Epoch 500, Loss: 0.0021363627165555954, Constraint losses: L1: -1.0529906749725342, L2: 0.0, L3: 0.002593696117401123, L4: 0.0005956572131253779
Epoch 1000, Loss: 0.0012487077619880438, Constraint losses: L1: -1.1179606914520264, L2: 0.0, L3: 0.0021830201148986816, L4: 0.0001836483716033399
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0091941356658936, Constraint losses: L1: 9.366500854492188, L2: 1.6712134311092086e-05, L3: 0.9999054670333862, L4: 0.9999054670333862
Epoch 500, Loss: 0.002328579779714346, Constraint losses: L1: -0.8536206483840942, L2: 0.0, L3: 0.0025899410247802734, L4: 0.0005922595737501979
Epoch 1000, Loss: 0.0012901005102321506, Constraint losses: L1: -1.0479828119277954, L2: 0.0, L3: 0.0021687746047973633, L4: 0.00016930872516240925
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 169.04298400878906, Losses: L1: 18.42068099975586, L2: 0.006540882866829634, L3: 1.0065408945083618, L4: 74.7375717163086, L5: 0.2550753355026245
Epoch 500, Loss: 5.799881935119629, Losses: L1: 1.1413745880126953, L2: 0.1120295375585556, L3: 0.0785169005393982, L4: 2.167304277420044, L5: 0.04264570027589798
Epoch 1000, Loss: 2.50809645652771, Losses: L1: 0.43558332324028015, L2: 0.06613776087760925, L3: 0.051972150802612305, L4: 0.9375689029693604, L5: 0.026255156844854355
Epoch 1500, Loss: 1.2934130430221558, Losses: L1: 0.17689251899719238, L2: 0.025435881689190865, L3: 0.051620662212371826, L4: 0.5018400549888611, L5: 0.02069585584104061
Epoch 2000, Loss: 1.6683733463287354, Losses: L1: -0.0025087189860641956, L2: 0.0071869888342916965, L3: 0.077145516872406, L4: 0.7859830260276794, L5: 0.014793026261031628
Epoch 2500, Loss: 3.0483558177948, Losses: L1: 0.6874847412109375, L2: 0.026071835309267044, L3: 0.07175678014755249, L4: 1.1071463823318481, L5: 0.04535587131977081
Epoch 3000, Loss: 2.8193469047546387, Losses: L1: 0.8874961137771606, L2: 0.060566503554582596, L3: 0.06562542915344238, L4: 0.8580448627471924, L5: 0.05800546705722809
Epoch 3500, Loss: 1.8133397102355957, Losses: L1: 0.7041473984718323, L2: 0.04972848296165466, L3: 0.06270849704742432, L4: 0.4612671434879303, L5: 0.04898491129279137
Epoch 4000, Loss: 1.6078482866287231, Losses: L1: 0.651463508605957, L2: 0.04534367099404335, L3: 0.0614778995513916, L4: 0.3907877206802368, L5: 0.045288290828466415
Epoch 4500, Loss: 1.5174074172973633, Losses: L1: 0.6442912817001343, L2: 0.0426471009850502, L3: 0.06084787845611572, L4: 0.35276252031326294, L5: 0.04289809986948967
Epoch 5000, Loss: 1.4067655801773071, Losses: L1: 0.5901932716369629, L2: 0.03864499554038048, L3: 0.060074448585510254, L4: 0.3297133445739746, L5: 0.03956243768334389
Epoch 5500, Loss: 1.3584927320480347, Losses: L1: 0.5708461999893188, L2: 0.03803127259016037, L3: 0.05965697765350342, L4: 0.3163173198699951, L5: 0.03858480602502823
Epoch 6000, Loss: 1.3391172885894775, Losses: L1: 0.5688923001289368, L2: 0.038058701902627945, L3: 0.059360384941101074, L4: 0.3078295588493347, L5: 0.03817617520689964
Epoch 6500, Loss: 1.324702501296997, Losses: L1: 0.5674935579299927, L2: 0.038017187267541885, L3: 0.05918622016906738, L4: 0.30153506994247437, L5: 0.03783663362264633
Epoch 7000, Loss: 1.314616322517395, Losses: L1: 0.566249430179596, L2: 0.037941351532936096, L3: 0.05905306339263916, L4: 0.29732877016067505, L5: 0.037547092884778976
Epoch 7500, Loss: 1.306918978691101, Losses: L1: 0.5651497840881348, L2: 0.037912845611572266, L3: 0.0589413046836853, L4: 0.294161319732666, L5: 0.0373590923845768
Epoch 8000, Loss: 1.3013496398925781, Losses: L1: 0.5642954707145691, L2: 0.037899311631917953, L3: 0.05885434150695801, L4: 0.2919028401374817, L5: 0.037190843373537064
Epoch 8500, Loss: 1.2972222566604614, Losses: L1: 0.5637197494506836, L2: 0.03787534683942795, L3: 0.0587921142578125, L4: 0.29021087288856506, L5: 0.037075743079185486
Epoch 9000, Loss: 1.2942421436309814, Losses: L1: 0.5633013844490051, L2: 0.03784629702568054, L3: 0.058746337890625, L4: 0.28900402784347534, L5: 0.036987483501434326
Epoch 9500, Loss: 1.292041301727295, Losses: L1: 0.5629997849464417, L2: 0.03782600164413452, L3: 0.058709144592285156, L4: 0.2881094515323639, L5: 0.036922916769981384
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0214617252349854, Constraint losses: L1: 18.42068099975586, L2: 0.001013729372061789, L3: 1.0010137557983398, L4: 1.0010135173797607
Epoch 500, Loss: 0.0022369518410414457, Constraint losses: L1: -1.0877121686935425, L2: 0.0, L3: 0.002661466598510742, L4: 0.0006631974829360843
Epoch 1000, Loss: 0.001308096805587411, Constraint losses: L1: -1.1183972358703613, L2: 0.0, L3: 0.0022129416465759277, L4: 0.0002135525573976338
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0277416706085205, Constraint losses: L1: 18.42068099975586, L2: 0.003106703981757164, L3: 1.003106713294983, L4: 1.0031075477600098
Epoch 500, Loss: 0.002433724934235215, Constraint losses: L1: -1.034656047821045, L2: 0.0, L3: 0.0027332305908203125, L4: 0.0007351504173129797
Epoch 1000, Loss: 0.0013991976156830788, Constraint losses: L1: -1.069843053817749, L2: 0.0, L3: 0.0022342801094055176, L4: 0.000234760605962947
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 145.97897338867188, Losses: L1: 18.42068099975586, L2: 0.002292629098519683, L3: 1.0022926330566406, L4: 63.17536926269531, L5: 0.20067653059959412
Epoch 500, Loss: 4.643519401550293, Losses: L1: 1.2655918598175049, L2: 0.06620368361473083, L3: 0.09210073947906494, L4: 1.5604658126831055, L5: 0.03248799592256546
Epoch 1000, Loss: 13.052494049072266, Losses: L1: 2.4842262268066406, L2: 0.10508996248245239, L3: 0.2084789276123047, L4: 5.055355548858643, L5: 0.03889813274145126
Epoch 1500, Loss: 6.93313455581665, Losses: L1: 0.845828652381897, L2: 0.12134406715631485, L3: 0.13598698377609253, L4: 2.84281325340271, L5: 0.023003946989774704
Epoch 2000, Loss: 4.325716018676758, Losses: L1: 1.0942052602767944, L2: 0.12843839824199677, L3: 0.11467134952545166, L4: 1.416765809059143, L5: 0.026430891826748848
Epoch 2500, Loss: 3.227252244949341, Losses: L1: 1.1028860807418823, L2: 0.08847387135028839, L3: 0.09927546977996826, L4: 0.9153160452842712, L5: 0.01751091144979
Epoch 3000, Loss: 2.7210428714752197, Losses: L1: 1.0322456359863281, L2: 0.08307012170553207, L3: 0.1005626916885376, L4: 0.7026330232620239, L5: 0.016828272491693497
Epoch 3500, Loss: 2.7039740085601807, Losses: L1: 0.965866208076477, L2: 0.0723138377070427, L3: 0.10034477710723877, L4: 0.7385258078575134, L5: 0.016083773225545883
Epoch 4000, Loss: 2.516547918319702, Losses: L1: 0.9448235630989075, L2: 0.07087142765522003, L3: 0.0990372896194458, L4: 0.6576199531555176, L5: 0.015704460442066193
Epoch 4500, Loss: 2.4457433223724365, Losses: L1: 0.9264357686042786, L2: 0.07001186907291412, L3: 0.09815216064453125, L4: 0.6327775120735168, L5: 0.015576506033539772
Epoch 5000, Loss: 2.409055709838867, Losses: L1: 0.9065315127372742, L2: 0.06881828606128693, L3: 0.09809237718582153, L4: 0.625722348690033, L5: 0.015350261703133583
Epoch 5500, Loss: 2.3942954540252686, Losses: L1: 0.9048600792884827, L2: 0.06823062896728516, L3: 0.0977400541305542, L4: 0.6199716329574585, L5: 0.015291059389710426
Epoch 6000, Loss: 2.3840131759643555, Losses: L1: 0.9040372967720032, L2: 0.0677863135933876, L3: 0.09743916988372803, L4: 0.6158428192138672, L5: 0.01527840830385685
Epoch 6500, Loss: 2.3754589557647705, Losses: L1: 0.9032479524612427, L2: 0.0675714835524559, L3: 0.09725147485733032, L4: 0.6122929453849792, L5: 0.015230829827487469
Epoch 7000, Loss: 2.3699400424957275, Losses: L1: 0.9029297828674316, L2: 0.06732629239559174, L3: 0.09709274768829346, L4: 0.6100204586982727, L5: 0.015223896130919456
Epoch 7500, Loss: 2.36628794670105, Losses: L1: 0.9024035334587097, L2: 0.06713159382343292, L3: 0.09700500965118408, L4: 0.608704686164856, L5: 0.015206880867481232
Epoch 8000, Loss: 2.341627359390259, Losses: L1: 0.8660273551940918, L2: 0.06644676625728607, L3: 0.09759759902954102, L4: 0.615086555480957, L5: 0.014935720711946487
Epoch 8500, Loss: 2.3252224922180176, Losses: L1: 0.8538836240768433, L2: 0.06486967951059341, L3: 0.09781616926193237, L4: 0.6144232153892517, L5: 0.014936945401132107
Epoch 9000, Loss: 2.3238322734832764, Losses: L1: 0.8548597097396851, L2: 0.06458934396505356, L3: 0.097800612449646, L4: 0.613527774810791, L5: 0.014937737956643105
Epoch 9500, Loss: 2.322930335998535, Losses: L1: 0.8548882007598877, L2: 0.0644308477640152, L3: 0.0978248119354248, L4: 0.6132150888442993, L5: 0.01492557767778635
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.004836082458496, Constraint losses: L1: 6.898803234100342, L2: 0.0, L3: 0.9989686608314514, L4: 0.9989687204360962
Epoch 500, Loss: 0.0021814536303281784, Constraint losses: L1: -1.0795669555664062, L2: 0.0, L3: 0.002629518508911133, L4: 0.000631502247415483
Epoch 1000, Loss: 0.0012784700375050306, Constraint losses: L1: -1.1171497106552124, L2: 0.0, L3: 0.002197563648223877, L4: 0.0001980560482479632
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0071403980255127, Constraint losses: L1: 7.784914493560791, L2: 0.00011927965533686802, L3: 0.9996181726455688, L4: 0.9996180534362793
Epoch 500, Loss: 0.0020774274598807096, Constraint losses: L1: -1.0650837421417236, L2: 0.0, L3: 0.002570509910583496, L4: 0.0005720013868995011
Epoch 1000, Loss: 0.0013050418347120285, Constraint losses: L1: -1.070680856704712, L2: 0.0, L3: 0.0021876096725463867, L4: 0.00018811311747413129
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 160.8298797607422, Losses: L1: 5.732542037963867, L2: 0.00011578973499126732, L3: 0.9874860048294067, L4: 76.78968048095703, L5: 0.2651262879371643
Epoch 500, Loss: 4.0866265296936035, Losses: L1: 0.34350380301475525, L2: 0.052802879363298416, L3: 0.06975454092025757, L4: 1.7564293146133423, L5: 0.0274518970400095
Epoch 1000, Loss: 2.4217941761016846, Losses: L1: 0.2994254231452942, L2: 0.062990702688694, L3: 0.07712727785110474, L4: 0.9399310946464539, L5: 0.019699016585946083
Epoch 1500, Loss: 1.841076374053955, Losses: L1: 0.09325136244297028, L2: 0.05379702150821686, L3: 0.0588071346282959, L4: 0.774749219417572, L5: 0.01596274971961975
Epoch 2000, Loss: 1.1298553943634033, Losses: L1: 0.10077981650829315, L2: 0.04052731394767761, L3: 0.005547225475311279, L4: 0.4571720361709595, L5: 0.014064875431358814
Epoch 2500, Loss: 0.9234833717346191, Losses: L1: 0.03299049660563469, L2: 0.04251909628510475, L3: 0.0015254020690917969, L4: 0.388566255569458, L5: 0.013398376293480396
Epoch 3000, Loss: 1.6620256900787354, Losses: L1: 0.09024513512849808, L2: 0.03953851759433746, L3: 0.0031487345695495605, L4: 0.7328398823738098, L5: 0.011937480419874191
Epoch 3500, Loss: 0.9293425679206848, Losses: L1: 0.09932957589626312, L2: 0.0334470272064209, L3: 0.005645692348480225, L4: 0.36692014336586, L5: 0.011816458776593208
Epoch 4000, Loss: 0.8300111293792725, Losses: L1: 0.05156118422746658, L2: 0.029057200998067856, L3: 0.0052117109298706055, L4: 0.3459872305393219, L5: 0.011574682779610157
Epoch 4500, Loss: 0.7694193720817566, Losses: L1: 0.10282620787620544, L2: 0.029712926596403122, L3: 0.0011418461799621582, L4: 0.2907392084598541, L5: 0.012273523956537247
Epoch 5000, Loss: 0.7512926459312439, Losses: L1: 0.10357573628425598, L2: 0.030149150639772415, L3: 0.0007245540618896484, L4: 0.2807401418685913, L5: 0.012606882490217686
Epoch 5500, Loss: 0.7399657368659973, Losses: L1: 0.10304004698991776, L2: 0.030250389128923416, L3: 0.00033777952194213867, L4: 0.2753872871398926, L5: 0.012656277045607567
Epoch 6000, Loss: 0.7320250272750854, Losses: L1: 0.10222022235393524, L2: 0.030260011553764343, L3: 3.8504600524902344e-05, L4: 0.27187350392341614, L5: 0.012749643065035343
Epoch 6500, Loss: 0.7272735238075256, Losses: L1: 0.10169130563735962, L2: 0.030294476076960564, L3: 8.094310760498047e-05, L4: 0.2696596682071686, L5: 0.012796490453183651
Epoch 7000, Loss: 0.7237842679023743, Losses: L1: 0.10111911594867706, L2: 0.030347544699907303, L3: 3.647804260253906e-05, L4: 0.2681441605091095, L5: 0.012822631746530533
Epoch 7500, Loss: 0.7216009497642517, Losses: L1: 0.10092534124851227, L2: 0.030397998169064522, L3: 9.274482727050781e-05, L4: 0.26704952120780945, L5: 0.012843895703554153
Epoch 8000, Loss: 0.7196304798126221, Losses: L1: 0.10090230405330658, L2: 0.030447576195001602, L3: 4.076957702636719e-05, L4: 0.26602262258529663, L5: 0.012873507104814053
Epoch 8500, Loss: 0.7183083295822144, Losses: L1: 0.10056795924901962, L2: 0.03048517368733883, L3: 2.3484230041503906e-05, L4: 0.2654901146888733, L5: 0.012883169576525688
Epoch 9000, Loss: 0.7175185680389404, Losses: L1: 0.10049741715192795, L2: 0.030511949211359024, L3: 2.372264862060547e-05, L4: 0.265094131231308, L5: 0.012892632745206356
Epoch 9500, Loss: 0.7169758081436157, Losses: L1: 0.10043786466121674, L2: 0.030532676726579666, L3: 7.62939453125e-06, L4: 0.2648312449455261, L5: 0.012901252135634422
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.019836664199829, Constraint losses: L1: 18.42068099975586, L2: 0.0004880014748778194, L3: 1.0004639625549316, L4: 1.0004639625549316
Epoch 500, Loss: 0.0024920112919062376, Constraint losses: L1: -0.9899746179580688, L2: 0.0, L3: 0.002739846706390381, L4: 0.0007421392947435379
Epoch 1000, Loss: 0.0013233842328190804, Constraint losses: L1: -1.1147761344909668, L2: 0.0, L3: 0.0022186636924743652, L4: 0.00021949672373011708
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.01975154876709, Constraint losses: L1: 18.42068099975586, L2: 0.00044722913298755884, L3: 1.0004417896270752, L4: 1.0004416704177856
Epoch 500, Loss: 0.0022053762804716825, Constraint losses: L1: -1.0293985605239868, L2: 0.0, L3: 0.0026165246963500977, L4: 0.0006182501674629748
Epoch 1000, Loss: 0.0013169993180781603, Constraint losses: L1: -1.0703133344650269, L2: 0.0, L3: 0.0021933913230895996, L4: 0.00019392136891838163
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 59.378746032714844, Losses: L1: 18.42068099975586, L2: 0.0013348867651075125, L3: 1.0013349056243896, L4: 77.6290054321289, L5: 0.2764417827129364
Epoch 500, Loss: 35.19401168823242, Losses: L1: 8.052562713623047, L2: 0.0, L3: 0.9994170069694519, L4: 49.980857849121094, L5: 0.30437278747558594
Epoch 1000, Loss: 15.167488098144531, Losses: L1: 6.225219249725342, L2: 0.9766301512718201, L3: 0.19913750886917114, L4: 13.02139949798584, L5: 0.16006901860237122
Epoch 1500, Loss: 30.59385108947754, Losses: L1: 5.18033504486084, L2: 0.002519289031624794, L3: 0.9329904317855835, L4: 46.80559539794922, L5: 0.2794013023376465
Epoch 2000, Loss: 9.237170219421387, Losses: L1: 4.747595310211182, L2: 0.21801923215389252, L3: 0.24443066120147705, L4: 7.0070295333862305, L5: 0.12232028692960739
Epoch 2500, Loss: 8.655258178710938, Losses: L1: 5.001429080963135, L2: 0.2177678346633911, L3: 0.22195059061050415, L4: 5.45285701751709, L5: 0.09592881798744202
Epoch 3000, Loss: 7.447504997253418, Losses: L1: 4.477128982543945, L2: 0.1527090221643448, L3: 0.2200155258178711, L4: 4.342157363891602, L5: 0.10769623517990112
Epoch 3500, Loss: 7.2611894607543945, Losses: L1: 4.425641059875488, L2: 0.14382199943065643, L3: 0.21612441539764404, L4: 4.127876281738281, L5: 0.10343554615974426
Epoch 4000, Loss: 7.129205226898193, Losses: L1: 4.443787097930908, L2: 0.13456356525421143, L3: 0.21674060821533203, L4: 3.8617827892303467, L5: 0.10383566468954086
Epoch 4500, Loss: 7.048713207244873, Losses: L1: 4.4340291023254395, L2: 0.13026082515716553, L3: 0.21389567852020264, L4: 3.7492589950561523, L5: 0.10348285734653473
Epoch 5000, Loss: 6.992326736450195, Losses: L1: 4.4261016845703125, L2: 0.12578566372394562, L3: 0.21304380893707275, L4: 3.673846960067749, L5: 0.10328498482704163
Epoch 5500, Loss: 6.816789150238037, Losses: L1: 4.250371932983398, L2: 0.12126091122627258, L3: 0.21092820167541504, L4: 3.7014174461364746, L5: 0.10266059637069702
Epoch 6000, Loss: 6.787438869476318, Losses: L1: 4.247714042663574, L2: 0.11996514350175858, L3: 0.21080440282821655, L4: 3.654111862182617, L5: 0.10226000845432281
Epoch 6500, Loss: 6.765413761138916, Losses: L1: 4.24632453918457, L2: 0.11954426020383835, L3: 0.21063584089279175, L4: 3.6157050132751465, L5: 0.1017519161105156
Epoch 7000, Loss: 6.748826026916504, Losses: L1: 4.244562149047852, L2: 0.11890475451946259, L3: 0.21041321754455566, L4: 3.589735746383667, L5: 0.10151983052492142
Epoch 7500, Loss: 6.736433982849121, Losses: L1: 4.243682861328125, L2: 0.11846714466810226, L3: 0.20991969108581543, L4: 3.570499897003174, L5: 0.10145605355501175
Epoch 8000, Loss: 6.727256774902344, Losses: L1: 4.243011951446533, L2: 0.11811745166778564, L3: 0.20952093601226807, L4: 3.5564985275268555, L5: 0.10143730044364929
Epoch 8500, Loss: 6.720440864562988, Losses: L1: 4.242480754852295, L2: 0.11785189807415009, L3: 0.20921111106872559, L4: 3.5462446212768555, L5: 0.10142332315444946
Epoch 9000, Loss: 6.702845096588135, Losses: L1: 4.224663257598877, L2: 0.11656010150909424, L3: 0.21016144752502441, L4: 3.548314094543457, L5: 0.10116321593523026
Epoch 9500, Loss: 6.700040817260742, Losses: L1: 4.2241530418396, L2: 0.11645852029323578, L3: 0.21008968353271484, L4: 3.5444629192352295, L5: 0.10111990571022034
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0082900524139404, Constraint losses: L1: 8.557371139526367, L2: 1.8782238839776255e-05, L3: 0.9998571276664734, L4: 0.9998568296432495
Epoch 500, Loss: 0.0022997278720140457, Constraint losses: L1: -0.9558835625648499, L2: 0.0, L3: 0.0026267170906066895, L4: 0.000628894311375916
Epoch 1000, Loss: 0.0012490819208323956, Constraint losses: L1: -1.1141226291656494, L2: 0.0, L3: 0.0021814703941345215, L4: 0.00018173418357037008
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0027709007263184, Constraint losses: L1: 6.354053497314453, L2: 0.0, L3: 0.9982081651687622, L4: 0.9982086420059204
Epoch 500, Loss: 0.0023943516425788403, Constraint losses: L1: -0.962786078453064, L2: 0.0, L3: 0.0026773810386657715, L4: 0.0006797566311433911
Epoch 1000, Loss: 0.0013480318011716008, Constraint losses: L1: -1.0674257278442383, L2: 0.0, L3: 0.002207338809967041, L4: 0.00020811884314753115
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 51.36805725097656, Losses: L1: 12.373478889465332, L2: 0.0006744620040990412, L3: 0.9996767640113831, L4: 73.487548828125, L5: 0.25010207295417786
Epoch 500, Loss: 2.5658957958221436, Losses: L1: 1.0345386266708374, L2: 0.08191513270139694, L3: 0.08735531568527222, L4: 2.3384785652160645, L5: 0.02357698604464531
Epoch 1000, Loss: 34.97381591796875, Losses: L1: 7.683935165405273, L2: 0.00012566434452310205, L3: 0.9934231638908386, L4: 50.01548385620117, L5: 0.29504087567329407
Epoch 1500, Loss: 7.22674036026001, Losses: L1: 1.0267466306686401, L2: 0.12761154770851135, L3: 0.250338077545166, L4: 10.756900787353516, L5: 0.06564357876777649
Epoch 2000, Loss: 28.86853790283203, Losses: L1: 2.8718531131744385, L2: 0.3443545997142792, L3: 0.8842629194259644, L4: 46.705299377441406, L5: 0.1868002861738205
Epoch 2500, Loss: 27.471115112304688, Losses: L1: 4.000245571136475, L2: 0.22008351981639862, L3: 0.9682877063751221, L4: 41.89565658569336, L5: 0.14629852771759033
Epoch 3000, Loss: 26.541053771972656, Losses: L1: 2.3297741413116455, L2: 0.19715802371501923, L3: 0.8613135814666748, L4: 43.884483337402344, L5: 0.15209583938121796
Epoch 3500, Loss: 26.63681983947754, Losses: L1: 2.8667216300964355, L2: 0.17489942908287048, L3: 0.9115529656410217, L4: 42.89726257324219, L5: 0.14856210350990295
Epoch 4000, Loss: 26.512699127197266, Losses: L1: 2.9125680923461914, L2: 0.1754000186920166, L3: 0.9201061725616455, L4: 42.52093505859375, L5: 0.14865073561668396
Epoch 4500, Loss: 26.470827102661133, Losses: L1: 2.9099388122558594, L2: 0.17562934756278992, L3: 0.9212429523468018, L4: 42.43745422363281, L5: 0.1484164446592331
Epoch 5000, Loss: 26.440391540527344, Losses: L1: 2.910640001296997, L2: 0.17419670522212982, L3: 0.9220764636993408, L4: 42.37804412841797, L5: 0.14818213880062103
Epoch 5500, Loss: 26.41738510131836, Losses: L1: 2.908738851547241, L2: 0.1731070727109909, L3: 0.9225980639457703, L4: 42.338417053222656, L5: 0.14802758395671844
Epoch 6000, Loss: 26.399667739868164, Losses: L1: 2.9052014350891113, L2: 0.17234453558921814, L3: 0.9228984713554382, L4: 42.31209945678711, L5: 0.1479310542345047
Epoch 6500, Loss: 26.385921478271484, Losses: L1: 2.9028334617614746, L2: 0.171705424785614, L3: 0.9231117963790894, L4: 42.29117202758789, L5: 0.14786624908447266
Epoch 7000, Loss: 26.375276565551758, Losses: L1: 2.9018208980560303, L2: 0.17111356556415558, L3: 0.9233488440513611, L4: 42.273460388183594, L5: 0.14780014753341675
Epoch 7500, Loss: 26.36701011657715, Losses: L1: 2.901319980621338, L2: 0.17062366008758545, L3: 0.9234926700592041, L4: 42.259403228759766, L5: 0.14775654673576355
Epoch 8000, Loss: 26.360626220703125, Losses: L1: 2.9012043476104736, L2: 0.1702171415090561, L3: 0.9236315488815308, L4: 42.248016357421875, L5: 0.14771606028079987
Epoch 8500, Loss: 26.355730056762695, Losses: L1: 2.9013237953186035, L2: 0.1698884516954422, L3: 0.9237561821937561, L4: 42.23887252807617, L5: 0.1476808786392212
Epoch 9000, Loss: 26.351993560791016, Losses: L1: 2.9014551639556885, L2: 0.16963082551956177, L3: 0.9238349199295044, L4: 42.23189926147461, L5: 0.14765694737434387
Epoch 9500, Loss: 26.349184036254883, Losses: L1: 2.9015958309173584, L2: 0.16943785548210144, L3: 0.9239048361778259, L4: 42.226531982421875, L5: 0.14763659238815308
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0191073417663574, Constraint losses: L1: 18.42068099975586, L2: 0.00022891393746249378, L3: 1.0002288818359375, L4: 1.0002288818359375
Epoch 500, Loss: 0.0023298831656575203, Constraint losses: L1: -1.0925886631011963, L2: 0.0, L3: 0.002710282802581787, L4: 0.0007121892413124442
Epoch 1000, Loss: 0.001339825103059411, Constraint losses: L1: -1.1184310913085938, L2: 0.0, L3: 0.002228856086730957, L4: 0.00022940010239835829
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9971569776535034, Constraint losses: L1: 5.4583659172058105, L2: 0.0, L3: 0.9958494901657104, L4: 0.9958491325378418
Epoch 500, Loss: 0.002161725191399455, Constraint losses: L1: -1.0394799709320068, L2: 0.0, L3: 0.0025997161865234375, L4: 0.0006014889804646373
Epoch 1000, Loss: 0.0013017880264669657, Constraint losses: L1: -1.0713388919830322, L2: 0.0, L3: 0.002186298370361328, L4: 0.0001868285471573472
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.31014633178711, Losses: L1: 6.014513969421387, L2: 1.4164977983455174e-05, L3: 0.9975090622901917, L4: 75.54077911376953, L5: 0.26509860157966614
Epoch 500, Loss: 1.6667476892471313, Losses: L1: 0.5539750456809998, L2: 0.03245489299297333, L3: 0.057686448097229004, L4: 1.8086090087890625, L5: 0.014092723838984966
Epoch 1000, Loss: 4.376666069030762, Losses: L1: 1.5979818105697632, L2: 0.16416877508163452, L3: 0.08673858642578125, L4: 4.376519203186035, L5: 0.0443047396838665
Epoch 1500, Loss: 27.809770584106445, Losses: L1: 2.1654248237609863, L2: 0.3439255952835083, L3: 0.8428780436515808, L4: 45.79403305053711, L5: 0.18686139583587646
Epoch 2000, Loss: 29.49948501586914, Losses: L1: 1.6480051279067993, L2: 0.12910126149654388, L3: 0.8674354553222656, L4: 50.828956604003906, L5: 0.22196395695209503
Epoch 2500, Loss: 3.4916677474975586, Losses: L1: 0.3059636056423187, L2: 0.10757777839899063, L3: 0.19286364316940308, L4: 5.046422004699707, L5: 0.030805053189396858
Epoch 3000, Loss: 2.324770450592041, Losses: L1: 0.3091239035129547, L2: 0.041098374873399734, L3: 0.15361905097961426, L4: 3.1674866676330566, L5: 0.021234149113297462
Epoch 3500, Loss: 2.1005499362945557, Losses: L1: 0.31462469696998596, L2: 0.04015272110700607, L3: 0.1448906660079956, L4: 2.7540478706359863, L5: 0.019407279789447784
Epoch 4000, Loss: 2.000520944595337, Losses: L1: 0.31392577290534973, L2: 0.043206702917814255, L3: 0.13726794719696045, L4: 2.57114315032959, L5: 0.020037207752466202
Epoch 4500, Loss: 1.9538816213607788, Losses: L1: 0.3059503436088562, L2: 0.04418649151921272, L3: 0.1351759433746338, L4: 2.5006299018859863, L5: 0.019445721060037613
Epoch 5000, Loss: 1.9205899238586426, Losses: L1: 0.30510610342025757, L2: 0.04444034397602081, L3: 0.1331040859222412, L4: 2.4425559043884277, L5: 0.01955847069621086
Epoch 5500, Loss: 1.89899480342865, Losses: L1: 0.30098193883895874, L2: 0.04448850825428963, L3: 0.13244789838790894, L4: 2.4104390144348145, L5: 0.019460266456007957
Epoch 6000, Loss: 1.8829319477081299, Losses: L1: 0.30052343010902405, L2: 0.04447265341877937, L3: 0.131422221660614, L4: 2.38346529006958, L5: 0.01944306492805481
Epoch 6500, Loss: 1.8714404106140137, Losses: L1: 0.29881682991981506, L2: 0.04455196112394333, L3: 0.13090455532073975, L4: 2.3657634258270264, L5: 0.019414404407143593
Epoch 7000, Loss: 1.8632080554962158, Losses: L1: 0.29770681262016296, L2: 0.04457182064652443, L3: 0.13057899475097656, L4: 2.3528852462768555, L5: 0.019378487020730972
Epoch 7500, Loss: 1.8572908639907837, Losses: L1: 0.29665836691856384, L2: 0.04457610473036766, L3: 0.13033956289291382, L4: 2.344179153442383, L5: 0.01935574971139431
Epoch 8000, Loss: 1.8531279563903809, Losses: L1: 0.296398788690567, L2: 0.04454297944903374, L3: 0.13014757633209229, L4: 2.337319850921631, L5: 0.01934407278895378
Epoch 8500, Loss: 1.850303292274475, Losses: L1: 0.2960647642612457, L2: 0.044551748782396317, L3: 0.13004225492477417, L4: 2.3327386379241943, L5: 0.019340593367815018
Epoch 9000, Loss: 1.8484195470809937, Losses: L1: 0.29606643319129944, L2: 0.04455043375492096, L3: 0.1299196481704712, L4: 2.3294241428375244, L5: 0.01935044676065445
Epoch 9500, Loss: 1.8470698595046997, Losses: L1: 0.29582175612449646, L2: 0.044549573212862015, L3: 0.12988179922103882, L4: 2.3274292945861816, L5: 0.019335316494107246
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0033469200134277, Constraint losses: L1: 6.4602885246276855, L2: 0.0, L3: 0.9984433650970459, L4: 0.9984433650970459
Epoch 500, Loss: 0.0024713596794754267, Constraint losses: L1: -1.0724352598190308, L2: 0.0, L3: 0.0027709007263183594, L4: 0.000772894243709743
Epoch 1000, Loss: 0.001371185528114438, Constraint losses: L1: -1.117520809173584, L2: 0.0, L3: 0.0022440552711486816, L4: 0.000244651164393872
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0056426525115967, Constraint losses: L1: 7.1282429695129395, L2: 0.0, L3: 0.9992573261260986, L4: 0.9992570877075195
Epoch 500, Loss: 0.0026677357964217663, Constraint losses: L1: -1.028510570526123, L2: 0.0, L3: 0.002847015857696533, L4: 0.0008492306806147099
Epoch 1000, Loss: 0.0014762399950996041, Constraint losses: L1: -1.0704377889633179, L2: 0.0, L3: 0.002273082733154297, L4: 0.000273595069302246
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.91553497314453, Losses: L1: 18.42068099975586, L2: 0.00902741402387619, L3: 1.009010910987854, L4: 67.35027313232422, L5: 0.2170051485300064
Epoch 500, Loss: 3.995676279067993, Losses: L1: 0.2393287867307663, L2: 0.075619176030159, L3: 0.07958453893661499, L4: 3.4272892475128174, L5: 0.03730146214365959
Epoch 1000, Loss: 13.229242324829102, Losses: L1: 3.5009195804595947, L2: 0.3141273856163025, L3: 0.2013121247291565, L4: 8.647435188293457, L5: 0.10001850128173828
Epoch 1500, Loss: 7.182705402374268, Losses: L1: 0.6655799746513367, L2: 0.03961201757192612, L3: 0.2065870761871338, L4: 6.002542972564697, L5: 0.04436894878745079
Epoch 2000, Loss: 2.488234519958496, Losses: L1: 0.12932917475700378, L2: 0.010037646628916264, L3: 0.11116957664489746, L4: 2.1089298725128174, L5: 0.01512184739112854
Epoch 2500, Loss: 1.7064298391342163, Losses: L1: 0.048150427639484406, L2: 0.00934937410056591, L3: 0.11146873235702515, L4: 1.409226417541504, L5: 0.014833735302090645
Epoch 3000, Loss: 1.52652907371521, Losses: L1: 0.016547614708542824, L2: 0.007736522704362869, L3: 0.10877197980880737, L4: 1.2697854042053223, L5: 0.014357942156493664
Epoch 3500, Loss: 1.40964674949646, Losses: L1: -0.003193708136677742, L2: 0.007664368953555822, L3: 0.10647249221801758, L4: 1.1778028011322021, L5: 0.01352782268077135
Epoch 4000, Loss: 1.323423981666565, Losses: L1: -0.00013448238314595073, L2: 0.009804163128137589, L3: 0.10436224937438965, L4: 1.0883241891860962, L5: 0.013802782632410526
Epoch 4500, Loss: 1.25626540184021, Losses: L1: -0.009115043096244335, L2: 0.012341894209384918, L3: 0.1027212142944336, L4: 1.0287460088729858, L5: 0.01301653403788805
Epoch 5000, Loss: 1.2070586681365967, Losses: L1: -0.018704870715737343, L2: 0.01456936914473772, L3: 0.10182851552963257, L4: 0.986574113368988, L5: 0.012787317857146263
Epoch 5500, Loss: 1.1768362522125244, Losses: L1: -0.020716771483421326, L2: 0.01608300767838955, L3: 0.10072994232177734, L4: 0.9575217962265015, L5: 0.012810640968382359
Epoch 6000, Loss: 1.1623659133911133, Losses: L1: -0.021602146327495575, L2: 0.01713833026587963, L3: 0.09993970394134521, L4: 0.9433903694152832, L5: 0.01284309383481741
Epoch 6500, Loss: 1.1493184566497803, Losses: L1: -0.02438219264149666, L2: 0.017702922224998474, L3: 0.09971380233764648, L4: 0.9324687123298645, L5: 0.012796914204955101
Epoch 7000, Loss: 1.1419087648391724, Losses: L1: -0.025530818849802017, L2: 0.017987506464123726, L3: 0.09952127933502197, L4: 0.9260203242301941, L5: 0.012803226709365845
Epoch 7500, Loss: 1.136786699295044, Losses: L1: -0.025965657085180283, L2: 0.01821630820631981, L3: 0.09933066368103027, L4: 0.9212472438812256, L5: 0.012822442688047886
Epoch 8000, Loss: 1.1328548192977905, Losses: L1: -0.026589782908558846, L2: 0.01838778331875801, L3: 0.09922134876251221, L4: 0.9178135395050049, L5: 0.012825829908251762
Epoch 8500, Loss: 1.129987359046936, Losses: L1: -0.026885369792580605, L2: 0.01851607859134674, L3: 0.09912484884262085, L4: 0.9151776432991028, L5: 0.012826482765376568
Epoch 9000, Loss: 1.127864956855774, Losses: L1: -0.027254270389676094, L2: 0.018606526777148247, L3: 0.09905576705932617, L4: 0.9133820533752441, L5: 0.012825141660869122
Epoch 9500, Loss: 1.1263679265975952, Losses: L1: -0.02717542089521885, L2: 0.018690209835767746, L3: 0.09895908832550049, L4: 0.91182541847229, L5: 0.012838604860007763
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0372369289398193, Constraint losses: L1: 18.42068099975586, L2: 0.0062723602168262005, L3: 1.006272315979004, L4: 1.0062716007232666
Epoch 500, Loss: 0.002198602072894573, Constraint losses: L1: -0.9981079697608948, L2: 0.0, L3: 0.0025974512100219727, L4: 0.0005992589867673814
Epoch 1000, Loss: 0.001235081348568201, Constraint losses: L1: -1.1166292428970337, L2: 0.0, L3: 0.002175569534301758, L4: 0.0001761412131600082
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.023739814758301, Constraint losses: L1: 18.42068099975586, L2: 0.0017730811377987266, L3: 1.0017731189727783, L4: 1.0017729997634888
Epoch 500, Loss: 0.0021207393147051334, Constraint losses: L1: -1.0635936260223389, L2: 0.0, L3: 0.0025914907455444336, L4: 0.0005928421160206199
Epoch 1000, Loss: 0.001317212008871138, Constraint losses: L1: -1.0714590549468994, L2: 0.0, L3: 0.0021941065788269043, L4: 0.00019456454901956022
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 93.31265258789062, Losses: L1: 17.983800888061523, L2: 0.0019715980160981417, L3: 1.0017895698547363, L4: 73.07176208496094, L5: 0.24957571923732758
Epoch 500, Loss: 66.78631591796875, Losses: L1: 14.878021240234375, L2: 0.03201849013566971, L3: 1.006665825843811, L4: 49.53242111206055, L5: 0.29850393533706665
Epoch 1000, Loss: 7.659233570098877, Losses: L1: 1.8875300884246826, L2: 0.157747283577919, L3: 0.1410161852836609, L4: 5.131460189819336, L5: 0.04271658509969711
Epoch 1500, Loss: 7.271258354187012, Losses: L1: 0.5178089737892151, L2: 0.21995410323143005, L3: 0.17737305164337158, L4: 5.888230323791504, L5: 0.07056494057178497
Epoch 2000, Loss: 4.113246440887451, Losses: L1: 0.4429522156715393, L2: 0.0712970420718193, L3: 0.11257922649383545, L4: 3.2680282592773438, L5: 0.034513410180807114
Epoch 2500, Loss: 16.576278686523438, Losses: L1: 3.4304215908050537, L2: 0.513451337814331, L3: 0.2620809078216553, L4: 11.48474407196045, L5: 0.11004792153835297
Epoch 3000, Loss: 11.042102813720703, Losses: L1: 1.710574984550476, L2: 0.2884155511856079, L3: 0.24259984493255615, L4: 8.193410873413086, L5: 0.07608602941036224
Epoch 3500, Loss: 9.58521556854248, Losses: L1: 1.3698326349258423, L2: 0.23440472781658173, L3: 0.24719053506851196, L4: 7.185288906097412, L5: 0.06690280139446259
Epoch 4000, Loss: 8.763693809509277, Losses: L1: 1.232369303703308, L2: 0.21710263192653656, L3: 0.2417745590209961, L4: 6.551011085510254, L5: 0.06255906820297241
Epoch 4500, Loss: 8.049897193908691, Losses: L1: 1.1073781251907349, L2: 0.198822021484375, L3: 0.23735135793685913, L4: 6.00983190536499, L5: 0.06034012883901596
Epoch 5000, Loss: 7.57098913192749, Losses: L1: 1.0935044288635254, L2: 0.1867353767156601, L3: 0.23335540294647217, L4: 5.579847812652588, L5: 0.05745565518736839
Epoch 5500, Loss: 7.159623622894287, Losses: L1: 1.082806944847107, L2: 0.17380838096141815, L3: 0.22916710376739502, L4: 5.2162604331970215, L5: 0.054605115205049515
Epoch 6000, Loss: 6.791624069213867, Losses: L1: 1.0648784637451172, L2: 0.16488361358642578, L3: 0.2227557897567749, L4: 4.899209976196289, L5: 0.05225670710206032
Epoch 6500, Loss: 6.551045894622803, Losses: L1: 1.0546501874923706, L2: 0.15772022306919098, L3: 0.21902930736541748, L4: 4.692407608032227, L5: 0.050489071756601334
Epoch 7000, Loss: 6.399038314819336, Losses: L1: 1.049542784690857, L2: 0.15245114266872406, L3: 0.21653103828430176, L4: 4.562211036682129, L5: 0.04932013899087906
Epoch 7500, Loss: 6.264382362365723, Losses: L1: 1.0334664583206177, L2: 0.14643555879592896, L3: 0.21194958686828613, L4: 4.464738368988037, L5: 0.04940680414438248
Epoch 8000, Loss: 6.1917853355407715, Losses: L1: 1.0332257747650146, L2: 0.14568215608596802, L3: 0.20963406562805176, L4: 4.398471355438232, L5: 0.049455516040325165
Epoch 8500, Loss: 6.143100738525391, Losses: L1: 1.034156084060669, L2: 0.14487777650356293, L3: 0.20899838209152222, L4: 4.351900100708008, L5: 0.049292322248220444
Epoch 9000, Loss: 6.109579086303711, Losses: L1: 1.0346935987472534, L2: 0.14430494606494904, L3: 0.2086106538772583, L4: 4.319887638092041, L5: 0.0491664744913578
Epoch 9500, Loss: 6.086801052093506, Losses: L1: 1.0350298881530762, L2: 0.14393942058086395, L3: 0.208315908908844, L4: 4.298182487487793, L5: 0.04907793551683426
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0046324729919434, Constraint losses: L1: 6.849155426025391, L2: 0.0, L3: 0.9988915324211121, L4: 0.9988917112350464
Epoch 500, Loss: 0.0022282947320491076, Constraint losses: L1: -1.1166045665740967, L2: 0.0, L3: 0.002671658992767334, L4: 0.0006732403999194503
Epoch 1000, Loss: 0.0013327380875125527, Constraint losses: L1: -1.1175494194030762, L2: 0.0, L3: 0.0022249221801757812, L4: 0.00022536542383022606
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9896916151046753, Constraint losses: L1: 4.854311466217041, L2: 0.0, L3: 0.9924190044403076, L4: 0.9924182891845703
Epoch 500, Loss: 0.002258483786135912, Constraint losses: L1: -0.9908207058906555, L2: 0.0, L3: 0.002623617649078369, L4: 0.0006256869528442621
Epoch 1000, Loss: 0.0013054889859631658, Constraint losses: L1: -1.0684813261032104, L2: 0.0, L3: 0.002186715602874756, L4: 0.0001872547436505556
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 89.04119110107422, Losses: L1: 11.706175804138184, L2: 0.00102421420160681, L3: 1.0000747442245483, L4: 74.8118896484375, L5: 0.2604618966579437
Epoch 500, Loss: 5.237636566162109, Losses: L1: 1.5332506895065308, L2: 0.09050280600786209, L3: 0.0783882737159729, L4: 3.3090596199035645, L5: 0.02877211757004261
Epoch 1000, Loss: 2.9975523948669434, Losses: L1: 0.4873121678829193, L2: 0.019591879099607468, L3: 0.051139652729034424, L4: 2.299931764602661, L5: 0.03442258760333061
Epoch 1500, Loss: 2.909566640853882, Losses: L1: 0.05786767601966858, L2: 0.013900374993681908, L3: 0.10955846309661865, L4: 2.558441638946533, L5: 0.023169852793216705
Epoch 2000, Loss: 1.128231167793274, Losses: L1: 0.03933245316147804, L2: 0.02093399502336979, L3: 0.08900690078735352, L4: 0.8478728532791138, L5: 0.010571989230811596
Epoch 2500, Loss: 1.2031943798065186, Losses: L1: -0.05948212742805481, L2: 0.010053613223135471, L3: 0.08584648370742798, L4: 1.04634428024292, L5: 0.01226602029055357
Epoch 3000, Loss: 0.762803852558136, Losses: L1: -0.07381577044725418, L2: 0.011435340158641338, L3: 0.08038198947906494, L4: 0.6368972063064575, L5: 0.008043893612921238
Epoch 3500, Loss: 0.6106234192848206, Losses: L1: -0.07932503521442413, L2: 0.0096763726323843, L3: 0.07979124784469604, L4: 0.4944750666618347, L5: 0.008269079029560089
Epoch 4000, Loss: 0.5812253952026367, Losses: L1: -0.08596210181713104, L2: 0.00911023747175932, L3: 0.07829850912094116, L4: 0.4759072959423065, L5: 0.008231354877352715
Epoch 4500, Loss: 0.5530242323875427, Losses: L1: -0.09038644284009933, L2: 0.008627920411527157, L3: 0.0775107741355896, L4: 0.4546665549278259, L5: 0.008233380503952503
Epoch 5000, Loss: 0.5326184034347534, Losses: L1: -0.09394557774066925, L2: 0.00817146711051464, L3: 0.07713055610656738, L4: 0.4394584894180298, L5: 0.008250702172517776
Epoch 5500, Loss: 0.5214637517929077, Losses: L1: -0.09689345955848694, L2: 0.008155430667102337, L3: 0.07669293880462646, L4: 0.4323471188545227, L5: 0.00815668422728777
Epoch 6000, Loss: 0.5136358141899109, Losses: L1: -0.09874193370342255, L2: 0.008008058182895184, L3: 0.07644814252853394, L4: 0.42715945839881897, L5: 0.008152955211699009
Epoch 6500, Loss: 0.507602870464325, Losses: L1: -0.10029561072587967, L2: 0.007965781725943089, L3: 0.07615983486175537, L4: 0.4234169125556946, L5: 0.008115161210298538
Epoch 7000, Loss: 0.5030979514122009, Losses: L1: -0.1015382632613182, L2: 0.007919429801404476, L3: 0.0760202407836914, L4: 0.4205896258354187, L5: 0.008083635941147804
Epoch 7500, Loss: 0.5000216364860535, Losses: L1: -0.10240449756383896, L2: 0.00790088064968586, L3: 0.075919508934021, L4: 0.41867125034332275, L5: 0.008057051338255405
Epoch 8000, Loss: 0.49799424409866333, Losses: L1: -0.1029638797044754, L2: 0.007904780097305775, L3: 0.07581859827041626, L4: 0.4174409508705139, L5: 0.00803520530462265
Epoch 8500, Loss: 0.4963265061378479, Losses: L1: -0.10337480902671814, L2: 0.00790785625576973, L3: 0.07576310634613037, L4: 0.4162980616092682, L5: 0.008030671626329422
Epoch 9000, Loss: 0.495285302400589, Losses: L1: -0.10367975383996964, L2: 0.00788991991430521, L3: 0.07573461532592773, L4: 0.41567009687423706, L5: 0.008022952824831009
Epoch 9500, Loss: 0.4945969879627228, Losses: L1: -0.10385576635599136, L2: 0.007886961102485657, L3: 0.07570230960845947, L4: 0.4152376353740692, L5: 0.00801828969269991
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.999836802482605, Constraint losses: L1: 5.798954010009766, L2: 0.0, L3: 0.9970191121101379, L4: 0.9970186948776245
Epoch 500, Loss: 0.002644023858010769, Constraint losses: L1: -1.0460162162780762, L2: 0.0, L3: 0.002843797206878662, L4: 0.0008462429977953434
Epoch 1000, Loss: 0.0014232380781322718, Constraint losses: L1: -1.1176122426986694, L2: 0.0, L3: 0.0022701025009155273, L4: 0.0002707478706724942
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.024928092956543, Constraint losses: L1: 18.42068099975586, L2: 0.0021690926514565945, L3: 1.002169132232666, L4: 1.0021692514419556
Epoch 500, Loss: 0.002180257812142372, Constraint losses: L1: -1.0634346008300781, L2: 0.0, L3: 0.002621173858642578, L4: 0.0006225184770300984
Epoch 1000, Loss: 0.0013389408122748137, Constraint losses: L1: -1.0715131759643555, L2: 0.0, L3: 0.00220489501953125, L4: 0.0002055590448435396
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 143.92041015625, Losses: L1: 8.350740432739258, L2: 0.000275458674877882, L3: 0.9993643164634705, L4: 66.73131561279297, L5: 0.21552547812461853
Epoch 500, Loss: 22.246776580810547, Losses: L1: 1.8558822870254517, L2: 0.2783130407333374, L3: 0.24676036834716797, L4: 9.651365280151367, L5: 0.07603561878204346
Epoch 1000, Loss: 15.322617530822754, Losses: L1: 6.44320821762085, L2: 0.5282220840454102, L3: 0.17031323909759521, L4: 3.7202200889587402, L5: 0.08379776030778885
Epoch 1500, Loss: 12.45484733581543, Losses: L1: 2.0921285152435303, L2: 0.1936197280883789, L3: 0.2374180555343628, L4: 4.73710298538208, L5: 0.05287589132785797
Epoch 2000, Loss: 8.269375801086426, Losses: L1: 2.327192544937134, L2: 0.13636578619480133, L3: 0.16363632678985596, L4: 2.6617612838745117, L5: 0.03731361776590347
Epoch 2500, Loss: 15.853408813476562, Losses: L1: 0.9875668287277222, L2: 0.12154880166053772, L3: 0.2700401544570923, L4: 7.026388168334961, L5: 0.05977596715092659
Epoch 3000, Loss: 12.946918487548828, Losses: L1: 1.38862943649292, L2: 0.11124298721551895, L3: 0.25892579555511475, L4: 5.394412994384766, L5: 0.05824969336390495
Epoch 3500, Loss: 13.713691711425781, Losses: L1: 0.8438804149627686, L2: 0.0459313727915287, L3: 0.26691925525665283, L4: 6.108600616455078, L5: 0.053816940635442734
Epoch 4000, Loss: 11.564599990844727, Losses: L1: 1.0991593599319458, L2: 0.04689193144440651, L3: 0.2506747245788574, L4: 4.920657634735107, L5: 0.05798289552330971
Epoch 4500, Loss: 10.639983177185059, Losses: L1: 1.077976942062378, L2: 0.046446237713098526, L3: 0.23887121677398682, L4: 4.481280326843262, L5: 0.05762040242552757
Epoch 5000, Loss: 10.140922546386719, Losses: L1: 1.0787205696105957, L2: 0.048387832939624786, L3: 0.22666919231414795, L4: 4.241183757781982, L5: 0.05944150313735008
Epoch 5500, Loss: 9.902066230773926, Losses: L1: 1.0761035680770874, L2: 0.04957053065299988, L3: 0.22293293476104736, L4: 4.1255083084106445, L5: 0.059877172112464905
Epoch 6000, Loss: 9.749028205871582, Losses: L1: 1.0805610418319702, L2: 0.04984133690595627, L3: 0.22082644701004028, L4: 4.0485687255859375, L5: 0.05998779833316803
Epoch 6500, Loss: 9.671592712402344, Losses: L1: 1.0884389877319336, L2: 0.049964841455221176, L3: 0.21830636262893677, L4: 4.008358001708984, L5: 0.059790659695863724
Epoch 7000, Loss: 9.611888885498047, Losses: L1: 1.0874106884002686, L2: 0.049656085669994354, L3: 0.21924781799316406, L4: 3.978393077850342, L5: 0.05976954102516174
Epoch 7500, Loss: 9.554865837097168, Losses: L1: 1.071014165878296, L2: 0.0495142936706543, L3: 0.21919536590576172, L4: 3.958332061767578, L5: 0.05953572690486908
Epoch 8000, Loss: 9.522746086120605, Losses: L1: 1.0695453882217407, L2: 0.04942375794053078, L3: 0.2190026044845581, L4: 3.9433035850524902, L5: 0.05948027968406677
Epoch 8500, Loss: 9.499613761901855, Losses: L1: 1.070007085800171, L2: 0.04939369857311249, L3: 0.21877634525299072, L4: 3.931766986846924, L5: 0.05946503207087517
Epoch 9000, Loss: 9.48308277130127, Losses: L1: 1.07102370262146, L2: 0.04940095543861389, L3: 0.21860134601593018, L4: 3.923166275024414, L5: 0.05944504216313362
Epoch 9500, Loss: 9.47138500213623, Losses: L1: 1.0712171792984009, L2: 0.049368999898433685, L3: 0.21849846839904785, L4: 3.917351722717285, L5: 0.059458762407302856
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.008413076400757, Constraint losses: L1: 8.758535385131836, L2: 0.0, L3: 0.9998272657394409, L4: 0.9998273253440857
Epoch 500, Loss: 0.0022306162863969803, Constraint losses: L1: -1.1060280799865723, L2: 0.0, L3: 0.0026674866676330566, L4: 0.0006691578309983015
Epoch 1000, Loss: 0.0013186157448217273, Constraint losses: L1: -1.118167757987976, L2: 0.0, L3: 0.0022181272506713867, L4: 0.00021865623421035707
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.020301342010498, Constraint losses: L1: 18.42068099975586, L2: 0.0006269102450460196, L3: 1.0006269216537476, L4: 1.000626802444458
Epoch 500, Loss: 0.0021434430964291096, Constraint losses: L1: -1.062487244606018, L2: 0.0, L3: 0.0026022791862487793, L4: 0.0006036510458216071
Epoch 1000, Loss: 0.0013292626244947314, Constraint losses: L1: -1.0713127851486206, L2: 0.0, L3: 0.002200007438659668, L4: 0.00020056802895851433
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 183.42941284179688, Losses: L1: 18.42068099975586, L2: 0.004889494739472866, L3: 1.0048894882202148, L4: 81.34672546386719, L5: 0.29571035504341125
Epoch 500, Loss: 8.128979682922363, Losses: L1: 1.1954118013381958, L2: 0.04467107355594635, L3: 0.12766754627227783, L4: 3.275973320007324, L5: 0.03694400563836098
Epoch 1000, Loss: 8.483083724975586, Losses: L1: 2.2201621532440186, L2: 0.079290010035038, L3: 0.05425077676773071, L4: 2.9711716175079346, L5: 0.05349704623222351
Epoch 1500, Loss: 1.7827045917510986, Losses: L1: 0.44449806213378906, L2: 0.0367090217769146, L3: 0.050412774085998535, L4: 0.5621623396873474, L5: 0.03963831812143326
Epoch 2000, Loss: 1.8431107997894287, Losses: L1: 0.5115149617195129, L2: 0.03211243450641632, L3: 0.0609973669052124, L4: 0.5400696396827698, L5: 0.0652368813753128
Epoch 2500, Loss: 3.2641758918762207, Losses: L1: 1.1404794454574585, L2: 0.054897308349609375, L3: 0.10182845592498779, L4: 0.8798829317092896, L5: 0.05047884210944176
Epoch 3000, Loss: 1.9425679445266724, Losses: L1: 0.7419647574424744, L2: 0.04652567580342293, L3: 0.07926452159881592, L4: 0.4530683755874634, L5: 0.04288603737950325
Epoch 3500, Loss: 1.7442342042922974, Losses: L1: 0.6241501569747925, L2: 0.047586288303136826, L3: 0.07266801595687866, L4: 0.4193668067455292, L5: 0.04084181785583496
Epoch 4000, Loss: 1.5642414093017578, Losses: L1: 0.5875735282897949, L2: 0.04570486396551132, L3: 0.06887644529342651, L4: 0.3530377745628357, L5: 0.041429806500673294
Epoch 4500, Loss: 1.4955835342407227, Losses: L1: 0.56340092420578, L2: 0.0435330867767334, L3: 0.06712782382965088, L4: 0.3350575566291809, L5: 0.04074579477310181
Epoch 5000, Loss: 1.466145396232605, Losses: L1: 0.5581552982330322, L2: 0.042864322662353516, L3: 0.06625133752822876, L4: 0.3248556852340698, L5: 0.04004739597439766
Epoch 5500, Loss: 1.4444482326507568, Losses: L1: 0.5553643107414246, L2: 0.04253149777650833, L3: 0.06550323963165283, L4: 0.3166535496711731, L5: 0.03970743343234062
Epoch 6000, Loss: 1.4290554523468018, Losses: L1: 0.5530709624290466, L2: 0.042166128754615784, L3: 0.06504666805267334, L4: 0.3110986351966858, L5: 0.03936154767870903
Epoch 6500, Loss: 1.403395414352417, Losses: L1: 0.5407944321632385, L2: 0.041643448173999786, L3: 0.06484073400497437, L4: 0.30514419078826904, L5: 0.03934432193636894
Epoch 7000, Loss: 1.3947683572769165, Losses: L1: 0.5396384000778198, L2: 0.0415082648396492, L3: 0.06461799144744873, L4: 0.30185607075691223, L5: 0.039165422320365906
Epoch 7500, Loss: 1.3884161710739136, Losses: L1: 0.539007306098938, L2: 0.04138997197151184, L3: 0.06444984674453735, L4: 0.2993261218070984, L5: 0.039076969027519226
Epoch 8000, Loss: 1.383772850036621, Losses: L1: 0.5386317372322083, L2: 0.041294824331998825, L3: 0.06431806087493896, L4: 0.29745230078697205, L5: 0.03901078924536705
Epoch 8500, Loss: 1.3655097484588623, Losses: L1: 0.523036777973175, L2: 0.04102800786495209, L3: 0.06425619125366211, L4: 0.29646235704421997, L5: 0.03897988051176071
Epoch 9000, Loss: 1.362425446510315, Losses: L1: 0.5224114060401917, L2: 0.041111670434474945, L3: 0.06413185596466064, L4: 0.2953053414821625, L5: 0.03891619294881821
Epoch 9500, Loss: 1.3605303764343262, Losses: L1: 0.5219482779502869, L2: 0.041095323860645294, L3: 0.06407856941223145, L4: 0.2946719527244568, L5: 0.03889038786292076
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.52060605]
 [0.97873798 2.28543443]
 [1.86755799 0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9992440938949585, Constraint losses: L1: 5.705211162567139, L2: 0.0, L3: 0.9967695474624634, L4: 0.9967693090438843
Epoch 500, Loss: 0.002005862072110176, Constraint losses: L1: -1.113253116607666, L2: 0.0, L3: 0.002558887004852295, L4: 0.0005602282471954823
Epoch 1000, Loss: 0.0012518522562459111, Constraint losses: L1: -1.1176321506500244, L2: 0.0, L3: 0.0021845102310180664, L4: 0.00018497425480745733
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005410671234131, Constraint losses: L1: 7.076176643371582, L2: 0.0, L3: 0.999167263507843, L4: 0.999167263507843
Epoch 500, Loss: 0.002323389984667301, Constraint losses: L1: -0.9279360771179199, L2: 0.0, L3: 0.002624690532684326, L4: 0.0006266353884711862
Epoch 1000, Loss: 0.0012926752679049969, Constraint losses: L1: -1.0693467855453491, L2: 0.0, L3: 0.002180755138397217, L4: 0.00018126689246855676
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 169.93377685546875, Losses: L1: 18.42068099975586, L2: 0.0018606085795909166, L3: 1.0018606185913086, L4: 74.49777221679688, L5: 0.25504717230796814
Epoch 500, Loss: 16.84714126586914, Losses: L1: 3.9380648136138916, L2: 0.1952420324087143, L3: 0.14381074905395508, L4: 6.06488561630249, L5: 0.050600048154592514
Epoch 1000, Loss: 26.808073043823242, Losses: L1: 2.281883478164673, L2: 0.37901735305786133, L3: 0.27785998582839966, L4: 11.505929946899414, L5: 0.1002870723605156
Epoch 1500, Loss: 13.965841293334961, Losses: L1: 2.3371520042419434, L2: 0.48337024450302124, L3: 0.23596882820129395, L4: 5.0092267990112305, L5: 0.08577849715948105
Epoch 2000, Loss: 11.846375465393066, Losses: L1: 2.4551734924316406, L2: 0.619292140007019, L3: 0.19953715801239014, L4: 3.7875595092773438, L5: 0.08921214938163757
Epoch 2500, Loss: 9.366528511047363, Losses: L1: 2.4055490493774414, L2: 0.6445491313934326, L3: 0.20139729976654053, L4: 2.5487477779388428, L5: 0.08579608052968979
Epoch 3000, Loss: 8.790157318115234, Losses: L1: 2.4264156818389893, L2: 0.6396698951721191, L3: 0.18676459789276123, L4: 2.2720746994018555, L5: 0.08336160331964493
Epoch 3500, Loss: 15.137725830078125, Losses: L1: 3.7477149963378906, L2: 0.4156213700771332, L3: 0.17120260000228882, L4: 4.995930194854736, L5: 0.1122511550784111
Epoch 4000, Loss: 9.136883735656738, Losses: L1: 3.053148031234741, L2: 0.6103379130363464, L3: 0.17814862728118896, L4: 2.161689281463623, L5: 0.0916920155286789
Epoch 4500, Loss: 8.882752418518066, Losses: L1: 2.9972853660583496, L2: 0.590438723564148, L3: 0.17696678638458252, L4: 2.084576368331909, L5: 0.09075214713811874
Epoch 5000, Loss: 8.82380199432373, Losses: L1: 2.992741107940674, L2: 0.5813559889793396, L3: 0.17770731449127197, L4: 2.066426992416382, L5: 0.09003982692956924
Epoch 5500, Loss: 8.78377628326416, Losses: L1: 2.9889352321624756, L2: 0.5766724348068237, L3: 0.17817556858062744, L4: 2.052893877029419, L5: 0.08967818319797516
Epoch 6000, Loss: 8.789220809936523, Losses: L1: 2.9804396629333496, L2: 0.5670260787010193, L3: 0.17647218704223633, L4: 2.0710413455963135, L5: 0.08985111862421036
Epoch 6500, Loss: 8.698529243469238, Losses: L1: 2.970100164413452, L2: 0.5599769353866577, L3: 0.17776167392730713, L4: 2.0371177196502686, L5: 0.0893578827381134
Epoch 7000, Loss: 8.67115306854248, Losses: L1: 2.9661388397216797, L2: 0.5547592639923096, L3: 0.17702984809875488, L4: 2.031582832336426, L5: 0.08913513273000717
Epoch 7500, Loss: 8.652087211608887, Losses: L1: 2.965266227722168, L2: 0.5507099628448486, L3: 0.17701828479766846, L4: 2.026799440383911, L5: 0.08888301998376846
Epoch 8000, Loss: 8.639646530151367, Losses: L1: 2.9656119346618652, L2: 0.5483078956604004, L3: 0.17708134651184082, L4: 2.022913932800293, L5: 0.08871398121118546
Epoch 8500, Loss: 8.631402015686035, Losses: L1: 2.965670585632324, L2: 0.5467526912689209, L3: 0.17710494995117188, L4: 2.020392656326294, L5: 0.08861541748046875
Epoch 9000, Loss: 8.625779151916504, Losses: L1: 2.965235471725464, L2: 0.5458414554595947, L3: 0.17713916301727295, L4: 2.018739938735962, L5: 0.08855084329843521
Epoch 9500, Loss: 8.62173080444336, Losses: L1: 2.9649710655212402, L2: 0.5451582670211792, L3: 0.17715251445770264, L4: 2.017564058303833, L5: 0.08850476145744324
Training done
----------------------------------------------------------------------------
######################### Running test with dataset: NegDepWeight ###########
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.007824420928955, Constraint losses: L1: 8.27999496459961, L2: 1.045328179571925e-08, L3: 0.9997721910476685, L4: 0.9997721314430237
Epoch 500, Loss: 0.002039576880633831, Constraint losses: L1: -1.0409044027328491, L2: 0.0, L3: 0.002539396286010742, L4: 0.0005410850280895829
Epoch 1000, Loss: 0.0012091674143448472, Constraint losses: L1: -1.1171860694885254, L2: 0.0, L3: 0.002162933349609375, L4: 0.00016342020535375923
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0050668716430664, Constraint losses: L1: 7.056080341339111, L2: 0.0001352820108877495, L3: 0.9989378452301025, L4: 0.998937726020813
Epoch 500, Loss: 0.0025650509633123875, Constraint losses: L1: -1.02435302734375, L2: 0.0, L3: 0.0027936697006225586, L4: 0.0007957342313602567
Epoch 1000, Loss: 0.001422993722371757, Constraint losses: L1: -1.0708225965499878, L2: 0.0, L3: 0.002246558666229248, L4: 0.000247257761657238
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 53.75901794433594, Losses: L1: 17.640121459960938, L2: 0.0018313342006877065, L3: 1.001691460609436, L4: 70.92158508300781, L5: 0.3126852214336395
Epoch 500, Loss: 13.606790542602539, Losses: L1: 4.700380325317383, L2: 1.0757983922958374, L3: 0.49450576305389404, L4: 16.175933837890625, L5: 0.06658109277486801
Epoch 1000, Loss: 44.018619537353516, Losses: L1: 18.420652389526367, L2: 6.74439948333827e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 1500, Loss: 44.018619537353516, Losses: L1: 18.420652389526367, L2: 6.824175946551492e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 2000, Loss: 44.018619537353516, Losses: L1: 18.420650482177734, L2: 6.8974471967298e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 2500, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 6.95820137619485e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 3000, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.007835284289499e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 3500, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.048112787844119e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 4000, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.081144004494888e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 4500, Loss: 44.018611907958984, Losses: L1: 18.42064666748047, L2: 7.107952421092634e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 5000, Loss: 44.018611907958984, Losses: L1: 18.42064666748047, L2: 7.128926615695974e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 5500, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.146414016112601e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 6000, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.16015857715746e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 6500, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.170505855746967e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 7000, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.179670052925857e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 7500, Loss: 44.018611907958984, Losses: L1: 18.42064666748047, L2: 7.18635290164471e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 8000, Loss: 44.018611907958984, Losses: L1: 18.42064666748047, L2: 7.191622297675337e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 8500, Loss: 44.018611907958984, Losses: L1: 18.42064666748047, L2: 7.196814671983631e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 9000, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.200390977901705e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Epoch 9500, Loss: 44.01861572265625, Losses: L1: 18.4206485748291, L2: 7.20331155834586e-11, L3: 1.0, L4: 50.00009536743164, L5: 0.1958378106355667
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0051541328430176, Constraint losses: L1: 6.965605735778809, L2: 0.0, L3: 0.9990943670272827, L4: 0.9990942478179932
Epoch 500, Loss: 0.0020829604472965, Constraint losses: L1: -1.0882186889648438, L2: 0.0, L3: 0.0025847554206848145, L4: 0.0005864237900823355
Epoch 1000, Loss: 0.00126375793479383, Constraint losses: L1: -1.1162015199661255, L2: 0.0, L3: 0.00218963623046875, L4: 0.00019032333511859179
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.006791591644287, Constraint losses: L1: 7.645572662353516, L2: 0.0, L3: 0.9995729923248291, L4: 0.9995728731155396
Epoch 500, Loss: 0.0023727109655737877, Constraint losses: L1: -0.9527976512908936, L2: 0.0, L3: 0.0026616454124450684, L4: 0.0006638632621616125
Epoch 1000, Loss: 0.001323052099905908, Constraint losses: L1: -1.0678757429122925, L2: 0.0, L3: 0.0021952390670776367, L4: 0.0001956888154381886
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 59.56224822998047, Losses: L1: 18.42068099975586, L2: 0.008908436633646488, L3: 1.0089083909988403, L4: 80.47624206542969, L5: 0.39454028010368347
Epoch 500, Loss: 13.89997386932373, Losses: L1: 1.4266868829727173, L2: 0.1356343775987625, L3: 0.36945629119873047, L4: 24.206432342529297, L5: 0.11752518266439438
Epoch 1000, Loss: 2.1553282737731934, Losses: L1: -0.04880689084529877, L2: 0.11342091858386993, L3: 0.17631280422210693, L4: 4.074491024017334, L5: 0.022022686898708344
Epoch 1500, Loss: 15.18699836730957, Losses: L1: 4.894065856933594, L2: 0.7205526232719421, L3: 0.28162848949432373, L4: 19.277313232421875, L5: 0.153185173869133
Epoch 2000, Loss: 29.65338134765625, Losses: L1: 3.3846943378448486, L2: 0.0013408031081780791, L3: 0.9414284229278564, L4: 51.244300842285156, L5: 0.17515255510807037
Epoch 2500, Loss: 30.04998207092285, Losses: L1: 3.382016658782959, L2: 0.006411950569599867, L3: 0.9666109681129456, L4: 51.98640441894531, L5: 0.18825143575668335
Epoch 3000, Loss: 29.047447204589844, Losses: L1: 2.8054635524749756, L2: 0.0007066824473440647, L3: 0.9074133038520813, L4: 51.22953414916992, L5: 0.17315629124641418
Epoch 3500, Loss: 29.45376205444336, Losses: L1: 3.0017409324645996, L2: 0.0020062196999788284, L3: 0.9316677451133728, L4: 51.61817169189453, L5: 0.17609794437885284
Epoch 4000, Loss: 29.31277084350586, Losses: L1: 2.896408796310425, L2: 0.0019596845377236605, L3: 0.9074094891548157, L4: 51.57574462890625, L5: 0.17380571365356445
Epoch 4500, Loss: 29.14635467529297, Losses: L1: 2.814769744873047, L2: 0.00010415012366138399, L3: 0.9245555996894836, L4: 51.38970184326172, L5: 0.17440401017665863
Epoch 5000, Loss: 28.93939208984375, Losses: L1: 2.6679272651672363, L2: 1.4071747500565834e-05, L3: 0.9075551629066467, L4: 51.290443420410156, L5: 0.17245832085609436
Epoch 5500, Loss: 28.769311904907227, Losses: L1: 2.636854648590088, L2: 1.2488012544054072e-05, L3: 0.8925527334213257, L4: 51.028961181640625, L5: 0.17169399559497833
Epoch 6000, Loss: 28.685230255126953, Losses: L1: 2.6490566730499268, L2: 1.0526997357374057e-05, L3: 0.8901050090789795, L4: 50.83949279785156, L5: 0.1713704764842987
Epoch 6500, Loss: 28.619094848632812, Losses: L1: 2.6265952587127686, L2: 1.0030252269643825e-05, L3: 0.8837506771087646, L4: 50.757896423339844, L5: 0.17167124152183533
Epoch 7000, Loss: 28.568981170654297, Losses: L1: 2.6284263134002686, L2: 1.0318654858565424e-05, L3: 0.8802288770675659, L4: 50.65717315673828, L5: 0.17184920608997345
Epoch 7500, Loss: 28.53957748413086, Losses: L1: 2.638150691986084, L2: 9.318468073615804e-06, L3: 0.8798273801803589, L4: 50.579444885253906, L5: 0.1717851310968399
Epoch 8000, Loss: 28.517236709594727, Losses: L1: 2.637638568878174, L2: 8.828646969050169e-06, L3: 0.8783408403396606, L4: 50.537010192871094, L5: 0.17191891372203827
Epoch 8500, Loss: 28.499650955200195, Losses: L1: 2.6349122524261475, L2: 8.538147994840983e-06, L3: 0.8766815066337585, L4: 50.50855255126953, L5: 0.17211781442165375
Epoch 9000, Loss: 28.48603630065918, Losses: L1: 2.631744384765625, L2: 8.473535672237631e-06, L3: 0.8751341700553894, L4: 50.48878479003906, L5: 0.17232944071292877
Epoch 9500, Loss: 28.476078033447266, Losses: L1: 2.6312825679779053, L2: 8.515306944900658e-06, L3: 0.8741775751113892, L4: 50.470489501953125, L5: 0.17245912551879883
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0013375282287598, Constraint losses: L1: 6.02738094329834, L2: 0.0, L3: 0.9976552724838257, L4: 0.997654914855957
Epoch 500, Loss: 0.002060346771031618, Constraint losses: L1: -1.1025688648223877, L2: 0.0, L3: 0.002580702304840088, L4: 0.0005822135135531425
Epoch 1000, Loss: 0.0012582368217408657, Constraint losses: L1: -1.1184930801391602, L2: 0.0, L3: 0.0021881461143493652, L4: 0.0001885839010355994
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019641876220703, Constraint losses: L1: 18.42068099975586, L2: 0.000425887294113636, L3: 1.0003974437713623, L4: 1.000397801399231
Epoch 500, Loss: 0.002591996220871806, Constraint losses: L1: -0.9215185046195984, L2: 0.0, L3: 0.0027556419372558594, L4: 0.0007578728254884481
Epoch 1000, Loss: 0.001367931254208088, Constraint losses: L1: -1.0702604055404663, L2: 0.0, L3: 0.0022188425064086914, L4: 0.00021934910910204053
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.781219482421875, Losses: L1: 17.720884323120117, L2: 0.008422480896115303, L3: 1.008407711982727, L4: 75.692138671875, L5: 0.3529246151447296
Epoch 500, Loss: 31.35541534423828, Losses: L1: 5.199467182159424, L2: 0.01024528406560421, L3: 0.995532214641571, L4: 50.525970458984375, L5: 0.19503732025623322
Epoch 1000, Loss: 30.616134643554688, Losses: L1: 3.6905293464660645, L2: 0.031055280938744545, L3: 0.9794315695762634, L4: 52.0817985534668, L5: 0.18973159790039062
Epoch 1500, Loss: 30.527385711669922, Losses: L1: 3.618905544281006, L2: 0.02411973848938942, L3: 0.9782132506370544, L4: 52.0655403137207, L5: 0.18727250397205353
Epoch 2000, Loss: 29.100902557373047, Losses: L1: 2.6637990474700928, L2: 0.009024687111377716, L3: 0.9140281677246094, L4: 51.26654815673828, L5: 0.1711515635251999
Epoch 2500, Loss: 5.305569171905518, Losses: L1: 0.8495874404907227, L2: 0.3856596052646637, L3: 0.24737286567687988, L4: 8.106377601623535, L5: 0.04313833639025688
Epoch 3000, Loss: 4.045478820800781, Losses: L1: 0.7243528962135315, L2: 0.35605180263519287, L3: 0.28268152475357056, L4: 5.892891883850098, L5: 0.02765670046210289
Epoch 3500, Loss: 3.7153916358947754, Losses: L1: 0.6965189576148987, L2: 0.3498029112815857, L3: 0.2830694317817688, L4: 5.297820568084717, L5: 0.026763146743178368
Epoch 4000, Loss: 3.5513057708740234, Losses: L1: 0.6642460227012634, L2: 0.3463193476200104, L3: 0.27419042587280273, L4: 5.043450355529785, L5: 0.027539895847439766
Epoch 4500, Loss: 3.4652297496795654, Losses: L1: 0.6584334969520569, L2: 0.3414916396141052, L3: 0.27677208185195923, L4: 4.886773109436035, L5: 0.027138905599713326
Epoch 5000, Loss: 3.4114737510681152, Losses: L1: 0.6539848446846008, L2: 0.34197214245796204, L3: 0.2753322124481201, L4: 4.788782596588135, L5: 0.027222804725170135
Epoch 5500, Loss: 3.3750994205474854, Losses: L1: 0.6510902643203735, L2: 0.34178969264030457, L3: 0.2740258574485779, L4: 4.723045825958252, L5: 0.027289312332868576
Epoch 6000, Loss: 3.339833974838257, Losses: L1: 0.6447122097015381, L2: 0.3354893922805786, L3: 0.2717248797416687, L4: 4.6716108322143555, L5: 0.02785453386604786
Epoch 6500, Loss: 3.3144664764404297, Losses: L1: 0.6264216899871826, L2: 0.33881571888923645, L3: 0.26828765869140625, L4: 4.657042503356934, L5: 0.027985887601971626
Epoch 7000, Loss: 3.3061788082122803, Losses: L1: 0.6246408820152283, L2: 0.33771443367004395, L3: 0.2685813903808594, L4: 4.64550256729126, L5: 0.027819374576210976
Epoch 7500, Loss: 3.299997568130493, Losses: L1: 0.6233834028244019, L2: 0.3368813097476959, L3: 0.2687641382217407, L4: 4.636760234832764, L5: 0.02770569920539856
Epoch 8000, Loss: 3.29540753364563, Losses: L1: 0.6224666833877563, L2: 0.3362550139427185, L3: 0.26890015602111816, L4: 4.630237579345703, L5: 0.02762223780155182
Epoch 8500, Loss: 3.292189359664917, Losses: L1: 0.62204909324646, L2: 0.33585867285728455, L3: 0.268801212310791, L4: 4.625194549560547, L5: 0.027606487274169922
Epoch 9000, Loss: 3.289965867996216, Losses: L1: 0.6218430399894714, L2: 0.33561065793037415, L3: 0.26870524883270264, L4: 4.621516227722168, L5: 0.027603445574641228
Epoch 9500, Loss: 3.288433313369751, Losses: L1: 0.621686577796936, L2: 0.3354751467704773, L3: 0.2686336040496826, L4: 4.618979454040527, L5: 0.027601333335042
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0252771377563477, Constraint losses: L1: 18.42068099975586, L2: 0.0022854101844131947, L3: 1.002285361289978, L4: 1.0022858381271362
Epoch 500, Loss: 0.0021769937593489885, Constraint losses: L1: -1.115420937538147, L2: 0.0, L3: 0.002645432949066162, L4: 0.0006469817599281669
Epoch 1000, Loss: 0.0013140151277184486, Constraint losses: L1: -1.1166019439697266, L2: 0.0, L3: 0.002214968204498291, L4: 0.00021564890630543232
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0050582885742188, Constraint losses: L1: 6.917191505432129, L2: 0.0, L3: 0.9990707039833069, L4: 0.999070405960083
Epoch 500, Loss: 0.0022622046526521444, Constraint losses: L1: -1.0537735223770142, L2: 0.0, L3: 0.002657175064086914, L4: 0.000658803153783083
Epoch 1000, Loss: 0.001354727428406477, Constraint losses: L1: -1.0714527368545532, L2: 0.0, L3: 0.002212822437286377, L4: 0.0002133576781488955
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 100.89546966552734, Losses: L1: 18.42068099975586, L2: 0.001205303124152124, L3: 1.001205325126648, L4: 81.7770767211914, L5: 0.39301684498786926
Epoch 500, Loss: 5.61792516708374, Losses: L1: -0.22695571184158325, L2: 0.2271999716758728, L3: 0.06720602512359619, L4: 5.684593200683594, L5: 0.02617001347243786
Epoch 1000, Loss: 1.4499835968017578, Losses: L1: -0.10447286814451218, L2: 0.1137189194560051, L3: 0.06411236524581909, L4: 1.4576265811920166, L5: 0.015828289091587067
Epoch 1500, Loss: 2.4903011322021484, Losses: L1: -0.06401760876178741, L2: 0.1443425565958023, L3: 0.06659388542175293, L4: 2.443309783935547, L5: 0.011081812903285027
Epoch 2000, Loss: 0.4367285370826721, Losses: L1: -0.151373028755188, L2: 0.07470197230577469, L3: 0.06158733367919922, L4: 0.5161145925521851, L5: 0.0076846349984407425
Epoch 2500, Loss: 0.20702055096626282, Losses: L1: -0.127188578248024, L2: 0.043361466377973557, L3: 0.05596423149108887, L4: 0.2814234495162964, L5: 0.006245665717869997
Epoch 3000, Loss: 0.9754696488380432, Losses: L1: -0.089867003262043, L2: 0.16230303049087524, L3: 0.07399505376815796, L4: 0.9430744647979736, L5: 0.008226264268159866
Epoch 3500, Loss: 0.23873229324817657, Losses: L1: -0.12875786423683167, L2: 0.0688931867480278, L3: 0.06523007154464722, L4: 0.29711949825286865, L5: 0.006618040148168802
Epoch 4000, Loss: 0.2216443568468094, Losses: L1: -0.13401399552822113, L2: 0.06338638812303543, L3: 0.06378412246704102, L4: 0.28878071904182434, L5: 0.006584763992577791
Epoch 4500, Loss: 0.17681941390037537, Losses: L1: -0.13564130663871765, L2: 0.05861586704850197, L3: 0.06306213140487671, L4: 0.24830621480941772, L5: 0.006631025578826666
Epoch 5000, Loss: 0.10791828483343124, Losses: L1: -0.174386128783226, L2: 0.05204741656780243, L3: 0.06224524974822998, L4: 0.2219529002904892, L5: 0.0064103733748197556
Epoch 5500, Loss: 0.07738278806209564, Losses: L1: -0.19435277581214905, L2: 0.04979827255010605, L3: 0.06182277202606201, L4: 0.21278539299964905, L5: 0.006279297173023224
Epoch 6000, Loss: 0.06738138198852539, Losses: L1: -0.19753865897655487, L2: 0.04841342940926552, L3: 0.06141120195388794, L4: 0.20690450072288513, L5: 0.006206451449543238
Epoch 6500, Loss: 0.030703818425536156, Losses: L1: -0.22895750403404236, L2: 0.04634973406791687, L3: 0.061051130294799805, L4: 0.2028924524784088, L5: 0.006136876996606588
Epoch 7000, Loss: 0.025308862328529358, Losses: L1: -0.23081454634666443, L2: 0.04563198238611221, L3: 0.060813069343566895, L4: 0.19985078275203705, L5: 0.006100209429860115
Epoch 7500, Loss: 0.021873068064451218, Losses: L1: -0.23185840249061584, L2: 0.045181624591350555, L3: 0.06065249443054199, L4: 0.19777220487594604, L5: 0.006084403023123741
Epoch 8000, Loss: 0.019632743671536446, Losses: L1: -0.2325478047132492, L2: 0.04487839713692665, L3: 0.06056874990463257, L4: 0.19641733169555664, L5: 0.006079290062189102
Epoch 8500, Loss: 0.01802755892276764, Losses: L1: -0.23297281563282013, L2: 0.04468787461519241, L3: 0.06050187349319458, L4: 0.19536679983139038, L5: 0.006077410653233528
Epoch 9000, Loss: 0.01689707115292549, Losses: L1: -0.23325945436954498, L2: 0.04454292356967926, L3: 0.06045621633529663, L4: 0.19461911916732788, L5: 0.006075656972825527
Epoch 9500, Loss: 0.016101544722914696, Losses: L1: -0.23346318304538727, L2: 0.0444498211145401, L3: 0.060424208641052246, L4: 0.19409024715423584, L5: 0.006074916105717421
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.02158784866333, Constraint losses: L1: 18.42068099975586, L2: 0.001055695815011859, L3: 1.0010557174682617, L4: 1.0010557174682617
Epoch 500, Loss: 0.0023087612353265285, Constraint losses: L1: -1.0930919647216797, L2: 0.0, L3: 0.00270003080368042, L4: 0.0007018225733190775
Epoch 1000, Loss: 0.0013371240347623825, Constraint losses: L1: -1.1186962127685547, L2: 0.0, L3: 0.002227604389190674, L4: 0.0002282159257447347
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0080482959747314, Constraint losses: L1: 8.589601516723633, L2: 0.0, L3: 0.9997291564941406, L4: 0.9997295141220093
Epoch 500, Loss: 0.002259962260723114, Constraint losses: L1: -1.0635699033737183, L2: 0.0, L3: 0.002660989761352539, L4: 0.0006625422975048423
Epoch 1000, Loss: 0.0013691193889826536, Constraint losses: L1: -1.070554494857788, L2: 0.0, L3: 0.002219557762145996, L4: 0.0002201162133133039
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 98.34314727783203, Losses: L1: 10.250103950500488, L2: 0.0003859107964672148, L3: 0.9985731244087219, L4: 87.16592407226562, L5: 0.42764315009117126
Epoch 500, Loss: 15.38744068145752, Losses: L1: 2.7943105697631836, L2: 0.42132607102394104, L3: 0.21237802505493164, L4: 12.213714599609375, L5: 0.06256359070539474
Epoch 1000, Loss: 11.84915828704834, Losses: L1: 2.3824195861816406, L2: 0.8103159070014954, L3: 0.15537381172180176, L4: 8.934456825256348, L5: 0.049437087029218674
Epoch 1500, Loss: 3.1343233585357666, Losses: L1: 0.008520293049514294, L2: 0.09628888219594955, L3: 0.09215456247329712, L4: 3.013556957244873, L5: 0.018024327233433723
Epoch 2000, Loss: 0.6061117649078369, Losses: L1: -0.18086259067058563, L2: 0.05311950668692589, L3: 0.08482474088668823, L4: 0.7095646262168884, L5: 0.008437654003500938
Epoch 2500, Loss: 0.6620987057685852, Losses: L1: -0.22655326128005981, L2: 0.05835261195898056, L3: 0.07651275396347046, L4: 0.8143519163131714, L5: 0.00686737522482872
Epoch 3000, Loss: 0.3078477382659912, Losses: L1: -0.21661026775836945, L2: 0.04937199130654335, L3: 0.07719260454177856, L4: 0.45460593700408936, L5: 0.006569763645529747
Epoch 3500, Loss: 0.403719037771225, Losses: L1: -0.21820390224456787, L2: 0.048290450125932693, L3: 0.07483577728271484, L4: 0.5534526705741882, L5: 0.006907134782522917
Epoch 4000, Loss: 0.24957583844661713, Losses: L1: -0.2155454158782959, L2: 0.04715513065457344, L3: 0.07430124282836914, L4: 0.39800745248794556, L5: 0.006385603919625282
Epoch 4500, Loss: 0.166366845369339, Losses: L1: -0.21586884558200836, L2: 0.0484425388276577, L3: 0.07356631755828857, L4: 0.3149578273296356, L5: 0.006273436360061169
Epoch 5000, Loss: 0.16788716614246368, Losses: L1: -0.21536096930503845, L2: 0.047601982951164246, L3: 0.07276046276092529, L4: 0.3167811632156372, L5: 0.0062857395969331264
Epoch 5500, Loss: 0.15379346907138824, Losses: L1: -0.21645766496658325, L2: 0.04757589101791382, L3: 0.07229351997375488, L4: 0.3040332794189453, L5: 0.006283145863562822
Epoch 6000, Loss: 0.14968210458755493, Losses: L1: -0.21721823513507843, L2: 0.04728285223245621, L3: 0.07198041677474976, L4: 0.3009869158267975, L5: 0.00628180056810379
Epoch 6500, Loss: 0.14658381044864655, Losses: L1: -0.2180904895067215, L2: 0.04712018743157387, L3: 0.07171732187271118, L4: 0.2989760637283325, L5: 0.006279481574892998
Epoch 7000, Loss: 0.14425376057624817, Losses: L1: -0.21874922513961792, L2: 0.04702397808432579, L3: 0.07153171300888062, L4: 0.2974458634853363, L5: 0.006279280874878168
Epoch 7500, Loss: 0.14227357506752014, Losses: L1: -0.2190806120634079, L2: 0.04687139019370079, L3: 0.07138442993164062, L4: 0.29595011472702026, L5: 0.006276165135204792
Epoch 8000, Loss: 0.14087705314159393, Losses: L1: -0.21948567032814026, L2: 0.04681126028299332, L3: 0.07125848531723022, L4: 0.29505348205566406, L5: 0.0062743742018938065
Epoch 8500, Loss: 0.13982900977134705, Losses: L1: -0.2196277529001236, L2: 0.04671090096235275, L3: 0.07117652893066406, L4: 0.2942410707473755, L5: 0.006271969061344862
Epoch 9000, Loss: 0.1390228122472763, Losses: L1: -0.21978721022605896, L2: 0.0466754250228405, L3: 0.07111477851867676, L4: 0.29364410042762756, L5: 0.006270831450819969
Epoch 9500, Loss: 0.1384490430355072, Losses: L1: -0.21991215646266937, L2: 0.046633291989564896, L3: 0.07106387615203857, L4: 0.2932429909706116, L5: 0.006269623525440693
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.003272771835327, Constraint losses: L1: 6.374807357788086, L2: 0.0, L3: 0.9984493255615234, L4: 0.9984486103057861
Epoch 500, Loss: 0.0023840544745326042, Constraint losses: L1: -1.0393195152282715, L2: 0.0, L3: 0.0027106404304504395, L4: 0.0007127337157726288
Epoch 1000, Loss: 0.001306123100221157, Constraint losses: L1: -1.1174376010894775, L2: 0.0, L3: 0.0022115111351013184, L4: 0.00021204956283327192
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9964187145233154, Constraint losses: L1: 5.4132232666015625, L2: 0.0, L3: 0.995502769947052, L4: 0.9955026507377625
Epoch 500, Loss: 0.002508740406483412, Constraint losses: L1: -0.8193345069885254, L2: 0.0, L3: 0.0026628971099853516, L4: 0.0006651778821833432
Epoch 1000, Loss: 0.0013123592361807823, Constraint losses: L1: -1.0581729412078857, L2: 0.0, L3: 0.0021849870681762695, L4: 0.00018554515554569662
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 95.82379913330078, Losses: L1: 18.300384521484375, L2: 0.003802303224802017, L3: 1.003801941871643, L4: 76.3116683959961, L5: 0.3539700210094452
Epoch 500, Loss: 4.044323921203613, Losses: L1: 0.11910174041986465, L2: 0.13357532024383545, L3: 0.08350658416748047, L4: 3.764326572418213, L5: 0.026177169755101204
Epoch 1000, Loss: 6.32450532913208, Losses: L1: 3.575665235519409, L2: 0.7270559072494507, L3: 0.065948486328125, L4: 2.305943012237549, L5: 0.023197466507554054
Epoch 1500, Loss: 1.6548717021942139, Losses: L1: -0.020374033600091934, L2: 0.10456320643424988, L3: 0.13655173778533936, L4: 1.5333094596862793, L5: 0.010689396411180496
Epoch 2000, Loss: 0.30869755148887634, Losses: L1: -0.2287234216928482, L2: 0.06316792964935303, L3: 0.07448291778564453, L4: 0.4548356533050537, L5: 0.006879943888634443
Epoch 2500, Loss: 0.5932844281196594, Losses: L1: -0.26072803139686584, L2: 0.06173950061202049, L3: 0.06788063049316406, L4: 0.7731375694274902, L5: 0.008032412268221378
Epoch 3000, Loss: 0.14117269217967987, Losses: L1: -0.24752569198608398, L2: 0.0534265860915184, L3: 0.06608366966247559, L4: 0.31650102138519287, L5: 0.006221118848770857
Epoch 3500, Loss: 0.11833027005195618, Losses: L1: -0.2722419202327728, L2: 0.05150894820690155, L3: 0.06410574913024902, L4: 0.3202784061431885, L5: 0.006243214476853609
Epoch 4000, Loss: 0.06785772740840912, Losses: L1: -0.27470681071281433, L2: 0.04868372529745102, L3: 0.0632791519165039, L4: 0.27415740489959717, L5: 0.006212852895259857
Epoch 4500, Loss: 0.0509805828332901, Losses: L1: -0.27695417404174805, L2: 0.048179496079683304, L3: 0.06252825260162354, L4: 0.2601913809776306, L5: 0.006194747984409332
Epoch 5000, Loss: 0.045181889086961746, Losses: L1: -0.2781125605106354, L2: 0.04787231981754303, L3: 0.06204104423522949, L4: 0.25591450929641724, L5: 0.006211632862687111
Epoch 5500, Loss: 0.036224689334630966, Losses: L1: -0.2787371873855591, L2: 0.04758307337760925, L3: 0.061681151390075684, L4: 0.2479272186756134, L5: 0.006201265379786491
Epoch 6000, Loss: 0.03199291229248047, Losses: L1: -0.2791358232498169, L2: 0.04742720350623131, L3: 0.061383724212646484, L4: 0.24433273077011108, L5: 0.006195276975631714
Epoch 6500, Loss: 0.028648879379034042, Losses: L1: -0.27942660450935364, L2: 0.04727443680167198, L3: 0.06117594242095947, L4: 0.2414851188659668, L5: 0.006182594690471888
Epoch 7000, Loss: 0.02641073800623417, Losses: L1: -0.2796104848384857, L2: 0.04716653749346733, L3: 0.061000704765319824, L4: 0.2395787090063095, L5: 0.006179449148476124
Epoch 7500, Loss: 0.0245176050812006, Losses: L1: -0.27980896830558777, L2: 0.04710673540830612, L3: 0.060867905616760254, L4: 0.23798923194408417, L5: 0.006175008602440357
Epoch 8000, Loss: 0.023176752030849457, Losses: L1: -0.2799447178840637, L2: 0.04705234244465828, L3: 0.060773611068725586, L4: 0.23686102032661438, L5: 0.006173741538077593
Epoch 8500, Loss: 0.02220786362886429, Losses: L1: -0.28009986877441406, L2: 0.04702630639076233, L3: 0.06069594621658325, L4: 0.2361033856868744, L5: 0.0061716181226074696
Epoch 9000, Loss: 0.02151036635041237, Losses: L1: -0.2801302671432495, L2: 0.04697757586836815, L3: 0.06064581871032715, L4: 0.2354864627122879, L5: 0.006171236280351877
Epoch 9500, Loss: 0.021025996655225754, Losses: L1: -0.2801172137260437, L2: 0.046935856342315674, L3: 0.060611844062805176, L4: 0.23502793908119202, L5: 0.006170710548758507
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0244593620300293, Constraint losses: L1: 18.42068099975586, L2: 0.002012963406741619, L3: 1.0020129680633545, L4: 1.0020127296447754
Epoch 500, Loss: 0.0022907936945557594, Constraint losses: L1: -1.0854381322860718, L2: 0.0, L3: 0.00268709659576416, L4: 0.0006891352823004127
Epoch 1000, Loss: 0.0013190391473472118, Constraint losses: L1: -1.1183735132217407, L2: 0.0, L3: 0.0022184252738952637, L4: 0.00021898740669712424
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.000868797302246, Constraint losses: L1: 5.9298810958862305, L2: 0.0, L3: 0.9974697828292847, L4: 0.9974693059921265
Epoch 500, Loss: 0.0021550727542489767, Constraint losses: L1: -1.057586908340454, L2: 0.0, L3: 0.0026055574417114258, L4: 0.0006071022944524884
Epoch 1000, Loss: 0.00132465036585927, Constraint losses: L1: -1.0715529918670654, L2: 0.0, L3: 0.0021978020668029785, L4: 0.00019840133609250188
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 169.63148498535156, Losses: L1: 10.445578575134277, L2: 0.0008156248950399458, L3: 0.9983353018760681, L4: 79.24900817871094, L5: 0.37661731243133545
Epoch 500, Loss: 13.362720489501953, Losses: L1: 1.0294512510299683, L2: 0.4570395350456238, L3: 0.1019052267074585, L4: 6.013824462890625, L5: 0.052295323461294174
Epoch 1000, Loss: 14.56733512878418, Losses: L1: 2.58901047706604, L2: 0.5613935589790344, L3: 0.13693898916244507, L4: 5.803057670593262, L5: 0.04608451575040817
Epoch 1500, Loss: 7.881855487823486, Losses: L1: 2.759026527404785, L2: 0.5111812353134155, L3: 0.10848033428192139, L4: 2.397761821746826, L5: 0.03494887799024582
Epoch 2000, Loss: 4.128909111022949, Losses: L1: 0.2733815908432007, L2: 0.1028735563158989, L3: 0.10605442523956299, L4: 1.8709287643432617, L5: 0.018411893397569656
Epoch 2500, Loss: 2.4769740104675293, Losses: L1: 0.1163206398487091, L2: 0.07391755282878876, L3: 0.1009206771850586, L4: 1.1328123807907104, L5: 0.015218496322631836
Epoch 3000, Loss: 1.4992244243621826, Losses: L1: 0.1823154240846634, L2: 0.06196090579032898, L3: 0.08720624446868896, L4: 0.6180262565612793, L5: 0.012545846402645111
Epoch 3500, Loss: 1.080236554145813, Losses: L1: 0.16769899427890778, L2: 0.05778732895851135, L3: 0.07854801416397095, L4: 0.41920700669288635, L5: 0.011911730282008648
Epoch 4000, Loss: 0.9874743819236755, Losses: L1: 0.08306741714477539, L2: 0.05564536154270172, L3: 0.07755959033966064, L4: 0.41603484749794006, L5: 0.011469628661870956
Epoch 4500, Loss: 0.8049704432487488, Losses: L1: 0.043807253241539, L2: 0.05422814190387726, L3: 0.07697194814682007, L4: 0.3450990617275238, L5: 0.010730072855949402
Epoch 5000, Loss: 0.7648862600326538, Losses: L1: 0.013347252272069454, L2: 0.05377491936087608, L3: 0.07633417844772339, L4: 0.3406345248222351, L5: 0.010430826805531979
Epoch 5500, Loss: 0.734541654586792, Losses: L1: -0.008588585071265697, L2: 0.05374394357204437, L3: 0.07582342624664307, L4: 0.3366110026836395, L5: 0.010249125771224499
Epoch 6000, Loss: 0.7151583433151245, Losses: L1: -0.022503390908241272, L2: 0.05340779200196266, L3: 0.07555454969406128, L4: 0.33406126499176025, L5: 0.01011604256927967
Epoch 6500, Loss: 0.7009304165840149, Losses: L1: -0.0329064279794693, L2: 0.05353352054953575, L3: 0.0751732587814331, L4: 0.332236111164093, L5: 0.010022551752626896
Epoch 7000, Loss: 0.6907373070716858, Losses: L1: -0.04001583531498909, L2: 0.053601622581481934, L3: 0.0749518871307373, L4: 0.33074867725372314, L5: 0.009958053007721901
Epoch 7500, Loss: 0.6838321089744568, Losses: L1: -0.04490603134036064, L2: 0.05365218222141266, L3: 0.07475996017456055, L4: 0.3297863006591797, L5: 0.009918930940330029
Epoch 8000, Loss: 0.6785227060317993, Losses: L1: -0.04854635149240494, L2: 0.05365881323814392, L3: 0.0746418833732605, L4: 0.32898831367492676, L5: 0.009884112514555454
Epoch 8500, Loss: 0.6749154925346375, Losses: L1: -0.05101222172379494, L2: 0.05365707725286484, L3: 0.07455718517303467, L4: 0.32844531536102295, L5: 0.009859904646873474
Epoch 9000, Loss: 0.6723011136054993, Losses: L1: -0.052713535726070404, L2: 0.05367967486381531, L3: 0.07448548078536987, L4: 0.3280048072338104, L5: 0.009844943881034851
Epoch 9500, Loss: 0.6704660058021545, Losses: L1: -0.053881220519542694, L2: 0.053671374917030334, L3: 0.07444357872009277, L4: 0.32768648862838745, L5: 0.009833632037043571
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0220587253570557, Constraint losses: L1: 18.42068099975586, L2: 0.0012126370565965772, L3: 1.0012125968933105, L4: 1.0012128353118896
Epoch 500, Loss: 0.0026319888420403004, Constraint losses: L1: -1.0339878797531128, L2: 0.0, L3: 0.002831876277923584, L4: 0.0008341004722751677
Epoch 1000, Loss: 0.0013949923450127244, Constraint losses: L1: -1.117883324623108, L2: 0.0, L3: 0.002256155014038086, L4: 0.0002567207266110927
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.035348415374756, Constraint losses: L1: 18.42068099975586, L2: 0.005642234813421965, L3: 1.0056421756744385, L4: 1.0056432485580444
Epoch 500, Loss: 0.0022631899919360876, Constraint losses: L1: -1.044946551322937, L2: 0.0, L3: 0.0026531219482421875, L4: 0.000655014649964869
Epoch 1000, Loss: 0.0013446862576529384, Constraint losses: L1: -1.07131028175354, L2: 0.0, L3: 0.0022076964378356934, L4: 0.00020830021821893752
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 163.86962890625, Losses: L1: 14.912198066711426, L2: 0.0007027932442724705, L3: 1.0006049871444702, L4: 74.05741882324219, L5: 0.3419369161128998
Epoch 500, Loss: 3.8785715103149414, Losses: L1: 0.18278977274894714, L2: 0.14328429102897644, L3: 0.08907634019851685, L4: 1.7800133228302002, L5: 0.019574791193008423
Epoch 1000, Loss: 1.8672959804534912, Losses: L1: -0.1695854216814041, L2: 0.1615157425403595, L3: 0.05735445022583008, L4: 0.9599789381027222, L5: 0.007488506846129894
Epoch 1500, Loss: 0.703629195690155, Losses: L1: -0.21622006595134735, L2: 0.08496154099702835, L3: 0.055646538734436035, L4: 0.4205436706542969, L5: 0.00845787301659584
Epoch 2000, Loss: 1.815743327140808, Losses: L1: -0.18191556632518768, L2: 0.06501547992229462, L3: 0.05439537763595581, L4: 0.9660161137580872, L5: 0.005921241827309132
Epoch 2500, Loss: 0.9117496013641357, Losses: L1: -0.2052212506532669, L2: 0.0539296492934227, L3: 0.053472161293029785, L4: 0.5292405486106873, L5: 0.004788867197930813
Epoch 3000, Loss: 0.3169090747833252, Losses: L1: -0.24632395803928375, L2: 0.05221359804272652, L3: 0.051472246646881104, L4: 0.2527391314506531, L5: 0.0059118312783539295
Epoch 3500, Loss: 0.09855771064758301, Losses: L1: -0.2443174421787262, L2: 0.04876368120312691, L3: 0.05143928527832031, L4: 0.14374485611915588, L5: 0.005283953621983528
Epoch 4000, Loss: 0.1154799684882164, Losses: L1: -0.2741784453392029, L2: 0.042664963752031326, L3: 0.05125153064727783, L4: 0.1687248945236206, L5: 0.005250386893749237
Epoch 4500, Loss: 0.0012504877522587776, Losses: L1: -0.27513062953948975, L2: 0.039692606776952744, L3: 0.05130362510681152, L4: 0.11282868683338165, L5: 0.005225640721619129
Epoch 5000, Loss: -0.009290634654462337, Losses: L1: -0.27519312500953674, L2: 0.038107164204120636, L3: 0.05124783515930176, L4: 0.10803654789924622, L5: 0.005151898600161076
Epoch 5500, Loss: -0.01791469380259514, Losses: L1: -0.2760670781135559, L2: 0.03741757944226265, L3: 0.05110853910446167, L4: 0.10438640415668488, L5: 0.005116512067615986
Epoch 6000, Loss: -0.02255060523748398, Losses: L1: -0.27632197737693787, L2: 0.03690500557422638, L3: 0.05101215839385986, L4: 0.10237080603837967, L5: 0.0050711864605546
Epoch 6500, Loss: -0.026245880872011185, Losses: L1: -0.27653828263282776, L2: 0.03658266365528107, L3: 0.05095189809799194, L4: 0.10073792934417725, L5: 0.005049270577728748
Epoch 7000, Loss: -0.02872716821730137, Losses: L1: -0.27677398920059204, L2: 0.036342278122901917, L3: 0.05089461803436279, L4: 0.09969435632228851, L5: 0.005039667245000601
Epoch 7500, Loss: -0.03050568513572216, Losses: L1: -0.2768084704875946, L2: 0.03616851940751076, L3: 0.050871312618255615, L4: 0.09887608885765076, L5: 0.005030693486332893
Epoch 8000, Loss: -0.031736962497234344, Losses: L1: -0.27684879302978516, L2: 0.03606182336807251, L3: 0.05084240436553955, L4: 0.09831798076629639, L5: 0.005023756995797157
Epoch 8500, Loss: -0.032604265958070755, Losses: L1: -0.2768690884113312, L2: 0.03596664220094681, L3: 0.050833940505981445, L4: 0.09792164713144302, L5: 0.005021239165216684
Epoch 9000, Loss: -0.03319012001156807, Losses: L1: -0.27688464522361755, L2: 0.03590909391641617, L3: 0.050826311111450195, L4: 0.09765351563692093, L5: 0.005019781645387411
Epoch 9500, Loss: -0.033557455986738205, Losses: L1: -0.276908814907074, L2: 0.035878509283065796, L3: 0.050819993019104004, L4: 0.09749090671539307, L5: 0.005020278971642256
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.027465343475342, Constraint losses: L1: 18.42068099975586, L2: 0.0030147035140544176, L3: 1.0030146837234497, L4: 1.003015160560608
Epoch 500, Loss: 0.002906989771872759, Constraint losses: L1: -1.079347014427185, L2: 0.0, L3: 0.002991914749145508, L4: 0.0009944220073521137
Epoch 1000, Loss: 0.0015156365698203444, Constraint losses: L1: -1.1178042888641357, L2: 0.0, L3: 0.0023163557052612305, L4: 0.0003170852141920477
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9958117008209229, Constraint losses: L1: 5.38531494140625, L2: 0.0, L3: 0.9952131509780884, L4: 0.9952132701873779
Epoch 500, Loss: 0.0019953311420977116, Constraint losses: L1: -1.0346431732177734, L2: 0.0, L3: 0.0025142431259155273, L4: 0.0005157313426025212
Epoch 1000, Loss: 0.0012556102592498064, Constraint losses: L1: -1.068294644355774, L2: 0.0, L3: 0.002161741256713867, L4: 0.0001621637202333659
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 155.94920349121094, Losses: L1: 18.42068099975586, L2: 0.00436610309407115, L3: 1.004366159439087, L4: 68.21662902832031, L5: 0.29545164108276367
Epoch 500, Loss: 41.42245864868164, Losses: L1: 5.646109104156494, L2: 1.6020079851150513, L3: 0.46406006813049316, L4: 17.28095817565918, L5: 0.09070003777742386
Epoch 1000, Loss: 12.060563087463379, Losses: L1: 1.5859326124191284, L2: 0.669128954410553, L3: 0.13923001289367676, L4: 4.997127056121826, L5: 0.038098178803920746
Epoch 1500, Loss: 5.216792106628418, Losses: L1: 1.1061975955963135, L2: 0.2672397494316101, L3: 0.15598243474960327, L4: 1.9266738891601562, L5: 0.022817915305495262
Epoch 2000, Loss: 6.883899211883545, Losses: L1: 2.879110097885132, L2: 0.48632508516311646, L3: 0.11359661817550659, L4: 1.8211658000946045, L5: 0.0312483087182045
Epoch 2500, Loss: 4.958935260772705, Losses: L1: 2.6188228130340576, L2: 0.29762741923332214, L3: 0.11948788166046143, L4: 1.0383386611938477, L5: 0.027438879013061523
Epoch 3000, Loss: 2.9989631175994873, Losses: L1: 0.6805168390274048, L2: 0.16843023896217346, L3: 0.146281898021698, L4: 1.0570365190505981, L5: 0.023508621379733086
Epoch 3500, Loss: 2.8122637271881104, Losses: L1: 0.7324346303939819, L2: 0.14345236122608185, L3: 0.1428985595703125, L4: 0.944947361946106, L5: 0.02337948977947235
Epoch 4000, Loss: 2.703359603881836, Losses: L1: 0.7773208618164062, L2: 0.12399003654718399, L3: 0.14070206880569458, L4: 0.873339831829071, L5: 0.02350657805800438
Epoch 4500, Loss: 2.6462059020996094, Losses: L1: 0.8047934770584106, L2: 0.11328155547380447, L3: 0.13950812816619873, L4: 0.8340221643447876, L5: 0.023486657068133354
Epoch 5000, Loss: 2.610985279083252, Losses: L1: 0.8233233094215393, L2: 0.10838771611452103, L3: 0.13790470361709595, L4: 0.8087419271469116, L5: 0.023515982553362846
Epoch 5500, Loss: 2.587050676345825, Losses: L1: 0.831989049911499, L2: 0.10578500479459763, L3: 0.1369091272354126, L4: 0.7934083342552185, L5: 0.023448962718248367
Epoch 6000, Loss: 2.5691659450531006, Losses: L1: 0.8376992344856262, L2: 0.10379917919635773, L3: 0.13590896129608154, L4: 0.7823564410209656, L5: 0.023449914529919624
Epoch 6500, Loss: 2.555938720703125, Losses: L1: 0.840852677822113, L2: 0.10244353860616684, L3: 0.1352400779724121, L4: 0.7746961116790771, L5: 0.02342604286968708
Epoch 7000, Loss: 2.546121120452881, Losses: L1: 0.8421269059181213, L2: 0.10151121765375137, L3: 0.134726881980896, L4: 0.7695348858833313, L5: 0.023402681574225426
Epoch 7500, Loss: 2.5387182235717773, Losses: L1: 0.842835545539856, L2: 0.10106615722179413, L3: 0.134432852268219, L4: 0.7657229900360107, L5: 0.023343579843640327
Epoch 8000, Loss: 2.532576084136963, Losses: L1: 0.8439664244651794, L2: 0.10064005851745605, L3: 0.13403165340423584, L4: 0.7622873783111572, L5: 0.023349478840827942
Epoch 8500, Loss: 2.528282403945923, Losses: L1: 0.8438754081726074, L2: 0.1002742350101471, L3: 0.13378894329071045, L4: 0.7603390216827393, L5: 0.023348672315478325
Epoch 9000, Loss: 2.525347948074341, Losses: L1: 0.8442645072937012, L2: 0.1000988632440567, L3: 0.13363385200500488, L4: 0.7587715983390808, L5: 0.023337023332715034
Epoch 9500, Loss: 2.5232067108154297, Losses: L1: 0.8444110155105591, L2: 0.0999964103102684, L3: 0.1334431767463684, L4: 0.7576927542686462, L5: 0.0233452171087265
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.008434772491455, Constraint losses: L1: 8.75048542022705, L2: 2.4769802621449344e-05, L3: 0.9998297691345215, L4: 0.9998297691345215
Epoch 500, Loss: 0.0027462407015264034, Constraint losses: L1: -0.9568110704421997, L2: 0.0, L3: 0.0028504133224487305, L4: 0.0008526385645382106
Epoch 1000, Loss: 0.0013866384979337454, Constraint losses: L1: -1.1166377067565918, L2: 0.0, L3: 0.0022512078285217285, L4: 0.0002520683337934315
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.006103515625, Constraint losses: L1: 7.413693904876709, L2: 0.0, L3: 0.9993448257446289, L4: 0.9993449449539185
Epoch 500, Loss: 0.002535472624003887, Constraint losses: L1: -1.0249685049057007, L2: 0.0, L3: 0.002779066562652588, L4: 0.0007813747506588697
Epoch 1000, Loss: 0.0014300133334472775, Constraint losses: L1: -1.0707905292510986, L2: 0.0, L3: 0.002250075340270996, L4: 0.00025072856806218624
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 45.68689727783203, Losses: L1: 10.00932502746582, L2: 0.0013097230112180114, L3: 0.9994041919708252, L4: 69.05980682373047, L5: 0.2952170968055725
Epoch 500, Loss: 3.6007697582244873, Losses: L1: 0.3043875992298126, L2: 0.16689927875995636, L3: 0.08574390411376953, L4: 6.216063976287842, L5: 0.038313280791044235
Epoch 1000, Loss: 1.8944717645645142, Losses: L1: -0.10742272436618805, L2: 0.02394251711666584, L3: 0.0671270489692688, L4: 3.828669548034668, L5: 0.0169227235019207
Epoch 1500, Loss: 3.8000829219818115, Losses: L1: 0.20515811443328857, L2: 0.7093160152435303, L3: 0.07306820154190063, L4: 6.2808051109313965, L5: 0.0535922609269619
Epoch 2000, Loss: 0.3897773027420044, Losses: L1: -0.06817816197872162, L2: 0.07119633257389069, L3: 0.06667447090148926, L4: 0.7052083611488342, L5: 0.006157299038022757
Epoch 2500, Loss: 0.14327943325042725, Losses: L1: -0.24541544914245605, L2: 0.03923986107110977, L3: 0.06518721580505371, L4: 0.6015246510505676, L5: 0.006250821985304356
Epoch 3000, Loss: 0.15234455466270447, Losses: L1: -0.2536907494068146, L2: 0.03794647008180618, L3: 0.06168210506439209, L4: 0.6454670429229736, L5: 0.0052928864024579525
Epoch 3500, Loss: 0.02099962718784809, Losses: L1: -0.2586342990398407, L2: 0.03705831989645958, L3: 0.061260223388671875, L4: 0.3944689631462097, L5: 0.005220117978751659
Epoch 4000, Loss: -0.0031454009003937244, Losses: L1: -0.2620811462402344, L2: 0.03619685396552086, L3: 0.06047868728637695, L4: 0.355835497379303, L5: 0.004881761036813259
Epoch 4500, Loss: -0.032632436603307724, Losses: L1: -0.26567021012306213, L2: 0.035650305449962616, L3: 0.05986499786376953, L4: 0.30579695105552673, L5: 0.004898285958915949
Epoch 5000, Loss: -0.040408991277217865, Losses: L1: -0.26727697253227234, L2: 0.035094816237688065, L3: 0.05947685241699219, L4: 0.29483476281166077, L5: 0.004852668382227421
Epoch 5500, Loss: -0.04531184211373329, Losses: L1: -0.2682862877845764, L2: 0.03464972972869873, L3: 0.05922889709472656, L4: 0.2879999577999115, L5: 0.004841407760977745
Epoch 6000, Loss: -0.04933343827724457, Losses: L1: -0.2693486213684082, L2: 0.03448808938264847, L3: 0.058978378772735596, L4: 0.2827523946762085, L5: 0.004833129234611988
Epoch 6500, Loss: -0.0520203672349453, Losses: L1: -0.26988300681114197, L2: 0.03421073406934738, L3: 0.058838069438934326, L4: 0.27900901436805725, L5: 0.0048293862491846085
Epoch 7000, Loss: -0.05394558981060982, Losses: L1: -0.2703114449977875, L2: 0.03406992182135582, L3: 0.05870771408081055, L4: 0.2764267921447754, L5: 0.004819597117602825
Epoch 7500, Loss: -0.055401433259248734, Losses: L1: -0.2706371545791626, L2: 0.03398902714252472, L3: 0.0586279034614563, L4: 0.27440550923347473, L5: 0.004821111913770437
Epoch 8000, Loss: -0.05650053918361664, Losses: L1: -0.2708451449871063, L2: 0.03392535820603371, L3: 0.058563053607940674, L4: 0.2728196978569031, L5: 0.0048180557787418365
Epoch 8500, Loss: -0.05729321390390396, Losses: L1: -0.27100732922554016, L2: 0.03387942910194397, L3: 0.05851095914840698, L4: 0.271711140871048, L5: 0.004815715830773115
Epoch 9000, Loss: -0.05790163204073906, Losses: L1: -0.27109938859939575, L2: 0.03383157402276993, L3: 0.058475375175476074, L4: 0.27079516649246216, L5: 0.004818003159016371
Epoch 9500, Loss: -0.05833511799573898, Losses: L1: -0.2712102234363556, L2: 0.033817682415246964, L3: 0.05844753980636597, L4: 0.2702201008796692, L5: 0.004817320965230465
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0018022060394287, Constraint losses: L1: 6.107509136199951, L2: 0.0, L3: 0.9978474378585815, L4: 0.9978472590446472
Epoch 500, Loss: 0.001985736656934023, Constraint losses: L1: -1.1069482564926147, L2: 0.0, L3: 0.0025457143783569336, L4: 0.0005469706957228482
Epoch 1000, Loss: 0.0012397636892274022, Constraint losses: L1: -1.1160035133361816, L2: 0.0, L3: 0.002177715301513672, L4: 0.00017805202514864504
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0228655338287354, Constraint losses: L1: 18.42068099975586, L2: 0.0014817051123827696, L3: 1.0014816522598267, L4: 1.001481533050537
Epoch 500, Loss: 0.002578623592853546, Constraint losses: L1: -0.8466627597808838, L2: 0.0, L3: 0.0027112960815429688, L4: 0.0007139901863411069
Epoch 1000, Loss: 0.0013297558762133121, Constraint losses: L1: -1.064880132675171, L2: 0.0, L3: 0.002196967601776123, L4: 0.00019766845798585564
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 58.21411895751953, Losses: L1: 18.42068099975586, L2: 0.00590132549405098, L3: 1.0058820247650146, L4: 76.8428955078125, L5: 0.3631608784198761
Epoch 500, Loss: 4.681431293487549, Losses: L1: 1.9570626020431519, L2: 0.3428551256656647, L3: 0.11242085695266724, L4: 4.834827423095703, L5: 0.023106448352336884
Epoch 1000, Loss: 0.7160567045211792, Losses: L1: -0.23828622698783875, L2: 0.18070116639137268, L3: 0.11635684967041016, L4: 1.4764539003372192, L5: 0.009408515878021717
Epoch 1500, Loss: 33.63689422607422, Losses: L1: 7.434771537780762, L2: 0.0, L3: 0.9991669654846191, L4: 50.017921447753906, L5: 0.1939941793680191
Epoch 2000, Loss: 30.613262176513672, Losses: L1: 3.5205299854278564, L2: 0.012901038862764835, L3: 0.9727688431739807, L4: 51.849327087402344, L5: 0.18884998559951782
Epoch 2500, Loss: 30.59783363342285, Losses: L1: 3.4165377616882324, L2: 0.011733891442418098, L3: 0.9702427387237549, L4: 52.031436920166016, L5: 0.18946634232997894
Epoch 3000, Loss: 30.589632034301758, Losses: L1: 3.406080722808838, L2: 0.010667429305613041, L3: 0.9697316288948059, L4: 52.03635025024414, L5: 0.1903119683265686
Epoch 3500, Loss: 30.584228515625, Losses: L1: 3.4018349647521973, L2: 0.00992618314921856, L3: 0.9693835377693176, L4: 52.03422927856445, L5: 0.19093403220176697
Epoch 4000, Loss: 30.580265045166016, Losses: L1: 3.3988075256347656, L2: 0.009377967566251755, L3: 0.9691056609153748, L4: 52.032562255859375, L5: 0.19138053059577942
Epoch 4500, Loss: 30.57724380493164, Losses: L1: 3.396475315093994, L2: 0.008964668028056622, L3: 0.9688833951950073, L4: 52.03138732910156, L5: 0.19170920550823212
Epoch 5000, Loss: 30.574914932250977, Losses: L1: 3.394620656967163, L2: 0.008648676797747612, L3: 0.9687075614929199, L4: 52.03061294555664, L5: 0.1919550895690918
Epoch 5500, Loss: 30.598033905029297, Losses: L1: 3.6811418533325195, L2: 0.00275096925906837, L3: 0.9678118228912354, L4: 51.51035690307617, L5: 0.19252680242061615
Epoch 6000, Loss: 30.51265525817871, Losses: L1: 3.423314094543457, L2: 0.004175156820565462, L3: 0.9628298878669739, L4: 51.8643913269043, L5: 0.19222857058048248
Epoch 6500, Loss: 30.484901428222656, Losses: L1: 3.322744846343994, L2: 0.004967381712049246, L3: 0.9614155888557434, L4: 52.01233673095703, L5: 0.19208958745002747
Epoch 7000, Loss: 30.476289749145508, Losses: L1: 3.289973735809326, L2: 0.005283751524984837, L3: 0.9612187743186951, L4: 52.060882568359375, L5: 0.1920149326324463
Epoch 7500, Loss: 30.475006103515625, Losses: L1: 3.2879483699798584, L2: 0.005242626648396254, L3: 0.9612773656845093, L4: 52.06237030029297, L5: 0.19197386503219604
Epoch 8000, Loss: 30.474048614501953, Losses: L1: 3.2866485118865967, L2: 0.00520904129371047, L3: 0.9613274335861206, L4: 52.063053131103516, L5: 0.19194261729717255
Epoch 8500, Loss: 30.47333335876465, Losses: L1: 3.2857437133789062, L2: 0.005183080211281776, L3: 0.9613677859306335, L4: 52.06342315673828, L5: 0.19191908836364746
Epoch 9000, Loss: 30.472795486450195, Losses: L1: 3.2851150035858154, L2: 0.005162506364285946, L3: 0.9614005088806152, L4: 52.063594818115234, L5: 0.191900834441185
Epoch 9500, Loss: 30.472366333007812, Losses: L1: 3.2845513820648193, L2: 0.0051468731835484505, L3: 0.9614242911338806, L4: 52.06386184692383, L5: 0.19188617169857025
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.999870777130127, Constraint losses: L1: 5.813815116882324, L2: 0.0, L3: 0.997028648853302, L4: 0.9970284104347229
Epoch 500, Loss: 0.0019494501175358891, Constraint losses: L1: -1.0624651908874512, L2: 0.0, L3: 0.002505183219909668, L4: 0.0005067321471869946
Epoch 1000, Loss: 0.00118364323861897, Constraint losses: L1: -1.1173127889633179, L2: 0.0, L3: 0.002150237560272217, L4: 0.00015071853704284877
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.01914381980896, Constraint losses: L1: 18.42068099975586, L2: 0.00024103301984723657, L3: 1.0002410411834717, L4: 1.0002410411834717
Epoch 500, Loss: 0.002361442893743515, Constraint losses: L1: -1.0605428218841553, L2: 0.0, L3: 0.002710103988647461, L4: 0.0007118817302398384
Epoch 1000, Loss: 0.0013989937724545598, Constraint losses: L1: -1.071549654006958, L2: 0.0, L3: 0.002234935760498047, L4: 0.0002356077020522207
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 53.173828125, Losses: L1: 13.550283432006836, L2: 0.00017576725804246962, L3: 0.9998835325241089, L4: 75.84642028808594, L5: 0.3501812517642975
Epoch 500, Loss: 36.16413879394531, Losses: L1: 9.77231216430664, L2: 4.0475970308762044e-05, L3: 0.9999518394470215, L4: 50.003360748291016, L5: 0.1950872838497162
Epoch 1000, Loss: 2.9282314777374268, Losses: L1: 0.18745936453342438, L2: 0.24707497656345367, L3: 0.26447707414627075, L4: 4.632265090942383, L5: 0.01831253245472908
Epoch 1500, Loss: 2.293069362640381, Losses: L1: 0.0994303748011589, L2: 0.1880841851234436, L3: 0.22846907377243042, L4: 3.679570198059082, L5: 0.01567140221595764
Epoch 2000, Loss: 9.2943696975708, Losses: L1: 1.660306453704834, L2: 0.7807690501213074, L3: 0.30822622776031494, L4: 13.637450218200684, L5: 0.058363255113363266
Epoch 2500, Loss: 6.496119499206543, Losses: L1: 1.2561992406845093, L2: 0.7355687022209167, L3: 0.20653903484344482, L4: 9.07957649230957, L5: 0.06290429830551147
Epoch 3000, Loss: 3.033118486404419, Losses: L1: 0.36082229018211365, L2: 0.2903541326522827, L3: 0.2505837678909302, L4: 4.456478595733643, L5: 0.02414804883301258
Epoch 3500, Loss: 2.790187120437622, Losses: L1: 0.36419448256492615, L2: 0.26633328199386597, L3: 0.24014687538146973, L4: 4.010959148406982, L5: 0.02359973080456257
Epoch 4000, Loss: 2.517646074295044, Losses: L1: 0.25250452756881714, L2: 0.2453622967004776, L3: 0.23193120956420898, L4: 3.730875015258789, L5: 0.022545859217643738
Epoch 4500, Loss: 2.434166431427002, Losses: L1: 0.24567565321922302, L2: 0.23511014878749847, L3: 0.22787946462631226, L4: 3.596644401550293, L5: 0.022366981953382492
Epoch 5000, Loss: 2.377714157104492, Losses: L1: 0.2466055154800415, L2: 0.22908930480480194, L3: 0.22583413124084473, L4: 3.4925079345703125, L5: 0.02223796397447586
Epoch 5500, Loss: 2.3346669673919678, Losses: L1: 0.247597336769104, L2: 0.2241722047328949, L3: 0.22439980506896973, L4: 3.412682056427002, L5: 0.02212127484381199
Epoch 6000, Loss: 2.301440715789795, Losses: L1: 0.24836593866348267, L2: 0.22010459005832672, L3: 0.2232142686843872, L4: 3.3514304161071777, L5: 0.022046584635972977
Epoch 6500, Loss: 2.2760744094848633, Losses: L1: 0.24925611913204193, L2: 0.21684995293617249, L3: 0.222314715385437, L4: 3.3042397499084473, L5: 0.021979309618473053
Epoch 7000, Loss: 2.256715774536133, Losses: L1: 0.24975252151489258, L2: 0.21449005603790283, L3: 0.22161465883255005, L4: 3.2685294151306152, L5: 0.02191946655511856
Epoch 7500, Loss: 2.242377996444702, Losses: L1: 0.2501485049724579, L2: 0.21278882026672363, L3: 0.22109436988830566, L4: 3.2419941425323486, L5: 0.021871773526072502
Epoch 8000, Loss: 2.2319984436035156, Losses: L1: 0.2501658797264099, L2: 0.21165014803409576, L3: 0.22069424390792847, L4: 3.2232704162597656, L5: 0.02183907851576805
Epoch 8500, Loss: 2.2244439125061035, Losses: L1: 0.2504875659942627, L2: 0.2107096165418625, L3: 0.2204885482788086, L4: 3.2089831829071045, L5: 0.021810786798596382
Epoch 9000, Loss: 2.2190487384796143, Losses: L1: 0.2507563829421997, L2: 0.21003475785255432, L3: 0.22034740447998047, L4: 3.1986773014068604, L5: 0.021794484928250313
Epoch 9500, Loss: 2.2152390480041504, Losses: L1: 0.2507350742816925, L2: 0.20966123044490814, L3: 0.22022438049316406, L4: 3.1917643547058105, L5: 0.02178332209587097
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0304362773895264, Constraint losses: L1: 18.42068099975586, L2: 0.0040052505210042, L3: 1.0040051937103271, L4: 1.0040051937103271
Epoch 500, Loss: 0.0021174869034439325, Constraint losses: L1: -1.062589168548584, L2: 0.0, L3: 0.002589106559753418, L4: 0.0005909695755690336
Epoch 1000, Loss: 0.0012550253886729479, Constraint losses: L1: -1.117303729057312, L2: 0.0, L3: 0.002186000347137451, L4: 0.00018632877618074417
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.004074811935425, Constraint losses: L1: 6.618642807006836, L2: 0.0, L3: 0.9987282156944275, L4: 0.9987279772758484
Epoch 500, Loss: 0.0023196986876428127, Constraint losses: L1: -1.0412468910217285, L2: 0.0, L3: 0.002679586410522461, L4: 0.0006813593208789825
Epoch 1000, Loss: 0.0013757410924881697, Constraint losses: L1: -1.069758415222168, L2: 0.0, L3: 0.0022224783897399902, L4: 0.00022302116849459708
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 96.27175903320312, Losses: L1: 18.42068099975586, L2: 0.0018239039927721024, L3: 1.001823902130127, L4: 76.67013549804688, L5: 0.3564215898513794
Epoch 500, Loss: 3.933130979537964, Losses: L1: 0.01978021301329136, L2: 0.10173006355762482, L3: 0.07751166820526123, L4: 3.772719621658325, L5: 0.02450917288661003
Epoch 1000, Loss: 1.0895543098449707, Losses: L1: -0.21695297956466675, L2: 0.0975249633193016, L3: 0.05913817882537842, L4: 1.1924203634262085, L5: 0.01237261202186346
Epoch 1500, Loss: 1.832167148590088, Losses: L1: -0.04973519220948219, L2: 0.16529114544391632, L3: 0.07855725288391113, L4: 1.710925817489624, L5: 0.019547540694475174
Epoch 2000, Loss: 1.3861232995986938, Losses: L1: -0.08219076693058014, L2: 0.1246015802025795, L3: 0.06701898574829102, L4: 1.3341760635375977, L5: 0.009636502712965012
Epoch 2500, Loss: 0.6104971170425415, Losses: L1: -0.24084419012069702, L2: 0.06077767163515091, L3: 0.06534016132354736, L4: 0.7519049644470215, L5: 0.007414651103317738
Epoch 3000, Loss: 0.43472036719322205, Losses: L1: -0.2696909010410309, L2: 0.06280417740345001, L3: 0.06120741367340088, L4: 0.6087803244590759, L5: 0.006042927037924528
Epoch 3500, Loss: 0.060308389365673065, Losses: L1: -0.27620169520378113, L2: 0.05087488144636154, L3: 0.06108391284942627, L4: 0.24715298414230347, L5: 0.005671482998877764
Epoch 4000, Loss: 0.03476095572113991, Losses: L1: -0.27882423996925354, L2: 0.05079951509833336, L3: 0.05990201234817505, L4: 0.22543445229530334, L5: 0.00569797120988369
Epoch 4500, Loss: 0.006814218126237392, Losses: L1: -0.2777085602283478, L2: 0.049403417855501175, L3: 0.059191882610321045, L4: 0.19779111444950104, L5: 0.005676133558154106
Epoch 5000, Loss: 0.004143843427300453, Losses: L1: -0.2773124575614929, L2: 0.04810076951980591, L3: 0.05901288986206055, L4: 0.19557826220989227, L5: 0.005629528313875198
Epoch 5500, Loss: -0.003111504949629307, Losses: L1: -0.27715641260147095, L2: 0.047240469604730606, L3: 0.05878102779388428, L4: 0.18882444500923157, L5: 0.005638374015688896
Epoch 6000, Loss: -0.00860784761607647, Losses: L1: -0.27651065587997437, L2: 0.04691748693585396, L3: 0.05849117040634155, L4: 0.18313398957252502, L5: 0.005637798923999071
Epoch 6500, Loss: -0.010635126382112503, Losses: L1: -0.27663204073905945, L2: 0.04659310355782509, L3: 0.058313846588134766, L4: 0.18156777322292328, L5: 0.005637460388243198
Epoch 7000, Loss: -0.012117937207221985, Losses: L1: -0.27690157294273376, L2: 0.04634496942162514, L3: 0.0581965446472168, L4: 0.180597722530365, L5: 0.005633741617202759
Epoch 7500, Loss: -0.013224759139120579, Losses: L1: -0.27693483233451843, L2: 0.04609028249979019, L3: 0.05812108516693115, L4: 0.1797284334897995, L5: 0.005630803760141134
Epoch 8000, Loss: -0.013973677530884743, Losses: L1: -0.27701520919799805, L2: 0.045933451503515244, L3: 0.05805230140686035, L4: 0.17920668423175812, L5: 0.00563166756182909
Epoch 8500, Loss: -0.014649352990090847, Losses: L1: -0.277023583650589, L2: 0.04582341015338898, L3: 0.057998061180114746, L4: 0.17864875495433807, L5: 0.005631433799862862
Epoch 9000, Loss: -0.015105117112398148, Losses: L1: -0.27706092596054077, L2: 0.04572915658354759, L3: 0.05796217918395996, L4: 0.17831359803676605, L5: 0.005630902945995331
Epoch 9500, Loss: -0.015423491597175598, Losses: L1: -0.27707216143608093, L2: 0.045660458505153656, L3: 0.057934343814849854, L4: 0.17806895077228546, L5: 0.0056303138844668865
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.017693042755127, Constraint losses: L1: 17.45960235595703, L2: 0.00010256778477923945, L3: 1.0000654458999634, L4: 1.0000653266906738
Epoch 500, Loss: 0.002258647233247757, Constraint losses: L1: -1.0778006315231323, L2: 0.0, L3: 0.002667367458343506, L4: 0.0006690804148092866
Epoch 1000, Loss: 0.0013029759284108877, Constraint losses: L1: -1.1174644231796265, L2: 0.0, L3: 0.002209901809692383, L4: 0.00021053860837128013
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005812883377075, Constraint losses: L1: 7.2214884757995605, L2: 0.0, L3: 0.999295711517334, L4: 0.9992956519126892
Epoch 500, Loss: 0.002472628839313984, Constraint losses: L1: -0.9284278750419617, L2: 0.0, L3: 0.002699136734008789, L4: 0.0007019200129434466
Epoch 1000, Loss: 0.0013545684050768614, Constraint losses: L1: -1.069224238395691, L2: 0.0, L3: 0.0022115707397460938, L4: 0.0002122220175806433
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 91.55091094970703, Losses: L1: 16.53132438659668, L2: 0.0034404753241688013, L3: 1.0033984184265137, L4: 73.67221069335938, L5: 0.34225115180015564
Epoch 500, Loss: 2.784726858139038, Losses: L1: -0.0801188051700592, L2: 0.05969133600592613, L3: 0.09477072954177856, L4: 2.7075326442718506, L5: 0.03269678354263306
Epoch 1000, Loss: 0.8665333390235901, Losses: L1: -0.25647690892219543, L2: 0.03870329633355141, L3: 0.06074172258377075, L4: 1.0363588333129883, L5: 0.006558075547218323
Epoch 1500, Loss: 12.834952354431152, Losses: L1: 5.6758832931518555, L2: 1.4684243202209473, L3: 0.06243926286697388, L4: 6.2975993156433105, L5: 0.06481856852769852
Epoch 2000, Loss: 21.627891540527344, Losses: L1: 2.334298610687256, L2: 2.0816471576690674, L3: 0.37001675367355347, L4: 17.795738220214844, L5: 0.08701527118682861
Epoch 2500, Loss: 2.394665002822876, Losses: L1: 0.8805937767028809, L2: 0.1894451081752777, L3: 0.15410703420639038, L4: 1.2264323234558105, L5: 0.038809340447187424
Epoch 3000, Loss: 3.402339220046997, Losses: L1: 0.21401944756507874, L2: 0.24585765600204468, L3: 0.11913979053497314, L4: 2.912296772003174, L5: 0.03395426645874977
Epoch 3500, Loss: 0.9732288122177124, Losses: L1: -0.04674092307686806, L2: 0.10129041969776154, L3: 0.12106335163116455, L4: 0.8284925222396851, L5: 0.019768649712204933
Epoch 4000, Loss: 0.8828341960906982, Losses: L1: -0.06398145109415054, L2: 0.09788335859775543, L3: 0.11778140068054199, L4: 0.7618345618247986, L5: 0.01825799234211445
Epoch 4500, Loss: 0.8578441143035889, Losses: L1: -0.0681672990322113, L2: 0.09600017964839935, L3: 0.11369907855987549, L4: 0.746095597743988, L5: 0.018216652795672417
Epoch 5000, Loss: 0.816674530506134, Losses: L1: -0.07138386368751526, L2: 0.09275311976671219, L3: 0.1123928427696228, L4: 0.7115632891654968, L5: 0.01772569864988327
Epoch 5500, Loss: 0.7913452386856079, Losses: L1: -0.07360632717609406, L2: 0.09036289155483246, L3: 0.11064928770065308, L4: 0.6912018060684204, L5: 0.0179190281778574
Epoch 6000, Loss: 0.7762849926948547, Losses: L1: -0.07446266710758209, L2: 0.08868005871772766, L3: 0.10971343517303467, L4: 0.6788671016693115, L5: 0.017827095463871956
Epoch 6500, Loss: 0.7645298838615417, Losses: L1: -0.07516516000032425, L2: 0.08733230084180832, L3: 0.10898184776306152, L4: 0.6692439317703247, L5: 0.017803112044930458
Epoch 7000, Loss: 0.7556736469268799, Losses: L1: -0.0753924772143364, L2: 0.08630642294883728, L3: 0.10845077037811279, L4: 0.6617212295532227, L5: 0.017740923911333084
Epoch 7500, Loss: 0.7488645911216736, Losses: L1: -0.07566280663013458, L2: 0.08564559370279312, L3: 0.10798889398574829, L4: 0.6560350656509399, L5: 0.017680617049336433
Epoch 8000, Loss: 0.7437562942504883, Losses: L1: -0.07586733996868134, L2: 0.08504776656627655, L3: 0.10769689083099365, L4: 0.6517861485481262, L5: 0.017616668716073036
Epoch 8500, Loss: 0.7398126721382141, Losses: L1: -0.07602903991937637, L2: 0.08451829850673676, L3: 0.10738658905029297, L4: 0.6486088633537292, L5: 0.01758710853755474
Epoch 9000, Loss: 0.7368620038032532, Losses: L1: -0.0762229859828949, L2: 0.08415914326906204, L3: 0.1071355938911438, L4: 0.6462959051132202, L5: 0.017573872581124306
Epoch 9500, Loss: 0.7346796989440918, Losses: L1: -0.07640837877988815, L2: 0.08392811566591263, L3: 0.10695046186447144, L4: 0.6446158289909363, L5: 0.017557747662067413
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0224480628967285, Constraint losses: L1: 18.42068099975586, L2: 0.0013423538766801357, L3: 1.0013422966003418, L4: 1.0013427734375
Epoch 500, Loss: 0.0021516121923923492, Constraint losses: L1: -1.112524151802063, L2: 0.0, L3: 0.0026313066482543945, L4: 0.0006328298477455974
Epoch 1000, Loss: 0.0012990173418074846, Constraint losses: L1: -1.1179486513137817, L2: 0.0, L3: 0.0022082924842834473, L4: 0.00020867359125986695
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0193512439727783, Constraint losses: L1: 18.42068099975586, L2: 0.00031018423032946885, L3: 1.0003101825714111, L4: 1.0003101825714111
Epoch 500, Loss: 0.0027183571364730597, Constraint losses: L1: -1.0672786235809326, L2: 0.0, L3: 0.002891838550567627, L4: 0.0008937973179854453
Epoch 1000, Loss: 0.0015266299014911056, Constraint losses: L1: -1.071317195892334, L2: 0.0, L3: 0.0022985339164733887, L4: 0.0002994132228195667
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 80.26673126220703, Losses: L1: 8.722217559814453, L2: 0.00010315670806448907, L3: 0.9980687499046326, L4: 69.93495178222656, L5: 0.3057223856449127
Epoch 500, Loss: 3.6733245849609375, Losses: L1: 0.2843555212020874, L2: 0.10203326493501663, L3: 0.0838092565536499, L4: 3.223315954208374, L5: 0.015413693152368069
Epoch 1000, Loss: 55.520729064941406, Losses: L1: 2.416569471359253, L2: 4.482032775878906, L3: 1.141775131225586, L4: 49.3635139465332, L5: 0.17892558872699738
Epoch 1500, Loss: 56.58641052246094, Losses: L1: 4.420308589935303, L2: 0.015568148344755173, L3: 0.9959719181060791, L4: 50.77780532836914, L5: 0.19227106869220734
Epoch 2000, Loss: 8.564474105834961, Losses: L1: 0.7995817065238953, L2: 0.1583051234483719, L3: 0.26009976863861084, L4: 7.359100341796875, L5: 0.03327002748847008
Epoch 2500, Loss: 1.9772493839263916, Losses: L1: 0.32333678007125854, L2: 0.04080990329384804, L3: 0.13194262981414795, L4: 1.4436581134796143, L5: 0.02895345911383629
Epoch 3000, Loss: 1.582242727279663, Losses: L1: 0.3781949579715729, L2: 0.04021026939153671, L3: 0.1245812177658081, L4: 1.0055994987487793, L5: 0.026880990713834763
Epoch 3500, Loss: 1.4484034776687622, Losses: L1: 0.3696269690990448, L2: 0.03826305642724037, L3: 0.11867308616638184, L4: 0.8917604684829712, L5: 0.02460571750998497
Epoch 4000, Loss: 1.3783570528030396, Losses: L1: 0.35759812593460083, L2: 0.03871999308466911, L3: 0.11576724052429199, L4: 0.8378098607063293, L5: 0.023910941556096077
Epoch 4500, Loss: 1.3283429145812988, Losses: L1: 0.34578457474708557, L2: 0.03816566243767738, L3: 0.11364161968231201, L4: 0.8033530712127686, L5: 0.02324039489030838
Epoch 5000, Loss: 1.2854561805725098, Losses: L1: 0.33518096804618835, L2: 0.03729015588760376, L3: 0.11240130662918091, L4: 0.7742642164230347, L5: 0.02248224802315235
Epoch 5500, Loss: 1.2595487833023071, Losses: L1: 0.3274643123149872, L2: 0.0370611809194088, L3: 0.11156082153320312, L4: 0.7575551867485046, L5: 0.022218968719244003
Epoch 6000, Loss: 1.2392975091934204, Losses: L1: 0.3215672969818115, L2: 0.036924052983522415, L3: 0.11101329326629639, L4: 0.7439635992050171, L5: 0.022145656868815422
Epoch 6500, Loss: 1.225125789642334, Losses: L1: 0.31732141971588135, L2: 0.03682834655046463, L3: 0.11052823066711426, L4: 0.734802782535553, L5: 0.02202954888343811
Epoch 7000, Loss: 1.21448814868927, Losses: L1: 0.3137803375720978, L2: 0.036746494472026825, L3: 0.11015212535858154, L4: 0.7283529043197632, L5: 0.021914806216955185
Epoch 7500, Loss: 1.206620216369629, Losses: L1: 0.31153857707977295, L2: 0.03667044639587402, L3: 0.10993939638137817, L4: 0.7230620384216309, L5: 0.02187252789735794
Epoch 8000, Loss: 1.2008957862854004, Losses: L1: 0.30971962213516235, L2: 0.03661061450839043, L3: 0.10980474948883057, L4: 0.7193820476531982, L5: 0.02184201031923294
Epoch 8500, Loss: 1.1968283653259277, Losses: L1: 0.30870887637138367, L2: 0.03653955087065697, L3: 0.1097038984298706, L4: 0.7164913415908813, L5: 0.02182719297707081
Epoch 9000, Loss: 1.193924903869629, Losses: L1: 0.30741024017333984, L2: 0.03653986006975174, L3: 0.10962200164794922, L4: 0.7150336503982544, L5: 0.02179454267024994
Epoch 9500, Loss: 1.191909909248352, Losses: L1: 0.3066096305847168, L2: 0.03653585538268089, L3: 0.10958224534988403, L4: 0.7138701677322388, L5: 0.02178998664021492
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0061278343200684, Constraint losses: L1: 7.3841938972473145, L2: 0.0, L3: 0.9993717074394226, L4: 0.9993717670440674
Epoch 500, Loss: 0.0024764155969023705, Constraint losses: L1: -1.0805234909057617, L2: 0.0, L3: 0.002777397632598877, L4: 0.0007795416750013828
Epoch 1000, Loss: 0.001370154437609017, Constraint losses: L1: -1.1181446313858032, L2: 0.0, L3: 0.00224381685256958, L4: 0.00024448230396956205
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0036771297454834, Constraint losses: L1: 6.523387432098389, L2: 0.0, L3: 0.9985769391059875, L4: 0.9985767602920532
Epoch 500, Loss: 0.002329004928469658, Constraint losses: L1: -0.9760248064994812, L2: 0.0, L3: 0.0026514530181884766, L4: 0.0006535769207403064
Epoch 1000, Loss: 0.001325326389633119, Constraint losses: L1: -1.0682711601257324, L2: 0.0, L3: 0.00219649076461792, L4: 0.00019710684136953205
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 178.491943359375, Losses: L1: 18.42068099975586, L2: 0.004962794948369265, L3: 1.0049628019332886, L4: 79.43759155273438, L5: 0.37724363803863525
Epoch 500, Loss: 3.1735620498657227, Losses: L1: 0.3457731306552887, L2: 0.0819094330072403, L3: 0.12022268772125244, L4: 1.330161690711975, L5: 0.012576127424836159
Epoch 1000, Loss: 1.760585069656372, Losses: L1: 0.13639624416828156, L2: 0.13125407695770264, L3: 0.07937783002853394, L4: 0.7368721961975098, L5: 0.010879015550017357
Epoch 1500, Loss: 2.230689764022827, Losses: L1: -0.17652124166488647, L2: 0.08734875172376633, L3: 0.05467081069946289, L4: 1.15216064453125, L5: 0.00908907875418663
Epoch 2000, Loss: 2.204317569732666, Losses: L1: -0.2079072743654251, L2: 0.037805307656526566, L3: 0.05108731985092163, L4: 1.169128179550171, L5: 0.007956956513226032
Epoch 2500, Loss: 1.460221767425537, Losses: L1: -0.17420566082000732, L2: 0.045351285487413406, L3: 0.048853158950805664, L4: 0.7796268463134766, L5: 0.007289932109415531
Epoch 3000, Loss: 0.43201202154159546, Losses: L1: -0.17207401990890503, L2: 0.033995453268289566, L3: 0.04845750331878662, L4: 0.26794928312301636, L5: 0.005464473739266396
Epoch 3500, Loss: 0.3869417607784271, Losses: L1: -0.17448268830776215, L2: 0.03388867899775505, L3: 0.04737198352813721, L4: 0.2472115308046341, L5: 0.005370116792619228
Epoch 4000, Loss: 0.191133052110672, Losses: L1: -0.1775224655866623, L2: 0.03146902844309807, L3: 0.04718935489654541, L4: 0.15153425931930542, L5: 0.0053262850269675255
Epoch 4500, Loss: 0.09001757204532623, Losses: L1: -0.18023914098739624, L2: 0.030262507498264313, L3: 0.04697352647781372, L4: 0.10275042057037354, L5: 0.0053021893836557865
Epoch 5000, Loss: 0.08802659809589386, Losses: L1: -0.18106864392757416, L2: 0.029205279424786568, L3: 0.046858251094818115, L4: 0.1025007963180542, L5: 0.005265508778393269
Epoch 5500, Loss: 0.07077424228191376, Losses: L1: -0.1815374791622162, L2: 0.028663717210292816, L3: 0.046756744384765625, L4: 0.09430713206529617, L5: 0.00521769467741251
Epoch 6000, Loss: 0.06397826224565506, Losses: L1: -0.18267720937728882, L2: 0.02862868644297123, L3: 0.046707987785339355, L4: 0.0915190577507019, L5: 0.005190064199268818
Epoch 6500, Loss: 0.06042628362774849, Losses: L1: -0.18338996171951294, L2: 0.028523942455649376, L3: 0.04666966199874878, L4: 0.09014775604009628, L5: 0.005178189370781183
Epoch 7000, Loss: 0.05771688371896744, Losses: L1: -0.18377862870693207, L2: 0.028457025066018105, L3: 0.046629488468170166, L4: 0.08902715146541595, L5: 0.005166423507034779
Epoch 7500, Loss: 0.055828485637903214, Losses: L1: -0.18415381014347076, L2: 0.028356654569506645, L3: 0.046580731868743896, L4: 0.0883219987154007, L5: 0.005158490501344204
Epoch 8000, Loss: 0.054421842098236084, Losses: L1: -0.1843961626291275, L2: 0.02826014719903469, L3: 0.04655599594116211, L4: 0.08777794986963272, L5: 0.005152078345417976
Epoch 8500, Loss: 0.05334150791168213, Losses: L1: -0.184597909450531, L2: 0.028225762769579887, L3: 0.04653501510620117, L4: 0.08735860884189606, L5: 0.005148620810359716
Epoch 9000, Loss: 0.052584391087293625, Losses: L1: -0.18473897874355316, L2: 0.028183117508888245, L3: 0.04652810096740723, L4: 0.08706554025411606, L5: 0.005145243369042873
Epoch 9500, Loss: 0.052076566964387894, Losses: L1: -0.1848154067993164, L2: 0.028154345229268074, L3: 0.046518802642822266, L4: 0.08686218410730362, L5: 0.005143264774233103
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0038084983825684, Constraint losses: L1: 6.6303181648254395, L2: 0.0, L3: 0.9985889196395874, L4: 0.9985893964767456
Epoch 500, Loss: 0.0020497003570199013, Constraint losses: L1: -1.0772342681884766, L2: 0.0, L3: 0.0025626420974731445, L4: 0.0005642925389111042
Epoch 1000, Loss: 0.0012370176846161485, Constraint losses: L1: -1.1151094436645508, L2: 0.0, L3: 0.002175748348236084, L4: 0.00017637887503951788
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0051803588867188, Constraint losses: L1: 7.012763023376465, L2: 0.0, L3: 0.9990838170051575, L4: 0.9990837574005127
Epoch 500, Loss: 0.002139101503416896, Constraint losses: L1: -1.0602011680603027, L2: 0.0, L3: 0.0025989413261413574, L4: 0.0006003613816574216
Epoch 1000, Loss: 0.0013092013541609049, Constraint losses: L1: -1.0713533163070679, L2: 0.0, L3: 0.0021899938583374023, L4: 0.00019056088058277965
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 152.29110717773438, Losses: L1: 10.473222732543945, L2: 0.0003835879033431411, L3: 0.9986401200294495, L4: 70.25401306152344, L5: 0.31102052330970764
Epoch 500, Loss: 8.937751770019531, Losses: L1: 0.7484716773033142, L2: 0.3097682595252991, L3: 0.11804735660552979, L4: 3.943399429321289, L5: 0.029549621045589447
Epoch 1000, Loss: 6.835849285125732, Losses: L1: 1.3725097179412842, L2: 0.5040991902351379, L3: 0.12902593612670898, L4: 2.5305514335632324, L5: 0.021160895004868507
Epoch 1500, Loss: 2.5908584594726562, Losses: L1: -0.006415264215320349, L2: 0.21315588057041168, L3: 0.08448922634124756, L4: 1.1924885511398315, L5: 0.021229421719908714
Epoch 2000, Loss: 1.5976332426071167, Losses: L1: -0.023366954177618027, L2: 0.11146005243062973, L3: 0.07869023084640503, L4: 0.7393074631690979, L5: 0.007964961230754852
Epoch 2500, Loss: 0.969225287437439, Losses: L1: -0.05698733031749725, L2: 0.08543801307678223, L3: 0.07478547096252441, L4: 0.4508124589920044, L5: 0.007083222735673189
Epoch 3000, Loss: 0.8824729323387146, Losses: L1: 0.03097945638000965, L2: 0.0794692113995552, L3: 0.07156288623809814, L4: 0.3667622208595276, L5: 0.006671563722193241
Epoch 3500, Loss: 0.8478222489356995, Losses: L1: -0.05214234068989754, L2: 0.07805215567350388, L3: 0.07133805751800537, L4: 0.3916209638118744, L5: 0.0063584838062524796
Epoch 4000, Loss: 0.7258859276771545, Losses: L1: -0.05307263135910034, L2: 0.07716718316078186, L3: 0.06980586051940918, L4: 0.33212757110595703, L5: 0.006313974037766457
Epoch 4500, Loss: 0.6101661920547485, Losses: L1: -0.07217108458280563, L2: 0.07785492390394211, L3: 0.06916403770446777, L4: 0.2839632034301758, L5: 0.0063193608075380325
Epoch 5000, Loss: 0.6007641553878784, Losses: L1: -0.07797250151634216, L2: 0.07883233577013016, L3: 0.06870222091674805, L4: 0.2821471393108368, L5: 0.006323967594653368
Epoch 5500, Loss: 0.5792366862297058, Losses: L1: -0.0820317268371582, L2: 0.07912351191043854, L3: 0.06828659772872925, L4: 0.27351683378219604, L5: 0.006386414170265198
Epoch 6000, Loss: 0.5693710446357727, Losses: L1: -0.08483156561851501, L2: 0.07936663925647736, L3: 0.06815922260284424, L4: 0.26996728777885437, L5: 0.006425484083592892
Epoch 6500, Loss: 0.5626214742660522, Losses: L1: -0.08724699914455414, L2: 0.07990814000368118, L3: 0.06798261404037476, L4: 0.26773566007614136, L5: 0.006460508797317743
Epoch 7000, Loss: 0.5577982664108276, Losses: L1: -0.08889421820640564, L2: 0.08024601638317108, L3: 0.06783896684646606, L4: 0.26612138748168945, L5: 0.006487748585641384
Epoch 7500, Loss: 0.5542324185371399, Losses: L1: -0.09004421532154083, L2: 0.08045768737792969, L3: 0.06771361827850342, L4: 0.264909029006958, L5: 0.006516076624393463
Epoch 8000, Loss: 0.5515121817588806, Losses: L1: -0.09113606065511703, L2: 0.08063682913780212, L3: 0.06765174865722656, L4: 0.2640707194805145, L5: 0.0065366486087441444
Epoch 8500, Loss: 0.5496858358383179, Losses: L1: -0.09182416647672653, L2: 0.08071555197238922, L3: 0.06761348247528076, L4: 0.2634938955307007, L5: 0.006550992373377085
Epoch 9000, Loss: 0.5485609173774719, Losses: L1: -0.09229514002799988, L2: 0.08081763982772827, L3: 0.06758040189743042, L4: 0.26315200328826904, L5: 0.006562815513461828
Epoch 9500, Loss: 0.5475881099700928, Losses: L1: -0.0926155373454094, L2: 0.08088573068380356, L3: 0.06755584478378296, L4: 0.2628185749053955, L5: 0.006567761767655611
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0221829414367676, Constraint losses: L1: 18.42068099975586, L2: 0.001254051341675222, L3: 1.0012540817260742, L4: 1.0012539625167847
Epoch 500, Loss: 0.002616767305880785, Constraint losses: L1: -1.084871530532837, L2: 0.0, L3: 0.002849757671356201, L4: 0.0008518811082467437
Epoch 1000, Loss: 0.0014414254110306501, Constraint losses: L1: -1.117565631866455, L2: 0.0, L3: 0.0022791028022766113, L4: 0.0002798883360810578
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9994077682495117, Constraint losses: L1: 5.611934661865234, L2: 0.0, L3: 0.996898889541626, L4: 0.9968969821929932
Epoch 500, Loss: 0.0026293175760656595, Constraint losses: L1: -1.0608311891555786, L2: 0.0, L3: 0.002844095230102539, L4: 0.000846053590066731
Epoch 1000, Loss: 0.00149019923992455, Constraint losses: L1: -1.071340560913086, L2: 0.0, L3: 0.0022804737091064453, L4: 0.00028106619720347226
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 181.41876220703125, Losses: L1: 5.792450904846191, L2: 3.452016983374051e-08, L3: 0.9961177706718445, L4: 86.88661193847656, L5: 0.42848074436187744
Epoch 500, Loss: 12.694445610046387, Losses: L1: 2.010730266571045, L2: 0.6361156702041626, L3: 0.18701130151748657, L4: 5.05246639251709, L5: 0.03685668110847473
Epoch 1000, Loss: 3.8183064460754395, Losses: L1: 0.62196946144104, L2: 0.2108106166124344, L3: 0.06638717651367188, L4: 1.4919700622558594, L5: 0.020302163437008858
Epoch 1500, Loss: 1.9473578929901123, Losses: L1: 0.12256832420825958, L2: 0.13304132223129272, L3: 0.06553316116333008, L4: 0.8334039449691772, L5: 0.012963914312422276
Epoch 2000, Loss: 1.0792213678359985, Losses: L1: -0.10369297862052917, L2: 0.07533174753189087, L3: 0.05834728479385376, L4: 0.5320132970809937, L5: 0.011437278240919113
Epoch 2500, Loss: 0.8249708414077759, Losses: L1: -0.21439452469348907, L2: 0.05183408036828041, L3: 0.05366760492324829, L4: 0.4700968861579895, L5: 0.009793465957045555
Epoch 3000, Loss: 0.30408284068107605, Losses: L1: -0.23494720458984375, L2: 0.04291219264268875, L3: 0.052953898906707764, L4: 0.22305473685264587, L5: 0.009255295619368553
Epoch 3500, Loss: 0.3161773085594177, Losses: L1: -0.24704283475875854, L2: 0.03863215819001198, L3: 0.05054652690887451, L4: 0.23844748735427856, L5: 0.008231282234191895
Epoch 4000, Loss: 0.1566782146692276, Losses: L1: -0.2557337284088135, L2: 0.034881364554166794, L3: 0.049225568771362305, L4: 0.16488558053970337, L5: 0.007987268269062042
Epoch 4500, Loss: 0.09496670961380005, Losses: L1: -0.2586183249950409, L2: 0.033220987766981125, L3: 0.04904019832611084, L4: 0.1361314207315445, L5: 0.007835752330720425
Epoch 5000, Loss: 0.07011566311120987, Losses: L1: -0.2606411874294281, L2: 0.03308666869997978, L3: 0.048867881298065186, L4: 0.125070720911026, L5: 0.0076020993292331696
Epoch 5500, Loss: 0.05861860141158104, Losses: L1: -0.26225101947784424, L2: 0.032969553023576736, L3: 0.04877293109893799, L4: 0.12036561220884323, L5: 0.007440341170877218
Epoch 6000, Loss: 0.05207240954041481, Losses: L1: -0.2636299431324005, L2: 0.032889556139707565, L3: 0.048676490783691406, L4: 0.11799104511737823, L5: 0.007299499120563269
Epoch 6500, Loss: 0.04642891511321068, Losses: L1: -0.2647683918476105, L2: 0.03300490230321884, L3: 0.04856252670288086, L4: 0.1158313974738121, L5: 0.007234765216708183
Epoch 7000, Loss: 0.043373625725507736, Losses: L1: -0.26556670665740967, L2: 0.033011458814144135, L3: 0.048497915267944336, L4: 0.11479254066944122, L5: 0.007175800856202841
Epoch 7500, Loss: 0.041298139840364456, Losses: L1: -0.2662090063095093, L2: 0.03302576765418053, L3: 0.04844385385513306, L4: 0.11413874477148056, L5: 0.007136458531022072
Epoch 8000, Loss: 0.03959649056196213, Losses: L1: -0.2666586935520172, L2: 0.03302088379859924, L3: 0.048418521881103516, L4: 0.11355779320001602, L5: 0.007105310447514057
Epoch 8500, Loss: 0.03832102194428444, Losses: L1: -0.2669520378112793, L2: 0.03302817419171333, L3: 0.04839134216308594, L4: 0.11310058832168579, L5: 0.007083224132657051
Epoch 9000, Loss: 0.03755241259932518, Losses: L1: -0.2671719193458557, L2: 0.03303216025233269, L3: 0.04837214946746826, L4: 0.11285156011581421, L5: 0.007066486869007349
Epoch 9500, Loss: 0.036854662001132965, Losses: L1: -0.26733461022377014, L2: 0.03303989768028259, L3: 0.04835909605026245, L4: 0.1125992089509964, L5: 0.00705591170117259
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0296707153320312, Constraint losses: L1: 18.42068099975586, L2: 0.003750417148694396, L3: 1.0037504434585571, L4: 1.0037492513656616
Epoch 500, Loss: 0.002311423420906067, Constraint losses: L1: -1.0848437547683716, L2: 0.0, L3: 0.0026972293853759766, L4: 0.0006990378606133163
Epoch 1000, Loss: 0.00133144308347255, Constraint losses: L1: -1.1174339056015015, L2: 0.0, L3: 0.0022242069244384766, L4: 0.00022467016242444515
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.021362781524658, Constraint losses: L1: 18.42068099975586, L2: 0.0009806823218241334, L3: 1.0009807348251343, L4: 1.0009808540344238
Epoch 500, Loss: 0.0023067407310009003, Constraint losses: L1: -0.9837108850479126, L2: 0.0, L3: 0.0026442408561706543, L4: 0.000646210799459368
Epoch 1000, Loss: 0.001310577616095543, Constraint losses: L1: -1.0701353549957275, L2: 0.0, L3: 0.0021900534629821777, L4: 0.00019065957167185843
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 44.735958099365234, Losses: L1: 5.301070690155029, L2: 4.0758864088275e-06, L3: 0.9891705513000488, L4: 74.57838439941406, L5: 0.33470427989959717
Epoch 500, Loss: 3.265432119369507, Losses: L1: 0.15977121889591217, L2: 0.21539242565631866, L3: 0.1104118824005127, L4: 5.506133556365967, L5: 0.048148252069950104
Epoch 1000, Loss: 0.4701972007751465, Losses: L1: -0.24081943929195404, L2: 0.08354112505912781, L3: 0.0818588137626648, L4: 1.0044199228286743, L5: 0.006636973470449448
Epoch 1500, Loss: 0.349468857049942, Losses: L1: -0.26561230421066284, L2: 0.06370219588279724, L3: 0.07392162084579468, L4: 0.8651479482650757, L5: 0.00562564842402935
Epoch 2000, Loss: 0.34101685881614685, Losses: L1: -0.28575924038887024, L2: 0.061217211186885834, L3: 0.066592276096344, L4: 0.919217050075531, L5: 0.006748880725353956
Epoch 2500, Loss: 0.08920496702194214, Losses: L1: -0.2917444705963135, L2: 0.06113573536276817, L3: 0.06354296207427979, L4: 0.44136032462120056, L5: 0.005230994429439306
Epoch 3000, Loss: 0.053065817803144455, Losses: L1: -0.29490694403648376, L2: 0.05962932109832764, L3: 0.06317639350891113, L4: 0.37843412160873413, L5: 0.005176509730517864
Epoch 3500, Loss: 0.026821453124284744, Losses: L1: -0.2938108742237091, L2: 0.05785098671913147, L3: 0.06237661838531494, L4: 0.3287535011768341, L5: 0.005153662990778685
Epoch 4000, Loss: 0.005800965707749128, Losses: L1: -0.2973809838294983, L2: 0.05806158483028412, L3: 0.06167888641357422, L4: 0.29650822281837463, L5: 0.005078530870378017
Epoch 4500, Loss: -0.005994646344333887, Losses: L1: -0.2983965277671814, L2: 0.05804344266653061, L3: 0.06114518642425537, L4: 0.2770548462867737, L5: 0.005124750547111034
Epoch 5000, Loss: -0.010950088500976562, Losses: L1: -0.30019935965538025, L2: 0.05834444612264633, L3: 0.0609394907951355, L4: 0.27131640911102295, L5: 0.005079746711999178
Epoch 5500, Loss: -0.014305532909929752, Losses: L1: -0.2998791038990021, L2: 0.05767582729458809, L3: 0.06084716320037842, L4: 0.26496267318725586, L5: 0.005119977984577417
Epoch 6000, Loss: -0.015673035755753517, Losses: L1: -0.30023297667503357, L2: 0.057436179369688034, L3: 0.06072986125946045, L4: 0.2635935842990875, L5: 0.00517068337649107
Epoch 6500, Loss: -0.018815413117408752, Losses: L1: -0.3008846342563629, L2: 0.05760728567838669, L3: 0.06058245897293091, L4: 0.25903117656707764, L5: 0.0051701366901397705
Epoch 7000, Loss: -0.019795475527644157, Losses: L1: -0.3010265529155731, L2: 0.057511795312166214, L3: 0.060507893562316895, L4: 0.2577340006828308, L5: 0.005184774752706289
Epoch 7500, Loss: -0.02040599286556244, Losses: L1: -0.3012915849685669, L2: 0.05752701312303543, L3: 0.060453057289123535, L4: 0.2572385370731354, L5: 0.005193410441279411
Epoch 8000, Loss: -0.020957984030246735, Losses: L1: -0.3014250695705414, L2: 0.057515036314725876, L3: 0.06040489673614502, L4: 0.256593257188797, L5: 0.005206300411373377
Epoch 8500, Loss: -0.021355539560317993, Losses: L1: -0.3014911711215973, L2: 0.057481829077005386, L3: 0.060379743576049805, L4: 0.2560589909553528, L5: 0.005211473908275366
Epoch 9000, Loss: -0.02161550708115101, Losses: L1: -0.3015817701816559, L2: 0.05748479440808296, L3: 0.060358524322509766, L4: 0.2557963728904724, L5: 0.005217250902205706
Epoch 9500, Loss: -0.021815970540046692, Losses: L1: -0.30162158608436584, L2: 0.05746947601437569, L3: 0.06034606695175171, L4: 0.25553667545318604, L5: 0.005220800172537565
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023355722427368, Constraint losses: L1: 18.42068099975586, L2: 0.0016450168332085013, L3: 1.0016449689865112, L4: 1.0016450881958008
Epoch 500, Loss: 0.0023148031905293465, Constraint losses: L1: -1.0794751644134521, L2: 0.0, L3: 0.002696096897125244, L4: 0.0006981813930906355
Epoch 1000, Loss: 0.0013274013763293624, Constraint losses: L1: -1.1181292533874512, L2: 0.0, L3: 0.002222418785095215, L4: 0.00022311195789370686
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0090761184692383, Constraint losses: L1: 9.194801330566406, L2: 2.1554298655246384e-05, L3: 0.9999300241470337, L4: 0.9999298453330994
Epoch 500, Loss: 0.002060023369267583, Constraint losses: L1: -1.0526318550109863, L2: 0.0, L3: 0.0025556087493896484, L4: 0.0005570465000346303
Epoch 1000, Loss: 0.0012920955196022987, Constraint losses: L1: -1.071046233177185, L2: 0.0, L3: 0.0021813511848449707, L4: 0.00018179068865720183
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 41.21567916870117, Losses: L1: 6.405727863311768, L2: 0.0, L3: 0.9983507990837097, L4: 65.08734893798828, L5: 0.2695728838443756
Epoch 500, Loss: 5.723576068878174, Losses: L1: 3.0435643196105957, L2: 0.5401132702827454, L3: 0.09124326705932617, L4: 4.407258987426758, L5: 0.023838933557271957
Epoch 1000, Loss: 2.04203724861145, Losses: L1: 0.06336670368909836, L2: 0.21272695064544678, L3: 0.1979956030845642, L4: 2.904690742492676, L5: 0.02397036924958229
Epoch 1500, Loss: 31.178531646728516, Losses: L1: 2.972470760345459, L2: 0.004248602781444788, L3: 0.9619815945625305, L4: 52.17093276977539, L5: 0.19450797140598297
Epoch 2000, Loss: 31.16968536376953, Losses: L1: 2.964820146560669, L2: 0.004791192710399628, L3: 0.9621329307556152, L4: 52.16693115234375, L5: 0.1947377622127533
Epoch 2500, Loss: 31.16364097595215, Losses: L1: 2.9602108001708984, L2: 0.005166003480553627, L3: 0.9622467756271362, L4: 52.16292190551758, L5: 0.1948934942483902
Epoch 3000, Loss: 31.159151077270508, Losses: L1: 2.956789255142212, L2: 0.0054281181655824184, L3: 0.962325930595398, L4: 52.15998840332031, L5: 0.19500237703323364
Epoch 3500, Loss: 31.155534744262695, Losses: L1: 2.9539215564727783, L2: 0.005618277471512556, L3: 0.9623793959617615, L4: 52.15793228149414, L5: 0.19507963955402374
Epoch 4000, Loss: 31.15226173400879, Losses: L1: 2.95119309425354, L2: 0.00575630459934473, L3: 0.9624029994010925, L4: 52.156497955322266, L5: 0.19513468444347382
Epoch 4500, Loss: 31.148656845092773, Losses: L1: 2.9480538368225098, L2: 0.005851744208484888, L3: 0.9623817205429077, L4: 52.155479431152344, L5: 0.19517292082309723
Epoch 5000, Loss: 31.143936157226562, Losses: L1: 2.9440035820007324, L2: 0.005906403064727783, L3: 0.9622970819473267, L4: 52.15437698364258, L5: 0.19519616663455963
Epoch 5500, Loss: 31.139060974121094, Losses: L1: 2.9401392936706543, L2: 0.005929532926529646, L3: 0.962194561958313, L4: 52.15272521972656, L5: 0.19520577788352966
Epoch 6000, Loss: 31.13591766357422, Losses: L1: 2.9378209114074707, L2: 0.0059546674601733685, L3: 0.962151288986206, L4: 52.151214599609375, L5: 0.19520927965641022
Epoch 6500, Loss: 31.13405418395996, Losses: L1: 2.9364230632781982, L2: 0.005985692609101534, L3: 0.9621423482894897, L4: 52.15028381347656, L5: 0.19521234929561615
Epoch 7000, Loss: 31.132844924926758, Losses: L1: 2.935474157333374, L2: 0.006014644633978605, L3: 0.9621437788009644, L4: 52.14971923828125, L5: 0.19521558284759521
Epoch 7500, Loss: 31.13200569152832, Losses: L1: 2.934814691543579, L2: 0.006038650404661894, L3: 0.9621486663818359, L4: 52.14931106567383, L5: 0.1952185332775116
Epoch 8000, Loss: 31.131404876708984, Losses: L1: 2.934335947036743, L2: 0.006057795602828264, L3: 0.9621526598930359, L4: 52.14902877807617, L5: 0.1952212005853653
Epoch 8500, Loss: 31.130970001220703, Losses: L1: 2.9340665340423584, L2: 0.0060722241178154945, L3: 0.9621592164039612, L4: 52.148651123046875, L5: 0.19522331655025482
Epoch 9000, Loss: 31.130657196044922, Losses: L1: 2.9338667392730713, L2: 0.006083138287067413, L3: 0.9621644020080566, L4: 52.14839172363281, L5: 0.19522510468959808
Epoch 9500, Loss: 31.130434036254883, Losses: L1: 2.9336917400360107, L2: 0.006090935319662094, L3: 0.9621668457984924, L4: 52.14827346801758, L5: 0.19522662460803986
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0354957580566406, Constraint losses: L1: 18.42068099975586, L2: 0.005690925754606724, L3: 1.0056909322738647, L4: 1.0056930780410767
Epoch 500, Loss: 0.0023684229236096144, Constraint losses: L1: -1.1123476028442383, L2: 0.0, L3: 0.0027394890785217285, L4: 0.0007412814884446561
Epoch 1000, Loss: 0.0013676530215889215, Constraint losses: L1: -1.1181817054748535, L2: 0.0, L3: 0.002242565155029297, L4: 0.00024326963466592133
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0217976570129395, Constraint losses: L1: 18.42068099975586, L2: 0.0011271742405369878, L3: 1.0011249780654907, L4: 1.0011248588562012
Epoch 500, Loss: 0.00244672573171556, Constraint losses: L1: -0.987447202205658, L2: 0.0, L3: 0.0027160048484802246, L4: 0.0007181680994108319
Epoch 1000, Loss: 0.001373120117932558, Constraint losses: L1: -1.0686625242233276, L2: 0.0, L3: 0.0022205710411071777, L4: 0.0002212116523878649
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 60.26756286621094, Losses: L1: 18.42068099975586, L2: 0.004490782041102648, L3: 1.0044907331466675, L4: 78.18467712402344, L5: 0.3716581463813782
Epoch 500, Loss: 3.0077531337738037, Losses: L1: 0.8449639678001404, L2: 0.3526056110858917, L3: 0.1402643918991089, L4: 3.284623622894287, L5: 0.031822800636291504
Epoch 1000, Loss: 33.22212219238281, Losses: L1: 5.59311056137085, L2: 0.004076113924384117, L3: 0.9958066940307617, L4: 50.535099029541016, L5: 0.1839039921760559
Epoch 1500, Loss: 35.99472427368164, Losses: L1: 8.602148056030273, L2: 7.335865692681409e-09, L3: 0.9995333552360535, L4: 50.015377044677734, L5: 0.192911297082901
Epoch 2000, Loss: 45.80244827270508, Losses: L1: 18.4111385345459, L2: 7.09536856352555e-12, L3: 1.0, L4: 50.001956939697266, L5: 0.1951661854982376
Epoch 2500, Loss: 45.666080474853516, Losses: L1: 18.274778366088867, L2: 6.276696523643821e-11, L3: 1.0, L4: 50.00187301635742, L5: 0.19518353044986725
Epoch 3000, Loss: 36.24629211425781, Losses: L1: 8.877212524414062, L2: 0.001015645102597773, L3: 0.9996024370193481, L4: 49.964298248291016, L5: 0.19361013174057007
Epoch 3500, Loss: 33.62506103515625, Losses: L1: 6.440633773803711, L2: 0.009358471259474754, L3: 0.9942871928215027, L4: 49.657257080078125, L5: 0.1812731921672821
Epoch 4000, Loss: 31.99204444885254, Losses: L1: 6.12584114074707, L2: 0.11540310084819794, L3: 0.9969068169593811, L4: 46.973045349121094, L5: 0.16408228874206543
Epoch 4500, Loss: 30.062530517578125, Losses: L1: 5.7843780517578125, L2: 0.25269100069999695, L3: 1.0103750228881836, L4: 43.46271514892578, L5: 0.1998499184846878
Epoch 5000, Loss: 29.479402542114258, Losses: L1: 6.32735013961792, L2: 0.2658688724040985, L3: 1.0104397535324097, L4: 41.16912078857422, L5: 0.20683957636356354
Epoch 5500, Loss: 29.027034759521484, Losses: L1: 6.111267566680908, L2: 0.2881936728954315, L3: 1.0127719640731812, L4: 40.64539337158203, L5: 0.2117147147655487
Epoch 6000, Loss: 28.906383514404297, Losses: L1: 6.085679054260254, L2: 0.30112817883491516, L3: 1.012127161026001, L4: 40.44254684448242, L5: 0.21230585873126984
Epoch 6500, Loss: 28.829833984375, Losses: L1: 6.073018550872803, L2: 0.30763813853263855, L3: 1.0116719007492065, L4: 40.31230926513672, L5: 0.21174892783164978
Epoch 7000, Loss: 28.77907943725586, Losses: L1: 6.064279556274414, L2: 0.3123253583908081, L3: 1.0113799571990967, L4: 40.22615051269531, L5: 0.21140050888061523
Epoch 7500, Loss: 28.744937896728516, Losses: L1: 6.057802200317383, L2: 0.3159801661968231, L3: 1.0111901760101318, L4: 40.16788864135742, L5: 0.21141088008880615
Epoch 8000, Loss: 28.722782135009766, Losses: L1: 6.0507378578186035, L2: 0.3185301423072815, L3: 1.0111101865768433, L4: 40.135108947753906, L5: 0.21150197088718414
Epoch 8500, Loss: 28.707622528076172, Losses: L1: 6.045207500457764, L2: 0.32052016258239746, L3: 1.011049747467041, L4: 40.113677978515625, L5: 0.21160787343978882
Epoch 9000, Loss: 28.69737434387207, Losses: L1: 6.041311740875244, L2: 0.3219969570636749, L3: 1.0110108852386475, L4: 40.09929656982422, L5: 0.2116978019475937
Epoch 9500, Loss: 28.690549850463867, Losses: L1: 6.038640022277832, L2: 0.3230258822441101, L3: 1.0109837055206299, L4: 40.08985137939453, L5: 0.2117517590522766
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.007657527923584, Constraint losses: L1: 8.168990135192871, L2: 0.0, L3: 0.9997442364692688, L4: 0.999744176864624
Epoch 500, Loss: 0.0027958224527537823, Constraint losses: L1: -0.9869322180747986, L2: 0.0, L3: 0.0028901100158691406, L4: 0.0008926446316763759
Epoch 1000, Loss: 0.0014165353495627642, Constraint losses: L1: -1.1169607639312744, L2: 0.0, L3: 0.0022662878036499023, L4: 0.0002672082919161767
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.007638931274414, Constraint losses: L1: 8.298073768615723, L2: 0.0, L3: 0.9996703267097473, L4: 0.9996705651283264
Epoch 500, Loss: 0.0023501142859458923, Constraint losses: L1: -1.022336721420288, L2: 0.0, L3: 0.0026853084564208984, L4: 0.000687142601236701
Epoch 1000, Loss: 0.0013630634639412165, Constraint losses: L1: -1.0691595077514648, L2: 0.0, L3: 0.002215862274169922, L4: 0.00021636081510223448
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 90.30609130859375, Losses: L1: 16.85418128967285, L2: 0.0005245148204267025, L3: 1.0005056858062744, L4: 71.2935791015625, L5: 0.3141191005706787
Epoch 500, Loss: 14.354649543762207, Losses: L1: 6.628108501434326, L2: 1.2167680263519287, L3: 0.20096033811569214, L4: 6.660144329071045, L5: 0.11218427121639252
Epoch 1000, Loss: 28.206539154052734, Losses: L1: 7.539533615112305, L2: 0.7641785144805908, L3: 0.3126354217529297, L4: 19.619922637939453, L5: 0.0794449895620346
Epoch 1500, Loss: 16.080480575561523, Losses: L1: 3.0561888217926025, L2: 0.4818170666694641, L3: 0.369343638420105, L4: 12.016786575317383, L5: 0.0558197982609272
Epoch 2000, Loss: 1.7575571537017822, Losses: L1: 0.15918280184268951, L2: 0.11719655245542526, L3: 0.09334522485733032, L4: 1.346482515335083, L5: 0.01320631057024002
Epoch 2500, Loss: 0.9269875288009644, Losses: L1: 0.006095713935792446, L2: 0.08474115282297134, L3: 0.0868837833404541, L4: 0.700188934803009, L5: 0.009129474870860577
Epoch 3000, Loss: 1.5579636096954346, Losses: L1: -0.19463057816028595, L2: 0.14426690340042114, L3: 0.07684791088104248, L4: 1.5212633609771729, L5: 0.011002915911376476
Epoch 3500, Loss: 0.4700210392475128, Losses: L1: -0.2097119241952896, L2: 0.06508269160985947, L3: 0.08648824691772461, L4: 0.47027653455734253, L5: 0.007877194322645664
Epoch 4000, Loss: 0.4377997815608978, Losses: L1: -0.20615430176258087, L2: 0.06218770518898964, L3: 0.0853121280670166, L4: 0.4382599890232086, L5: 0.007951951585710049
Epoch 4500, Loss: 0.4259141981601715, Losses: L1: -0.20761585235595703, L2: 0.061380431056022644, L3: 0.08417761325836182, L4: 0.4305065870285034, L5: 0.007956002838909626
Epoch 5000, Loss: 0.40661534667015076, Losses: L1: -0.2081177830696106, L2: 0.06076907739043236, L3: 0.0833139419555664, L4: 0.4137239158153534, L5: 0.007993591018021107
Epoch 5500, Loss: 0.3992254436016083, Losses: L1: -0.20849230885505676, L2: 0.06026587262749672, L3: 0.08266925811767578, L4: 0.4082410931587219, L5: 0.008010419085621834
Epoch 6000, Loss: 0.3930676579475403, Losses: L1: -0.20897330343723297, L2: 0.059901781380176544, L3: 0.08228397369384766, L4: 0.4035109877586365, L5: 0.008022320456802845
Epoch 6500, Loss: 0.38782650232315063, Losses: L1: -0.2088291347026825, L2: 0.05959048494696617, L3: 0.08189499378204346, L4: 0.3990633487701416, L5: 0.008014108054339886
Epoch 7000, Loss: 0.38437506556510925, Losses: L1: -0.2093787044286728, L2: 0.05949420481920242, L3: 0.08163619041442871, L4: 0.39672404527664185, L5: 0.008020458742976189
Epoch 7500, Loss: 0.38172951340675354, Losses: L1: -0.20920026302337646, L2: 0.05931920185685158, L3: 0.08143627643585205, L4: 0.39438146352767944, L5: 0.008032294921576977
Epoch 8000, Loss: 0.37986865639686584, Losses: L1: -0.20956885814666748, L2: 0.05931739881634712, L3: 0.08126300573348999, L4: 0.3932349681854248, L5: 0.008035633713006973
Epoch 8500, Loss: 0.3785024881362915, Losses: L1: -0.20951099693775177, L2: 0.05925338715314865, L3: 0.08115315437316895, L4: 0.39206093549728394, L5: 0.008039118722081184
Epoch 9000, Loss: 0.3775230050086975, Losses: L1: -0.20948228240013123, L2: 0.05921893194317818, L3: 0.08106815814971924, L4: 0.3912387192249298, L5: 0.00804155133664608
Epoch 9500, Loss: 0.37679022550582886, Losses: L1: -0.20952290296554565, L2: 0.05920448899269104, L3: 0.08101475238800049, L4: 0.390658974647522, L5: 0.008044855669140816
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.003204345703125, Constraint losses: L1: 6.394812107086182, L2: 0.0, L3: 0.9984049797058105, L4: 0.9984046220779419
Epoch 500, Loss: 0.0022412382531911135, Constraint losses: L1: -1.0139340162277222, L2: 0.0, L3: 0.0026265382766723633, L4: 0.0006286339485086501
Epoch 1000, Loss: 0.0012531316606327891, Constraint losses: L1: -1.116295576095581, L2: 0.0, L3: 0.0021843910217285156, L4: 0.00018503623141441494
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005277395248413, Constraint losses: L1: 7.1322407722473145, L2: 0.0, L3: 0.9990723729133606, L4: 0.9990727305412292
Epoch 500, Loss: 0.002350524067878723, Constraint losses: L1: -1.0186433792114258, L2: 0.0, L3: 0.0026834607124328613, L4: 0.0006857068510726094
Epoch 1000, Loss: 0.001371500315144658, Constraint losses: L1: -1.0674409866333008, L2: 0.0, L3: 0.0022192001342773438, L4: 0.00021974125411361456
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 74.08541870117188, Losses: L1: 4.885035037994385, L2: 0.0, L3: 0.9923844933509827, L4: 66.93757629394531, L5: 0.2780410051345825
Epoch 500, Loss: 6.012323379516602, Losses: L1: 3.8270609378814697, L2: 0.4324592649936676, L3: 0.07039189338684082, L4: 1.8046092987060547, L5: 0.023639662191271782
Epoch 1000, Loss: 3.3781282901763916, Losses: L1: -0.1892772614955902, L2: 0.09743206202983856, L3: 0.06064021587371826, L4: 3.3759782314300537, L5: 0.02143079601228237
Epoch 1500, Loss: 0.7052850723266602, Losses: L1: -0.15189199149608612, L2: 0.09528987109661102, L3: 0.05347645282745361, L4: 0.6956843733787537, L5: 0.00689483480527997
Epoch 2000, Loss: 2.812777042388916, Losses: L1: 0.630122721195221, L2: 0.12995445728302002, L3: 0.052562057971954346, L4: 1.9992772340774536, L5: 0.01327557023614645
Epoch 2500, Loss: 1.1947922706604004, Losses: L1: -0.19313980638980865, L2: 0.05397072434425354, L3: 0.05021047592163086, L4: 1.2529714107513428, L5: 0.007554234936833382
Epoch 3000, Loss: 0.08571387082338333, Losses: L1: -0.2785685658454895, L2: 0.03521035611629486, L3: 0.049143195152282715, L4: 0.24203772842884064, L5: 0.006353133358061314
Epoch 3500, Loss: 0.23467783629894257, Losses: L1: -0.28196534514427185, L2: 0.03528771921992302, L3: 0.04869687557220459, L4: 0.3947107195854187, L5: 0.006894840858876705
Epoch 4000, Loss: -0.028401147574186325, Losses: L1: -0.28315645456314087, L2: 0.031919583678245544, L3: 0.04814410209655762, L4: 0.1364838182926178, L5: 0.006023484747856855
Epoch 4500, Loss: -0.016552722081542015, Losses: L1: -0.28554609417915344, L2: 0.03226642683148384, L3: 0.0479130744934082, L4: 0.15100745856761932, L5: 0.006026545539498329
Epoch 5000, Loss: -0.057008128613233566, Losses: L1: -0.2850096523761749, L2: 0.031383007764816284, L3: 0.04769259691238403, L4: 0.11087294667959213, L5: 0.006051893346011639
Epoch 5500, Loss: -0.061471596360206604, Losses: L1: -0.2851637303829193, L2: 0.03124137781560421, L3: 0.04751676321029663, L4: 0.10699505358934402, L5: 0.006042875349521637
Epoch 6000, Loss: -0.06474772840738297, Losses: L1: -0.2853017747402191, L2: 0.03101276233792305, L3: 0.04741787910461426, L4: 0.10414670407772064, L5: 0.006065200082957745
Epoch 6500, Loss: -0.06649258732795715, Losses: L1: -0.28550660610198975, L2: 0.030937135219573975, L3: 0.04731959104537964, L4: 0.10284246504306793, L5: 0.006063800770789385
Epoch 7000, Loss: -0.06749864667654037, Losses: L1: -0.28562986850738525, L2: 0.03084597736597061, L3: 0.04725801944732666, L4: 0.10212483257055283, L5: 0.006067347712814808
Epoch 7500, Loss: -0.06827282905578613, Losses: L1: -0.28573134541511536, L2: 0.030788885429501534, L3: 0.04721057415008545, L4: 0.1015729010105133, L5: 0.006070017348974943
Epoch 8000, Loss: -0.06883745640516281, Losses: L1: -0.28584015369415283, L2: 0.030740171670913696, L3: 0.047168076038360596, L4: 0.10122555494308472, L5: 0.006070917472243309
Epoch 8500, Loss: -0.06917308270931244, Losses: L1: -0.2858918309211731, L2: 0.030694518238306046, L3: 0.04714357852935791, L4: 0.10101160407066345, L5: 0.006072711665183306
Epoch 9000, Loss: -0.06950633227825165, Losses: L1: -0.2859466075897217, L2: 0.03067919798195362, L3: 0.04712212085723877, L4: 0.10078419744968414, L5: 0.006072220392525196
Epoch 9500, Loss: -0.06971322745084763, Losses: L1: -0.2859855592250824, L2: 0.030666619539260864, L3: 0.04710853099822998, L4: 0.10064894706010818, L5: 0.0060729957185685635
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.019627809524536, Constraint losses: L1: 18.42068099975586, L2: 0.0004023674118798226, L3: 1.0004023313522339, L4: 1.0004024505615234
Epoch 500, Loss: 0.002014163415879011, Constraint losses: L1: -1.1079492568969727, L2: 0.0, L3: 0.0025603771209716797, L4: 0.0005617354763671756
Epoch 1000, Loss: 0.0012431151699274778, Constraint losses: L1: -1.1165902614593506, L2: 0.0, L3: 0.0021796226501464844, L4: 0.000180082832230255
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0077147483825684, Constraint losses: L1: 8.235231399536133, L2: 1.6748033885960467e-05, L3: 0.9997313618659973, L4: 0.9997314214706421
Epoch 500, Loss: 0.0025799705181270838, Constraint losses: L1: -1.033078670501709, L2: 0.0, L3: 0.002805471420288086, L4: 0.0008075778605416417
Epoch 1000, Loss: 0.0014526082668453455, Constraint losses: L1: -1.0713481903076172, L2: 0.0, L3: 0.0022616982460021973, L4: 0.00026225828332826495
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 80.85440063476562, Losses: L1: 5.5249199867248535, L2: 0.0, L3: 0.9960196614265442, L4: 72.68672180175781, L5: 0.3253609240055084
Epoch 500, Loss: 3.1256282329559326, Losses: L1: 0.328701913356781, L2: 0.07349139451980591, L3: 0.10155940055847168, L4: 2.533337116241455, L5: 0.011862386018037796
Epoch 1000, Loss: 1.8295609951019287, Losses: L1: 0.007376919034868479, L2: 0.16163624823093414, L3: 0.07856839895248413, L4: 1.5531283617019653, L5: 0.015550381503999233
Epoch 1500, Loss: 1.6418100595474243, Losses: L1: -0.24105529487133026, L2: 0.10028835386037827, L3: 0.05718028545379639, L4: 1.6984084844589233, L5: 0.009976060129702091
Epoch 2000, Loss: 0.7932624220848083, Losses: L1: -0.22360171377658844, L2: 0.09542247653007507, L3: 0.06331980228424072, L4: 0.8309417963027954, L5: 0.005785738117992878
Epoch 2500, Loss: 0.7604745030403137, Losses: L1: -0.25349700450897217, L2: 0.06317276507616043, L3: 0.05660116672515869, L4: 0.8537999391555786, L5: 0.007691419683396816
Epoch 3000, Loss: 0.6133646965026855, Losses: L1: -0.273154079914093, L2: 0.0776042714715004, L3: 0.08215099573135376, L4: 0.6724570393562317, L5: 0.005478802137076855
Epoch 3500, Loss: 0.366468220949173, Losses: L1: -0.27242690324783325, L2: 0.0654655247926712, L3: 0.07547533512115479, L4: 0.4445595145225525, L5: 0.005326090846210718
Epoch 4000, Loss: 0.39786428213119507, Losses: L1: -0.2742249071598053, L2: 0.06156926229596138, L3: 0.07152938842773438, L4: 0.486968994140625, L5: 0.0056383912451565266
Epoch 4500, Loss: 0.23901166021823883, Losses: L1: -0.27069225907325745, L2: 0.05604362487792969, L3: 0.07008326053619385, L4: 0.3307937979698181, L5: 0.0053608957678079605
Epoch 5000, Loss: 0.21859195828437805, Losses: L1: -0.270825058221817, L2: 0.05403783917427063, L3: 0.06880885362625122, L4: 0.3139705955982208, L5: 0.005404900759458542
Epoch 5500, Loss: 0.2057848423719406, Losses: L1: -0.27154645323753357, L2: 0.052882127463817596, L3: 0.06794154644012451, L4: 0.3042745292186737, L5: 0.005366302561014891
Epoch 6000, Loss: 0.19716417789459229, Losses: L1: -0.27199235558509827, L2: 0.051900096237659454, L3: 0.06736493110656738, L4: 0.2977733016014099, L5: 0.005351664964109659
Epoch 6500, Loss: 0.19091790914535522, Losses: L1: -0.27243104577064514, L2: 0.05127967521548271, L3: 0.06690394878387451, L4: 0.2932415306568146, L5: 0.0053298454731702805
Epoch 7000, Loss: 0.18671013414859772, Losses: L1: -0.27282553911209106, L2: 0.050974201411008835, L3: 0.06652259826660156, L4: 0.29037755727767944, L5: 0.005312912631779909
Epoch 7500, Loss: 0.1830371916294098, Losses: L1: -0.2730841636657715, L2: 0.050797849893569946, L3: 0.06621038913726807, L4: 0.28769248723983765, L5: 0.005304581485688686
Epoch 8000, Loss: 0.18054381012916565, Losses: L1: -0.2732645869255066, L2: 0.050687044858932495, L3: 0.06597894430160522, L4: 0.2859084904193878, L5: 0.0052992478013038635
Epoch 8500, Loss: 0.17868657410144806, Losses: L1: -0.27340686321258545, L2: 0.05061288923025131, L3: 0.06579810380935669, L4: 0.28460708260536194, L5: 0.005291847046464682
Epoch 9000, Loss: 0.17727868258953094, Losses: L1: -0.273481160402298, L2: 0.05054287612438202, L3: 0.06566810607910156, L4: 0.2835792601108551, L5: 0.005286459811031818
Epoch 9500, Loss: 0.17628030478954315, Losses: L1: -0.27353131771087646, L2: 0.05048849806189537, L3: 0.06557571887969971, L4: 0.282848596572876, L5: 0.005283670034259558
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0221827030181885, Constraint losses: L1: 18.42068099975586, L2: 0.0012538931332528591, L3: 1.0012538433074951, L4: 1.0012543201446533
Epoch 500, Loss: 0.0021720989607274532, Constraint losses: L1: -1.1068230867385864, L2: 0.0, L3: 0.002638697624206543, L4: 0.0006402244325727224
Epoch 1000, Loss: 0.0013040307676419616, Constraint losses: L1: -1.1188149452209473, L2: 0.0, L3: 0.0022112131118774414, L4: 0.0002116326941177249
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0186502933502197, Constraint losses: L1: 18.42068099975586, L2: 7.659416587557644e-05, L3: 1.0000766515731812, L4: 1.000076413154602
Epoch 500, Loss: 0.0024036304093897343, Constraint losses: L1: -1.030631422996521, L2: 0.0, L3: 0.0027161240577697754, L4: 0.0007181378896348178
Epoch 1000, Loss: 0.0013852103147655725, Constraint losses: L1: -1.071362853050232, L2: 0.0, L3: 0.002227962017059326, L4: 0.00022861121396999806
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 179.8467559814453, Losses: L1: 18.42068099975586, L2: 0.016588330268859863, L3: 1.0165883302688599, L4: 79.59557342529297, L5: 0.38690975308418274
Epoch 500, Loss: 4.43820333480835, Losses: L1: 1.210999608039856, L2: 0.1887313723564148, L3: 0.09084546566009521, L4: 1.4697699546813965, L5: 0.02321428805589676
Epoch 1000, Loss: 2.7881624698638916, Losses: L1: -0.12573042511940002, L2: 0.12567327916622162, L3: 0.06498849391937256, L4: 1.3546932935714722, L5: 0.02338552102446556
Epoch 1500, Loss: 2.185039520263672, Losses: L1: -0.03788429871201515, L2: 0.08855321258306503, L3: 0.09000241756439209, L4: 0.9955532550811768, L5: 0.015071972273290157
Epoch 2000, Loss: 10.181572914123535, Losses: L1: 1.6535700559616089, L2: 1.0308088064193726, L3: 0.28739655017852783, L4: 3.707383155822754, L5: 0.04607759416103363
Epoch 2500, Loss: 4.136298656463623, Losses: L1: 1.4664876461029053, L2: 0.6979631185531616, L3: 0.12493836879730225, L4: 1.021334171295166, L5: 0.05656905472278595
Epoch 3000, Loss: 3.432440757751465, Losses: L1: 1.48776113986969, L2: 0.6072474718093872, L3: 0.11159253120422363, L4: 0.6955875158309937, L5: 0.053391601890325546
Epoch 3500, Loss: 3.1493327617645264, Losses: L1: 1.4399546384811401, L2: 0.5357474684715271, L3: 0.10406529903411865, L4: 0.6044809222221375, L5: 0.04882381483912468
Epoch 4000, Loss: 2.9409072399139404, Losses: L1: 1.2762190103530884, L2: 0.49600160121917725, L3: 0.10216009616851807, L4: 0.5943666100502014, L5: 0.047268304973840714
Epoch 4500, Loss: 2.8117761611938477, Losses: L1: 1.2486435174942017, L2: 0.46202006936073303, L3: 0.09773707389831543, L4: 0.5567845106124878, L5: 0.046158842742443085
Epoch 5000, Loss: 2.7287566661834717, Losses: L1: 1.2136367559432983, L2: 0.4397083818912506, L3: 0.09576737880706787, L4: 0.5405781865119934, L5: 0.04514941945672035
Epoch 5500, Loss: 2.6568946838378906, Losses: L1: 1.1736090183258057, L2: 0.4228576123714447, L3: 0.09433555603027344, L4: 0.5305179357528687, L5: 0.04430001601576805
Epoch 6000, Loss: 2.591038465499878, Losses: L1: 1.13679838180542, L2: 0.40964311361312866, L3: 0.09295511245727539, L4: 0.5208189487457275, L5: 0.04374083876609802
Epoch 6500, Loss: 2.54599928855896, Losses: L1: 1.1199463605880737, L2: 0.39979037642478943, L3: 0.09179389476776123, L4: 0.5104825496673584, L5: 0.04320932552218437
Epoch 7000, Loss: 2.476245641708374, Losses: L1: 1.1067769527435303, L2: 0.3903278708457947, L3: 0.0900692343711853, L4: 0.48635196685791016, L5: 0.04292422533035278
Epoch 7500, Loss: 2.4090702533721924, Losses: L1: 1.0930060148239136, L2: 0.3836159110069275, L3: 0.08838200569152832, L4: 0.46307867765426636, L5: 0.04266999289393425
Epoch 8000, Loss: 2.3742833137512207, Losses: L1: 1.0757734775543213, L2: 0.37952062487602234, L3: 0.08780884742736816, L4: 0.45598918199539185, L5: 0.04230709746479988
Epoch 8500, Loss: 2.3548591136932373, Losses: L1: 1.0652304887771606, L2: 0.3754499852657318, L3: 0.08746147155761719, L4: 0.4529653787612915, L5: 0.04210009425878525
Epoch 9000, Loss: 2.341756820678711, Losses: L1: 1.0578252077102661, L2: 0.37254536151885986, L3: 0.08725273609161377, L4: 0.4510926604270935, L5: 0.04193602502346039
Epoch 9500, Loss: 2.333202362060547, Losses: L1: 1.0535533428192139, L2: 0.37039291858673096, L3: 0.0870664119720459, L4: 0.44970300793647766, L5: 0.04182753339409828
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0231547355651855, Constraint losses: L1: 18.42068099975586, L2: 0.0015780365793034434, L3: 1.0015780925750732, L4: 1.0015778541564941
Epoch 500, Loss: 0.0022678235545754433, Constraint losses: L1: -1.0830556154251099, L2: 0.0, L3: 0.0026745200157165527, L4: 0.000676359049975872
Epoch 1000, Loss: 0.001315892906859517, Constraint losses: L1: -1.1183874607086182, L2: 0.0, L3: 0.0022168755531311035, L4: 0.00021740490046795458
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0326743125915527, Constraint losses: L1: 18.42068099975586, L2: 0.004751075059175491, L3: 1.0047510862350464, L4: 1.0047515630722046
Epoch 500, Loss: 0.002696692943572998, Constraint losses: L1: -1.0251802206039429, L2: 0.0, L3: 0.0028597116470336914, L4: 0.0008621614542789757
Epoch 1000, Loss: 0.0014667925424873829, Constraint losses: L1: -1.0711619853973389, L2: 0.0, L3: 0.0022686123847961426, L4: 0.00026934227207675576
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 154.14859008789062, Losses: L1: 11.476272583007812, L2: 4.526664997683838e-05, L3: 0.9997640252113342, L4: 70.1799087524414, L5: 0.3129402697086334
Epoch 500, Loss: 6.9968671798706055, Losses: L1: 0.019848046824336052, L2: 0.13386626541614532, L3: 0.06754761934280396, L4: 3.373589277267456, L5: 0.027812207117676735
Epoch 1000, Loss: 1.9487988948822021, Losses: L1: -0.1828615367412567, L2: 0.11009448021650314, L3: 0.061149775981903076, L4: 0.9726366996765137, L5: 0.00904028583317995
Epoch 1500, Loss: 1.0113162994384766, Losses: L1: -0.13502076268196106, L2: 0.11321285367012024, L3: 0.05754709243774414, L4: 0.48333480954170227, L5: 0.007966899313032627
Epoch 2000, Loss: 1.5615410804748535, Losses: L1: -0.1586136519908905, L2: 0.06387859582901001, L3: 0.0513228178024292, L4: 0.7896149754524231, L5: 0.006339819636195898
Epoch 2500, Loss: 1.8945785760879517, Losses: L1: -0.23211535811424255, L2: 0.05440158396959305, L3: 0.04708826541900635, L4: 0.9971876740455627, L5: 0.010941240936517715
Epoch 3000, Loss: 0.2959520220756531, Losses: L1: -0.2544861435890198, L2: 0.03505518659949303, L3: 0.04775810241699219, L4: 0.21583940088748932, L5: 0.005715538281947374
Epoch 3500, Loss: 0.4143890142440796, Losses: L1: -0.2545628547668457, L2: 0.03016076050698757, L3: 0.047682762145996094, L4: 0.27640703320503235, L5: 0.005691878963261843
Epoch 4000, Loss: 0.27074968814849854, Losses: L1: -0.26066911220550537, L2: 0.031243352219462395, L3: 0.04756051301956177, L4: 0.2072540819644928, L5: 0.006167960353195667
Epoch 4500, Loss: 0.05463409051299095, Losses: L1: -0.25825679302215576, L2: 0.029283571988344193, L3: 0.0472947359085083, L4: 0.09902284294366837, L5: 0.005613935645669699
Epoch 5000, Loss: 0.044279880821704865, Losses: L1: -0.2600177824497223, L2: 0.02937213145196438, L3: 0.047190070152282715, L4: 0.09480347484350204, L5: 0.00562451034784317
Epoch 5500, Loss: 0.03640567138791084, Losses: L1: -0.26118335127830505, L2: 0.02927863970398903, L3: 0.04708099365234375, L4: 0.09160451591014862, L5: 0.005578684154897928
Epoch 6000, Loss: 0.032501112669706345, Losses: L1: -0.2621474266052246, L2: 0.029148852452635765, L3: 0.04702925682067871, L4: 0.0902259573340416, L5: 0.005563687067478895
Epoch 6500, Loss: 0.02980995923280716, Losses: L1: -0.26278093457221985, L2: 0.029120342805981636, L3: 0.04697698354721069, L4: 0.0892622247338295, L5: 0.005552298855036497
Epoch 7000, Loss: 0.026957908645272255, Losses: L1: -0.26323243975639343, L2: 0.028974128887057304, L3: 0.04694777727127075, L4: 0.08812695741653442, L5: 0.005553821567445993
Epoch 7500, Loss: 0.02531520277261734, Losses: L1: -0.2635527551174164, L2: 0.02893591858446598, L3: 0.04691249132156372, L4: 0.08751211315393448, L5: 0.005550794769078493
Epoch 8000, Loss: 0.0240629892796278, Losses: L1: -0.2638343572616577, L2: 0.028905071318149567, L3: 0.04688894748687744, L4: 0.08706071972846985, L5: 0.00554548017680645
Epoch 8500, Loss: 0.023208238184452057, Losses: L1: -0.26402467489242554, L2: 0.02887784317135811, L3: 0.04686760902404785, L4: 0.08675912022590637, L5: 0.00554052647203207
Epoch 9000, Loss: 0.022542130202054977, Losses: L1: -0.2641541063785553, L2: 0.02885027974843979, L3: 0.04685473442077637, L4: 0.08651119470596313, L5: 0.0055392347276210785
Epoch 9500, Loss: 0.022097831591963768, Losses: L1: -0.2642398774623871, L2: 0.02883160300552845, L3: 0.0468447208404541, L4: 0.08634762465953827, L5: 0.005537217482924461
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.022174119949341, Constraint losses: L1: 18.42068099975586, L2: 0.001251158188097179, L3: 1.0012511014938354, L4: 1.001251220703125
Epoch 500, Loss: 0.002384509425610304, Constraint losses: L1: -1.0952184200286865, L2: 0.0, L3: 0.0027388930320739746, L4: 0.0007408348028548062
Epoch 1000, Loss: 0.0013690217165276408, Constraint losses: L1: -1.118302822113037, L2: 0.0, L3: 0.002243340015411377, L4: 0.00024398459936492145
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0073535442352295, Constraint losses: L1: 8.168597221374512, L2: 0.00010019994078902528, L3: 0.9995423555374146, L4: 0.9995424151420593
Epoch 500, Loss: 0.002360787708312273, Constraint losses: L1: -1.058724284172058, L2: 0.0, L3: 0.0027087926864624023, L4: 0.0007107192650437355
Epoch 1000, Loss: 0.0013913982547819614, Constraint losses: L1: -1.0713645219802856, L2: 0.0, L3: 0.0022310614585876465, L4: 0.0002317013859283179
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 142.1190643310547, Losses: L1: 11.410526275634766, L2: 0.0006512373220175505, L3: 0.9994932413101196, L4: 64.0865707397461, L5: 0.26804035902023315
Epoch 500, Loss: 10.136005401611328, Losses: L1: 0.555995523929596, L2: 0.15851633250713348, L3: 0.07206284999847412, L4: 4.6438117027282715, L5: 0.034501172602176666
Epoch 1000, Loss: 2.7707746028900146, Losses: L1: -0.18236738443374634, L2: 0.09176371991634369, L3: 0.05700254440307617, L4: 1.3876019716262817, L5: 0.009025545790791512
Epoch 1500, Loss: 1.017799735069275, Losses: L1: -0.06865926086902618, L2: 0.04886887967586517, L3: 0.054865479469299316, L4: 0.47068047523498535, L5: 0.005466342903673649
Epoch 2000, Loss: 1.2993558645248413, Losses: L1: -0.25059378147125244, L2: 0.03676993027329445, L3: 0.051858603954315186, L4: 0.708234429359436, L5: 0.005689344834536314
Epoch 2500, Loss: 0.24138398468494415, Losses: L1: -0.26934999227523804, L2: 0.04083053767681122, L3: 0.05021542310714722, L4: 0.18966464698314667, L5: 0.005279277916997671
Epoch 3000, Loss: 0.41850051283836365, Losses: L1: -0.2687513828277588, L2: 0.04138518497347832, L3: 0.04931819438934326, L4: 0.2781388759613037, L5: 0.005822583567351103
Epoch 3500, Loss: 0.08319129049777985, Losses: L1: -0.27350232005119324, L2: 0.03980390354990959, L3: 0.04919421672821045, L4: 0.1136595830321312, L5: 0.0055420235730707645
Epoch 4000, Loss: 0.07639104872941971, Losses: L1: -0.2741784155368805, L2: 0.03964568302035332, L3: 0.04879558086395264, L4: 0.11109393835067749, L5: 0.005483794026076794
Epoch 4500, Loss: 0.08615884929895401, Losses: L1: -0.27332741022109985, L2: 0.0386921726167202, L3: 0.04860961437225342, L4: 0.11624950170516968, L5: 0.0052109695971012115
Epoch 5000, Loss: 0.009328864514827728, Losses: L1: -0.2734338045120239, L2: 0.039216771721839905, L3: 0.04845023155212402, L4: 0.07781261205673218, L5: 0.005314301699399948
Epoch 5500, Loss: -0.0010097455233335495, Losses: L1: -0.27333924174308777, L2: 0.03930153697729111, L3: 0.04838383197784424, L4: 0.07265811413526535, L5: 0.005297423340380192
Epoch 6000, Loss: -0.003928535617887974, Losses: L1: -0.2735522389411926, L2: 0.03892495110630989, L3: 0.04835212230682373, L4: 0.07144668698310852, L5: 0.005281809251755476
Epoch 6500, Loss: -0.005691147409379482, Losses: L1: -0.2738628387451172, L2: 0.038743484765291214, L3: 0.048322439193725586, L4: 0.07078404724597931, L5: 0.00529348524287343
Epoch 7000, Loss: -0.008150621317327023, Losses: L1: -0.2740696966648102, L2: 0.03852611780166626, L3: 0.04830211400985718, L4: 0.069734588265419, L5: 0.00529130594804883
Epoch 7500, Loss: -0.008977961726486683, Losses: L1: -0.2743067443370819, L2: 0.038385968655347824, L3: 0.048285484313964844, L4: 0.06949043273925781, L5: 0.005291977431625128
Epoch 8000, Loss: -0.009704520925879478, Losses: L1: -0.27447742223739624, L2: 0.038279999047517776, L3: 0.04827713966369629, L4: 0.06924928724765778, L5: 0.005290021188557148
Epoch 8500, Loss: -0.010194456204771996, Losses: L1: -0.2745690941810608, L2: 0.038204941898584366, L3: 0.04827207326889038, L4: 0.0690736472606659, L5: 0.0052903564646840096
Epoch 9000, Loss: -0.010506750084459782, Losses: L1: -0.27463436126708984, L2: 0.038158267736434937, L3: 0.04826664924621582, L4: 0.06896831840276718, L5: 0.005289263557642698
Epoch 9500, Loss: -0.010738116689026356, Losses: L1: -0.27468422055244446, L2: 0.03812715411186218, L3: 0.04826325178146362, L4: 0.06889044493436813, L5: 0.005287574138492346
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9944772720336914, Constraint losses: L1: 5.213076591491699, L2: 0.0, L3: 0.9946322441101074, L4: 0.9946320056915283
Epoch 500, Loss: 0.001961912726983428, Constraint losses: L1: -1.08878493309021, L2: 0.0, L3: 0.0025244951248168945, L4: 0.0005262026097625494
Epoch 1000, Loss: 0.0012103596236556768, Constraint losses: L1: -1.1169304847717285, L2: 0.0, L3: 0.0021633505821228027, L4: 0.00016393950500059873
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0045130252838135, Constraint losses: L1: 6.77732515335083, L2: 0.0, L3: 0.9988678693771362, L4: 0.9988678097724915
Epoch 500, Loss: 0.0024932115338742733, Constraint losses: L1: -0.9017869234085083, L2: 0.0, L3: 0.002696216106414795, L4: 0.0006987825036048889
Epoch 1000, Loss: 0.001330187893472612, Constraint losses: L1: -1.0695403814315796, L2: 0.0, L3: 0.0021994709968566895, L4: 0.00020025725825689733
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 44.687828063964844, Losses: L1: 5.2930755615234375, L2: 0.0, L3: 0.9947593212127686, L4: 77.43180847167969, L5: 0.36293497681617737
Epoch 500, Loss: 3.5616931915283203, Losses: L1: 0.16509239375591278, L2: 0.3128035068511963, L3: 0.08345979452133179, L4: 6.060524940490723, L5: 0.023610051721334457
Epoch 1000, Loss: 34.2590217590332, Losses: L1: 11.872624397277832, L2: 3.120126962661743, L3: 0.7808989882469177, L4: 37.46142578125, L5: 0.2902137041091919
Epoch 1500, Loss: 2.9453048706054688, Losses: L1: 0.1421561986207962, L2: 0.36292681097984314, L3: 0.2220144271850586, L4: 4.619539260864258, L5: 0.03888972848653793
Epoch 2000, Loss: 1.4257885217666626, Losses: L1: -0.05512085184454918, L2: 0.24437299370765686, L3: 0.149871826171875, L4: 2.2991557121276855, L5: 0.024045290425419807
Epoch 2500, Loss: 1.0346260070800781, Losses: L1: -0.0988018587231636, L2: 0.19698002934455872, L3: 0.1365964412689209, L4: 1.7109707593917847, L5: 0.025328408926725388
Epoch 3000, Loss: 0.8690898418426514, Losses: L1: -0.15757514536380768, L2: 0.16365163028240204, L3: 0.1335136890411377, L4: 1.5729156732559204, L5: 0.01959732361137867
Epoch 3500, Loss: 0.7975645065307617, Losses: L1: -0.1627172976732254, L2: 0.15207397937774658, L3: 0.1301819086074829, L4: 1.466646671295166, L5: 0.01958705484867096
Epoch 4000, Loss: 0.7573015093803406, Losses: L1: -0.16470955312252045, L2: 0.143931046128273, L3: 0.1294538378715515, L4: 1.407753348350525, L5: 0.018952900543808937
Epoch 4500, Loss: 0.7300238609313965, Losses: L1: -0.16738077998161316, L2: 0.13991692662239075, L3: 0.12866628170013428, L4: 1.3682407140731812, L5: 0.01806839369237423
Epoch 5000, Loss: 0.7119253277778625, Losses: L1: -0.16886837780475616, L2: 0.1370323747396469, L3: 0.12810564041137695, L4: 1.3417761325836182, L5: 0.01764095202088356
Epoch 5500, Loss: 0.6987525224685669, Losses: L1: -0.16920366883277893, L2: 0.1344621628522873, L3: 0.1277795433998108, L4: 1.3216602802276611, L5: 0.017548177391290665
Epoch 6000, Loss: 0.6894671320915222, Losses: L1: -0.16985031962394714, L2: 0.1330539584159851, L3: 0.1274251937866211, L4: 1.3077044486999512, L5: 0.017397243529558182
Epoch 6500, Loss: 0.6830589771270752, Losses: L1: -0.17077060043811798, L2: 0.13215310871601105, L3: 0.12723565101623535, L4: 1.2990317344665527, L5: 0.017085589468479156
Epoch 7000, Loss: 0.6775716543197632, Losses: L1: -0.17081515491008759, L2: 0.13117216527462006, L3: 0.12709075212478638, L4: 1.2902714014053345, L5: 0.017067190259695053
Epoch 7500, Loss: 0.6741770505905151, Losses: L1: -0.1709040254354477, L2: 0.13050377368927002, L3: 0.12700915336608887, L4: 1.2850691080093384, L5: 0.017076384276151657
Epoch 8000, Loss: 0.6713627576828003, Losses: L1: -0.1712327003479004, L2: 0.13019044697284698, L3: 0.12691032886505127, L4: 1.280928134918213, L5: 0.016971580684185028
Epoch 8500, Loss: 0.6694864630699158, Losses: L1: -0.17139887809753418, L2: 0.12995080649852753, L3: 0.12683510780334473, L4: 1.2780838012695312, L5: 0.016950087621808052
Epoch 9000, Loss: 0.6682014465332031, Losses: L1: -0.1714804768562317, L2: 0.1297619640827179, L3: 0.12678873538970947, L4: 1.2761156558990479, L5: 0.016935642808675766
Epoch 9500, Loss: 0.6673295497894287, Losses: L1: -0.1715305894613266, L2: 0.12962348759174347, L3: 0.12676513195037842, L4: 1.2747864723205566, L5: 0.01692170836031437
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.025631904602051, Constraint losses: L1: 18.42068099975586, L2: 0.0024036753457039595, L3: 1.0024036169052124, L4: 1.0024040937423706
Epoch 500, Loss: 0.0022280740085989237, Constraint losses: L1: -1.1166921854019165, L2: 0.0, L3: 0.002671658992767334, L4: 0.0006731072207912803
Epoch 1000, Loss: 0.0013306462205946445, Constraint losses: L1: -1.117911458015442, L2: 0.0, L3: 0.002223968505859375, L4: 0.00022458922467194498
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0270235538482666, Constraint losses: L1: 18.42068099975586, L2: 0.002867231611162424, L3: 1.0028672218322754, L4: 1.002868413925171
Epoch 500, Loss: 0.0022129961289465427, Constraint losses: L1: -1.0322134494781494, L2: 0.0, L3: 0.0026216506958007812, L4: 0.0006235589971765876
Epoch 1000, Loss: 0.0013224221765995026, Constraint losses: L1: -1.07057523727417, L2: 0.0, L3: 0.0021961331367492676, L4: 0.00019686433370225132
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 43.2147331237793, Losses: L1: 7.254943370819092, L2: 0.00011535108933458105, L3: 0.9987804889678955, L4: 70.30255126953125, L5: 0.3090078830718994
Epoch 500, Loss: 29.462749481201172, Losses: L1: 2.989838123321533, L2: 0.01053598802536726, L3: 0.9617944359779358, L4: 51.59107208251953, L5: 0.18594075739383698
Epoch 1000, Loss: 30.25197410583496, Losses: L1: 3.688307762145996, L2: 0.005626996513456106, L3: 0.9483567476272583, L4: 51.79143524169922, L5: 0.18814191222190857
Epoch 1500, Loss: 6.981754302978516, Losses: L1: 0.9767695665359497, L2: 0.5394091606140137, L3: 0.2237837314605713, L4: 10.594741821289062, L5: 0.05631241947412491
Epoch 2000, Loss: 2.211107015609741, Losses: L1: 0.08565764874219894, L2: 0.1398390829563141, L3: 0.17445921897888184, L4: 3.7604823112487793, L5: 0.01813950017094612
Epoch 2500, Loss: 3.9721593856811523, Losses: L1: 0.6367524862289429, L2: 0.1389353722333908, L3: 0.17644238471984863, L4: 6.14039945602417, L5: 0.03805064782500267
Epoch 3000, Loss: 1.3996281623840332, Losses: L1: 0.05928638204932213, L2: 0.0972197875380516, L3: 0.17229509353637695, L4: 2.2891721725463867, L5: 0.012388334609568119
Epoch 3500, Loss: 1.1913771629333496, Losses: L1: 0.027837753295898438, L2: 0.09412892907857895, L3: 0.16683954000473022, L4: 1.9459409713745117, L5: 0.013020250014960766
Epoch 4000, Loss: 1.1443653106689453, Losses: L1: 0.015912320464849472, L2: 0.09398562461137772, L3: 0.16443943977355957, L4: 1.879289150238037, L5: 0.01260307151824236
Epoch 4500, Loss: 1.1149892807006836, Losses: L1: 0.009728504344820976, L2: 0.09459097683429718, L3: 0.16224944591522217, L4: 1.833957552909851, L5: 0.012566285207867622
Epoch 5000, Loss: 1.0959612131118774, Losses: L1: 0.008478996343910694, L2: 0.09426836669445038, L3: 0.16138190031051636, L4: 1.7999955415725708, L5: 0.012525101192295551
Epoch 5500, Loss: 1.0807124376296997, Losses: L1: 0.0041720145381987095, L2: 0.09405111521482468, L3: 0.16014021635055542, L4: 1.7800319194793701, L5: 0.012403280474245548
Epoch 6000, Loss: 1.0707292556762695, Losses: L1: 0.0023967400193214417, L2: 0.09392382204532623, L3: 0.15938687324523926, L4: 1.764661431312561, L5: 0.012384496629238129
Epoch 6500, Loss: 1.0631611347198486, Losses: L1: 0.0017871781019493937, L2: 0.09364296495914459, L3: 0.15902841091156006, L4: 1.7518033981323242, L5: 0.012315009720623493
Epoch 7000, Loss: 1.0578469038009644, Losses: L1: 0.0013310890644788742, L2: 0.09353111684322357, L3: 0.15875613689422607, L4: 1.742628812789917, L5: 0.012292314320802689
Epoch 7500, Loss: 1.054024577140808, Losses: L1: 0.001079084468074143, L2: 0.0934101939201355, L3: 0.1585369110107422, L4: 1.7359875440597534, L5: 0.012273037806153297
Epoch 8000, Loss: 1.0511751174926758, Losses: L1: 0.0003961525217164308, L2: 0.09334386885166168, L3: 0.15830057859420776, L4: 1.73206627368927, L5: 0.012251589447259903
Epoch 8500, Loss: 1.0493762493133545, Losses: L1: 0.0003213300951756537, L2: 0.09325647354125977, L3: 0.1581815481185913, L4: 1.7289352416992188, L5: 0.012240099720656872
Epoch 9000, Loss: 1.0483015775680542, Losses: L1: 0.00020455934281926602, L2: 0.09330043941736221, L3: 0.15807998180389404, L4: 1.7269930839538574, L5: 0.012260076589882374
Epoch 9500, Loss: 1.0472842454910278, Losses: L1: 6.591987767023966e-05, L2: 0.09322536736726761, L3: 0.15802538394927979, L4: 1.7254772186279297, L5: 0.012241757474839687
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9993380308151245, Constraint losses: L1: 5.7003607749938965, L2: 0.0, L3: 0.9968191385269165, L4: 0.9968185424804688
Epoch 500, Loss: 0.0020031118765473366, Constraint losses: L1: -1.0959358215332031, L2: 0.0, L3: 0.0025487542152404785, L4: 0.0005502934218384326
Epoch 1000, Loss: 0.0012329756282269955, Constraint losses: L1: -1.1167877912521362, L2: 0.0, L3: 0.002174675464630127, L4: 0.00017508806195110083
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9983665943145752, Constraint losses: L1: 5.630905628204346, L2: 0.0, L3: 0.9963679313659668, L4: 0.9963678121566772
Epoch 500, Loss: 0.00244875717908144, Constraint losses: L1: -1.0424634218215942, L2: 0.0, L3: 0.0027445554733276367, L4: 0.0007466652896255255
Epoch 1000, Loss: 0.0014101606793701649, Constraint losses: L1: -1.0711578130722046, L2: 0.0, L3: 0.0022403597831726074, L4: 0.00024095881963148713
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 44.750038146972656, Losses: L1: 11.896081924438477, L2: 0.001177420956082642, L3: 0.9995959997177124, L4: 63.64216613769531, L5: 0.2659500539302826
Epoch 500, Loss: 1.9695608615875244, Losses: L1: 0.13236136734485626, L2: 0.18831473588943481, L3: 0.13484656810760498, L4: 3.0837831497192383, L5: 0.019784903153777122
Epoch 1000, Loss: 5.500128746032715, Losses: L1: 0.363298237323761, L2: 0.23576386272907257, L3: 0.21193981170654297, L4: 9.336213111877441, L5: 0.06349512189626694
Epoch 1500, Loss: 44.309364318847656, Losses: L1: 18.417707443237305, L2: 2.0195801975209093e-10, L3: 1.0, L4: 50.00048828125, L5: 0.19570626318454742
Epoch 2000, Loss: 44.31254959106445, Losses: L1: 18.42068099975586, L2: 4.8855988699081365e-12, L3: 1.0, L4: 50.002376556396484, L5: 0.19534100592136383
Epoch 2500, Loss: 44.31255340576172, Losses: L1: 18.42068099975586, L2: 4.28074979977322e-12, L3: 1.0, L4: 50.00238037109375, L5: 0.19534023106098175
Epoch 3000, Loss: 44.31254959106445, Losses: L1: 18.42068099975586, L2: 4.273957056322164e-12, L3: 1.0, L4: 50.002376556396484, L5: 0.19534100592136383
Epoch 3500, Loss: 44.31254959106445, Losses: L1: 18.42068099975586, L2: 4.2682381067027375e-12, L3: 1.0, L4: 50.00236892700195, L5: 0.19534164667129517
Epoch 4000, Loss: 44.31255340576172, Losses: L1: 18.42068099975586, L2: 4.264210512472388e-12, L3: 1.0, L4: 50.00236892700195, L5: 0.19534210860729218
Epoch 4500, Loss: 44.31254959106445, Losses: L1: 18.42068099975586, L2: 4.26077315790474e-12, L3: 1.0, L4: 50.00236511230469, L5: 0.19534249603748322
Epoch 5000, Loss: 44.31254959106445, Losses: L1: 18.42068099975586, L2: 4.258175409499465e-12, L3: 1.0, L4: 50.00236511230469, L5: 0.1953427940607071
Epoch 5500, Loss: 44.31254577636719, Losses: L1: 18.42068099975586, L2: 4.2559688412380225e-12, L3: 1.0, L4: 50.00236129760742, L5: 0.195343017578125
Epoch 6000, Loss: 44.31254959106445, Losses: L1: 18.42068099975586, L2: 4.254657823971053e-12, L3: 1.0, L4: 50.00236511230469, L5: 0.19534318149089813
Epoch 6500, Loss: 44.31254577636719, Losses: L1: 18.42068099975586, L2: 4.253708930229694e-12, L3: 1.0, L4: 50.00236129760742, L5: 0.19534330070018768
Epoch 7000, Loss: 44.31254959106445, Losses: L1: 18.42068099975586, L2: 4.2529838158167355e-12, L3: 1.0, L4: 50.00236511230469, L5: 0.19534337520599365
Epoch 7500, Loss: 44.31254959106445, Losses: L1: 18.42068099975586, L2: 4.252838532725622e-12, L3: 1.0, L4: 50.00236511230469, L5: 0.19534340500831604
Epoch 8000, Loss: 44.31254577636719, Losses: L1: 18.42068099975586, L2: 4.25273618404054e-12, L3: 1.0, L4: 50.00236129760742, L5: 0.19534343481063843
Epoch 8500, Loss: 44.31254577636719, Losses: L1: 18.42068099975586, L2: 4.252652049951955e-12, L3: 1.0, L4: 50.00236129760742, L5: 0.19534343481063843
Epoch 9000, Loss: 44.31254577636719, Losses: L1: 18.42068099975586, L2: 4.252622993333732e-12, L3: 1.0, L4: 50.00236129760742, L5: 0.19534343481063843
Epoch 9500, Loss: 44.31254577636719, Losses: L1: 18.42068099975586, L2: 4.252593069353772e-12, L3: 1.0, L4: 50.00236129760742, L5: 0.19534344971179962
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.002080202102661, Constraint losses: L1: 6.166313648223877, L2: 0.0, L3: 0.997957170009613, L4: 0.9979568123817444
Epoch 500, Loss: 0.0020992362406104803, Constraint losses: L1: -1.0545767545700073, L2: 0.0, L3: 0.002575993537902832, L4: 0.0005778195336461067
Epoch 1000, Loss: 0.0012358673848211765, Constraint losses: L1: -1.118160605430603, L2: 0.0, L3: 0.0021767616271972656, L4: 0.00017726636724546552
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0039374828338623, Constraint losses: L1: 6.721495151519775, L2: 7.781982276355848e-05, L3: 0.9985690116882324, L4: 0.9985691905021667
Epoch 500, Loss: 0.002025479916483164, Constraint losses: L1: -1.0581135749816895, L2: 0.0, L3: 0.002541065216064453, L4: 0.0005425282288342714
Epoch 1000, Loss: 0.0012786530423909426, Constraint losses: L1: -1.0705461502075195, L2: 0.0, L3: 0.0021743178367614746, L4: 0.00017488139565102756
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 76.99031066894531, Losses: L1: 6.678785800933838, L2: 4.03710400860291e-05, L3: 0.9982802271842957, L4: 69.66157531738281, L5: 0.3015448749065399
Epoch 500, Loss: 15.624065399169922, Losses: L1: 3.957357168197632, L2: 0.9619536995887756, L3: 0.14849650859832764, L4: 10.597156524658203, L5: 0.06669919192790985
Epoch 1000, Loss: 4.34519624710083, Losses: L1: 0.935310959815979, L2: 0.2726404368877411, L3: 0.10583710670471191, L4: 3.063840866088867, L5: 0.040971167385578156
Epoch 1500, Loss: 4.4555983543396, Losses: L1: 1.6901079416275024, L2: 0.2895181179046631, L3: 0.156866192817688, L4: 2.3832991123199463, L5: 0.02847956493496895
Epoch 2000, Loss: 0.9598126411437988, Losses: L1: -0.12137237936258316, L2: 0.06479507684707642, L3: 0.0864783525466919, L4: 0.9677582383155823, L5: 0.010785107500851154
Epoch 2500, Loss: 0.858961284160614, Losses: L1: -0.22554892301559448, L2: 0.05023287981748581, L3: 0.07510215044021606, L4: 0.9926987290382385, L5: 0.00805510301142931
Epoch 3000, Loss: 0.3193841576576233, Losses: L1: -0.26044782996177673, L2: 0.048232756555080414, L3: 0.06937479972839355, L4: 0.4939374029636383, L5: 0.005948820151388645
Epoch 3500, Loss: 0.11328139901161194, Losses: L1: -0.2637312710285187, L2: 0.043231409043073654, L3: 0.06663310527801514, L4: 0.2977111339569092, L5: 0.005507138092070818
Epoch 4000, Loss: 0.06193532422184944, Losses: L1: -0.26810988783836365, L2: 0.04169025272130966, L3: 0.06532371044158936, L4: 0.25303325057029724, L5: 0.005319694522768259
Epoch 4500, Loss: 0.04749246686697006, Losses: L1: -0.2695205807685852, L2: 0.04094245657324791, L3: 0.06445908546447754, L4: 0.2412148416042328, L5: 0.005252409260720015
Epoch 5000, Loss: 0.0349191315472126, Losses: L1: -0.27055975794792175, L2: 0.04005160927772522, L3: 0.06393969058990479, L4: 0.23083749413490295, L5: 0.005239882506430149
Epoch 5500, Loss: 0.028945868834853172, Losses: L1: -0.27142035961151123, L2: 0.039593301713466644, L3: 0.06347715854644775, L4: 0.2264253795146942, L5: 0.005217921920120716
Epoch 6000, Loss: 0.02372359298169613, Losses: L1: -0.27181476354599, L2: 0.039030175656080246, L3: 0.0632256269454956, L4: 0.22229927778244019, L5: 0.005192173179239035
Epoch 6500, Loss: 0.020437944680452347, Losses: L1: -0.27230238914489746, L2: 0.03879764303565025, L3: 0.0629582405090332, L4: 0.21987049281597137, L5: 0.005186146590858698
Epoch 7000, Loss: 0.017474303022027016, Losses: L1: -0.2726333737373352, L2: 0.03856697306036949, L3: 0.06278204917907715, L4: 0.2175622284412384, L5: 0.005174894351512194
Epoch 7500, Loss: 0.015663497149944305, Losses: L1: -0.27288997173309326, L2: 0.038395531475543976, L3: 0.06265318393707275, L4: 0.2162465751171112, L5: 0.0051695541478693485
Epoch 8000, Loss: 0.01411079615354538, Losses: L1: -0.2730804681777954, L2: 0.03825688362121582, L3: 0.06255489587783813, L4: 0.21507370471954346, L5: 0.0051664551720023155
Epoch 8500, Loss: 0.013082245364785194, Losses: L1: -0.2732025980949402, L2: 0.03813626617193222, L3: 0.06249457597732544, L4: 0.2143206000328064, L5: 0.005161363631486893
Epoch 9000, Loss: 0.012313428334891796, Losses: L1: -0.2733149528503418, L2: 0.03807554766535759, L3: 0.06243699789047241, L4: 0.2137545943260193, L5: 0.005159473512321711
Epoch 9500, Loss: 0.011727876029908657, Losses: L1: -0.2734050154685974, L2: 0.03803115710616112, L3: 0.06240183115005493, L4: 0.21332253515720367, L5: 0.005156559869647026
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.02166485786438, Constraint losses: L1: 18.42068099975586, L2: 0.0010813124245032668, L3: 1.0010813474655151, L4: 1.0010814666748047
Epoch 500, Loss: 0.002010664902627468, Constraint losses: L1: -1.1091394424438477, L2: 0.0, L3: 0.002559185028076172, L4: 0.0005606192862614989
Epoch 1000, Loss: 0.0012477609561756253, Constraint losses: L1: -1.1162208318710327, L2: 0.0, L3: 0.002181708812713623, L4: 0.0001822729827836156
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0028300285339355, Constraint losses: L1: 6.262430667877197, L2: 0.0, L3: 0.9982840418815613, L4: 0.9982833862304688
Epoch 500, Loss: 0.0020523755811154842, Constraint losses: L1: -1.0573962926864624, L2: 0.0, L3: 0.002554178237915039, L4: 0.0005555935204029083
Epoch 1000, Loss: 0.0012923908652737737, Constraint losses: L1: -1.071521520614624, L2: 0.0, L3: 0.002181708812713623, L4: 0.00018220359925180674
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 79.50503540039062, Losses: L1: 5.63832950592041, L2: 8.254325621237513e-06, L3: 0.996813178062439, L4: 73.04108428955078, L5: 0.32720881700515747
Epoch 500, Loss: 11.645843505859375, Losses: L1: 4.818126678466797, L2: 0.5745652914047241, L3: 0.2743513584136963, L4: 6.084872245788574, L5: 0.031102849170565605
Epoch 1000, Loss: 13.96441650390625, Losses: L1: 4.036768436431885, L2: 1.709925889968872, L3: 0.09539580345153809, L4: 8.115859985351562, L5: 0.05416424572467804
Epoch 1500, Loss: 3.0549709796905518, Losses: L1: 0.10852199047803879, L2: 0.11127874255180359, L3: 0.14594876766204834, L4: 2.7486934661865234, L5: 0.013502437621355057
Epoch 2000, Loss: 1.1477253437042236, Losses: L1: -0.038063354790210724, L2: 0.07952291518449783, L3: 0.11639350652694702, L4: 1.0357263088226318, L5: 0.01234270166605711
Epoch 2500, Loss: 1.5756843090057373, Losses: L1: -0.12541450560092926, L2: 0.07891661673784256, L3: 0.10202372074127197, L4: 1.5570783615112305, L5: 0.014091979712247849
Epoch 3000, Loss: 0.6117686629295349, Losses: L1: -0.12419610470533371, L2: 0.06128876656293869, L3: 0.09789001941680908, L4: 0.6160926222801208, L5: 0.0096383485943079
Epoch 3500, Loss: 0.4730164110660553, Losses: L1: -0.13733667135238647, L2: 0.057205356657505035, L3: 0.09273231029510498, L4: 0.4977925717830658, L5: 0.008989010006189346
Epoch 4000, Loss: 0.3918144404888153, Losses: L1: -0.15002195537090302, L2: 0.05400039628148079, L3: 0.09020233154296875, L4: 0.43396133184432983, L5: 0.00877350103110075
Epoch 4500, Loss: 0.34826818108558655, Losses: L1: -0.16005997359752655, L2: 0.0515131950378418, L3: 0.0874253511428833, L4: 0.4044080078601837, L5: 0.008694261312484741
Epoch 5000, Loss: 0.32159385085105896, Losses: L1: -0.1686745136976242, L2: 0.04996221140027046, L3: 0.08551537990570068, L4: 0.388838529586792, L5: 0.008709937334060669
Epoch 5500, Loss: 0.302399218082428, Losses: L1: -0.17477178573608398, L2: 0.049041278660297394, L3: 0.08394402265548706, L4: 0.3774165213108063, L5: 0.008741186000406742
Epoch 6000, Loss: 0.2882830798625946, Losses: L1: -0.1792377382516861, L2: 0.048362430185079575, L3: 0.08266609907150269, L4: 0.3691067099571228, L5: 0.008718643337488174
Epoch 6500, Loss: 0.27750346064567566, Losses: L1: -0.1826554536819458, L2: 0.04775962233543396, L3: 0.08166646957397461, L4: 0.36283090710639954, L5: 0.008735154755413532
Epoch 7000, Loss: 0.2697393596172333, Losses: L1: -0.1855820119380951, L2: 0.047151923179626465, L3: 0.08105230331420898, L4: 0.35892635583877563, L5: 0.008716939017176628
Epoch 7500, Loss: 0.2640012502670288, Losses: L1: -0.18730193376541138, L2: 0.04663065820932388, L3: 0.08058291673660278, L4: 0.35569483041763306, L5: 0.008686231449246407
Epoch 8000, Loss: 0.25993651151657104, Losses: L1: -0.18852628767490387, L2: 0.04629381746053696, L3: 0.08023476600646973, L4: 0.353381872177124, L5: 0.008669738657772541
Epoch 8500, Loss: 0.2570847272872925, Losses: L1: -0.1894095242023468, L2: 0.04604904726147652, L3: 0.0799943208694458, L4: 0.35179558396339417, L5: 0.008652462624013424
Epoch 9000, Loss: 0.25512099266052246, Losses: L1: -0.19005973637104034, L2: 0.0459013432264328, L3: 0.07983410358428955, L4: 0.350715696811676, L5: 0.00864662416279316
Epoch 9500, Loss: 0.2538275122642517, Losses: L1: -0.1905212700366974, L2: 0.045796994119882584, L3: 0.07973062992095947, L4: 0.3500435948371887, L5: 0.008642897009849548
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.001540184020996, Constraint losses: L1: 6.098240375518799, L2: 0.0, L3: 0.9977208375930786, L4: 0.9977209568023682
Epoch 500, Loss: 0.0019527219701558352, Constraint losses: L1: -1.1036241054534912, L2: 0.0, L3: 0.002527475357055664, L4: 0.0005288707907311618
Epoch 1000, Loss: 0.0012213180307298899, Constraint losses: L1: -1.1174970865249634, L2: 0.0, L3: 0.0021691322326660156, L4: 0.00016968295676633716
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0005905628204346, Constraint losses: L1: 5.925548076629639, L2: 0.0, L3: 0.9973325729370117, L4: 0.9973324537277222
Epoch 500, Loss: 0.0019219127716496587, Constraint losses: L1: -1.0508757829666138, L2: 0.0, L3: 0.0024857521057128906, L4: 0.0004870365373790264
Epoch 1000, Loss: 0.0012437704717740417, Constraint losses: L1: -1.070142149925232, L2: 0.0, L3: 0.0021567344665527344, L4: 0.0001571782340761274
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 106.28077697753906, Losses: L1: 13.618934631347656, L2: 0.002331273863092065, L3: 1.001684308052063, L4: 91.23916625976562, L5: 0.45975184440612793
Epoch 500, Loss: 3.298651695251465, Losses: L1: 0.1728585958480835, L2: 0.4261106252670288, L3: 0.0751768946647644, L4: 2.628662586212158, L5: 0.016715794801712036
Epoch 1000, Loss: 0.8742808103561401, Losses: L1: -0.21917933225631714, L2: 0.044655200093984604, L3: 0.0569080114364624, L4: 1.0018409490585327, L5: 0.009254992939531803
Epoch 1500, Loss: 0.9400907158851624, Losses: L1: -0.290682315826416, L2: 0.046698179095983505, L3: 0.05026233196258545, L4: 1.1417272090911865, L5: 0.008608263917267323
Epoch 2000, Loss: 0.2184186577796936, Losses: L1: -0.2882848381996155, L2: 0.033328212797641754, L3: 0.04931998252868652, L4: 0.43517404794692993, L5: 0.00677062664180994
Epoch 2500, Loss: 0.21841557323932648, Losses: L1: -0.2985008656978607, L2: 0.03408559784293175, L3: 0.04823732376098633, L4: 0.44489359855651855, L5: 0.006909290794283152
Epoch 3000, Loss: 0.167289599776268, Losses: L1: -0.29310786724090576, L2: 0.030304567888379097, L3: 0.047896385192871094, L4: 0.3928978145122528, L5: 0.006623437162488699
Epoch 3500, Loss: -0.04318368062376976, Losses: L1: -0.2965613603591919, L2: 0.02981272153556347, L3: 0.04714012145996094, L4: 0.18731343746185303, L5: 0.006340728607028723
Epoch 4000, Loss: -0.09615938365459442, Losses: L1: -0.2988683879375458, L2: 0.03129538521170616, L3: 0.046648383140563965, L4: 0.13550767302513123, L5: 0.006290876772254705
Epoch 4500, Loss: -0.10112953931093216, Losses: L1: -0.2971112132072449, L2: 0.029457438737154007, L3: 0.046601057052612305, L4: 0.1307177096605301, L5: 0.006252992432564497
Epoch 5000, Loss: -0.12265868484973907, Losses: L1: -0.29648083448410034, L2: 0.028722209855914116, L3: 0.04643702507019043, L4: 0.10942119359970093, L5: 0.006230123341083527
Epoch 5500, Loss: -0.13053034245967865, Losses: L1: -0.29634836316108704, L2: 0.028057631105184555, L3: 0.046334266662597656, L4: 0.10216198861598969, L5: 0.006215629633516073
Epoch 6000, Loss: -0.13228513300418854, Losses: L1: -0.29655906558036804, L2: 0.027865849435329437, L3: 0.04621303081512451, L4: 0.10088521242141724, L5: 0.006208174861967564
Epoch 6500, Loss: -0.13387344777584076, Losses: L1: -0.296680212020874, L2: 0.027654672041535378, L3: 0.04616248607635498, L4: 0.09966257959604263, L5: 0.006204134784638882
Epoch 7000, Loss: -0.13489669561386108, Losses: L1: -0.2967257797718048, L2: 0.027513286098837852, L3: 0.04610884189605713, L4: 0.09886114299297333, L5: 0.0062001110054552555
Epoch 7500, Loss: -0.13554975390434265, Losses: L1: -0.2966291904449463, L2: 0.027347058057785034, L3: 0.046076297760009766, L4: 0.09830407798290253, L5: 0.006195079069584608
Epoch 8000, Loss: -0.13606129586696625, Losses: L1: -0.2966901361942291, L2: 0.027271263301372528, L3: 0.046044886112213135, L4: 0.09794721752405167, L5: 0.006193958688527346
Epoch 8500, Loss: -0.1364503651857376, Losses: L1: -0.2966982424259186, L2: 0.02720862627029419, L3: 0.04602628946304321, L4: 0.09764260053634644, L5: 0.006191749591380358
Epoch 9000, Loss: -0.13672931492328644, Losses: L1: -0.2966877222061157, L2: 0.027168767526745796, L3: 0.046011388301849365, L4: 0.09740197658538818, L5: 0.0061909789219498634
Epoch 9500, Loss: -0.13691294193267822, Losses: L1: -0.29669445753097534, L2: 0.027144860476255417, L3: 0.04600149393081665, L4: 0.09725607931613922, L5: 0.006189922336488962
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.034998893737793, Constraint losses: L1: 18.42068099975586, L2: 0.005525870248675346, L3: 1.005525827407837, L4: 1.0055265426635742
Epoch 500, Loss: 0.0024975966662168503, Constraint losses: L1: -1.0533289909362793, L2: 0.0, L3: 0.002774357795715332, L4: 0.0007765678456053138
Epoch 1000, Loss: 0.0013730732025578618, Constraint losses: L1: -1.1179898977279663, L2: 0.0, L3: 0.002245187759399414, L4: 0.000245875446125865
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0212759971618652, Constraint losses: L1: 18.42068099975586, L2: 0.0009518368751741946, L3: 1.000951886177063, L4: 1.0009517669677734
Epoch 500, Loss: 0.002453817054629326, Constraint losses: L1: -1.0627645254135132, L2: 0.0, L3: 0.0027573704719543457, L4: 0.0007592112524434924
Epoch 1000, Loss: 0.001432914286851883, Constraint losses: L1: -1.0711804628372192, L2: 0.0, L3: 0.0022518038749694824, L4: 0.0002522909198887646
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 148.36660766601562, Losses: L1: 6.292271137237549, L2: 5.22119307788671e-06, L3: 0.9982022643089294, L4: 70.71006774902344, L5: 0.3101758360862732
Epoch 500, Loss: 5.888894081115723, Losses: L1: -0.08003899455070496, L2: 0.128013014793396, L3: 0.05533647537231445, L4: 2.898174285888672, L5: 0.03380659222602844
Epoch 1000, Loss: 3.8459177017211914, Losses: L1: -0.16935977339744568, L2: 0.03317262977361679, L3: 0.05151844024658203, L4: 1.9760098457336426, L5: 0.008651894517242908
Epoch 1500, Loss: 0.8967998027801514, Losses: L1: -0.20872610807418823, L2: 0.02573331817984581, L3: 0.051576197147369385, L4: 0.5230259895324707, L5: 0.015904992818832397
Epoch 2000, Loss: 5.527388095855713, Losses: L1: 2.6551785469055176, L2: 0.6216258406639099, L3: 0.061377644538879395, L4: 1.100262999534607, L5: 0.03873731568455696
Epoch 2500, Loss: 0.49678850173950195, Losses: L1: -0.09135773777961731, L2: 0.07063468545675278, L3: 0.05476725101470947, L4: 0.24238085746765137, L5: 0.010732414200901985
Epoch 3000, Loss: 0.23256637156009674, Losses: L1: -0.16674022376537323, L2: 0.060020074248313904, L3: 0.05288928747177124, L4: 0.15459902584552765, L5: 0.007287661544978619
Epoch 3500, Loss: 0.3772868514060974, Losses: L1: -0.05493278056383133, L2: 0.05571753904223442, L3: 0.0496334433555603, L4: 0.17382144927978516, L5: 0.008084937930107117
Epoch 4000, Loss: 0.11878348141908646, Losses: L1: -0.2118844836950302, L2: 0.04806164652109146, L3: 0.0493091344833374, L4: 0.12705102562904358, L5: 0.007699389476329088
Epoch 4500, Loss: 0.06898824870586395, Losses: L1: -0.21535426378250122, L2: 0.04808096960186958, L3: 0.04898303747177124, L4: 0.10400360077619553, L5: 0.007525656837970018
Epoch 5000, Loss: 0.05947935953736305, Losses: L1: -0.2164175808429718, L2: 0.04756869748234749, L3: 0.048920392990112305, L4: 0.100123830139637, L5: 0.007240776438266039
Epoch 5500, Loss: 0.05017862841486931, Losses: L1: -0.21733002364635468, L2: 0.04714204743504524, L3: 0.04884594678878784, L4: 0.09619294106960297, L5: 0.007115508895367384
Epoch 6000, Loss: 0.043542638421058655, Losses: L1: -0.2179807424545288, L2: 0.046878159046173096, L3: 0.04881167411804199, L4: 0.0933627262711525, L5: 0.007027866318821907
Epoch 6500, Loss: 0.03995193541049957, Losses: L1: -0.21829873323440552, L2: 0.0465371273458004, L3: 0.048812031745910645, L4: 0.09191907197237015, L5: 0.006938755512237549
Epoch 7000, Loss: 0.03714718669652939, Losses: L1: -0.21856789290905, L2: 0.04629412293434143, L3: 0.04880475997924805, L4: 0.0907876193523407, L5: 0.006886678747832775
Epoch 7500, Loss: 0.03537202626466751, Losses: L1: -0.21878288686275482, L2: 0.04614444449543953, L3: 0.048804402351379395, L4: 0.09009329974651337, L5: 0.00684334384277463
Epoch 8000, Loss: 0.03411990776658058, Losses: L1: -0.21886885166168213, L2: 0.04601781815290451, L3: 0.048812270164489746, L4: 0.0895780697464943, L5: 0.006817320827394724
Epoch 8500, Loss: 0.033220384269952774, Losses: L1: -0.2189483344554901, L2: 0.04592376574873924, L3: 0.04881852865219116, L4: 0.08921828866004944, L5: 0.006798212416470051
Epoch 9000, Loss: 0.03251774236559868, Losses: L1: -0.219045951962471, L2: 0.04587104916572571, L3: 0.04882127046585083, L4: 0.0889458954334259, L5: 0.006780440453439951
Epoch 9500, Loss: 0.032143231481313705, Losses: L1: -0.21911019086837769, L2: 0.04583347961306572, L3: 0.048823773860931396, L4: 0.08881136775016785, L5: 0.0067706359550356865
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0267367362976074, Constraint losses: L1: 18.42068099975586, L2: 0.002771886996924877, L3: 1.0027718544006348, L4: 1.0027722120285034
Epoch 500, Loss: 0.0025134324096143246, Constraint losses: L1: -1.1019163131713867, L2: 0.0, L3: 0.0028066039085388184, L4: 0.0008087448077276349
Epoch 1000, Loss: 0.0014076146762818098, Constraint losses: L1: -1.118524193763733, L2: 0.0, L3: 0.002262711524963379, L4: 0.00026342744240537286
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.007579803466797, Constraint losses: L1: 8.384906768798828, L2: 5.8525816712062806e-05, L3: 0.999567985534668, L4: 0.9995683431625366
Epoch 500, Loss: 0.0021982474718242884, Constraint losses: L1: -1.0037758350372314, L2: 0.0, L3: 0.00260007381439209, L4: 0.0006019495776854455
Epoch 1000, Loss: 0.0013119399081915617, Constraint losses: L1: -1.0704072713851929, L2: 0.0, L3: 0.002191007137298584, L4: 0.00019134006288368255
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 177.96511840820312, Losses: L1: 18.42068099975586, L2: 0.0038130369503051043, L3: 1.0038130283355713, L4: 79.32920837402344, L5: 0.38029831647872925
Epoch 500, Loss: 36.55757522583008, Losses: L1: 2.2089576721191406, L2: 0.9312124848365784, L3: 0.5274784564971924, L4: 16.55144500732422, L5: 0.05077836662530899
Epoch 1000, Loss: 104.10540008544922, Losses: L1: 6.444835662841797, L2: 0.134891539812088, L3: 0.9146917462348938, L4: 48.451602935791016, L5: 0.1651197075843811
Epoch 1500, Loss: 119.14382934570312, Losses: L1: 18.42068099975586, L2: 1.6513572735805948e-13, L3: 1.0, L4: 50.01525115966797, L5: 0.1926429122686386
Epoch 2000, Loss: 119.1364517211914, Losses: L1: 18.42068099975586, L2: 1.3103855836787276e-13, L3: 1.0, L4: 50.011234283447266, L5: 0.1933046281337738
Epoch 2500, Loss: 119.13285064697266, Losses: L1: 18.42068099975586, L2: 1.1292641219915259e-13, L3: 1.0, L4: 50.00926208496094, L5: 0.19364187121391296
Epoch 3000, Loss: 119.13077545166016, Losses: L1: 18.42068099975586, L2: 1.0197700024911285e-13, L3: 1.0, L4: 50.00812911987305, L5: 0.1938362568616867
Epoch 3500, Loss: 119.12947845458984, Losses: L1: 18.42068099975586, L2: 9.486564366088107e-14, L3: 1.0, L4: 50.00741958618164, L5: 0.1939629465341568
Epoch 4000, Loss: 119.12860107421875, Losses: L1: 18.42068099975586, L2: 9.000290204959349e-14, L3: 1.0, L4: 50.006935119628906, L5: 0.19404835999011993
Epoch 4500, Loss: 119.12799072265625, Losses: L1: 18.42068099975586, L2: 8.656189507587689e-14, L3: 1.0, L4: 50.0066032409668, L5: 0.19410786032676697
Epoch 5000, Loss: 119.1275634765625, Losses: L1: 18.42068099975586, L2: 8.40683927094861e-14, L3: 1.0, L4: 50.00636672973633, L5: 0.19415050745010376
Epoch 5500, Loss: 119.12724304199219, Losses: L1: 18.42068099975586, L2: 8.222996529571105e-14, L3: 1.0, L4: 50.00619125366211, L5: 0.1941816657781601
Epoch 6000, Loss: 119.12700653076172, Losses: L1: 18.42068099975586, L2: 8.085629469569908e-14, L3: 1.0, L4: 50.00606155395508, L5: 0.19420482218265533
Epoch 6500, Loss: 119.12683868408203, Losses: L1: 18.42068099975586, L2: 7.982071221438597e-14, L3: 1.0, L4: 50.00596618652344, L5: 0.19422218203544617
Epoch 7000, Loss: 119.12670135498047, Losses: L1: 18.42068099975586, L2: 7.903357466089792e-14, L3: 1.0, L4: 50.005889892578125, L5: 0.19423533976078033
Epoch 7500, Loss: 119.12660217285156, Losses: L1: 18.42068099975586, L2: 7.843195087538571e-14, L3: 1.0, L4: 50.005836486816406, L5: 0.1942453533411026
Epoch 8000, Loss: 119.12651824951172, Losses: L1: 18.42068099975586, L2: 7.797157152789405e-14, L3: 1.0, L4: 50.00579071044922, L5: 0.19425301253795624
Epoch 8500, Loss: 119.12644958496094, Losses: L1: 18.42068099975586, L2: 7.761673926189386e-14, L3: 1.0, L4: 50.00575637817383, L5: 0.194258913397789
Epoch 9000, Loss: 119.12641906738281, Losses: L1: 18.42068099975586, L2: 7.734223960061126e-14, L3: 1.0, L4: 50.0057373046875, L5: 0.19426344335079193
Epoch 9500, Loss: 119.12638092041016, Losses: L1: 18.42068099975586, L2: 7.713175530135036e-14, L3: 1.0, L4: 50.005714416503906, L5: 0.19426694512367249
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0130386352539062, Constraint losses: L1: 12.949528694152832, L2: 0.00022768184135202318, L3: 0.9999305605888367, L4: 0.9999308586120605
Epoch 500, Loss: 0.002206389792263508, Constraint losses: L1: -1.075387954711914, L2: 0.0, L3: 0.0026398897171020508, L4: 0.000641888240352273
Epoch 1000, Loss: 0.0012841596035286784, Constraint losses: L1: -1.1178432703018188, L2: 0.0, L3: 0.0022007226943969727, L4: 0.00020128022879362106
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.006176233291626, Constraint losses: L1: 7.4278669357299805, L2: 0.0, L3: 0.9993741512298584, L4: 0.9993742108345032
Epoch 500, Loss: 0.002288066316395998, Constraint losses: L1: -1.0539987087249756, L2: 0.0, L3: 0.0026701688766479492, L4: 0.0006718960357829928
Epoch 1000, Loss: 0.0013669145992025733, Constraint losses: L1: -1.0712579488754272, L2: 0.0, L3: 0.0022188425064086914, L4: 0.00021933003154117614
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.41783142089844, Losses: L1: 5.522764205932617, L2: 0.0, L3: 0.9960458874702454, L4: 80.31722259521484, L5: 0.3812987208366394
Epoch 500, Loss: 40.534446716308594, Losses: L1: 4.8135881423950195, L2: 1.827742576599121, L3: 0.10270571708679199, L4: 16.831424713134766, L5: 0.08945584297180176
Epoch 1000, Loss: 5.278726577758789, Losses: L1: 1.2151814699172974, L2: 0.34799590706825256, L3: 0.14047139883041382, L4: 1.809255838394165, L5: 0.013401146978139877
Epoch 1500, Loss: 103.92576599121094, Losses: L1: 5.049759864807129, L2: 0.008925835601985455, L3: 0.9840654730796814, L4: 48.99913787841797, L5: 0.18838539719581604
Epoch 2000, Loss: 4.438547611236572, Losses: L1: -0.021699314936995506, L2: 0.12949274480342865, L3: 0.10539770126342773, L4: 2.1244680881500244, L5: 0.014559554867446423
Epoch 2500, Loss: 2.0002262592315674, Losses: L1: -0.08768036961555481, L2: 0.09780745953321457, L3: 0.09180057048797607, L4: 0.9647809267044067, L5: 0.007318470627069473
Epoch 3000, Loss: 1.3948595523834229, Losses: L1: -0.1075763925909996, L2: 0.07914113253355026, L3: 0.0933566689491272, L4: 0.6818581819534302, L5: 0.006450076121836901
Epoch 3500, Loss: 1.2038655281066895, Losses: L1: -0.13922205567359924, L2: 0.07394858449697495, L3: 0.09013378620147705, L4: 0.6054651737213135, L5: 0.006570896599441767
Epoch 4000, Loss: 1.0962245464324951, Losses: L1: -0.14849290251731873, L2: 0.07139252126216888, L3: 0.08864003419876099, L4: 0.5579556822776794, L5: 0.0065467823296785355
Epoch 4500, Loss: 1.1067622900009155, Losses: L1: -0.161542147397995, L2: 0.07073276489973068, L3: 0.0870160460472107, L4: 0.570526123046875, L5: 0.006505726370960474
Epoch 5000, Loss: 1.026503562927246, Losses: L1: -0.16579990088939667, L2: 0.06912650913000107, L3: 0.08673059940338135, L4: 0.5334345102310181, L5: 0.006471340078860521
Epoch 5500, Loss: 0.9808314442634583, Losses: L1: -0.16945338249206543, L2: 0.06838208436965942, L3: 0.08633601665496826, L4: 0.512891411781311, L5: 0.00647594453766942
Epoch 6000, Loss: 0.965639591217041, Losses: L1: -0.1718582957983017, L2: 0.06800422072410583, L3: 0.0859038233757019, L4: 0.5068166255950928, L5: 0.006454248446971178
Epoch 6500, Loss: 0.9527744054794312, Losses: L1: -0.1734483391046524, L2: 0.06776487082242966, L3: 0.08560281991958618, L4: 0.5014166831970215, L5: 0.006411567330360413
Epoch 7000, Loss: 0.9447339177131653, Losses: L1: -0.17447017133235931, L2: 0.06754253059625626, L3: 0.08539581298828125, L4: 0.49809324741363525, L5: 0.006388580892235041
Epoch 7500, Loss: 0.9393341541290283, Losses: L1: -0.17515061795711517, L2: 0.06735303997993469, L3: 0.08524084091186523, L4: 0.49587395787239075, L5: 0.006381690036505461
Epoch 8000, Loss: 0.9346970319747925, Losses: L1: -0.1757572442293167, L2: 0.06729099899530411, L3: 0.08513164520263672, L4: 0.49393659830093384, L5: 0.00636215228587389
Epoch 8500, Loss: 0.9314525723457336, Losses: L1: -0.17607270181179047, L2: 0.0671820119023323, L3: 0.08505034446716309, L4: 0.49255141615867615, L5: 0.0063576363027095795
Epoch 9000, Loss: 0.9292031526565552, Losses: L1: -0.17631681263446808, L2: 0.06710903346538544, L3: 0.08500027656555176, L4: 0.49160271883010864, L5: 0.006352652329951525
Epoch 9500, Loss: 0.9275585412979126, Losses: L1: -0.1765030324459076, L2: 0.0670660138130188, L3: 0.08495771884918213, L4: 0.4909098744392395, L5: 0.006348482798784971
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.030733585357666, Constraint losses: L1: 18.42068099975586, L2: 0.004104085732251406, L3: 1.0041041374206543, L4: 1.0041048526763916
Epoch 500, Loss: 0.0026208919007331133, Constraint losses: L1: -1.0252267122268677, L2: 0.0, L3: 0.0028218626976013184, L4: 0.0008242560434155166
Epoch 1000, Loss: 0.0013893252471461892, Constraint losses: L1: -1.1173704862594604, L2: 0.0, L3: 0.0022529959678649902, L4: 0.0002536998363211751
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001596450805664, Constraint losses: L1: 6.093153476715088, L2: 0.0, L3: 0.9977517127990723, L4: 0.9977516531944275
Epoch 500, Loss: 0.0019369336077943444, Constraint losses: L1: -1.0406990051269531, L2: 0.0, L3: 0.0024881958961486816, L4: 0.0004894367884844542
Epoch 1000, Loss: 0.0012396370293572545, Constraint losses: L1: -1.069419503211975, L2: 0.0, L3: 0.0021543502807617188, L4: 0.00015470627113245428
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 43.01777648925781, Losses: L1: 4.657124042510986, L2: 0.0, L3: 0.9906895160675049, L4: 74.40133666992188, L5: 0.3385942280292511
Epoch 500, Loss: 34.81100845336914, Losses: L1: 8.209675788879395, L2: 0.02416265569627285, L3: 1.0201029777526855, L4: 50.9429817199707, L5: 0.17114759981632233
Epoch 1000, Loss: 31.578603744506836, Losses: L1: 4.614934921264648, L2: 0.022646520286798477, L3: 0.9862440824508667, L4: 51.716407775878906, L5: 0.19314923882484436
Epoch 1500, Loss: 30.309356689453125, Losses: L1: 3.3143999576568604, L2: 0.01604815572500229, L3: 0.9719484448432922, L4: 51.8218994140625, L5: 0.19201970100402832
Epoch 2000, Loss: 31.144779205322266, Losses: L1: 4.263116836547852, L2: 0.0005641214665956795, L3: 0.945559024810791, L4: 51.696495056152344, L5: 0.1745852679014206
Epoch 2500, Loss: 30.83187484741211, Losses: L1: 4.786288261413574, L2: 0.00230110390111804, L3: 0.915230393409729, L4: 50.085792541503906, L5: 0.17031840980052948
Epoch 3000, Loss: 33.19869613647461, Losses: L1: 6.561668395996094, L2: 2.8779022613889538e-05, L3: 0.9926815629005432, L4: 51.117427825927734, L5: 0.17121346294879913
Epoch 3500, Loss: 31.610246658325195, Losses: L1: 5.07094669342041, L2: 9.562313789501786e-05, L3: 0.9774365425109863, L4: 50.95241928100586, L5: 0.17111554741859436
Epoch 4000, Loss: 30.304670333862305, Losses: L1: 3.870002269744873, L2: 0.0002791354199871421, L3: 0.9499331116676331, L4: 50.797767639160156, L5: 0.17114102840423584
Epoch 4500, Loss: 29.795734405517578, Losses: L1: 3.3697426319122314, L2: 0.0004982817335985601, L3: 0.9350255727767944, L4: 50.8095588684082, L5: 0.17138080298900604
Epoch 5000, Loss: 29.297819137573242, Losses: L1: 2.966454029083252, L2: 0.0015389950713142753, L3: 0.8873945474624634, L4: 50.712669372558594, L5: 0.17219170928001404
Epoch 5500, Loss: 29.178430557250977, Losses: L1: 2.8537755012512207, L2: 0.0016351243248209357, L3: 0.8777188658714294, L4: 50.71808624267578, L5: 0.17251518368721008
Epoch 6000, Loss: 29.093181610107422, Losses: L1: 2.7834041118621826, L2: 0.001724969013594091, L3: 0.8719964027404785, L4: 50.699493408203125, L5: 0.17261706292629242
Epoch 6500, Loss: 29.030963897705078, Losses: L1: 2.737680196762085, L2: 0.0017922860570251942, L3: 0.8685344457626343, L4: 50.673309326171875, L5: 0.17260482907295227
Epoch 7000, Loss: 28.984691619873047, Losses: L1: 2.7039194107055664, L2: 0.0018468121998012066, L3: 0.8659197688102722, L4: 50.653419494628906, L5: 0.17259392142295837
Epoch 7500, Loss: 28.949979782104492, Losses: L1: 2.67868971824646, L2: 0.0018886853940784931, L3: 0.8639546036720276, L4: 50.638309478759766, L5: 0.17258451879024506
Epoch 8000, Loss: 28.913148880004883, Losses: L1: 2.6486361026763916, L2: 0.0019095255993306637, L3: 0.8624563217163086, L4: 50.62771224975586, L5: 0.1725807636976242
Epoch 8500, Loss: 28.89386558532715, Losses: L1: 2.6298673152923584, L2: 0.001955127576366067, L3: 0.8606754541397095, L4: 50.63008499145508, L5: 0.17264972627162933
Epoch 9000, Loss: 28.880022048950195, Losses: L1: 2.6166818141937256, L2: 0.0019761675503104925, L3: 0.8595538139343262, L4: 50.63093185424805, L5: 0.17268776893615723
Epoch 9500, Loss: 28.869808197021484, Losses: L1: 2.6068506240844727, L2: 0.0019920337945222855, L3: 0.8587112426757812, L4: 50.63179016113281, L5: 0.17271733283996582
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0212411880493164, Constraint losses: L1: 18.42068099975586, L2: 0.000950783840380609, L3: 1.0009348392486572, L4: 1.0009348392486572
Epoch 500, Loss: 0.0021062283776700497, Constraint losses: L1: -1.0928101539611816, L2: 0.0, L3: 0.0025987625122070312, L4: 0.0006002761656418443
Epoch 1000, Loss: 0.001262873294763267, Constraint losses: L1: -1.1184624433517456, L2: 0.0, L3: 0.0021904706954956055, L4: 0.0001908651611302048
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9939665794372559, Constraint losses: L1: 5.128720283508301, L2: 0.0, L3: 0.994419515132904, L4: 0.9944182634353638
Epoch 500, Loss: 0.0020093920174986124, Constraint losses: L1: -1.0577760934829712, L2: 0.0, L3: 0.0025328397750854492, L4: 0.0005343283992260695
Epoch 1000, Loss: 0.001277412986382842, Constraint losses: L1: -1.0716816186904907, L2: 0.0, L3: 0.0021742582321166992, L4: 0.00017483641568105668
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 47.729190826416016, Losses: L1: 9.29638671875, L2: 0.00043653786997310817, L3: 0.9994118809700012, L4: 74.18461608886719, L5: 0.34064799547195435
Epoch 500, Loss: 1.290370225906372, Losses: L1: -0.06746186316013336, L2: 0.1605345606803894, L3: 0.13613319396972656, L4: 2.0792667865753174, L5: 0.021530983969569206
Epoch 1000, Loss: 1.336529016494751, Losses: L1: -0.11551041156053543, L2: 0.1899711936712265, L3: 0.06249594688415527, L4: 2.3640284538269043, L5: 0.01755811646580696
Epoch 1500, Loss: 31.897796630859375, Losses: L1: 6.694816589355469, L2: 0.06560925394296646, L3: 0.9381839036941528, L4: 48.07199478149414, L5: 0.16318824887275696
Epoch 2000, Loss: 27.17977523803711, Losses: L1: 5.743507385253906, L2: 0.18633271753787994, L3: 1.0016847848892212, L4: 40.07840347290039, L5: 0.20904859900474548
Epoch 2500, Loss: 27.04355812072754, Losses: L1: 6.313380241394043, L2: 0.21683046221733093, L3: 1.006247878074646, L4: 38.60095977783203, L5: 0.20661869645118713
Epoch 3000, Loss: 26.94688606262207, Losses: L1: 6.233145713806152, L2: 0.2668302059173584, L3: 1.0069267749786377, L4: 38.46180725097656, L5: 0.20907892286777496
Epoch 3500, Loss: 26.872516632080078, Losses: L1: 6.189972877502441, L2: 0.2959623336791992, L3: 1.0067598819732666, L4: 38.341461181640625, L5: 0.2090913951396942
Epoch 4000, Loss: 26.825180053710938, Losses: L1: 6.175143718719482, L2: 0.31454023718833923, L3: 1.006569266319275, L4: 38.24066162109375, L5: 0.20859506726264954
Epoch 4500, Loss: 26.792530059814453, Losses: L1: 6.166175365447998, L2: 0.3271685838699341, L3: 1.0064557790756226, L4: 38.16923522949219, L5: 0.20811200141906738
Epoch 5000, Loss: 26.770235061645508, Losses: L1: 6.158492565155029, L2: 0.3380339443683624, L3: 1.0063668489456177, L4: 38.1187629699707, L5: 0.20795920491218567
Epoch 5500, Loss: 26.753246307373047, Losses: L1: 6.1537957191467285, L2: 0.346213161945343, L3: 1.0063037872314453, L4: 38.078460693359375, L5: 0.2077033817768097
Epoch 6000, Loss: 26.7413272857666, Losses: L1: 6.149965286254883, L2: 0.35213392972946167, L3: 1.0062674283981323, L4: 38.05084228515625, L5: 0.20754054188728333
Epoch 6500, Loss: 26.73221206665039, Losses: L1: 6.146573543548584, L2: 0.35712170600891113, L3: 1.0062376260757446, L4: 38.02971649169922, L5: 0.20742033421993256
Epoch 7000, Loss: 26.725601196289062, Losses: L1: 6.144298076629639, L2: 0.36058881878852844, L3: 1.0062246322631836, L4: 38.014305114746094, L5: 0.20733590424060822
Epoch 7500, Loss: 26.720643997192383, Losses: L1: 6.142207622528076, L2: 0.36340010166168213, L3: 1.006208896636963, L4: 38.003135681152344, L5: 0.20726026594638824
Epoch 8000, Loss: 26.716976165771484, Losses: L1: 6.140411853790283, L2: 0.36561155319213867, L3: 1.006198525428772, L4: 37.99504089355469, L5: 0.20723305642604828
Epoch 8500, Loss: 26.71426773071289, Losses: L1: 6.139111518859863, L2: 0.36722299456596375, L3: 1.0061925649642944, L4: 37.98908615112305, L5: 0.20719802379608154
Epoch 9000, Loss: 26.712331771850586, Losses: L1: 6.137956142425537, L2: 0.3684259057044983, L3: 1.0061893463134766, L4: 37.98514938354492, L5: 0.2071855366230011
Epoch 9500, Loss: 26.710996627807617, Losses: L1: 6.137078285217285, L2: 0.36919933557510376, L3: 1.006191611289978, L4: 37.982704162597656, L5: 0.20717421174049377
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0066473484039307, Constraint losses: L1: 7.504793167114258, L2: 1.6226911611738615e-05, L3: 0.999563455581665, L4: 0.9995629191398621
Epoch 500, Loss: 0.0020211399532854557, Constraint losses: L1: -1.113830804824829, L2: 0.0, L3: 0.002566814422607422, L4: 0.000568156479857862
Epoch 1000, Loss: 0.001259694341570139, Constraint losses: L1: -1.1185344457626343, L2: 0.0, L3: 0.00218886137008667, L4: 0.0001893674343591556
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.029313564300537, Constraint losses: L1: 18.42068099975586, L2: 0.003630926599726081, L3: 1.0036308765411377, L4: 1.0036312341690063
Epoch 500, Loss: 0.0023283257614821196, Constraint losses: L1: -1.0461589097976685, L2: 0.0, L3: 0.00268632173538208, L4: 0.000688163039740175
Epoch 1000, Loss: 0.0013808495132252574, Constraint losses: L1: -1.0706405639648438, L2: 0.0, L3: 0.0022254586219787598, L4: 0.0002260315086459741
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 59.74695587158203, Losses: L1: 16.680253982543945, L2: 0.00036782302777282894, L3: 1.0003479719161987, L4: 82.53319549560547, L5: 0.3996935486793518
Epoch 500, Loss: 1.6235162019729614, Losses: L1: -0.09703360497951508, L2: 0.10922403633594513, L3: 0.1040601134300232, L4: 2.894343614578247, L5: 0.030046923086047173
Epoch 1000, Loss: 0.5514126420021057, Losses: L1: -0.24701334536075592, L2: 0.08638204634189606, L3: 0.07738560438156128, L4: 1.2206637859344482, L5: 0.012163207866251469
Epoch 1500, Loss: 0.22410766780376434, Losses: L1: -0.23452316224575043, L2: 0.05207028239965439, L3: 0.08002638816833496, L4: 0.6161380410194397, L5: 0.009232573211193085
Epoch 2000, Loss: 0.45130109786987305, Losses: L1: -0.23492980003356934, L2: 0.055255431681871414, L3: 0.07374471426010132, L4: 1.0855648517608643, L5: 0.0072241658344864845
Epoch 2500, Loss: 0.11795469373464584, Losses: L1: -0.2586817741394043, L2: 0.057723019272089005, L3: 0.06955444812774658, L4: 0.4687556326389313, L5: 0.007490592543035746
Epoch 3000, Loss: 0.025256842374801636, Losses: L1: -0.25439193844795227, L2: 0.04830115661025047, L3: 0.07062757015228271, L4: 0.2928737998008728, L5: 0.007141575217247009
Epoch 3500, Loss: 0.011620436795055866, Losses: L1: -0.2573244273662567, L2: 0.04554543271660805, L3: 0.07022380828857422, L4: 0.2797318696975708, L5: 0.006654846016317606
Epoch 4000, Loss: 0.012795211747288704, Losses: L1: -0.25928613543510437, L2: 0.044360872358083725, L3: 0.06926178932189941, L4: 0.2907201051712036, L5: 0.006549314595758915
Epoch 4500, Loss: -0.004277664236724377, Losses: L1: -0.26157647371292114, L2: 0.043189745396375656, L3: 0.06854867935180664, L4: 0.26451513171195984, L5: 0.006651407573372126
Epoch 5000, Loss: -0.011861505918204784, Losses: L1: -0.26264262199401855, L2: 0.042615316808223724, L3: 0.0681142807006836, L4: 0.25383663177490234, L5: 0.006566597614437342
Epoch 5500, Loss: -0.01795138791203499, Losses: L1: -0.26353028416633606, L2: 0.04208909347653389, L3: 0.06759542226791382, L4: 0.24593272805213928, L5: 0.0064640105701982975
Epoch 6000, Loss: -0.02040068432688713, Losses: L1: -0.2642080783843994, L2: 0.04172033444046974, L3: 0.06740379333496094, L4: 0.24362249672412872, L5: 0.006436010356992483
Epoch 6500, Loss: -0.02239234745502472, Losses: L1: -0.26474788784980774, L2: 0.04155942425131798, L3: 0.0672144889831543, L4: 0.241576686501503, L5: 0.006396639626473188
Epoch 7000, Loss: -0.023777712136507034, Losses: L1: -0.2651410698890686, L2: 0.04139390215277672, L3: 0.067027747631073, L4: 0.24041080474853516, L5: 0.006368150934576988
Epoch 7500, Loss: -0.02492201328277588, Losses: L1: -0.265451580286026, L2: 0.041352007538080215, L3: 0.06690013408660889, L4: 0.23910512030124664, L5: 0.006362434942275286
Epoch 8000, Loss: -0.025658948346972466, Losses: L1: -0.26565617322921753, L2: 0.041293494403362274, L3: 0.06681942939758301, L4: 0.23837999999523163, L5: 0.006347146816551685
Epoch 8500, Loss: -0.026350706815719604, Losses: L1: -0.26583749055862427, L2: 0.04124888777732849, L3: 0.06672877073287964, L4: 0.23764009773731232, L5: 0.006344538647681475
Epoch 9000, Loss: -0.026814397424459457, Losses: L1: -0.2659606337547302, L2: 0.04122016951441765, L3: 0.06667190790176392, L4: 0.23715049028396606, L5: 0.006339454557746649
Epoch 9500, Loss: -0.027164055034518242, Losses: L1: -0.2660585939884186, L2: 0.04120338708162308, L3: 0.0666242241859436, L4: 0.23679706454277039, L5: 0.00633420143276453
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0240025520324707, Constraint losses: L1: 18.42068099975586, L2: 0.001860734773799777, L3: 1.0018607378005981, L4: 1.001860499382019
Epoch 500, Loss: 0.0022330977953970432, Constraint losses: L1: -1.0422236919403076, L2: 0.0, L3: 0.0026366710662841797, L4: 0.0006386504974216223
Epoch 1000, Loss: 0.0012616784079000354, Constraint losses: L1: -1.118149757385254, L2: 0.0, L3: 0.0021895766258239746, L4: 0.00019025159417651594
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0131032466888428, Constraint losses: L1: 13.085434913635254, L2: 1.4366110008268151e-05, L3: 1.0000017881393433, L4: 1.0000016689300537
Epoch 500, Loss: 0.002549290657043457, Constraint losses: L1: -1.0073139667510986, L2: 0.0, L3: 0.0027771592140197754, L4: 0.0007794455159455538
Epoch 1000, Loss: 0.0014127244940027595, Constraint losses: L1: -1.0684115886688232, L2: 0.0, L3: 0.002240300178527832, L4: 0.00024083592870738357
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 106.43907165527344, Losses: L1: 18.385597229003906, L2: 0.0016556677874177694, L3: 1.0016467571258545, L4: 86.83518981933594, L5: 0.4299696087837219
Epoch 500, Loss: 55.25617218017578, Losses: L1: 3.3389029502868652, L2: 0.00607032235711813, L3: 0.953902006149292, L4: 50.869606018066406, L5: 0.17538224160671234
Epoch 1000, Loss: 5.734064102172852, Losses: L1: 1.0130891799926758, L2: 0.2650894820690155, L3: 0.2443321943283081, L4: 4.199113845825195, L5: 0.024878915399312973
Epoch 1500, Loss: 4.221776962280273, Losses: L1: 0.16840583086013794, L2: 0.22588908672332764, L3: 0.16274487972259521, L4: 3.652829647064209, L5: 0.023815598338842392
Epoch 2000, Loss: 13.152101516723633, Losses: L1: 1.1498403549194336, L2: 0.7579149007797241, L3: 0.3639809489250183, L4: 10.859368324279785, L5: 0.041994739323854446
Epoch 2500, Loss: 56.66154861450195, Losses: L1: 5.723211288452148, L2: 0.0, L3: 0.9949782490730286, L4: 49.848541259765625, L5: 0.18963894248008728
Epoch 3000, Loss: 10.903826713562012, Losses: L1: 0.6693684458732605, L2: 0.6223615407943726, L3: 0.36111223697662354, L4: 9.230939865112305, L5: 0.04008801281452179
Epoch 3500, Loss: 7.767143249511719, Losses: L1: 0.529079258441925, L2: 0.39843037724494934, L3: 0.32060563564300537, L4: 6.504257678985596, L5: 0.029541460797190666
Epoch 4000, Loss: 6.4362287521362305, Losses: L1: 0.4580930173397064, L2: 0.31641605496406555, L3: 0.29186779260635376, L4: 5.358270645141602, L5: 0.023163188248872757
Epoch 4500, Loss: 6.0404486656188965, Losses: L1: 0.4524492919445038, L2: 0.30381348729133606, L3: 0.27721285820007324, L4: 4.99513053894043, L5: 0.023684874176979065
Epoch 5000, Loss: 5.728806018829346, Losses: L1: 0.4024370610713959, L2: 0.2879432439804077, L3: 0.27417659759521484, L4: 4.752620697021484, L5: 0.023257441818714142
Epoch 5500, Loss: 5.552082061767578, Losses: L1: 0.39614173769950867, L2: 0.28309276700019836, L3: 0.2724367380142212, L4: 4.588894844055176, L5: 0.023032430559396744
Epoch 6000, Loss: 5.434808254241943, Losses: L1: 0.39298152923583984, L2: 0.28214550018310547, L3: 0.2699258327484131, L4: 4.478115081787109, L5: 0.02327994629740715
Epoch 6500, Loss: 5.353123664855957, Losses: L1: 0.39054208993911743, L2: 0.28196948766708374, L3: 0.26837724447250366, L4: 4.400492191314697, L5: 0.023485630750656128
Epoch 7000, Loss: 5.294933795928955, Losses: L1: 0.38872382044792175, L2: 0.28177908062934875, L3: 0.26768064498901367, L4: 4.344946384429932, L5: 0.023608053103089333
Epoch 7500, Loss: 5.253724575042725, Losses: L1: 0.38762685656547546, L2: 0.2818436920642853, L3: 0.26698625087738037, L4: 4.305391311645508, L5: 0.02375291846692562
Epoch 8000, Loss: 5.225025653839111, Losses: L1: 0.38721826672554016, L2: 0.2818584442138672, L3: 0.26626622676849365, L4: 4.277718544006348, L5: 0.023928452283143997
Epoch 8500, Loss: 5.204611301422119, Losses: L1: 0.3865245282649994, L2: 0.2822853922843933, L3: 0.26576173305511475, L4: 4.2580366134643555, L5: 0.024005932733416557
Epoch 9000, Loss: 5.19093656539917, Losses: L1: 0.38612881302833557, L2: 0.28246253728866577, L3: 0.2654479742050171, L4: 4.244864463806152, L5: 0.024065734818577766
Epoch 9500, Loss: 5.1818976402282715, Losses: L1: 0.3858864903450012, L2: 0.2825671136379242, L3: 0.26521235704421997, L4: 4.236178398132324, L5: 0.024106962606310844
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023250102996826, Constraint losses: L1: 18.42068099975586, L2: 0.00160982646048069, L3: 1.0016098022460938, L4: 1.0016098022460938
Epoch 500, Loss: 0.002822672948241234, Constraint losses: L1: -0.926938533782959, L2: 0.0, L3: 0.0028734803199768066, L4: 0.0008761313511058688
Epoch 1000, Loss: 0.0013941875658929348, Constraint losses: L1: -1.115249752998352, L2: 0.0, L3: 0.002254307270050049, L4: 0.0002551301149651408
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0079104900360107, Constraint losses: L1: 8.27390193939209, L2: 8.278413588413969e-06, L3: 0.9998143315315247, L4: 0.9998140335083008
Epoch 500, Loss: 0.002517424989491701, Constraint losses: L1: -1.0377883911132812, L2: 0.0, L3: 0.0027766823768615723, L4: 0.000778531190007925
Epoch 1000, Loss: 0.0014419795479625463, Constraint losses: L1: -1.0698801279067993, L2: 0.0, L3: 0.0022556185722351074, L4: 0.00025624115369282663
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 86.69813537597656, Losses: L1: 10.604985237121582, L2: 0.0007175793289206922, L3: 0.9986077547073364, L4: 74.75465393066406, L5: 0.3391696810722351
Epoch 500, Loss: 4.43337345123291, Losses: L1: 0.11423812061548233, L2: 0.10391560941934586, L3: 0.08571767807006836, L4: 4.059882640838623, L5: 0.06961923837661743
Epoch 1000, Loss: 0.9829522371292114, Losses: L1: 0.06606688350439072, L2: 0.07174082100391388, L3: 0.062299907207489014, L4: 0.7462561726570129, L5: 0.03658844530582428
Epoch 1500, Loss: 5.8457489013671875, Losses: L1: 1.5013269186019897, L2: 0.81425940990448, L3: 0.18681657314300537, L4: 3.3142402172088623, L5: 0.029106304049491882
Epoch 2000, Loss: 4.135870456695557, Losses: L1: 1.0941637754440308, L2: 0.37449848651885986, L3: 0.12825477123260498, L4: 2.5093722343444824, L5: 0.02958129718899727
Epoch 2500, Loss: 1.9923142194747925, Losses: L1: 0.21794365346431732, L2: 0.08780461549758911, L3: 0.10167551040649414, L4: 1.5697835683822632, L5: 0.015106829814612865
Epoch 3000, Loss: 1.238883137702942, Losses: L1: -0.11896008998155594, L2: 0.07069290429353714, L3: 0.0874640941619873, L4: 1.1832294464111328, L5: 0.016456667333841324
Epoch 3500, Loss: 0.5474942326545715, Losses: L1: -0.1506028026342392, L2: 0.05722658708691597, L3: 0.08776253461837769, L4: 0.5411639213562012, L5: 0.011943989433348179
Epoch 4000, Loss: 0.48489224910736084, Losses: L1: -0.15960243344306946, L2: 0.054880540817976, L3: 0.0868523120880127, L4: 0.49122899770736694, L5: 0.011532831937074661
Epoch 4500, Loss: 0.4459708034992218, Losses: L1: -0.16438153386116028, L2: 0.05340954288840294, L3: 0.0859520435333252, L4: 0.459689199924469, L5: 0.011301548220217228
Epoch 5000, Loss: 0.42593351006507874, Losses: L1: -0.16737903654575348, L2: 0.05269905924797058, L3: 0.08489811420440674, L4: 0.4445700943470001, L5: 0.011145269498229027
Epoch 5500, Loss: 0.410411536693573, Losses: L1: -0.16919931769371033, L2: 0.052141521126031876, L3: 0.08424222469329834, L4: 0.4321896731853485, L5: 0.011037442833185196
Epoch 6000, Loss: 0.3992995023727417, Losses: L1: -0.17031943798065186, L2: 0.0516570545732975, L3: 0.0837441086769104, L4: 0.4232600927352905, L5: 0.010957677848637104
Epoch 6500, Loss: 0.3917791545391083, Losses: L1: -0.1713954657316208, L2: 0.05139585956931114, L3: 0.08343225717544556, L4: 0.417450875043869, L5: 0.010895641520619392
Epoch 7000, Loss: 0.38668304681777954, Losses: L1: -0.1720556914806366, L2: 0.05111783742904663, L3: 0.08314049243927002, L4: 0.4136257767677307, L5: 0.010854621417820454
Epoch 7500, Loss: 0.3821225166320801, Losses: L1: -0.17255254089832306, L2: 0.050997890532016754, L3: 0.08297169208526611, L4: 0.4098770022392273, L5: 0.010828454047441483
Epoch 8000, Loss: 0.37890732288360596, Losses: L1: -0.17284661531448364, L2: 0.05086515098810196, L3: 0.08282452821731567, L4: 0.40724825859069824, L5: 0.010816005058586597
Epoch 8500, Loss: 0.37703391909599304, Losses: L1: -0.17308218777179718, L2: 0.05078178644180298, L3: 0.08271729946136475, L4: 0.405817449092865, L5: 0.010799556039273739
Epoch 9000, Loss: 0.37544310092926025, Losses: L1: -0.17325125634670258, L2: 0.05072878301143646, L3: 0.08265447616577148, L4: 0.40452155470848083, L5: 0.010789553634822369
Epoch 9500, Loss: 0.3744875192642212, Losses: L1: -0.1733909249305725, L2: 0.050691619515419006, L3: 0.08259797096252441, L4: 0.40380552411079407, L5: 0.010783320292830467
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0186240673065186, Constraint losses: L1: 17.693113327026367, L2: 0.0003979704051744193, L3: 1.000266671180725, L4: 1.0002663135528564
Epoch 500, Loss: 0.0022819621954113245, Constraint losses: L1: -1.1105036735534668, L2: 0.0, L3: 0.002695441246032715, L4: 0.0006970245740376413
Epoch 1000, Loss: 0.0013378176372498274, Constraint losses: L1: -1.1174204349517822, L2: 0.0, L3: 0.0022273659706115723, L4: 0.00022787218040321022
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.015592575073242, Constraint losses: L1: 15.503209114074707, L2: 0.00010594056220725179, L3: 0.9999915957450867, L4: 0.9999916553497314
Epoch 500, Loss: 0.002603160450235009, Constraint losses: L1: -0.982123076915741, L2: 0.0, L3: 0.0027914047241210938, L4: 0.0007938788621686399
Epoch 1000, Loss: 0.0014282743213698268, Constraint losses: L1: -1.0682705640792847, L2: 0.0, L3: 0.0022478699684143066, L4: 0.0002486750017851591
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 90.82814025878906, Losses: L1: 7.711585521697998, L2: 0.00019910802075173706, L3: 0.997089684009552, L4: 81.34294128417969, L5: 0.3881593644618988
Epoch 500, Loss: 30.415863037109375, Losses: L1: 2.871206283569336, L2: 2.839362144470215, L3: 0.2721765637397766, L4: 24.14626121520996, L5: 0.14342841506004333
Epoch 1000, Loss: 7.277061462402344, Losses: L1: 0.3340313732624054, L2: 0.3225536048412323, L3: 0.17057949304580688, L4: 6.37761116027832, L5: 0.03614291176199913
Epoch 1500, Loss: 1.4575244188308716, Losses: L1: -0.17780885100364685, L2: 0.09561239928007126, L3: 0.08439195156097412, L4: 1.4362422227859497, L5: 0.00954337790608406
Epoch 2000, Loss: 2.1603305339813232, Losses: L1: -0.15545108914375305, L2: 0.07164284586906433, L3: 0.07815289497375488, L4: 2.142911434173584, L5: 0.011537187732756138
Epoch 2500, Loss: 0.6772322058677673, Losses: L1: -0.2288006693124771, L2: 0.07092797756195068, L3: 0.07781684398651123, L4: 0.7446212768554688, L5: 0.00633337302133441
Epoch 3000, Loss: 0.38203006982803345, Losses: L1: -0.23739133775234222, L2: 0.06684195250272751, L3: 0.07834893465042114, L4: 0.4618780016899109, L5: 0.006176260765641928
Epoch 3500, Loss: 0.445919930934906, Losses: L1: -0.2308925837278366, L2: 0.06071174144744873, L3: 0.07725274562835693, L4: 0.5268920660018921, L5: 0.005977983120828867
Epoch 4000, Loss: 0.36745572090148926, Losses: L1: -0.23347073793411255, L2: 0.060027215629816055, L3: 0.07611322402954102, L4: 0.4529556334018707, L5: 0.0059151966124773026
Epoch 4500, Loss: 0.24847754836082458, Losses: L1: -0.2339288741350174, L2: 0.05906683951616287, L3: 0.07626307010650635, L4: 0.33532005548477173, L5: 0.005878228694200516
Epoch 5000, Loss: 0.2387864589691162, Losses: L1: -0.2360338717699051, L2: 0.058467186987400055, L3: 0.07587188482284546, L4: 0.3287877142429352, L5: 0.005846772342920303
Epoch 5500, Loss: 0.23355397582054138, Losses: L1: -0.23714269697666168, L2: 0.05803017318248749, L3: 0.07555854320526123, L4: 0.32544106245040894, L5: 0.00583344791084528
Epoch 6000, Loss: 0.22990906238555908, Losses: L1: -0.23775263130664825, L2: 0.057646896690130234, L3: 0.07534795999526978, L4: 0.3230211138725281, L5: 0.00582285737618804
Epoch 6500, Loss: 0.22671815752983093, Losses: L1: -0.2381127029657364, L2: 0.05735141411423683, L3: 0.07519614696502686, L4: 0.32064181566238403, L5: 0.005820746533572674
Epoch 7000, Loss: 0.22448013722896576, Losses: L1: -0.23843295872211456, L2: 0.05712707340717316, L3: 0.0750805139541626, L4: 0.31907081604003906, L5: 0.005817346274852753
Epoch 7500, Loss: 0.22288741171360016, Losses: L1: -0.23865190148353577, L2: 0.056973736733198166, L3: 0.07498002052307129, L4: 0.3179550766944885, L5: 0.0058152382262051105
Epoch 8000, Loss: 0.2216130793094635, Losses: L1: -0.23881100118160248, L2: 0.05684272199869156, L3: 0.07492232322692871, L4: 0.3170320987701416, L5: 0.005813468247652054
Epoch 8500, Loss: 0.2207268327474594, Losses: L1: -0.23892630636692047, L2: 0.0567561574280262, L3: 0.0748593807220459, L4: 0.31641069054603577, L5: 0.005813458003103733
Epoch 9000, Loss: 0.22002609074115753, Losses: L1: -0.23894834518432617, L2: 0.0566699281334877, L3: 0.07482898235321045, L4: 0.3158508241176605, L5: 0.0058123525232076645
Epoch 9500, Loss: 0.21954308450222015, Losses: L1: -0.23899951577186584, L2: 0.05662015825510025, L3: 0.07480579614639282, L4: 0.31549304723739624, L5: 0.005811805371195078
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0065150260925293, Constraint losses: L1: 7.539590358734131, L2: 1.2173478353361133e-05, L3: 0.9994816184043884, L4: 0.9994816184043884
Epoch 500, Loss: 0.0020892247557640076, Constraint losses: L1: -1.1141473054885864, L2: 0.0, L3: 0.0026009082794189453, L4: 0.0006024637841619551
Epoch 1000, Loss: 0.0012788815656676888, Constraint losses: L1: -1.1167700290679932, L2: 0.0, L3: 0.002197444438934326, L4: 0.00019820721354335546
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0051372051239014, Constraint losses: L1: 6.962309837341309, L2: 0.0, L3: 0.9990875124931335, L4: 0.9990872740745544
Epoch 500, Loss: 0.0025270734913647175, Constraint losses: L1: -1.0442447662353516, L2: 0.0, L3: 0.0027846097946166992, L4: 0.0007867086678743362
Epoch 1000, Loss: 0.0014369150158017874, Constraint losses: L1: -1.071143627166748, L2: 0.0, L3: 0.0022536516189575195, L4: 0.00025440703029744327
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 142.5529327392578, Losses: L1: 7.445900917053223, L2: 0.0003374369698576629, L3: 0.9984709024429321, L4: 66.98464965820312, L5: 0.27787259221076965
Epoch 500, Loss: 14.285840034484863, Losses: L1: 0.5942049622535706, L2: 0.19781985878944397, L3: 0.08949089050292969, L4: 6.69175386428833, L5: 0.04163343831896782
Epoch 1000, Loss: 10.861733436584473, Losses: L1: 3.3384032249450684, L2: 0.36150288581848145, L3: 0.15616095066070557, L4: 3.494894027709961, L5: 0.03175519406795502
Epoch 1500, Loss: 3.3064582347869873, Losses: L1: 0.05088919401168823, L2: 0.10139462351799011, L3: 0.07748514413833618, L4: 1.5354678630828857, L5: 0.011506968177855015
Epoch 2000, Loss: 1.7725753784179688, Losses: L1: -0.2545868754386902, L2: 0.0581088624894619, L3: 0.058469951152801514, L4: 0.9530099034309387, L5: 0.009127151221036911
Epoch 2500, Loss: 0.9154558777809143, Losses: L1: -0.24035407602787018, L2: 0.04659239575266838, L3: 0.05563700199127197, L4: 0.5248965620994568, L5: 0.007574963383376598
Epoch 3000, Loss: 0.4809647500514984, Losses: L1: -0.2717542052268982, L2: 0.04321304336190224, L3: 0.0524601936340332, L4: 0.3267584443092346, L5: 0.007057638373225927
Epoch 3500, Loss: 0.412881463766098, Losses: L1: -0.2749010920524597, L2: 0.03749578073620796, L3: 0.05120265483856201, L4: 0.2977829873561859, L5: 0.007036283612251282
Epoch 4000, Loss: 0.08689480274915695, Losses: L1: -0.2740347981452942, L2: 0.034022506326436996, L3: 0.05044353008270264, L4: 0.1365388035774231, L5: 0.006771902088075876
Epoch 4500, Loss: 0.098953977227211, Losses: L1: -0.2772974967956543, L2: 0.03192690387368202, L3: 0.04994058609008789, L4: 0.14552457630634308, L5: 0.006669670809060335
Epoch 5000, Loss: 0.03910239040851593, Losses: L1: -0.2767221927642822, L2: 0.02898605354130268, L3: 0.049627065658569336, L4: 0.11696138978004456, L5: 0.006577373947948217
Epoch 5500, Loss: 0.02906728908419609, Losses: L1: -0.2775557041168213, L2: 0.0276590995490551, L3: 0.049405574798583984, L4: 0.11314978450536728, L5: 0.006517490837723017
Epoch 6000, Loss: 0.02304861694574356, Losses: L1: -0.2780328392982483, L2: 0.026749007403850555, L3: 0.04927372932434082, L4: 0.11091147363185883, L5: 0.006471527740359306
Epoch 6500, Loss: 0.018113091588020325, Losses: L1: -0.2784995138645172, L2: 0.026154451072216034, L3: 0.04917764663696289, L4: 0.10902933776378632, L5: 0.006443650461733341
Epoch 7000, Loss: 0.014997907914221287, Losses: L1: -0.27876535058021545, L2: 0.02616093121469021, L3: 0.049063682556152344, L4: 0.10766330361366272, L5: 0.0064240857027471066
Epoch 7500, Loss: 0.012603942304849625, Losses: L1: -0.2789457142353058, L2: 0.026210006326436996, L3: 0.048988401889801025, L4: 0.10657328367233276, L5: 0.006409353576600552
Epoch 8000, Loss: 0.010990593582391739, Losses: L1: -0.2791060209274292, L2: 0.026192132383584976, L3: 0.048937320709228516, L4: 0.10588385164737701, L5: 0.00639892416074872
Epoch 8500, Loss: 0.009906268678605556, Losses: L1: -0.27926284074783325, L2: 0.02623623050749302, L3: 0.048900067806243896, L4: 0.10541833937168121, L5: 0.0063922530971467495
Epoch 9000, Loss: 0.008998855948448181, Losses: L1: -0.2793675661087036, L2: 0.02628949284553528, L3: 0.04887211322784424, L4: 0.10500532388687134, L5: 0.006388336420059204
Epoch 9500, Loss: 0.008446888998150826, Losses: L1: -0.279438853263855, L2: 0.026331163942813873, L3: 0.04885357618331909, L4: 0.10475414991378784, L5: 0.006385419983416796
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.019108533859253, Constraint losses: L1: 18.42068099975586, L2: 0.0002292655990459025, L3: 1.0002292394638062, L4: 1.0002293586730957
Epoch 500, Loss: 0.0021884238813072443, Constraint losses: L1: -1.1143299341201782, L2: 0.0, L3: 0.0026506781578063965, L4: 0.000652075745165348
Epoch 1000, Loss: 0.0013149669393897057, Constraint losses: L1: -1.1172431707382202, L2: 0.0, L3: 0.0022159218788146973, L4: 0.00021628820104524493
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0072014331817627, Constraint losses: L1: 7.9409942626953125, L2: 0.0, L3: 0.9996302723884583, L4: 0.9996302127838135
Epoch 500, Loss: 0.0021851614583283663, Constraint losses: L1: -1.0592819452285767, L2: 0.0, L3: 0.0026214122772216797, L4: 0.0006230312283150852
Epoch 1000, Loss: 0.0013383689802139997, Constraint losses: L1: -1.0699535608291626, L2: 0.0, L3: 0.0022038817405700684, L4: 0.00020444084657356143
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 184.5413055419922, Losses: L1: 17.24275779724121, L2: 0.0001433577126590535, L3: 1.0001378059387207, L4: 82.94817352294922, L5: 0.4019133150577545
Epoch 500, Loss: 7.380745887756348, Losses: L1: 0.5049285292625427, L2: 0.0664466843008995, L3: 0.1297803521156311, L4: 3.320375919342041, L5: 0.03883820027112961
Epoch 1000, Loss: 3.7617151737213135, Losses: L1: -0.13221940398216248, L2: 0.07723616808652878, L3: 0.08695769309997559, L4: 1.8604145050048828, L5: 0.008911692537367344
Epoch 1500, Loss: 4.285525798797607, Losses: L1: -0.19165003299713135, L2: 0.06356210261583328, L3: 0.07262754440307617, L4: 2.158447504043579, L5: 0.024091051891446114
Epoch 2000, Loss: 0.974323570728302, Losses: L1: -0.22575852274894714, L2: 0.048012979328632355, L3: 0.06893020868301392, L4: 0.5376380681991577, L5: 0.007862770929932594
Epoch 2500, Loss: 0.8188486695289612, Losses: L1: -0.24082405865192413, L2: 0.04979085922241211, L3: 0.06349444389343262, L4: 0.4687063694000244, L5: 0.00897470023483038
Epoch 3000, Loss: 0.8711195588111877, Losses: L1: -0.25503432750701904, L2: 0.05079279839992523, L3: 0.06180775165557861, L4: 0.502675473690033, L5: 0.008202373050153255
Epoch 3500, Loss: 0.4799013137817383, Losses: L1: -0.25792619585990906, L2: 0.048653580248355865, L3: 0.060607075691223145, L4: 0.31139954924583435, L5: 0.005767770577222109
Epoch 4000, Loss: 0.2931799590587616, Losses: L1: -0.2623975872993469, L2: 0.050184205174446106, L3: 0.06003987789154053, L4: 0.21954089403152466, L5: 0.006271675694733858
Epoch 4500, Loss: 0.2268155962228775, Losses: L1: -0.2631648778915405, L2: 0.04865958169102669, L3: 0.05959475040435791, L4: 0.18788066506385803, L5: 0.005964809563010931
Epoch 5000, Loss: 0.2065790295600891, Losses: L1: -0.263642817735672, L2: 0.04799837991595268, L3: 0.05939209461212158, L4: 0.17840902507305145, L5: 0.00601331377401948
Epoch 5500, Loss: 0.20305295288562775, Losses: L1: -0.2645609378814697, L2: 0.04760712757706642, L3: 0.05905294418334961, L4: 0.17750772833824158, L5: 0.005938365589827299
Epoch 6000, Loss: 0.18918675184249878, Losses: L1: -0.26522719860076904, L2: 0.04752911999821663, L3: 0.05885422229766846, L4: 0.1710381805896759, L5: 0.005954248830676079
Epoch 6500, Loss: 0.18585745990276337, Losses: L1: -0.2651480734348297, L2: 0.04699833691120148, L3: 0.05875927209854126, L4: 0.1696474850177765, L5: 0.005952948704361916
Epoch 7000, Loss: 0.18200479447841644, Losses: L1: -0.26567140221595764, L2: 0.047110505402088165, L3: 0.05860096216201782, L4: 0.16801413893699646, L5: 0.005936456844210625
Epoch 7500, Loss: 0.17924843728542328, Losses: L1: -0.2657466530799866, L2: 0.046929873526096344, L3: 0.058497488498687744, L4: 0.1668190211057663, L5: 0.005929689854383469
Epoch 8000, Loss: 0.17753739655017853, Losses: L1: -0.2657744884490967, L2: 0.0468224436044693, L3: 0.058420419692993164, L4: 0.16607080399990082, L5: 0.00592740997672081
Epoch 8500, Loss: 0.17632721364498138, Losses: L1: -0.26591941714286804, L2: 0.046753011643886566, L3: 0.05838727951049805, L4: 0.1655917912721634, L5: 0.005922744516283274
Epoch 9000, Loss: 0.17539501190185547, Losses: L1: -0.26597633957862854, L2: 0.04667961224913597, L3: 0.05835789442062378, L4: 0.16520778834819794, L5: 0.005918262992054224
Epoch 9500, Loss: 0.17472006380558014, Losses: L1: -0.26601672172546387, L2: 0.046632926911115646, L3: 0.05833792686462402, L4: 0.1649242341518402, L5: 0.005917462985962629
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.033639907836914, Constraint losses: L1: 18.42068099975586, L2: 0.005072448868304491, L3: 1.0050724744796753, L4: 1.0050742626190186
Epoch 500, Loss: 0.0022112298756837845, Constraint losses: L1: -1.102533221244812, L2: 0.0, L3: 0.002656102180480957, L4: 0.0006576608866453171
Epoch 1000, Loss: 0.0013052041176706553, Constraint losses: L1: -1.1182781457901, L2: 0.0, L3: 0.0022115111351013184, L4: 0.00021197128808125854
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0200343132019043, Constraint losses: L1: 18.42068099975586, L2: 0.000537825864739716, L3: 1.0005378723144531, L4: 1.0005378723144531
Epoch 500, Loss: 0.0022466909140348434, Constraint losses: L1: -0.9974647760391235, L2: 0.0, L3: 0.0026210546493530273, L4: 0.0006231010193005204
Epoch 1000, Loss: 0.0013141622766852379, Constraint losses: L1: -1.0697712898254395, L2: 0.0, L3: 0.002191781997680664, L4: 0.00019215168140362948
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 173.69320678710938, Losses: L1: 5.88806676864624, L2: 2.344095082662534e-05, L3: 0.9971131682395935, L4: 83.00495910644531, L5: 0.39903828501701355
Epoch 500, Loss: 17.700790405273438, Losses: L1: 3.9932754039764404, L2: 0.8245095610618591, L3: 0.10234272480010986, L4: 6.345716953277588, L5: 0.04461519047617912
Epoch 1000, Loss: 3.1200082302093506, Losses: L1: 0.25113222002983093, L2: 0.24724237620830536, L3: 0.06764739751815796, L4: 1.26088547706604, L5: 0.0161077119410038
Epoch 1500, Loss: 1.2925080060958862, Losses: L1: -0.13960407674312592, L2: 0.04477478563785553, L3: 0.061457157135009766, L4: 0.6558825969696045, L5: 0.007057467475533485
Epoch 2000, Loss: 2.687351703643799, Losses: L1: -0.028636101633310318, L2: 0.0643000453710556, L3: 0.051502108573913574, L4: 1.2890969514846802, L5: 0.010995916090905666
Epoch 2500, Loss: 0.6429609060287476, Losses: L1: -0.25492170453071594, L2: 0.04878314211964607, L3: 0.051839470863342285, L4: 0.39272698760032654, L5: 0.0059030018746852875
Epoch 3000, Loss: 0.5345355272293091, Losses: L1: -0.26054278016090393, L2: 0.03690958023071289, L3: 0.051349639892578125, L4: 0.3476099371910095, L5: 0.0057995994575321674
Epoch 3500, Loss: 0.3239072263240814, Losses: L1: -0.27255403995513916, L2: 0.03937554359436035, L3: 0.04998922348022461, L4: 0.24774903059005737, L5: 0.005799224134534597
Epoch 4000, Loss: 0.13503728806972504, Losses: L1: -0.26947951316833496, L2: 0.03605521470308304, L3: 0.049655139446258545, L4: 0.15361107885837555, L5: 0.005792149808257818
Epoch 4500, Loss: 0.12967179715633392, Losses: L1: -0.27140122652053833, L2: 0.03455967456102371, L3: 0.049628496170043945, L4: 0.15265370905399323, L5: 0.005788721144199371
Epoch 5000, Loss: 0.09094629436731339, Losses: L1: -0.2711254060268402, L2: 0.03387304022908211, L3: 0.04951775074005127, L4: 0.13357199728488922, L5: 0.005768459290266037
Epoch 5500, Loss: 0.0846213698387146, Losses: L1: -0.2706741392612457, L2: 0.033134493976831436, L3: 0.04953420162200928, L4: 0.13055232167243958, L5: 0.005761086009442806
Epoch 6000, Loss: 0.07286283373832703, Losses: L1: -0.2714046239852905, L2: 0.033106427639722824, L3: 0.04946458339691162, L4: 0.12508979439735413, L5: 0.0057584261521697044
Epoch 6500, Loss: 0.06865371763706207, Losses: L1: -0.2714267671108246, L2: 0.03303597494959831, L3: 0.049437642097473145, L4: 0.12304870784282684, L5: 0.005754723679274321
Epoch 7000, Loss: 0.06571435183286667, Losses: L1: -0.2711336016654968, L2: 0.03284456208348274, L3: 0.04941093921661377, L4: 0.12154025584459305, L5: 0.005755973514169455
Epoch 7500, Loss: 0.06379193812608719, Losses: L1: -0.2710005044937134, L2: 0.0327465794980526, L3: 0.049394965171813965, L4: 0.12057226896286011, L5: 0.0057531786151230335
Epoch 8000, Loss: 0.06256777048110962, Losses: L1: -0.2708885073661804, L2: 0.03268822655081749, L3: 0.04937779903411865, L4: 0.11994200944900513, L5: 0.005753114353865385
Epoch 8500, Loss: 0.06156780570745468, Losses: L1: -0.27080172300338745, L2: 0.03264145180583, L3: 0.04936915636062622, L4: 0.11942841857671738, L5: 0.0057510389015078545
Epoch 9000, Loss: 0.0609750859439373, Losses: L1: -0.2707294523715973, L2: 0.03259509429335594, L3: 0.049363911151885986, L4: 0.1191229596734047, L5: 0.005749805364757776
Epoch 9500, Loss: 0.060404494404792786, Losses: L1: -0.2706861197948456, L2: 0.03259227052330971, L3: 0.04935634136199951, L4: 0.11882103979587555, L5: 0.005749963223934174
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.022143840789795, Constraint losses: L1: 18.42068099975586, L2: 0.001240768819116056, L3: 1.0012407302856445, L4: 1.001241683959961
Epoch 500, Loss: 0.0021438105031847954, Constraint losses: L1: -1.1140000820159912, L2: 0.0, L3: 0.002628147602081299, L4: 0.0006296631181612611
Epoch 1000, Loss: 0.0013001954648643732, Constraint losses: L1: -1.118079423904419, L2: 0.0, L3: 0.002208888530731201, L4: 0.00020938643137924373
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0346741676330566, Constraint losses: L1: 18.42068099975586, L2: 0.005417645908892155, L3: 1.0054177045822144, L4: 1.005418062210083
Epoch 500, Loss: 0.0022441374603658915, Constraint losses: L1: -0.9028902053833008, L2: 0.0, L3: 0.002572357654571533, L4: 0.0005746700335294008
Epoch 1000, Loss: 0.001250575645826757, Constraint losses: L1: -1.0635632276535034, L2: 0.0, L3: 0.0021567940711975098, L4: 0.00015734482440166175
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.310123443603516, Losses: L1: 12.819924354553223, L2: 9.758384840097278e-05, L3: 0.9999427199363708, L4: 78.60858154296875, L5: 0.3718513250350952
Epoch 500, Loss: 33.65116882324219, Losses: L1: 5.073212146759033, L2: 0.0078060207888484, L3: 0.9881236553192139, L4: 53.010738372802734, L5: 0.17706967890262604
Epoch 1000, Loss: 5.112476348876953, Losses: L1: 0.5467348694801331, L2: 0.4257228374481201, L3: 0.24093186855316162, L4: 7.280986785888672, L5: 0.035323500633239746
Epoch 1500, Loss: 3.197819709777832, Losses: L1: 0.12999491393566132, L2: 0.23382370173931122, L3: 0.17289382219314575, L4: 4.951269626617432, L5: 0.025156991556286812
Epoch 2000, Loss: 1.7468745708465576, Losses: L1: 0.010777168907225132, L2: 0.18172340095043182, L3: 0.15497970581054688, L4: 2.4735679626464844, L5: 0.015261096879839897
Epoch 2500, Loss: 6.6052656173706055, Losses: L1: 0.3723435401916504, L2: 0.21051698923110962, L3: 0.1416633129119873, L4: 11.384805679321289, L5: 0.09335098415613174
Epoch 3000, Loss: 1.507922887802124, Losses: L1: 0.030494676902890205, L2: 0.15592823922634125, L3: 0.15176427364349365, L4: 2.019148349761963, L5: 0.01679455302655697
Epoch 3500, Loss: 1.3329485654830933, Losses: L1: 0.0017013150500133634, L2: 0.14785102009773254, L3: 0.14017659425735474, L4: 1.7899866104125977, L5: 0.01609944738447666
Epoch 4000, Loss: 1.2678405046463013, Losses: L1: -0.0011959323892369866, L2: 0.1464809626340866, L3: 0.13580667972564697, L4: 1.6864877939224243, L5: 0.015396340750157833
Epoch 4500, Loss: 1.2295498847961426, Losses: L1: -0.005395624320954084, L2: 0.14578008651733398, L3: 0.13333064317703247, L4: 1.6298818588256836, L5: 0.015126544050872326
Epoch 5000, Loss: 1.2062938213348389, Losses: L1: -0.006273216567933559, L2: 0.1447037309408188, L3: 0.1320565938949585, L4: 1.5927777290344238, L5: 0.014722427353262901
Epoch 5500, Loss: 1.1904406547546387, Losses: L1: -0.007525917608290911, L2: 0.14427708089351654, L3: 0.13103139400482178, L4: 1.5688283443450928, L5: 0.014424938708543777
Epoch 6000, Loss: 1.1803338527679443, Losses: L1: -0.009649667888879776, L2: 0.14440739154815674, L3: 0.13013970851898193, L4: 1.5563266277313232, L5: 0.014266811311244965
Epoch 6500, Loss: 1.1712156534194946, Losses: L1: -0.008928871713578701, L2: 0.14362269639968872, L3: 0.1297910213470459, L4: 1.5398368835449219, L5: 0.014042563736438751
Epoch 7000, Loss: 1.1655020713806152, Losses: L1: -0.009107109159231186, L2: 0.14319941401481628, L3: 0.12945693731307983, L4: 1.531076431274414, L5: 0.0139153515920043
Epoch 7500, Loss: 1.1609324216842651, Losses: L1: -0.009672907181084156, L2: 0.1429605484008789, L3: 0.12918514013290405, L4: 1.5246949195861816, L5: 0.013854018412530422
Epoch 8000, Loss: 1.1579290628433228, Losses: L1: -0.010106327012181282, L2: 0.14280965924263, L3: 0.1289900541305542, L4: 1.5206966400146484, L5: 0.013794662430882454
Epoch 8500, Loss: 1.1557559967041016, Losses: L1: -0.0102529376745224, L2: 0.14266948401927948, L3: 0.1288996934890747, L4: 1.5173351764678955, L5: 0.013744767755270004
Epoch 9000, Loss: 1.1543108224868774, Losses: L1: -0.010459130629897118, L2: 0.14260971546173096, L3: 0.12883234024047852, L4: 1.5152827501296997, L5: 0.013708422891795635
Epoch 9500, Loss: 1.1532938480377197, Losses: L1: -0.01053414586931467, L2: 0.1425437033176422, L3: 0.12880587577819824, L4: 1.5136668682098389, L5: 0.013678048737347126
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9965848922729492, Constraint losses: L1: 5.337679862976074, L2: 0.0, L3: 0.9956244230270386, L4: 0.9956227540969849
Epoch 500, Loss: 0.002141614444553852, Constraint losses: L1: -1.0843733549118042, L2: 0.0, L3: 0.0026122331619262695, L4: 0.0006137547316029668
Epoch 1000, Loss: 0.001271863584406674, Constraint losses: L1: -1.1176470518112183, L2: 0.0, L3: 0.002194523811340332, L4: 0.0001949869329109788
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0241024494171143, Constraint losses: L1: 18.42068099975586, L2: 0.001893920823931694, L3: 1.0018938779830933, L4: 1.0018939971923828
Epoch 500, Loss: 0.002528424607589841, Constraint losses: L1: -0.9826309680938721, L2: 0.0, L3: 0.0027543306350708008, L4: 0.0007567249704152346
Epoch 1000, Loss: 0.001377145410515368, Constraint losses: L1: -1.0716526508331299, L2: 0.0, L3: 0.002224147319793701, L4: 0.00022465083748102188
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.96934127807617, Losses: L1: 15.597871780395508, L2: 0.0007279880228452384, L3: 1.0003968477249146, L4: 78.01000213623047, L5: 0.3649492859840393
Epoch 500, Loss: 9.180168151855469, Losses: L1: 3.721864938735962, L2: 0.14231829345226288, L3: 0.20431041717529297, L4: 9.653301239013672, L5: 0.08071309328079224
Epoch 1000, Loss: 42.39549255371094, Losses: L1: 15.198137283325195, L2: 0.0021595428697764874, L3: 0.9997936487197876, L4: 50.00045394897461, L5: 0.19538001716136932
Epoch 1500, Loss: 32.10211944580078, Losses: L1: 5.822829723358154, L2: 0.26598650217056274, L3: 0.8845618367195129, L4: 48.14406204223633, L5: 0.17214779555797577
Epoch 2000, Loss: 20.38094711303711, Losses: L1: 5.2203264236450195, L2: 0.8806673884391785, L3: 0.6463062167167664, L4: 25.81429100036621, L5: 0.08019708842039108
Epoch 2500, Loss: 6.446812629699707, Losses: L1: 0.982594907283783, L2: 0.35622453689575195, L3: 0.26136481761932373, L4: 9.093727111816406, L5: 0.038399577140808105
Epoch 3000, Loss: 3.158048391342163, Losses: L1: 0.18478824198246002, L2: 0.1651000678539276, L3: 0.17409706115722656, L4: 4.874201774597168, L5: 0.022865114733576775
Epoch 3500, Loss: 1.476014256477356, Losses: L1: -0.1256948858499527, L2: 0.1988420933485031, L3: 0.1405726671218872, L4: 2.201125144958496, L5: 0.02115919627249241
Epoch 4000, Loss: 1.2898883819580078, Losses: L1: -0.14098133146762848, L2: 0.19750705361366272, L3: 0.13114917278289795, L4: 1.9004449844360352, L5: 0.02084178477525711
Epoch 4500, Loss: 1.2049270868301392, Losses: L1: -0.14835520088672638, L2: 0.19433705508708954, L3: 0.12644386291503906, L4: 1.7702327966690063, L5: 0.020941106602549553
Epoch 5000, Loss: 1.1579828262329102, Losses: L1: -0.14885416626930237, L2: 0.18848766386508942, L3: 0.12437844276428223, L4: 1.6975791454315186, L5: 0.020802902057766914
Epoch 5500, Loss: 1.1274827718734741, Losses: L1: -0.1511053889989853, L2: 0.18551968038082123, L3: 0.1229090690612793, L4: 1.6540250778198242, L5: 0.020237773656845093
Epoch 6000, Loss: 1.1074755191802979, Losses: L1: -0.1523260921239853, L2: 0.18346673250198364, L3: 0.12170439958572388, L4: 1.6256308555603027, L5: 0.0201105959713459
Epoch 6500, Loss: 1.0935351848602295, Losses: L1: -0.15447913110256195, L2: 0.18292883038520813, L3: 0.12060374021530151, L4: 1.608026385307312, L5: 0.019864831119775772
Epoch 7000, Loss: 1.0830018520355225, Losses: L1: -0.1544003039598465, L2: 0.18177291750907898, L3: 0.11996138095855713, L4: 1.591439962387085, L5: 0.019986514002084732
Epoch 7500, Loss: 1.0758781433105469, Losses: L1: -0.15513324737548828, L2: 0.18143552541732788, L3: 0.11938285827636719, L4: 1.5816607475280762, L5: 0.01997976191341877
Epoch 8000, Loss: 1.0708426237106323, Losses: L1: -0.15573835372924805, L2: 0.18118803203105927, L3: 0.1190025806427002, L4: 1.5748686790466309, L5: 0.019953347742557526
Epoch 8500, Loss: 1.0673037767410278, Losses: L1: -0.15621085464954376, L2: 0.18110217154026031, L3: 0.11868917942047119, L4: 1.5701807737350464, L5: 0.019943702965974808
Epoch 9000, Loss: 1.0650237798690796, Losses: L1: -0.1563345342874527, L2: 0.18086932599544525, L3: 0.11853086948394775, L4: 1.566962718963623, L5: 0.01994580402970314
Epoch 9500, Loss: 1.0634609460830688, Losses: L1: -0.15645037591457367, L2: 0.1807539463043213, L3: 0.11843127012252808, L4: 1.5647084712982178, L5: 0.019940607249736786
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.000265598297119, Constraint losses: L1: 5.858645439147949, L2: 0.0, L3: 0.9972036480903625, L4: 0.9972034692764282
Epoch 500, Loss: 0.0025323466397821903, Constraint losses: L1: -1.0899760723114014, L2: 0.0, L3: 0.002810060977935791, L4: 0.0008122617146000266
Epoch 1000, Loss: 0.0014085050206631422, Constraint losses: L1: -1.1182329654693604, L2: 0.0, L3: 0.002263009548187256, L4: 0.0002637284342199564
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9952187538146973, Constraint losses: L1: 5.276800632476807, L2: 0.0, L3: 0.9949711561203003, L4: 0.9949707984924316
Epoch 500, Loss: 0.002189299324527383, Constraint losses: L1: -1.0408364534378052, L2: 0.0, L3: 0.002614259719848633, L4: 0.0006158761098049581
Epoch 1000, Loss: 0.0013283159350976348, Constraint losses: L1: -1.069879412651062, L2: 0.0, L3: 0.00219881534576416, L4: 0.00019938009791076183
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.24635696411133, Losses: L1: 18.42068099975586, L2: 0.0019213216146454215, L3: 1.00192129611969, L4: 70.38590240478516, L5: 0.3134799599647522
Epoch 500, Loss: 1.6410387754440308, Losses: L1: 0.04585589841008186, L2: 0.13494658470153809, L3: 0.1137005090713501, L4: 2.4251534938812256, L5: 0.010129288770258427
Epoch 1000, Loss: 1.9945247173309326, Losses: L1: -0.1076161116361618, L2: 0.05118650943040848, L3: 0.0854792594909668, L4: 3.6514902114868164, L5: 0.027125367894768715
Epoch 1500, Loss: 0.7129641175270081, Losses: L1: -0.23517517745494843, L2: 0.050252415239810944, L3: 0.06258058547973633, L4: 1.5010490417480469, L5: 0.011100579053163528
Epoch 2000, Loss: 1.1279414892196655, Losses: L1: 0.016302453354001045, L2: 0.06933941692113876, L3: 0.06309360265731812, L4: 1.7871005535125732, L5: 0.011281045153737068
Epoch 2500, Loss: 0.1271381378173828, Losses: L1: -0.2678123116493225, L2: 0.04367584362626076, L3: 0.05641454458236694, L4: 0.45230233669281006, L5: 0.0061471727676689625
Epoch 3000, Loss: 0.48470765352249146, Losses: L1: -0.17702148854732513, L2: 0.06526045501232147, L3: 0.09504830837249756, L4: 0.7863329648971558, L5: 0.00660279393196106
Epoch 3500, Loss: 0.2905867397785187, Losses: L1: -0.20464017987251282, L2: 0.058354105800390244, L3: 0.08496302366256714, L4: 0.5085750818252563, L5: 0.006329606287181377
Epoch 4000, Loss: 0.23599712550640106, Losses: L1: -0.2158304899930954, L2: 0.05504297837615013, L3: 0.07903814315795898, L4: 0.45355623960494995, L5: 0.005965110845863819
Epoch 4500, Loss: 0.20166897773742676, Losses: L1: -0.22382421791553497, L2: 0.05295971408486366, L3: 0.07601797580718994, L4: 0.41779500246047974, L5: 0.005800014361739159
Epoch 5000, Loss: 0.18018527328968048, Losses: L1: -0.2270183563232422, L2: 0.05195256322622299, L3: 0.07419121265411377, L4: 0.3908107578754425, L5: 0.005731629207730293
Epoch 5500, Loss: 0.16499917209148407, Losses: L1: -0.2279643714427948, L2: 0.05105212703347206, L3: 0.07311296463012695, L4: 0.36834436655044556, L5: 0.005756653379648924
Epoch 6000, Loss: 0.15540316700935364, Losses: L1: -0.22821839153766632, L2: 0.05039004981517792, L3: 0.0723501443862915, L4: 0.3540339171886444, L5: 0.005757134407758713
Epoch 6500, Loss: 0.14890336990356445, Losses: L1: -0.2283080518245697, L2: 0.049845848232507706, L3: 0.07182246446609497, L4: 0.34439560770988464, L5: 0.005761421285569668
Epoch 7000, Loss: 0.14414720237255096, Losses: L1: -0.2282339632511139, L2: 0.04948977380990982, L3: 0.0714033842086792, L4: 0.33713245391845703, L5: 0.00575920520350337
Epoch 7500, Loss: 0.14078599214553833, Losses: L1: -0.22812668979167938, L2: 0.04922918602824211, L3: 0.07109189033508301, L4: 0.33195894956588745, L5: 0.0057601178996264935
Epoch 8000, Loss: 0.13830482959747314, Losses: L1: -0.2281641960144043, L2: 0.04905562102794647, L3: 0.07085633277893066, L4: 0.3283655047416687, L5: 0.005758993327617645
Epoch 8500, Loss: 0.13645392656326294, Losses: L1: -0.22813327610492706, L2: 0.048912640661001205, L3: 0.07068192958831787, L4: 0.3255890905857086, L5: 0.005758078768849373
Epoch 9000, Loss: 0.1350862979888916, Losses: L1: -0.22804835438728333, L2: 0.04879399761557579, L3: 0.07055008411407471, L4: 0.3234536051750183, L5: 0.00575683731585741
Epoch 9500, Loss: 0.13409490883350372, Losses: L1: -0.22796735167503357, L2: 0.04871692135930061, L3: 0.07045102119445801, L4: 0.32185882329940796, L5: 0.005756946746259928
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.002777576446533, Constraint losses: L1: 6.28941011428833, L2: 0.0, L3: 0.9982443451881409, L4: 0.9982438087463379
Epoch 500, Loss: 0.0020114697981625795, Constraint losses: L1: -1.088806390762329, L2: 0.0, L3: 0.0025493502616882324, L4: 0.0005509259644895792
Epoch 1000, Loss: 0.0012368158204481006, Constraint losses: L1: -1.1183942556381226, L2: 0.0, L3: 0.002177298069000244, L4: 0.00017791209393180907
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001094102859497, Constraint losses: L1: 6.007312774658203, L2: 0.0, L3: 0.9975433349609375, L4: 0.997543454170227
Epoch 500, Loss: 0.0021509218495339155, Constraint losses: L1: -1.0249803066253662, L2: 0.0, L3: 0.00258713960647583, L4: 0.0005887626321054995
Epoch 1000, Loss: 0.0013059996999800205, Constraint losses: L1: -1.069790244102478, L2: 0.0, L3: 0.002187669277191162, L4: 0.0001881207135738805
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 85.58641815185547, Losses: L1: 13.218839645385742, L2: 0.0008951509371399879, L3: 1.0002754926681519, L4: 70.2125473022461, L5: 0.30717334151268005
Epoch 500, Loss: 8.971875190734863, Losses: L1: 1.019271969795227, L2: 0.40409934520721436, L3: 0.12737607955932617, L4: 7.273214340209961, L5: 0.04107452556490898
Epoch 1000, Loss: 1.648260235786438, Losses: L1: -0.24644681811332703, L2: 0.06587230414152145, L3: 0.04766690731048584, L4: 1.7285823822021484, L5: 0.009837049059569836
Epoch 1500, Loss: 0.5446593165397644, Losses: L1: -0.2654125988483429, L2: 0.031205620616674423, L3: 0.05038875341415405, L4: 0.6746330857276917, L5: 0.0069114393554627895
Epoch 2000, Loss: 2.6456799507141113, Losses: L1: 0.29457032680511475, L2: 0.31866058707237244, L3: 0.04663240909576416, L4: 1.9337828159332275, L5: 0.010802938602864742
Epoch 2500, Loss: 0.9670878052711487, Losses: L1: -0.23732981085777283, L2: 0.03133682906627655, L3: 0.05218285322189331, L4: 1.0623364448547363, L5: 0.012757331132888794
Epoch 3000, Loss: 0.09446295350790024, Losses: L1: -0.2510538101196289, L2: 0.028491787612438202, L3: 0.05050230026245117, L4: 0.21277597546577454, L5: 0.006488792132586241
Epoch 3500, Loss: 0.11440609395503998, Losses: L1: -0.2557692229747772, L2: 0.03000306338071823, L3: 0.05097699165344238, L4: 0.2349657416343689, L5: 0.006505048368126154
Epoch 4000, Loss: 0.08000448346138, Losses: L1: -0.2581847012042999, L2: 0.03062983974814415, L3: 0.05086928606033325, L4: 0.20271463692188263, L5: 0.006212261971086264
Epoch 4500, Loss: 0.02094285748898983, Losses: L1: -0.2579231262207031, L2: 0.02988174371421337, L3: 0.05072152614593506, L4: 0.14460928738117218, L5: 0.0058637959882617
Epoch 5000, Loss: 0.016729479655623436, Losses: L1: -0.25768768787384033, L2: 0.029100537300109863, L3: 0.05067932605743408, L4: 0.14103983342647552, L5: 0.005836288910359144
Epoch 5500, Loss: 0.012580476701259613, Losses: L1: -0.25812551379203796, L2: 0.02865363471210003, L3: 0.05069410800933838, L4: 0.13776840269565582, L5: 0.005791469942778349
Epoch 6000, Loss: 0.010527001693844795, Losses: L1: -0.2587476372718811, L2: 0.028455669060349464, L3: 0.05060124397277832, L4: 0.13672900199890137, L5: 0.00577494828030467
Epoch 6500, Loss: 0.009144880808889866, Losses: L1: -0.25933149456977844, L2: 0.02842702530324459, L3: 0.05057245492935181, L4: 0.1360243409872055, L5: 0.005760209169238806
Epoch 7000, Loss: 0.007996615022420883, Losses: L1: -0.2596224546432495, L2: 0.028379665687680244, L3: 0.05052757263183594, L4: 0.13531281054019928, L5: 0.005742899142205715
Epoch 7500, Loss: 0.00716818030923605, Losses: L1: -0.25992798805236816, L2: 0.028381889685988426, L3: 0.050495445728302, L4: 0.13485464453697205, L5: 0.0057374960742890835
Epoch 8000, Loss: 0.006511234678328037, Losses: L1: -0.26008114218711853, L2: 0.02834327332675457, L3: 0.05047416687011719, L4: 0.13443537056446075, L5: 0.0057307942770421505
Epoch 8500, Loss: 0.006063670851290226, Losses: L1: -0.26023101806640625, L2: 0.028349626809358597, L3: 0.05045515298843384, L4: 0.13417255878448486, L5: 0.00572440167888999
Epoch 9000, Loss: 0.005742980632930994, Losses: L1: -0.26031410694122314, L2: 0.02833676151931286, L3: 0.05044090747833252, L4: 0.13397790491580963, L5: 0.005721208639442921
Epoch 9500, Loss: 0.005478494800627232, Losses: L1: -0.26041027903556824, L2: 0.0283452570438385, L3: 0.05042904615402222, L4: 0.13382554054260254, L5: 0.005719768349081278
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.025827169418335, Constraint losses: L1: 18.42068099975586, L2: 0.0024688730482012033, L3: 1.0024688243865967, L4: 1.0024688243865967
Epoch 500, Loss: 0.002073925454169512, Constraint losses: L1: -1.0302655696868896, L2: 0.0, L3: 0.0025511980056762695, L4: 0.0005529930349439383
Epoch 1000, Loss: 0.0012062208261340857, Constraint losses: L1: -1.1171345710754395, L2: 0.0, L3: 0.0021614432334899902, L4: 0.00016191213217098266
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0277514457702637, Constraint losses: L1: 18.42068099975586, L2: 0.003110087476670742, L3: 1.0031100511550903, L4: 1.003110647201538
Epoch 500, Loss: 0.0021224692463874817, Constraint losses: L1: -1.0464873313903809, L2: 0.0, L3: 0.002583742141723633, L4: 0.0005852143513038754
Epoch 1000, Loss: 0.0013079199707135558, Constraint losses: L1: -1.0701665878295898, L2: 0.0, L3: 0.0021888017654418945, L4: 0.00018928477948065847
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 83.03755950927734, Losses: L1: 13.115021705627441, L2: 0.0007770145894028246, L3: 1.0004498958587646, L4: 67.6285629272461, L5: 0.29229775071144104
Epoch 500, Loss: 4.640380382537842, Losses: L1: 0.8798561096191406, L2: 0.5796754956245422, L3: 0.16151833534240723, L4: 2.8357882499694824, L5: 0.022023748606443405
Epoch 1000, Loss: 11.061028480529785, Losses: L1: 1.2517613172531128, L2: 0.798642098903656, L3: 0.3151979446411133, L4: 8.334766387939453, L5: 0.04546266421675682
Epoch 1500, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.087654517792032e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542552530765533
Epoch 2000, Loss: 70.61618041992188, Losses: L1: 18.42068099975586, L2: 9.080904361802311e-10, L3: 1.0, L4: 50.00007247924805, L5: 0.19542555510997772
Epoch 2500, Loss: 70.61618041992188, Losses: L1: 18.42068099975586, L2: 9.075312723538786e-10, L3: 1.0, L4: 50.00007247924805, L5: 0.19542555510997772
Epoch 3000, Loss: 70.61618041992188, Losses: L1: 18.42068099975586, L2: 9.071443596297968e-10, L3: 1.0, L4: 50.00007247924805, L5: 0.19542555510997772
Epoch 3500, Loss: 70.61618041992188, Losses: L1: 18.42068099975586, L2: 9.069155426644215e-10, L3: 1.0, L4: 50.00007247924805, L5: 0.19542555510997772
Epoch 4000, Loss: 70.61618041992188, Losses: L1: 18.42068099975586, L2: 9.067498418779962e-10, L3: 1.0, L4: 50.00007247924805, L5: 0.19542555510997772
Epoch 4500, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.06600960970394e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 5000, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.065357353676973e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 5500, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064957118276595e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 6000, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064605177577789e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 6500, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064624051369208e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 7000, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064641259826089e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 7500, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064644035383651e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 8000, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064644035383651e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 8500, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064644035383651e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 9000, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064644035383651e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Epoch 9500, Loss: 70.6161880493164, Losses: L1: 18.42068099975586, L2: 9.064644035383651e-10, L3: 1.0, L4: 50.00007629394531, L5: 0.19542557001113892
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021676540374756, Constraint losses: L1: 18.42068099975586, L2: 0.0010853528510779142, L3: 1.0010854005813599, L4: 1.0010852813720703
Epoch 500, Loss: 0.0022547845728695393, Constraint losses: L1: -1.0941506624221802, L2: 0.0, L3: 0.0026736855506896973, L4: 0.0006752496119588614
Epoch 1000, Loss: 0.001310750492848456, Constraint losses: L1: -1.1164969205856323, L2: 0.0, L3: 0.002213418483734131, L4: 0.00021382898557931185
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0027880668640137, Constraint losses: L1: 6.318836688995361, L2: 0.0, L3: 0.998234748840332, L4: 0.9982345104217529
Epoch 500, Loss: 0.0021736216731369495, Constraint losses: L1: -1.0644547939300537, L2: 0.0, L3: 0.0026183128356933594, L4: 0.0006197637412697077
Epoch 1000, Loss: 0.001338785863481462, Constraint losses: L1: -1.0700244903564453, L2: 0.0, L3: 0.0022041797637939453, L4: 0.00020463066175580025
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 104.35482025146484, Losses: L1: 18.42068099975586, L2: 0.004850753117352724, L3: 1.0048507452011108, L4: 83.10717010498047, L5: 0.40620654821395874
Epoch 500, Loss: 3.8377928733825684, Losses: L1: -0.031534209847450256, L2: 0.09162912517786026, L3: 0.07342886924743652, L4: 3.5591044425964355, L5: 0.035867881029844284
Epoch 1000, Loss: 1.661002516746521, Losses: L1: -0.07078801095485687, L2: 0.08348117768764496, L3: 0.05021411180496216, L4: 1.5051618814468384, L5: 0.02135964296758175
Epoch 1500, Loss: 1.0459562540054321, Losses: L1: -0.2541954815387726, L2: 0.05240312218666077, L3: 0.04892033338546753, L4: 1.1268032789230347, L5: 0.011552316136658192
Epoch 2000, Loss: 0.5702977180480957, Losses: L1: -0.2911983132362366, L2: 0.029052911326289177, L3: 0.046561241149902344, L4: 0.723082959651947, L5: 0.008118833415210247
Epoch 2500, Loss: 0.2658723294734955, Losses: L1: -0.13993601500988007, L2: 0.0683966875076294, L3: 0.04734325408935547, L4: 0.23156693577766418, L5: 0.005579100456088781
Epoch 3000, Loss: 0.30416563153266907, Losses: L1: -0.23723408579826355, L2: 0.03735272213816643, L3: 0.04548931121826172, L4: 0.4008612036705017, L5: 0.00610359339043498
Epoch 3500, Loss: 0.1209784522652626, Losses: L1: -0.239266037940979, L2: 0.0259685181081295, L3: 0.044863343238830566, L4: 0.23420457541942596, L5: 0.005172352306544781
Epoch 4000, Loss: 0.021387215703725815, Losses: L1: -0.24095852673053741, L2: 0.02561037801206112, L3: 0.04428929090499878, L4: 0.13805989921092987, L5: 0.005048444028943777
Epoch 4500, Loss: -0.0084222462028265, Losses: L1: -0.24267655611038208, L2: 0.024956731125712395, L3: 0.0438845157623291, L4: 0.11154544353485107, L5: 0.004991550929844379
Epoch 5000, Loss: -0.014986706897616386, Losses: L1: -0.24315840005874634, L2: 0.024440094828605652, L3: 0.04364728927612305, L4: 0.1064586490392685, L5: 0.004989185370504856
Epoch 5500, Loss: -0.024241186678409576, Losses: L1: -0.24413101375102997, L2: 0.024145759642124176, L3: 0.04348015785217285, L4: 0.09879118949174881, L5: 0.004996277391910553
Epoch 6000, Loss: -0.027538973838090897, Losses: L1: -0.24507556855678558, L2: 0.023929426446557045, L3: 0.04335927963256836, L4: 0.09688478708267212, L5: 0.005001908168196678
Epoch 6500, Loss: -0.03056943789124489, Losses: L1: -0.24551761150360107, L2: 0.023606915026903152, L3: 0.043280601501464844, L4: 0.094769686460495, L5: 0.005005186889320612
Epoch 7000, Loss: -0.03247302770614624, Losses: L1: -0.24582664668560028, L2: 0.023449359461665154, L3: 0.04321712255477905, L4: 0.09345711767673492, L5: 0.005006446503102779
Epoch 7500, Loss: -0.03370675444602966, Losses: L1: -0.2459779530763626, L2: 0.023445427417755127, L3: 0.04316842555999756, L4: 0.09246790409088135, L5: 0.0050105080008506775
Epoch 8000, Loss: -0.03460147976875305, Losses: L1: -0.24608974158763885, L2: 0.023454856127500534, L3: 0.04313254356384277, L4: 0.09174694865942001, L5: 0.00501068402081728
Epoch 8500, Loss: -0.03516390547156334, Losses: L1: -0.2461736649274826, L2: 0.023471616208553314, L3: 0.043106138706207275, L4: 0.09130289405584335, L5: 0.005011489149183035
Epoch 9000, Loss: -0.03567861393094063, Losses: L1: -0.2461843341588974, L2: 0.023463238030672073, L3: 0.043087661266326904, L4: 0.09084740281105042, L5: 0.005009880755096674
Epoch 9500, Loss: -0.0360095351934433, Losses: L1: -0.2462041974067688, L2: 0.023462628945708275, L3: 0.04307490587234497, L4: 0.09056185930967331, L5: 0.005010184366255999
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0207152366638184, Constraint losses: L1: 18.42068099975586, L2: 0.0007679103291593492, L3: 1.0007630586624146, L4: 1.0007634162902832
Epoch 500, Loss: 0.0021560792811214924, Constraint losses: L1: -1.080246090888977, L2: 0.0, L3: 0.0026172995567321777, L4: 0.0006190257845446467
Epoch 1000, Loss: 0.0012677954509854317, Constraint losses: L1: -1.1182136535644531, L2: 0.0, L3: 0.0021927356719970703, L4: 0.00019327353220432997
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005666494369507, Constraint losses: L1: 7.3285813331604, L2: 4.7072808229131624e-05, L3: 0.9991452693939209, L4: 0.9991455674171448
Epoch 500, Loss: 0.0023848935961723328, Constraint losses: L1: -1.062854290008545, L2: 0.0, L3: 0.0027228593826293945, L4: 0.0007248885813169181
Epoch 1000, Loss: 0.001397572224959731, Constraint losses: L1: -1.0682179927825928, L2: 0.0, L3: 0.0022325515747070312, L4: 0.00023323862114921212
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 160.56802368164062, Losses: L1: 8.394521713256836, L2: 0.00019342511950526386, L3: 0.9971457719802856, L4: 75.00379943847656, L5: 0.3428304195404053
Epoch 500, Loss: 7.2059550285339355, Losses: L1: 0.03166027367115021, L2: 0.04938898980617523, L3: 0.0719454288482666, L4: 3.4867289066314697, L5: 0.015113619156181812
Epoch 1000, Loss: 105.54275512695312, Losses: L1: 3.5579841136932373, L2: 0.001347713521681726, L3: 0.9694258570671082, L4: 49.976654052734375, L5: 0.182532399892807
Epoch 1500, Loss: 25.92182731628418, Losses: L1: 2.7198233604431152, L2: 1.3136132955551147, L3: 0.32179737091064453, L4: 10.606733322143555, L5: 0.06265522539615631
Epoch 2000, Loss: 17.83086585998535, Losses: L1: 0.8909018039703369, L2: 0.4060494899749756, L3: 0.24371325969696045, L4: 8.009369850158691, L5: 0.055497996509075165
Epoch 2500, Loss: 11.87903881072998, Losses: L1: 0.6811586022377014, L2: 0.46901872754096985, L3: 0.263525128364563, L4: 5.091782569885254, L5: 0.03649182617664337
Epoch 3000, Loss: 10.747305870056152, Losses: L1: 0.6427044868469238, L2: 0.45191794633865356, L3: 0.26714885234832764, L4: 4.548191070556641, L5: 0.04400882124900818
Epoch 3500, Loss: 9.559619903564453, Losses: L1: 0.6211066246032715, L2: 0.4891461730003357, L3: 0.26730942726135254, L4: 3.944490909576416, L5: 0.05153181031346321
Epoch 4000, Loss: 8.331143379211426, Losses: L1: 0.6351883411407471, L2: 0.5610072016716003, L3: 0.2543584108352661, L4: 3.296877145767212, L5: 0.06495235115289688
Epoch 4500, Loss: 7.898251533508301, Losses: L1: 0.6980867981910706, L2: 0.6019198298454285, L3: 0.24752503633499146, L4: 3.034172534942627, L5: 0.0696992427110672
Epoch 5000, Loss: 7.750122547149658, Losses: L1: 0.7527971267700195, L2: 0.6166106462478638, L3: 0.24222314357757568, L4: 2.9300782680511475, L5: 0.0722239688038826
Epoch 5500, Loss: 7.592278480529785, Losses: L1: 0.769800066947937, L2: 0.6174116730690002, L3: 0.24067533016204834, L4: 2.8433780670166016, L5: 0.07391922920942307
Epoch 6000, Loss: 7.531235694885254, Losses: L1: 0.7835874557495117, L2: 0.6234170198440552, L3: 0.2393365502357483, L4: 2.804172992706299, L5: 0.07442474365234375
Epoch 6500, Loss: 7.498879909515381, Losses: L1: 0.7922292947769165, L2: 0.6270241141319275, L3: 0.23860085010528564, L4: 2.782526731491089, L5: 0.07474207878112793
Epoch 7000, Loss: 7.473013877868652, Losses: L1: 0.8003146648406982, L2: 0.6283402442932129, L3: 0.23792338371276855, L4: 2.765481948852539, L5: 0.07509647309780121
Epoch 7500, Loss: 7.453939914703369, Losses: L1: 0.8041480779647827, L2: 0.6304193735122681, L3: 0.23741930723190308, L4: 2.753464460372925, L5: 0.07520953565835953
Epoch 8000, Loss: 7.440589904785156, Losses: L1: 0.8074149489402771, L2: 0.6316209435462952, L3: 0.2370011806488037, L4: 2.7449445724487305, L5: 0.07532493770122528
Epoch 8500, Loss: 7.4307732582092285, Losses: L1: 0.8095188140869141, L2: 0.6325069069862366, L3: 0.23675978183746338, L4: 2.7387654781341553, L5: 0.07539428770542145
Epoch 9000, Loss: 7.423608303070068, Losses: L1: 0.8112041354179382, L2: 0.6330016851425171, L3: 0.2365727424621582, L4: 2.7342641353607178, L5: 0.07545741647481918
Epoch 9500, Loss: 7.418849468231201, Losses: L1: 0.8123513460159302, L2: 0.6332572102546692, L3: 0.23646438121795654, L4: 2.7312798500061035, L5: 0.07550487667322159
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9975463151931763, Constraint losses: L1: 5.431299686431885, L2: 0.0, L3: 0.9960583448410034, L4: 0.9960566759109497
Epoch 500, Loss: 0.0023039618972688913, Constraint losses: L1: -1.1103911399841309, L2: 0.0, L3: 0.0027063488960266113, L4: 0.0007080042269080877
Epoch 1000, Loss: 0.0013515363680198789, Constraint losses: L1: -1.118638038635254, L2: 0.0, L3: 0.0022348761558532715, L4: 0.0002352983137825504
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.028156042098999, Constraint losses: L1: 18.42068099975586, L2: 0.0032448929268866777, L3: 1.0032448768615723, L4: 1.0032455921173096
Epoch 500, Loss: 0.0022647790610790253, Constraint losses: L1: -1.0558907985687256, L2: 0.0, L3: 0.0026594996452331543, L4: 0.0006611701101064682
Epoch 1000, Loss: 0.0013586303684860468, Constraint losses: L1: -1.0714612007141113, L2: 0.0, L3: 0.002214789390563965, L4: 0.00021530223602894694
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 152.37149047851562, Losses: L1: 5.093673229217529, L2: 8.056087244767696e-05, L3: 0.9938303828239441, L4: 72.48648071289062, L5: 0.31710556149482727
Epoch 500, Loss: 8.139945983886719, Losses: L1: 0.223822221159935, L2: 0.09802749007940292, L3: 0.0827782154083252, L4: 3.8143420219421387, L5: 0.02385585568845272
Epoch 1000, Loss: 2.571490526199341, Losses: L1: -0.11936260759830475, L2: 0.08550819009542465, L3: 0.05834686756134033, L4: 1.2369295358657837, L5: 0.014792232774198055
Epoch 1500, Loss: 1.5222562551498413, Losses: L1: 0.1488858163356781, L2: 0.06265801936388016, L3: 0.0707433819770813, L4: 0.5703762769699097, L5: 0.02847311645746231
Epoch 2000, Loss: 1.6098248958587646, Losses: L1: -0.228140726685524, L2: 0.02594136819243431, L3: 0.05319488048553467, L4: 0.8468645215034485, L5: 0.011905446648597717
Epoch 2500, Loss: 0.6060925126075745, Losses: L1: -0.25005707144737244, L2: 0.03500641882419586, L3: 0.04739588499069214, L4: 0.35832297801971436, L5: 0.00970545131713152
Epoch 3000, Loss: 0.24781003594398499, Losses: L1: -0.25315728783607483, L2: 0.027208583429455757, L3: 0.04706370830535889, L4: 0.18488308787345886, L5: 0.009865153580904007
Epoch 3500, Loss: 0.18043358623981476, Losses: L1: -0.25703683495521545, L2: 0.027427656576037407, L3: 0.04607963562011719, L4: 0.15397393703460693, L5: 0.009935619309544563
Epoch 4000, Loss: 0.17418129742145538, Losses: L1: -0.256161630153656, L2: 0.027631785720586777, L3: 0.045807480812072754, L4: 0.15056997537612915, L5: 0.00995622482150793
Epoch 4500, Loss: 0.06164301931858063, Losses: L1: -0.2544277310371399, L2: 0.02689412236213684, L3: 0.045770108699798584, L4: 0.09416882693767548, L5: 0.009298755787312984
Epoch 5000, Loss: 0.07518553733825684, Losses: L1: -0.25550681352615356, L2: 0.02634272351861, L3: 0.045736849308013916, L4: 0.10179850459098816, L5: 0.009278926067054272
Epoch 5500, Loss: 0.032366473227739334, Losses: L1: -0.25649493932724, L2: 0.02631268836557865, L3: 0.045654296875, L4: 0.08087458461523056, L5: 0.00949095655232668
Epoch 6000, Loss: 0.016362573951482773, Losses: L1: -0.25653231143951416, L2: 0.026311876252293587, L3: 0.04560542106628418, L4: 0.07296761870384216, L5: 0.009436932392418385
Epoch 6500, Loss: 0.011676697060465813, Losses: L1: -0.2568839192390442, L2: 0.026178842410445213, L3: 0.04557013511657715, L4: 0.07090668380260468, L5: 0.009428141638636589
Epoch 7000, Loss: 0.010019654408097267, Losses: L1: -0.2571621537208557, L2: 0.026081841439008713, L3: 0.04554462432861328, L4: 0.07029591500759125, L5: 0.009418884292244911
Epoch 7500, Loss: 0.008967950008809566, Losses: L1: -0.257323682308197, L2: 0.026019157841801643, L3: 0.045529067516326904, L4: 0.06989528238773346, L5: 0.009423776529729366
Epoch 8000, Loss: 0.00796014629304409, Losses: L1: -0.257418155670166, L2: 0.02596910670399666, L3: 0.04551881551742554, L4: 0.06947758793830872, L5: 0.00941639207303524
Epoch 8500, Loss: 0.0073568858206272125, Losses: L1: -0.2575053572654724, L2: 0.025906743481755257, L3: 0.04551577568054199, L4: 0.06925822794437408, L5: 0.009407494217157364
Epoch 9000, Loss: 0.006908902898430824, Losses: L1: -0.25754091143608093, L2: 0.025871889665722847, L3: 0.04551279544830322, L4: 0.06907285004854202, L5: 0.009406635537743568
Epoch 9500, Loss: 0.006579175591468811, Losses: L1: -0.25757747888565063, L2: 0.02586064673960209, L3: 0.04550957679748535, L4: 0.06893749535083771, L5: 0.009401857852935791
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0040128231048584, Constraint losses: L1: 6.63719367980957, L2: 0.0, L3: 0.9986878037452698, L4: 0.9986878037452698
Epoch 500, Loss: 0.0022051131818443537, Constraint losses: L1: -1.1052204370498657, L2: 0.0, L3: 0.0026543140411376953, L4: 0.00065601960523054
Epoch 1000, Loss: 0.001307012396864593, Constraint losses: L1: -1.118446946144104, L2: 0.0, L3: 0.0022124052047729492, L4: 0.00021305421250872314
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0119478702545166, Constraint losses: L1: 12.042984962463379, L2: 1.190882994706044e-05, L3: 0.9999464154243469, L4: 0.9999465346336365
Epoch 500, Loss: 0.0032500955276191235, Constraint losses: L1: -0.7908210158348083, L2: 0.0, L3: 0.0030189156532287598, L4: 0.0010220009135082364
Epoch 1000, Loss: 0.0015376692172139883, Constraint losses: L1: -1.058909296989441, L2: 0.0, L3: 0.002297818660736084, L4: 0.0002987599582411349
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 164.42356872558594, Losses: L1: 4.5846171379089355, L2: 0.0, L3: 0.9883133769035339, L4: 78.5596694946289, L5: 0.37148958444595337
Epoch 500, Loss: 27.05396842956543, Losses: L1: 1.4937456846237183, L2: 2.367172956466675, L3: 0.07232755422592163, L4: 11.444704055786133, L5: 0.07949313521385193
Epoch 1000, Loss: 4.295886039733887, Losses: L1: 0.39452821016311646, L2: 0.2090456485748291, L3: 0.0947461724281311, L4: 1.7307624816894531, L5: 0.020647456869482994
Epoch 1500, Loss: 1.241982340812683, Losses: L1: -0.08004657179117203, L2: 0.11171215772628784, L3: 0.07623231410980225, L4: 0.5192525386810303, L5: 0.00967351533472538
Epoch 2000, Loss: 2.0835800170898438, Losses: L1: -0.16243918240070343, L2: 0.1026846393942833, L3: 0.06119799613952637, L4: 1.001863718032837, L5: 0.008605655282735825
Epoch 2500, Loss: 1.155359148979187, Losses: L1: -0.18024121224880219, L2: 0.07688804715871811, L3: 0.06084632873535156, L4: 0.5604907274246216, L5: 0.00801907293498516
Epoch 3000, Loss: 0.5803337097167969, Losses: L1: -0.19643715023994446, L2: 0.06270886957645416, L3: 0.05990523099899292, L4: 0.29040956497192383, L5: 0.006716204807162285
Epoch 3500, Loss: 0.6051401495933533, Losses: L1: -0.19864246249198914, L2: 0.05727944150567055, L3: 0.05906355381011963, L4: 0.30763518810272217, L5: 0.006552832666784525
Epoch 4000, Loss: 0.4271046221256256, Losses: L1: -0.19901300966739655, L2: 0.05346369370818138, L3: 0.05826735496520996, L4: 0.22158527374267578, L5: 0.006474328227341175
Epoch 4500, Loss: 0.37678012251853943, Losses: L1: -0.20133079588413239, L2: 0.049999963492155075, L3: 0.05788302421569824, L4: 0.19989755749702454, L5: 0.006274895276874304
Epoch 5000, Loss: 0.3523236811161041, Losses: L1: -0.20607443153858185, L2: 0.04811680316925049, L3: 0.05740088224411011, L4: 0.19158510863780975, L5: 0.0061546675860881805
Epoch 5500, Loss: 0.3388943076133728, Losses: L1: -0.20875394344329834, L2: 0.04702574014663696, L3: 0.05706906318664551, L4: 0.18710973858833313, L5: 0.0061324592679739
Epoch 6000, Loss: 0.32837021350860596, Losses: L1: -0.21048204600811005, L2: 0.04633333161473274, L3: 0.05683183670043945, L4: 0.18332156538963318, L5: 0.006106068380177021
Epoch 6500, Loss: 0.3216902017593384, Losses: L1: -0.21123574674129486, L2: 0.04592124745249748, L3: 0.05664646625518799, L4: 0.18073773384094238, L5: 0.006118152290582657
Epoch 7000, Loss: 0.3169374465942383, Losses: L1: -0.21184778213500977, L2: 0.04555331915616989, L3: 0.05653780698776245, L4: 0.1789654791355133, L5: 0.006112668197602034
Epoch 7500, Loss: 0.3137124478816986, Losses: L1: -0.21220175921916962, L2: 0.04527689516544342, L3: 0.05645716190338135, L4: 0.1777445673942566, L5: 0.006116928532719612
Epoch 8000, Loss: 0.3112478256225586, Losses: L1: -0.21245181560516357, L2: 0.04509010538458824, L3: 0.05640149116516113, L4: 0.17678871750831604, L5: 0.00611455412581563
Epoch 8500, Loss: 0.3095146417617798, Losses: L1: -0.21256138384342194, L2: 0.04495424032211304, L3: 0.056362688541412354, L4: 0.17608383297920227, L5: 0.00611436553299427
Epoch 9000, Loss: 0.3082936108112335, Losses: L1: -0.21266880631446838, L2: 0.04485179856419563, L3: 0.05633080005645752, L4: 0.17560887336730957, L5: 0.006115629803389311
Epoch 9500, Loss: 0.3074128031730652, Losses: L1: -0.21277371048927307, L2: 0.04478819668292999, L3: 0.05631685256958008, L4: 0.17526768147945404, L5: 0.006114635616540909
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0284228324890137, Constraint losses: L1: 18.42068099975586, L2: 0.0033340868540108204, L3: 1.0033340454101562, L4: 1.0033340454101562
Epoch 500, Loss: 0.0023190337233245373, Constraint losses: L1: -1.1059398651123047, L2: 0.0, L3: 0.0027115941047668457, L4: 0.0007133797043934464
Epoch 1000, Loss: 0.0013497889740392566, Constraint losses: L1: -1.118106484413147, L2: 0.0, L3: 0.0022336840629577637, L4: 0.00023421147488988936
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0088961124420166, Constraint losses: L1: 9.090070724487305, L2: 9.518022125121206e-05, L3: 0.9998554587364197, L4: 0.9998553395271301
Epoch 500, Loss: 0.002247290685772896, Constraint losses: L1: -0.9877763986587524, L2: 0.0, L3: 0.0026164650917053223, L4: 0.0006186020327731967
Epoch 1000, Loss: 0.0013114515459164977, Constraint losses: L1: -1.068364143371582, L2: 0.0, L3: 0.00218963623046875, L4: 0.00019017957674805075
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.1870231628418, Losses: L1: 18.42068099975586, L2: 0.006465525832027197, L3: 1.0064655542373657, L4: 74.15687561035156, L5: 0.34348657727241516
Epoch 500, Loss: 29.021703720092773, Losses: L1: 3.160924196243286, L2: 0.0021888883784413338, L3: 0.8889931440353394, L4: 50.65532684326172, L5: 0.1684829443693161
Epoch 1000, Loss: 6.332499027252197, Losses: L1: 1.4585403203964233, L2: 0.27581000328063965, L3: 0.26424074172973633, L4: 8.332255363464355, L5: 0.04818020015954971
Epoch 1500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7385592343543976e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502276182174683
Epoch 2000, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7363372251111286e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.1950228214263916
Epoch 2500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7342664193620294e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502286612987518
Epoch 3000, Loss: 44.01827621459961, Losses: L1: 18.42068099975586, L2: 1.732681482735643e-07, L3: 1.0000001192092896, L4: 50.00016784667969, L5: 0.19502289593219757
Epoch 3500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.731340972810358e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502292573451996
Epoch 4000, Loss: 44.01827621459961, Losses: L1: 18.42068099975586, L2: 1.7303055699358083e-07, L3: 1.0000001192092896, L4: 50.00016784667969, L5: 0.19502294063568115
Epoch 4500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7294718190896674e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502297043800354
Epoch 5000, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7288584786001593e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502298533916473
Epoch 5500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7285903197716834e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Epoch 6000, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.728379572796257e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Epoch 6500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7282100372995046e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Epoch 7000, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.728095355701953e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Epoch 7500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7280100905736617e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Epoch 8000, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.727948557572745e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Epoch 8500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7279025144034676e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Epoch 9000, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.7278622976846236e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Epoch 9500, Loss: 44.018280029296875, Losses: L1: 18.42068099975586, L2: 1.727843113030758e-07, L3: 1.0000001192092896, L4: 50.00017166137695, L5: 0.19502300024032593
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0192079544067383, Constraint losses: L1: 18.42068099975586, L2: 0.00026356481248512864, L3: 1.000261902809143, L4: 1.0002617835998535
Epoch 500, Loss: 0.0021582404151558876, Constraint losses: L1: -1.1124165058135986, L2: 0.0, L3: 0.0026345252990722656, L4: 0.0006361316191032529
Epoch 1000, Loss: 0.001300221774727106, Constraint losses: L1: -1.1177644729614258, L2: 0.0, L3: 0.002208709716796875, L4: 0.00020927654986735433
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019658088684082, Constraint losses: L1: 18.42068099975586, L2: 0.0004124552942812443, L3: 1.0004124641418457, L4: 1.0004124641418457
Epoch 500, Loss: 0.0021335750352591276, Constraint losses: L1: -1.0450359582901, L2: 0.0, L3: 0.0025884509086608887, L4: 0.0005901601980440319
Epoch 1000, Loss: 0.001306622289121151, Constraint losses: L1: -1.0709304809570312, L2: 0.0, L3: 0.002188563346862793, L4: 0.000188989462913014
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.01115798950195, Losses: L1: 14.224652290344238, L2: 0.0045989202335476875, L3: 1.0038713216781616, L4: 73.88221740722656, L5: 0.33426326513290405
Epoch 500, Loss: 13.985434532165527, Losses: L1: 3.595585584640503, L2: 1.460214376449585, L3: 0.3952241539955139, L4: 14.384162902832031, L5: 0.07972594350576401
Epoch 1000, Loss: 29.124406814575195, Losses: L1: 2.8528244495391846, L2: 0.0, L3: 0.9251767992973328, L4: 51.27365493774414, L5: 0.17216618359088898
Epoch 1500, Loss: 3.2555086612701416, Losses: L1: 0.5388116836547852, L2: 0.0854625552892685, L3: 0.21573877334594727, L4: 4.8496270179748535, L5: 0.013089003041386604
Epoch 2000, Loss: 1.5534961223602295, Losses: L1: 0.03488319367170334, L2: 0.06784142553806305, L3: 0.16341954469680786, L4: 2.5792839527130127, L5: 0.011578266508877277
Epoch 2500, Loss: 1.741363763809204, Losses: L1: 0.09547872096300125, L2: 0.1092718243598938, L3: 0.20128142833709717, L4: 2.6292943954467773, L5: 0.012053519487380981
Epoch 3000, Loss: 1.4059916734695435, Losses: L1: 0.009825765155255795, L2: 0.10150926560163498, L3: 0.1879427433013916, L4: 2.176816940307617, L5: 0.010767633095383644
Epoch 3500, Loss: 0.905707836151123, Losses: L1: 0.022207411006093025, L2: 0.07823551446199417, L3: 0.1493605375289917, L4: 1.2795460224151611, L5: 0.012576117180287838
Epoch 4000, Loss: 0.8365166187286377, Losses: L1: 0.004587013274431229, L2: 0.07045324891805649, L3: 0.142112135887146, L4: 1.2161355018615723, L5: 0.011899284087121487
Epoch 4500, Loss: 0.7962162494659424, Losses: L1: -0.0007339296862483025, L2: 0.06900514662265778, L3: 0.13817715644836426, L4: 1.1554710865020752, L5: 0.012115748599171638
Epoch 5000, Loss: 0.7423927187919617, Losses: L1: -0.03622687980532646, L2: 0.06663370132446289, L3: 0.13547015190124512, L4: 1.1309778690338135, L5: 0.012128165923058987
Epoch 5500, Loss: 0.727438747882843, Losses: L1: -0.03965526819229126, L2: 0.06532812118530273, L3: 0.1340741515159607, L4: 1.1147693395614624, L5: 0.012016006745398045
Epoch 6000, Loss: 0.7183217406272888, Losses: L1: -0.040229432284832, L2: 0.06452914327383041, L3: 0.133020281791687, L4: 1.1020305156707764, L5: 0.011967454105615616
Epoch 6500, Loss: 0.7119942903518677, Losses: L1: -0.04008093848824501, L2: 0.0641736164689064, L3: 0.13250786066055298, L4: 1.0909836292266846, L5: 0.01198229007422924
Epoch 7000, Loss: 0.7075559496879578, Losses: L1: -0.040431126952171326, L2: 0.0638871043920517, L3: 0.13205790519714355, L4: 1.0844883918762207, L5: 0.011939678341150284
Epoch 7500, Loss: 0.7042906880378723, Losses: L1: -0.04027450829744339, L2: 0.06372624635696411, L3: 0.13164854049682617, L4: 1.0786782503128052, L5: 0.01194929052144289
Epoch 8000, Loss: 0.7018863558769226, Losses: L1: -0.04034072905778885, L2: 0.0635298416018486, L3: 0.13139724731445312, L4: 1.0750682353973389, L5: 0.011934719979763031
Epoch 8500, Loss: 0.7001252174377441, Losses: L1: -0.040817104279994965, L2: 0.06347771733999252, L3: 0.13120317459106445, L4: 1.0729153156280518, L5: 0.011927622370421886
Epoch 9000, Loss: 0.6988689303398132, Losses: L1: -0.041059743613004684, L2: 0.06342994421720505, L3: 0.13107049465179443, L4: 1.0712155103683472, L5: 0.011925764381885529
Epoch 9500, Loss: 0.6979836821556091, Losses: L1: -0.04130909591913223, L2: 0.06339298188686371, L3: 0.13097000122070312, L4: 1.0702037811279297, L5: 0.011919895187020302
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.002232074737549, Constraint losses: L1: 6.173573017120361, L2: 0.0, L3: 0.9980294704437256, L4: 0.9980290532112122
Epoch 500, Loss: 0.0026447509881109, Constraint losses: L1: -1.1114692687988281, L2: 0.0, L3: 0.002877175807952881, L4: 0.000879044528119266
Epoch 1000, Loss: 0.0014645338524132967, Constraint losses: L1: -1.118730902671814, L2: 0.0, L3: 0.0022913217544555664, L4: 0.000291943084448576
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.010618209838867, Constraint losses: L1: 10.702811241149902, L2: 2.493626561772544e-05, L3: 0.9999452233314514, L4: 0.9999452829360962
Epoch 500, Loss: 0.002151933964341879, Constraint losses: L1: -1.0354605913162231, L2: 0.0, L3: 0.002592802047729492, L4: 0.0005945926532149315
Epoch 1000, Loss: 0.0013049498666077852, Constraint losses: L1: -1.0705173015594482, L2: 0.0, L3: 0.0021874308586120605, L4: 0.00018803635612130165
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.6846809387207, Losses: L1: 6.348238468170166, L2: 0.0, L3: 0.9983215928077698, L4: 78.20332336425781, L5: 0.3678097426891327
Epoch 500, Loss: 35.630374908447266, Losses: L1: 9.750543594360352, L2: 1.2139157945512125e-07, L3: 0.996471643447876, L4: 49.995174407958984, L5: 0.19200405478477478
Epoch 1000, Loss: 35.617305755615234, Losses: L1: 9.761248588562012, L2: 0.0006342385313473642, L3: 0.9983415603637695, L4: 49.931365966796875, L5: 0.1949670910835266
Epoch 1500, Loss: 30.055431365966797, Losses: L1: 3.9336910247802734, L2: 0.08948417752981186, L3: 0.9248119592666626, L4: 50.281558990478516, L5: 0.16979271173477173
Epoch 2000, Loss: 2.663269281387329, Losses: L1: 0.19461634755134583, L2: 0.18237614631652832, L3: 0.1739709973335266, L4: 3.9490714073181152, L5: 0.021189754828810692
Epoch 2500, Loss: 2.3993935585021973, Losses: L1: 0.03542241454124451, L2: 0.14882118999958038, L3: 0.1581190824508667, L4: 3.8710367679595947, L5: 0.02587542124092579
Epoch 3000, Loss: 1.1781892776489258, Losses: L1: -0.1568557322025299, L2: 0.15405787527561188, L3: 0.14570587873458862, L4: 1.8674287796020508, L5: 0.010180954821407795
Epoch 3500, Loss: 0.9948980212211609, Losses: L1: -0.1814463585615158, L2: 0.13970786333084106, L3: 0.13946682214736938, L4: 1.6143344640731812, L5: 0.010013984516263008
Epoch 4000, Loss: 0.9085395336151123, Losses: L1: -0.1867259293794632, L2: 0.13075028359889984, L3: 0.13630706071853638, L4: 1.489780068397522, L5: 0.010360668413341045
Epoch 4500, Loss: 0.8558233380317688, Losses: L1: -0.18811030685901642, L2: 0.1253594011068344, L3: 0.13415074348449707, L4: 1.4083998203277588, L5: 0.01096978411078453
Epoch 5000, Loss: 0.8257190585136414, Losses: L1: -0.18960626423358917, L2: 0.122566357254982, L3: 0.132648766040802, L4: 1.363639235496521, L5: 0.011024306528270245
Epoch 5500, Loss: 0.7897234559059143, Losses: L1: -0.2042885273694992, L2: 0.12043839693069458, L3: 0.1304032802581787, L4: 1.3339438438415527, L5: 0.010480835102498531
Epoch 6000, Loss: 0.7740673422813416, Losses: L1: -0.20571644604206085, L2: 0.11922663450241089, L3: 0.12887883186340332, L4: 1.311245083808899, L5: 0.010634271427989006
Epoch 6500, Loss: 0.7628710269927979, Losses: L1: -0.20663845539093018, L2: 0.11834069341421127, L3: 0.12814921140670776, L4: 1.2946224212646484, L5: 0.010721161030232906
Epoch 7000, Loss: 0.7548683285713196, Losses: L1: -0.20723360776901245, L2: 0.11741391569375992, L3: 0.12766706943511963, L4: 1.2836828231811523, L5: 0.010799585841596127
Epoch 7500, Loss: 0.7490582466125488, Losses: L1: -0.20784121751785278, L2: 0.11685202270746231, L3: 0.12746953964233398, L4: 1.2755639553070068, L5: 0.010839341208338737
Epoch 8000, Loss: 0.7449570298194885, Losses: L1: -0.20828382670879364, L2: 0.116417795419693, L3: 0.12731289863586426, L4: 1.2699929475784302, L5: 0.010876164771616459
Epoch 8500, Loss: 0.7419103980064392, Losses: L1: -0.2084665596485138, L2: 0.11602368205785751, L3: 0.12719345092773438, L4: 1.265822410583496, L5: 0.010910836979746819
Epoch 9000, Loss: 0.7398099899291992, Losses: L1: -0.2086237221956253, L2: 0.11578686535358429, L3: 0.12709581851959229, L4: 1.2629079818725586, L5: 0.010929037816822529
Epoch 9500, Loss: 0.7383646965026855, Losses: L1: -0.2087630033493042, L2: 0.11562348157167435, L3: 0.127028226852417, L4: 1.26100754737854, L5: 0.01093143131583929
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0082852840423584, Constraint losses: L1: 8.37774658203125, L2: 6.206181569723412e-05, L3: 0.999923050403595, L4: 0.9999223351478577
Epoch 500, Loss: 0.0019218048546463251, Constraint losses: L1: -1.0932819843292236, L2: 0.0, L3: 0.002506852149963379, L4: 0.0005082347197458148
Epoch 1000, Loss: 0.0012066209455952048, Constraint losses: L1: -1.1179543733596802, L2: 0.0, L3: 0.002162039279937744, L4: 0.00016253601643256843
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.025696277618408, Constraint losses: L1: 18.42068099975586, L2: 0.0024249807465821505, L3: 1.002424955368042, L4: 1.0024256706237793
Epoch 500, Loss: 0.0022272635251283646, Constraint losses: L1: -1.0275475978851318, L2: 0.0, L3: 0.002626478672027588, L4: 0.0006283323746174574
Epoch 1000, Loss: 0.0013283895095810294, Constraint losses: L1: -1.0676040649414062, L2: 0.0, L3: 0.0021976828575134277, L4: 0.00019831082317978144
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 83.3558120727539, Losses: L1: 15.900076866149902, L2: 0.002819425892084837, L3: 1.0025898218154907, L4: 66.80715942382812, L5: 0.28328368067741394
Epoch 500, Loss: 2.6825106143951416, Losses: L1: -0.07261093705892563, L2: 0.08146300166845322, L3: 0.07762700319290161, L4: 2.546776533126831, L5: 0.013210796751081944
Epoch 1000, Loss: 1.3065952062606812, Losses: L1: -0.1787230372428894, L2: 0.037833087146282196, L3: 0.06698113679885864, L4: 1.366420030593872, L5: 0.019482744857668877
Epoch 1500, Loss: 1.6627354621887207, Losses: L1: -0.15394379198551178, L2: 0.02723374217748642, L3: 0.05730438232421875, L4: 1.7243027687072754, L5: 0.018513590097427368
Epoch 2000, Loss: 0.4349008798599243, Losses: L1: -0.2276659607887268, L2: 0.061656370759010315, L3: 0.06029057502746582, L4: 0.5028323531150818, L5: 0.01255293283611536
Epoch 2500, Loss: 0.4627475142478943, Losses: L1: -0.2621036171913147, L2: 0.04254317656159401, L3: 0.05887711048126221, L4: 0.6047940254211426, L5: 0.011064420454204082
Epoch 3000, Loss: 0.4415227770805359, Losses: L1: -0.26525917649269104, L2: 0.035383448004722595, L3: 0.05674934387207031, L4: 0.6045241951942444, L5: 0.006232354789972305
Epoch 3500, Loss: 0.01937912218272686, Losses: L1: -0.2679179310798645, L2: 0.03200216218829155, L3: 0.05615043640136719, L4: 0.19171598553657532, L5: 0.007003036327660084
Epoch 4000, Loss: 0.026627734303474426, Losses: L1: -0.26636219024658203, L2: 0.030979149043560028, L3: 0.055975914001464844, L4: 0.1997615396976471, L5: 0.006564259063452482
Epoch 4500, Loss: 0.0010497032199054956, Losses: L1: -0.26688188314437866, L2: 0.030841875821352005, L3: 0.05541837215423584, L4: 0.1751791536808014, L5: 0.006719004828482866
Epoch 5000, Loss: -0.016473013907670975, Losses: L1: -0.26613324880599976, L2: 0.030185094103217125, L3: 0.05515480041503906, L4: 0.15849050879478455, L5: 0.006444268859922886
Epoch 5500, Loss: -0.026413533836603165, Losses: L1: -0.2658085227012634, L2: 0.03003811649978161, L3: 0.05493658781051636, L4: 0.1486278772354126, L5: 0.006445163395255804
Epoch 6000, Loss: -0.029816515743732452, Losses: L1: -0.2659658193588257, L2: 0.029835201799869537, L3: 0.05479025840759277, L4: 0.14588186144828796, L5: 0.006403820589184761
Epoch 6500, Loss: -0.031637027859687805, Losses: L1: -0.2660885155200958, L2: 0.0295530054718256, L3: 0.05468416213989258, L4: 0.1448204517364502, L5: 0.006365893874317408
Epoch 7000, Loss: -0.03373608738183975, Losses: L1: -0.26621440052986145, L2: 0.029505040496587753, L3: 0.05460631847381592, L4: 0.14298956096172333, L5: 0.006351009011268616
Epoch 7500, Loss: -0.034979864954948425, Losses: L1: -0.2662942707538605, L2: 0.02941063791513443, L3: 0.054527461528778076, L4: 0.14206302165985107, L5: 0.006332751363515854
Epoch 8000, Loss: -0.03590436279773712, Losses: L1: -0.26635676622390747, L2: 0.029349520802497864, L3: 0.05445706844329834, L4: 0.14136555790901184, L5: 0.006318540778011084
Epoch 8500, Loss: -0.036584775894880295, Losses: L1: -0.26642537117004395, L2: 0.029324330389499664, L3: 0.05440884828567505, L4: 0.1408325880765915, L5: 0.006309846881777048
Epoch 9000, Loss: -0.037050679326057434, Losses: L1: -0.26642903685569763, L2: 0.029283490031957626, L3: 0.05437445640563965, L4: 0.14047184586524963, L5: 0.006304592359811068
Epoch 9500, Loss: -0.03737868741154671, Losses: L1: -0.26646116375923157, L2: 0.02926451340317726, L3: 0.0543515682220459, L4: 0.14022812247276306, L5: 0.006299102213233709
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0052123069763184, Constraint losses: L1: 6.95330286026001, L2: 0.0, L3: 0.9991297125816345, L4: 0.9991292357444763
Epoch 500, Loss: 0.0021124915219843388, Constraint losses: L1: -1.10804283618927, L2: 0.0, L3: 0.0026094913482666016, L4: 0.000611043069511652
Epoch 1000, Loss: 0.0012818715767934918, Constraint losses: L1: -1.1187509298324585, L2: 0.0, L3: 0.002200007438659668, L4: 0.00020061517716385424
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.998321294784546, Constraint losses: L1: 5.6001410484313965, L2: 0.0, L3: 0.9963608980178833, L4: 0.9963603615760803
Epoch 500, Loss: 0.002347982255741954, Constraint losses: L1: -1.0340116024017334, L2: 0.0, L3: 0.002690136432647705, L4: 0.000691857363563031
Epoch 1000, Loss: 0.0013671983033418655, Constraint losses: L1: -1.0713657140731812, L2: 0.0, L3: 0.002218961715698242, L4: 0.00021960237063467503
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 85.29778289794922, Losses: L1: 12.504377365112305, L2: 0.0004005112568847835, L3: 1.000177025794983, L4: 71.9649429321289, L5: 0.32757607102394104
Epoch 500, Loss: 2.697788953781128, Losses: L1: -0.06641928851604462, L2: 0.03775392845273018, L3: 0.08232349157333374, L4: 2.610180139541626, L5: 0.03735863417387009
Epoch 1000, Loss: 1.6900501251220703, Losses: L1: -0.21876102685928345, L2: 0.04050884395837784, L3: 0.0569150447845459, L4: 1.7701709270477295, L5: 0.029165031388401985
Epoch 1500, Loss: 0.5194475054740906, Losses: L1: -0.25365149974823, L2: 0.03179097920656204, L3: 0.05300498008728027, L4: 0.6742910146713257, L5: 0.008723560720682144
Epoch 2000, Loss: 0.17626357078552246, Losses: L1: -0.2626122832298279, L2: 0.026568438857793808, L3: 0.053105294704437256, L4: 0.3502999544143677, L5: 0.008886361494660378
Epoch 2500, Loss: 0.16038399934768677, Losses: L1: -0.27203503251075745, L2: 0.026059497147798538, L3: 0.05053746700286865, L4: 0.34866058826446533, L5: 0.006370721850544214
Epoch 3000, Loss: 0.43421614170074463, Losses: L1: -0.2745971083641052, L2: 0.023499436676502228, L3: 0.050101518630981445, L4: 0.6315754652023315, L5: 0.005188157316297293
Epoch 3500, Loss: -0.02233554981648922, Losses: L1: -0.2861350178718567, L2: 0.02977813594043255, L3: 0.04817765951156616, L4: 0.17449727654457092, L5: 0.005657086614519358
Epoch 4000, Loss: -0.07884597778320312, Losses: L1: -0.2826603353023529, L2: 0.02672249637544155, L3: 0.04824608564376831, L4: 0.12048123776912689, L5: 0.00576507905498147
Epoch 4500, Loss: -0.07830516248941422, Losses: L1: -0.2821434438228607, L2: 0.026331542059779167, L3: 0.0479733943939209, L4: 0.12192489206790924, L5: 0.005263603292405605
Epoch 5000, Loss: -0.10311903059482574, Losses: L1: -0.28214356303215027, L2: 0.025949718430638313, L3: 0.04795682430267334, L4: 0.09777627885341644, L5: 0.0053704106248915195
Epoch 5500, Loss: -0.10094192624092102, Losses: L1: -0.2822266221046448, L2: 0.025886425748467445, L3: 0.04780465364456177, L4: 0.10032856464385986, L5: 0.005280957091599703
Epoch 6000, Loss: -0.1150444746017456, Losses: L1: -0.2814610004425049, L2: 0.02577279321849346, L3: 0.0477370023727417, L4: 0.08581656217575073, L5: 0.005185870453715324
Epoch 6500, Loss: -0.11617724597454071, Losses: L1: -0.28149092197418213, L2: 0.025714056566357613, L3: 0.04771018028259277, L4: 0.08486717939376831, L5: 0.005163296591490507
Epoch 7000, Loss: -0.11732641607522964, Losses: L1: -0.2814926207065582, L2: 0.025680571794509888, L3: 0.04766845703125, L4: 0.0838196724653244, L5: 0.005151163320988417
Epoch 7500, Loss: -0.11755000054836273, Losses: L1: -0.281546413898468, L2: 0.025650030001997948, L3: 0.04764389991760254, L4: 0.08373258262872696, L5: 0.00514181749895215
Epoch 8000, Loss: -0.11799561977386475, Losses: L1: -0.28157034516334534, L2: 0.025634054094552994, L3: 0.047625184059143066, L4: 0.08336731791496277, L5: 0.005126711912453175
Epoch 8500, Loss: -0.11841145902872086, Losses: L1: -0.2815968692302704, L2: 0.025642607361078262, L3: 0.04760909080505371, L4: 0.08297058939933777, L5: 0.005125064868479967
Epoch 9000, Loss: -0.11858421564102173, Losses: L1: -0.2816337049007416, L2: 0.025642668828368187, L3: 0.04759824275970459, L4: 0.08284348994493484, L5: 0.005121533293277025
Epoch 9500, Loss: -0.11871173232793808, Losses: L1: -0.2816529870033264, L2: 0.025645365938544273, L3: 0.047589778900146484, L4: 0.08273700624704361, L5: 0.005118625704199076
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0070571899414062, Constraint losses: L1: 7.968385219573975, L2: 0.0, L3: 0.9995441436767578, L4: 0.9995446801185608
Epoch 500, Loss: 0.002200717106461525, Constraint losses: L1: -1.0356451272964478, L2: 0.0, L3: 0.0026171207427978516, L4: 0.000619241502135992
Epoch 1000, Loss: 0.0012570042163133621, Constraint losses: L1: -1.116393804550171, L2: 0.0, L3: 0.002186417579650879, L4: 0.0001869804982561618
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.004312038421631, Constraint losses: L1: 6.7278876304626465, L2: 0.0, L3: 0.9987919330596924, L4: 0.9987920522689819
Epoch 500, Loss: 0.0022958770859986544, Constraint losses: L1: -1.064018964767456, L2: 0.0, L3: 0.002679169178009033, L4: 0.0006807269528508186
Epoch 1000, Loss: 0.0013769622892141342, Constraint losses: L1: -1.071418285369873, L2: 0.0, L3: 0.0022239089012145996, L4: 0.00022447164519689977
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.36688995361328, Losses: L1: 4.862229347229004, L2: 0.0, L3: 0.9907057285308838, L4: 88.12655639648438, L5: 0.441375732421875
Epoch 500, Loss: 2.1403305530548096, Losses: L1: -0.07635991275310516, L2: 0.08012191951274872, L3: 0.07659107446670532, L4: 1.9718259572982788, L5: 0.02316262386739254
Epoch 1000, Loss: 7.514537334442139, Losses: L1: 0.41323599219322205, L2: 0.14990799129009247, L3: 0.14257019758224487, L4: 6.6491312980651855, L5: 0.04053453728556633
Epoch 1500, Loss: 54.261375427246094, Losses: L1: 3.9360108375549316, L2: 0.19774965941905975, L3: 1.0036981105804443, L4: 49.06461715698242, L5: 0.18170058727264404
Epoch 2000, Loss: 56.023681640625, Losses: L1: 4.109222412109375, L2: 0.003205908229574561, L3: 0.9827705025672913, L4: 51.02708435058594, L5: 0.19478817284107208
Epoch 2500, Loss: 55.7570915222168, Losses: L1: 3.866525173187256, L2: 0.002176214475184679, L3: 0.9834475517272949, L4: 51.0046272277832, L5: 0.19493092596530914
Epoch 3000, Loss: 55.92725372314453, Losses: L1: 4.216175079345703, L2: 0.00425198907032609, L3: 0.9851963520050049, L4: 50.82161331176758, L5: 0.19418153166770935
Epoch 3500, Loss: 55.802642822265625, Losses: L1: 3.9411110877990723, L2: 0.004292432218790054, L3: 0.9818350076675415, L4: 50.9744758605957, L5: 0.19377726316452026
Epoch 4000, Loss: 55.769046783447266, Losses: L1: 3.901559829711914, L2: 0.00390288676135242, L3: 0.9813417196273804, L4: 50.98186111450195, L5: 0.19357414543628693
Epoch 4500, Loss: 55.74977493286133, Losses: L1: 3.8819055557250977, L2: 0.0036346823908388615, L3: 0.9811137914657593, L4: 50.983154296875, L5: 0.1934443861246109
Epoch 5000, Loss: 55.73658752441406, Losses: L1: 3.8690457344055176, L2: 0.0034471869003027678, L3: 0.9809602499008179, L4: 50.98347473144531, L5: 0.1933465600013733
Epoch 5500, Loss: 55.726966857910156, Losses: L1: 3.8598275184631348, L2: 0.003313432913273573, L3: 0.980843722820282, L4: 50.983551025390625, L5: 0.1932702660560608
Epoch 6000, Loss: 55.71971893310547, Losses: L1: 3.8529603481292725, L2: 0.003216438926756382, L3: 0.9807524681091309, L4: 50.98352813720703, L5: 0.19321051239967346
Epoch 6500, Loss: 55.71415328979492, Losses: L1: 3.847731590270996, L2: 0.0031453075353056192, L3: 0.980679988861084, L4: 50.98346710205078, L5: 0.19316372275352478
Epoch 7000, Loss: 55.70985412597656, Losses: L1: 3.843670129776001, L2: 0.0030925627797842026, L3: 0.9806218147277832, L4: 50.98343276977539, L5: 0.19312691688537598
Epoch 7500, Loss: 55.706512451171875, Losses: L1: 3.840533971786499, L2: 0.003052942920476198, L3: 0.9805758595466614, L4: 50.9833869934082, L5: 0.1930980384349823
Epoch 8000, Loss: 55.703922271728516, Losses: L1: 3.8380484580993652, L2: 0.0030233252327889204, L3: 0.9805386066436768, L4: 50.98340606689453, L5: 0.19307556748390198
Epoch 8500, Loss: 55.70192337036133, Losses: L1: 3.8361051082611084, L2: 0.003001333912834525, L3: 0.9805088639259338, L4: 50.98344421386719, L5: 0.19305846095085144
Epoch 9000, Loss: 55.70038986206055, Losses: L1: 3.834547281265259, L2: 0.002984661143273115, L3: 0.9804845452308655, L4: 50.98353958129883, L5: 0.19304518401622772
Epoch 9500, Loss: 55.699222564697266, Losses: L1: 3.8332407474517822, L2: 0.0029724249616265297, L3: 0.980463981628418, L4: 50.983734130859375, L5: 0.1930350363254547
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.004544734954834, Constraint losses: L1: 6.777492046356201, L2: 0.0, L3: 0.9988837838172913, L4: 0.9988836050033569
Epoch 500, Loss: 0.0024125943891704082, Constraint losses: L1: -1.095055103302002, L2: 0.0, L3: 0.0027529001235961914, L4: 0.0007547494024038315
Epoch 1000, Loss: 0.0013727954355999827, Constraint losses: L1: -1.1183315515518188, L2: 0.0, L3: 0.0022452473640441895, L4: 0.00024587963707745075
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0208311080932617, Constraint losses: L1: 18.42068099975586, L2: 0.0008035871433094144, L3: 1.0008035898208618, L4: 1.0008033514022827
Epoch 500, Loss: 0.002102265367284417, Constraint losses: L1: -1.0675712823867798, L2: 0.0, L3: 0.0025842785835266113, L4: 0.0005855581257492304
Epoch 1000, Loss: 0.00132153055164963, Constraint losses: L1: -1.071277141571045, L2: 0.0, L3: 0.0021961331367492676, L4: 0.0001966745767276734
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 163.7069854736328, Losses: L1: 4.361800193786621, L2: 0.0, L3: 0.9864694476127625, L4: 79.33378601074219, L5: 0.3687295913696289
Epoch 500, Loss: 18.545806884765625, Losses: L1: 0.9679721593856812, L2: 0.5577447414398193, L3: 0.28575825691223145, L4: 8.1506986618042, L5: 0.03613691404461861
Epoch 1000, Loss: 106.72308349609375, Losses: L1: 5.1720099449157715, L2: 0.0036462126299738884, L3: 0.9948869347572327, L4: 50.474849700927734, L5: 0.193284809589386
Epoch 1500, Loss: 28.361068725585938, Losses: L1: 1.5099204778671265, L2: 0.7232630848884583, L3: 0.24101626873016357, L4: 12.625606536865234, L5: 0.06580168753862381
Epoch 2000, Loss: 5.71466588973999, Losses: L1: 0.24479812383651733, L2: 0.16721075773239136, L3: 0.1822655200958252, L4: 2.5161659717559814, L5: 0.023962922394275665
Epoch 2500, Loss: 4.481075286865234, Losses: L1: 0.26463764905929565, L2: 0.12668490409851074, L3: 0.1811160445213318, L4: 1.931974172592163, L5: 0.017123287543654442
Epoch 3000, Loss: 4.467230796813965, Losses: L1: 0.10726919025182724, L2: 0.12238696962594986, L3: 0.17159420251846313, L4: 2.0105552673339844, L5: 0.01655961014330387
Epoch 3500, Loss: 3.3219950199127197, Losses: L1: 0.20088797807693481, L2: 0.08442166447639465, L3: 0.16401737928390503, L4: 1.4311575889587402, L5: 0.015879599377512932
Epoch 4000, Loss: 2.827237129211426, Losses: L1: 0.2126597762107849, L2: 0.071298748254776, L3: 0.15710973739624023, L4: 1.1926605701446533, L5: 0.016207512468099594
Epoch 4500, Loss: 2.5796167850494385, Losses: L1: 0.18656733632087708, L2: 0.0731731653213501, L3: 0.1482640504837036, L4: 1.0820708274841309, L5: 0.016859132796525955
Epoch 5000, Loss: 2.3726279735565186, Losses: L1: 0.1792571246623993, L2: 0.06717424839735031, L3: 0.14829039573669434, L4: 0.988330602645874, L5: 0.01643160916864872
Epoch 5500, Loss: 2.276261568069458, Losses: L1: 0.19128866493701935, L2: 0.06768053770065308, L3: 0.1466057300567627, L4: 0.9340583086013794, L5: 0.016384636983275414
Epoch 6000, Loss: 2.2310729026794434, Losses: L1: 0.19941367208957672, L2: 0.06769413501024246, L3: 0.145382821559906, L4: 0.9076943397521973, L5: 0.016381582245230675
Epoch 6500, Loss: 2.2131996154785156, Losses: L1: 0.20165079832077026, L2: 0.06816644966602325, L3: 0.1444273591041565, L4: 0.8974118232727051, L5: 0.01635754480957985
Epoch 7000, Loss: 2.2004988193511963, Losses: L1: 0.20343239605426788, L2: 0.06859312951564789, L3: 0.14358603954315186, L4: 0.8899562358856201, L5: 0.01634909398853779
Epoch 7500, Loss: 2.19119930267334, Losses: L1: 0.2045816332101822, L2: 0.06888140738010406, L3: 0.14304810762405396, L4: 0.8845841288566589, L5: 0.016325125470757484
Epoch 8000, Loss: 2.184373378753662, Losses: L1: 0.2052302360534668, L2: 0.06911053508520126, L3: 0.14259833097457886, L4: 0.8807330131530762, L5: 0.01631331443786621
Epoch 8500, Loss: 2.1793508529663086, Losses: L1: 0.20581085979938507, L2: 0.0692782998085022, L3: 0.14224004745483398, L4: 0.8778548836708069, L5: 0.016307517886161804
Epoch 9000, Loss: 2.1757888793945312, Losses: L1: 0.2065158635377884, L2: 0.06928965449333191, L3: 0.14202630519866943, L4: 0.8757652044296265, L5: 0.016300253570079803
Epoch 9500, Loss: 2.173305034637451, Losses: L1: 0.20726008713245392, L2: 0.06924710422754288, L3: 0.1418929100036621, L4: 0.8742290139198303, L5: 0.016292663291096687
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0015013217926025, Constraint losses: L1: 6.013981819152832, L2: 0.0, L3: 0.9977441430091858, L4: 0.9977432489395142
Epoch 500, Loss: 0.0022666880395263433, Constraint losses: L1: -1.0628745555877686, L2: 0.0, L3: 0.0026637911796569824, L4: 0.0006657714257016778
Epoch 1000, Loss: 0.0012890497455373406, Constraint losses: L1: -1.117948293685913, L2: 0.0, L3: 0.0022032856941223145, L4: 0.00020371240680105984
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0052225589752197, Constraint losses: L1: 6.957667350769043, L2: 0.0, L3: 0.9991325736045837, L4: 0.9991322755813599
Epoch 500, Loss: 0.002354690805077553, Constraint losses: L1: -1.0205063819885254, L2: 0.0, L3: 0.002686619758605957, L4: 0.000688577420078218
Epoch 1000, Loss: 0.0013702443102374673, Constraint losses: L1: -1.0695720911026, L2: 0.0, L3: 0.002219557762145996, L4: 0.00022025872021913528
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 189.70550537109375, Losses: L1: 17.303468704223633, L2: 0.002800238784402609, L3: 1.002311110496521, L4: 85.73313903808594, L5: 0.4290046691894531
Epoch 500, Loss: 7.060888290405273, Losses: L1: 0.7079246044158936, L2: 0.32447925209999084, L3: 0.0753319263458252, L4: 2.821735143661499, L5: 0.02286887727677822
Epoch 1000, Loss: 6.046047210693359, Losses: L1: 0.7713396549224854, L2: 0.4122318625450134, L3: 0.047397732734680176, L4: 2.202023506164551, L5: 0.02249816618859768
Epoch 1500, Loss: 1.035798192024231, Losses: L1: -0.256110280752182, L2: 0.03357435762882233, L3: 0.051161885261535645, L4: 0.595269501209259, L5: 0.008639797568321228
Epoch 2000, Loss: 1.6536648273468018, Losses: L1: -0.2779064178466797, L2: 0.04202306270599365, L3: 0.049021363258361816, L4: 0.9064579606056213, L5: 0.010098428465425968
Epoch 2500, Loss: 0.4849308133125305, Losses: L1: -0.26962190866470337, L2: 0.03555995970964432, L3: 0.04820966720581055, L4: 0.3261868357658386, L5: 0.0069542983546853065
Epoch 3000, Loss: 0.29221799969673157, Losses: L1: -0.26912808418273926, L2: 0.03249499946832657, L3: 0.04799652099609375, L4: 0.2332032322883606, L5: 0.005951368249952793
Epoch 3500, Loss: 0.16018380224704742, Losses: L1: -0.2674991190433502, L2: 0.031170537695288658, L3: 0.047931134700775146, L4: 0.16755355894565582, L5: 0.006269160192459822
Epoch 4000, Loss: 0.01726517267525196, Losses: L1: -0.26870429515838623, L2: 0.03092307038605213, L3: 0.047871947288513184, L4: 0.09709931910037994, L5: 0.005988718941807747
Epoch 4500, Loss: -0.007506283465772867, Losses: L1: -0.26740896701812744, L2: 0.029856007546186447, L3: 0.04801476001739502, L4: 0.08509539812803268, L5: 0.005992484744638205
Epoch 5000, Loss: -0.006937756203114986, Losses: L1: -0.26660555601119995, L2: 0.029413975775241852, L3: 0.048050880432128906, L4: 0.08543089032173157, L5: 0.005952627398073673
Epoch 5500, Loss: -0.017706673592329025, Losses: L1: -0.26677918434143066, L2: 0.029360095039010048, L3: 0.04800140857696533, L4: 0.08020827919244766, L5: 0.005935061722993851
Epoch 6000, Loss: -0.020456433296203613, Losses: L1: -0.2668386995792389, L2: 0.029368599876761436, L3: 0.04796791076660156, L4: 0.07886579632759094, L5: 0.005929514765739441
Epoch 6500, Loss: -0.022387083619832993, Losses: L1: -0.2666609287261963, L2: 0.0291623305529356, L3: 0.04797399044036865, L4: 0.07802419364452362, L5: 0.00591379776597023
Epoch 7000, Loss: -0.024928275495767593, Losses: L1: -0.2666923403739929, L2: 0.029136724770069122, L3: 0.04796135425567627, L4: 0.07679666578769684, L5: 0.00591660663485527
Epoch 7500, Loss: -0.026279237121343613, Losses: L1: -0.2667207717895508, L2: 0.02910497598350048, L3: 0.04794609546661377, L4: 0.07617455720901489, L5: 0.005909416358917952
Epoch 8000, Loss: -0.026854177936911583, Losses: L1: -0.2666935324668884, L2: 0.029046809300780296, L3: 0.04794418811798096, L4: 0.07593271136283875, L5: 0.005908215418457985
Epoch 8500, Loss: -0.02760741300880909, Losses: L1: -0.2667447328567505, L2: 0.02903810702264309, L3: 0.047936201095581055, L4: 0.075593501329422, L5: 0.0059059988707304
Epoch 9000, Loss: -0.02797815203666687, Losses: L1: -0.266727089881897, L2: 0.029005223885178566, L3: 0.0479353666305542, L4: 0.07543325424194336, L5: 0.005904302466660738
Epoch 9500, Loss: -0.02830447070300579, Losses: L1: -0.2667323052883148, L2: 0.028993526473641396, L3: 0.04793292284011841, L4: 0.07528507709503174, L5: 0.005904169753193855
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9976963996887207, Constraint losses: L1: 5.48586368560791, L2: 0.0, L3: 0.9961056709289551, L4: 0.9961048364639282
Epoch 500, Loss: 0.002357862889766693, Constraint losses: L1: -1.0607717037200928, L2: 0.0, L3: 0.002708256244659424, L4: 0.0007103785173967481
Epoch 1000, Loss: 0.001319354516454041, Constraint losses: L1: -1.1173548698425293, L2: 0.0, L3: 0.0022180676460266113, L4: 0.00021864184236619622
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.997654914855957, Constraint losses: L1: 5.50537109375, L2: 0.0, L3: 0.9960750341415405, L4: 0.9960744976997375
Epoch 500, Loss: 0.0020619782153517008, Constraint losses: L1: -1.0500142574310303, L2: 0.0, L3: 0.002555251121520996, L4: 0.0005567413754761219
Epoch 1000, Loss: 0.0012918913271278143, Constraint losses: L1: -1.0708004236221313, L2: 0.0, L3: 0.002181112766265869, L4: 0.00018157903105020523
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 160.8540496826172, Losses: L1: 18.42068099975586, L2: 0.0007354493718594313, L3: 1.0007354021072388, L4: 70.65016174316406, L5: 0.3156055510044098
Epoch 500, Loss: 110.0483169555664, Losses: L1: 9.401494979858398, L2: 0.014814814552664757, L3: 1.0041303634643555, L4: 49.86638641357422, L5: 0.19117790460586548
Epoch 1000, Loss: 22.97027587890625, Losses: L1: 2.2049591541290283, L2: 0.838887095451355, L3: 0.37431758642196655, L4: 9.406965255737305, L5: 0.043226536363363266
Epoch 1500, Loss: 8.025557518005371, Losses: L1: 0.18345791101455688, L2: 0.18058104813098907, L3: 0.18041855096817017, L4: 3.656507968902588, L5: 0.03885619342327118
Epoch 2000, Loss: 3.5152313709259033, Losses: L1: 0.15168876945972443, L2: 0.1405227780342102, L3: 0.12701141834259033, L4: 1.4894477128982544, L5: 0.020048027858138084
Epoch 2500, Loss: 3.21134352684021, Losses: L1: 0.09158249199390411, L2: 0.11386695504188538, L3: 0.12588411569595337, L4: 1.399453043937683, L5: 0.015089521184563637
Epoch 3000, Loss: 7.795950889587402, Losses: L1: 4.283417224884033, L2: 0.27671384811401367, L3: 0.08986914157867432, L4: 1.4387545585632324, L5: 0.018331166356801987
Epoch 3500, Loss: 2.5071704387664795, Losses: L1: 0.030123865231871605, L2: 0.11292745172977448, L3: 0.13144850730895996, L4: 1.0817294120788574, L5: 0.011004344560205936
Epoch 4000, Loss: 2.180412530899048, Losses: L1: -0.02942011132836342, L2: 0.10746017843484879, L3: 0.12237846851348877, L4: 0.9566363096237183, L5: 0.010225127451121807
Epoch 4500, Loss: 2.00606632232666, Losses: L1: -0.0746728852391243, L2: 0.10126929730176926, L3: 0.11913931369781494, L4: 0.8994725942611694, L5: 0.009842927567660809
Epoch 5000, Loss: 1.8827794790267944, Losses: L1: -0.10510455071926117, L2: 0.09714703261852264, L3: 0.11646789312362671, L4: 0.8579877614974976, L5: 0.009690197184681892
Epoch 5500, Loss: 1.7923905849456787, Losses: L1: -0.12674911320209503, L2: 0.09357471764087677, L3: 0.11468207836151123, L4: 0.8277084827423096, L5: 0.009616166353225708
Epoch 6000, Loss: 1.7261953353881836, Losses: L1: -0.1389368623495102, L2: 0.0907730907201767, L3: 0.11334514617919922, L4: 0.8039150238037109, L5: 0.009541665203869343
Epoch 6500, Loss: 1.6788654327392578, Losses: L1: -0.14569547772407532, L2: 0.08877776563167572, L3: 0.11227893829345703, L4: 0.7859707474708557, L5: 0.009462223388254642
Epoch 7000, Loss: 1.6419501304626465, Losses: L1: -0.15013767778873444, L2: 0.08720212429761887, L3: 0.11124646663665771, L4: 0.7715282440185547, L5: 0.009501957334578037
Epoch 7500, Loss: 1.613937497138977, Losses: L1: -0.1531158685684204, L2: 0.08593878149986267, L3: 0.11059212684631348, L4: 0.7604297399520874, L5: 0.009510110132396221
Epoch 8000, Loss: 1.5924218893051147, Losses: L1: -0.15526312589645386, L2: 0.08501340448856354, L3: 0.11005598306655884, L4: 0.7518001794815063, L5: 0.009514906443655491
Epoch 8500, Loss: 1.5759360790252686, Losses: L1: -0.15672031044960022, L2: 0.08423630148172379, L3: 0.10971367359161377, L4: 0.7451469302177429, L5: 0.009516511112451553
Epoch 9000, Loss: 1.5637938976287842, Losses: L1: -0.15793946385383606, L2: 0.08370792120695114, L3: 0.10943615436553955, L4: 0.7402769327163696, L5: 0.009522794745862484
Epoch 9500, Loss: 1.555037021636963, Losses: L1: -0.158654123544693, L2: 0.08327355980873108, L3: 0.10926324129104614, L4: 0.7367311120033264, L5: 0.009525039233267307
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023378610610962, Constraint losses: L1: 18.42068099975586, L2: 0.0016526791732758284, L3: 1.001652717590332, L4: 1.001652479171753
Epoch 500, Loss: 0.002242947928607464, Constraint losses: L1: -1.0406608581542969, L2: 0.0, L3: 0.0026407837867736816, L4: 0.0006428250344470143
Epoch 1000, Loss: 0.001270005013793707, Constraint losses: L1: -1.1181910037994385, L2: 0.0, L3: 0.0021938085556030273, L4: 0.0001943875540746376
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0196022987365723, Constraint losses: L1: 18.42068099975586, L2: 0.00039375832420773804, L3: 1.0003937482833862, L4: 1.0003941059112549
Epoch 500, Loss: 0.002283168025314808, Constraint losses: L1: -1.0543546676635742, L2: 0.0, L3: 0.0026679635047912598, L4: 0.0006695592310279608
Epoch 1000, Loss: 0.0013718685368075967, Constraint losses: L1: -1.070759654045105, L2: 0.0, L3: 0.002221047878265381, L4: 0.0002215803979197517
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.720375061035156, Losses: L1: 16.64272117614746, L2: 0.002563444897532463, L3: 1.0024833679199219, L4: 73.80450439453125, L5: 0.33558738231658936
Epoch 500, Loss: 31.541719436645508, Losses: L1: 5.480774879455566, L2: 0.005078495945781469, L3: 0.9563684463500977, L4: 50.01634216308594, L5: 0.17249520123004913
Epoch 1000, Loss: 31.5926456451416, Losses: L1: 5.377902507781982, L2: 0.0022457255981862545, L3: 0.9947718977928162, L4: 50.23816680908203, L5: 0.192789226770401
Epoch 1500, Loss: 31.050704956054688, Losses: L1: 3.1296427249908447, L2: 0.018300533294677734, L3: 0.9383878111839294, L4: 53.71355438232422, L5: 0.17859144508838654
Epoch 2000, Loss: 29.686798095703125, Losses: L1: 3.0898497104644775, L2: 9.724448318593204e-05, L3: 0.933123767375946, L4: 51.15596008300781, L5: 0.1712988018989563
Epoch 2500, Loss: 7.746548652648926, Losses: L1: 1.1375811100006104, L2: 0.35706377029418945, L3: 0.3543161153793335, L4: 11.04581356048584, L5: 0.03523487597703934
Epoch 3000, Loss: 5.8294196128845215, Losses: L1: 0.8592774868011475, L2: 0.3425195515155792, L3: 0.3181164264678955, L4: 7.906890869140625, L5: 0.027082741260528564
Epoch 3500, Loss: 5.244882106781006, Losses: L1: 0.7422950267791748, L2: 0.36106184124946594, L3: 0.30586594343185425, L4: 6.922749996185303, L5: 0.02644410915672779
Epoch 4000, Loss: 4.468282699584961, Losses: L1: 0.6429159045219421, L2: 0.3197811543941498, L3: 0.2835808992385864, L4: 5.77908182144165, L5: 0.025365451350808144
Epoch 4500, Loss: 4.242611885070801, Losses: L1: 0.6388272643089294, L2: 0.3025663197040558, L3: 0.2873724699020386, L4: 5.398090839385986, L5: 0.024468574672937393
Epoch 5000, Loss: 4.080442428588867, Losses: L1: 0.6275333166122437, L2: 0.2918022871017456, L3: 0.2834738492965698, L4: 5.147837162017822, L5: 0.023824544623494148
Epoch 5500, Loss: 3.9460456371307373, Losses: L1: 0.6214354634284973, L2: 0.28326311707496643, L3: 0.2764490842819214, L4: 4.939568042755127, L5: 0.023701844736933708
Epoch 6000, Loss: 3.8376307487487793, Losses: L1: 0.6026628017425537, L2: 0.27441778779029846, L3: 0.2734798192977905, L4: 4.801977634429932, L5: 0.02332792617380619
Epoch 6500, Loss: 3.770811080932617, Losses: L1: 0.5990404486656189, L2: 0.2685912847518921, L3: 0.27214837074279785, L4: 4.701961040496826, L5: 0.022918013855814934
Epoch 7000, Loss: 3.7212820053100586, Losses: L1: 0.5977487564086914, L2: 0.26333239674568176, L3: 0.27104049921035767, L4: 4.628990173339844, L5: 0.0226658396422863
Epoch 7500, Loss: 3.68552303314209, Losses: L1: 0.5967272520065308, L2: 0.259601891040802, L3: 0.2702115774154663, L4: 4.5762858390808105, L5: 0.022475088015198708
Epoch 8000, Loss: 3.6603047847747803, Losses: L1: 0.5961219668388367, L2: 0.25687700510025024, L3: 0.2696676254272461, L4: 4.53918981552124, L5: 0.02233269065618515
Epoch 8500, Loss: 3.6429603099823, Losses: L1: 0.5955865383148193, L2: 0.2551373839378357, L3: 0.2692328691482544, L4: 4.513494491577148, L5: 0.02223774418234825
Epoch 9000, Loss: 3.631218910217285, Losses: L1: 0.5954955220222473, L2: 0.2538166344165802, L3: 0.2689090371131897, L4: 4.496172904968262, L5: 0.022188998758792877
Epoch 9500, Loss: 3.6234207153320312, Losses: L1: 0.5952481627464294, L2: 0.25307518243789673, L3: 0.2686970829963684, L4: 4.484501838684082, L5: 0.022148724645376205
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.000882148742676, Constraint losses: L1: 5.969222068786621, L2: 0.0, L3: 0.997456431388855, L4: 0.997456431388855
Epoch 500, Loss: 0.002204158343374729, Constraint losses: L1: -1.1118998527526855, L2: 0.0, L3: 0.002657294273376465, L4: 0.0006587638054043055
Epoch 1000, Loss: 0.001317907590419054, Constraint losses: L1: -1.117742657661438, L2: 0.0, L3: 0.0022174715995788574, L4: 0.0002181787567678839
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9967005252838135, Constraint losses: L1: 5.394506931304932, L2: 0.0, L3: 0.9956534504890442, L4: 0.9956525564193726
Epoch 500, Loss: 0.002491509076207876, Constraint losses: L1: -0.9521636366844177, L2: 0.0, L3: 0.002720654010772705, L4: 0.0007230187766253948
Epoch 1000, Loss: 0.0013701170682907104, Constraint losses: L1: -1.069644808769226, L2: 0.0, L3: 0.0022196173667907715, L4: 0.00022014445858076215
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 42.765968322753906, Losses: L1: 5.839372158050537, L2: 0.0, L3: 0.9965715408325195, L4: 71.22210693359375, L5: 0.3189697563648224
Epoch 500, Loss: 4.572338581085205, Losses: L1: -0.16006727516651154, L2: 0.32428330183029175, L3: 0.09122854471206665, L4: 7.892618179321289, L5: 0.046301186084747314
Epoch 1000, Loss: 3.0185227394104004, Losses: L1: -0.013065663166344166, L2: 0.09443249553442001, L3: 0.14756011962890625, L4: 5.356130599975586, L5: 0.0170979555696249
Epoch 1500, Loss: 0.7062157392501831, Losses: L1: -0.2491915076971054, L2: 0.06139899045228958, L3: 0.09158933162689209, L4: 1.4501457214355469, L5: 0.015947099775075912
Epoch 2000, Loss: 0.391882985830307, Losses: L1: -0.2312411218881607, L2: 0.047469135373830795, L3: 0.07781070470809937, L4: 0.8868676424026489, L5: 0.006941310130059719
Epoch 2500, Loss: 0.16521793603897095, Losses: L1: -0.2450351119041443, L2: 0.037265580147504807, L3: 0.07538080215454102, L4: 0.5061665773391724, L5: 0.007257787976413965
Epoch 3000, Loss: 0.23284496366977692, Losses: L1: -0.26125621795654297, L2: 0.04227201268076897, L3: 0.0706624984741211, L4: 0.6603870391845703, L5: 0.008701135404407978
Epoch 3500, Loss: 0.09773124754428864, Losses: L1: -0.25857746601104736, L2: 0.03909311816096306, L3: 0.07049381732940674, L4: 0.4005613625049591, L5: 0.007347969803959131
Epoch 4000, Loss: 0.066197469830513, Losses: L1: -0.25816312432289124, L2: 0.03779883682727814, L3: 0.06984543800354004, L4: 0.3444952964782715, L5: 0.006669831462204456
Epoch 4500, Loss: 0.050665222108364105, Losses: L1: -0.2579890787601471, L2: 0.037277646362781525, L3: 0.06915056705474854, L4: 0.31645023822784424, L5: 0.006723321974277496
Epoch 5000, Loss: 0.04573516920208931, Losses: L1: -0.25767454504966736, L2: 0.03721616789698601, L3: 0.06884115934371948, L4: 0.3068315088748932, L5: 0.0067204562947154045
Epoch 5500, Loss: 0.04067165032029152, Losses: L1: -0.2581978738307953, L2: 0.03730804845690727, L3: 0.06851977109909058, L4: 0.297939270734787, L5: 0.006764011923223734
Epoch 6000, Loss: 0.03778858482837677, Losses: L1: -0.2583049535751343, L2: 0.03715035319328308, L3: 0.06827735900878906, L4: 0.2935516834259033, L5: 0.006739631295204163
Epoch 6500, Loss: 0.03577391803264618, Losses: L1: -0.25831618905067444, L2: 0.03698832169175148, L3: 0.06812870502471924, L4: 0.2905004024505615, L5: 0.006734565366059542
Epoch 7000, Loss: 0.034255824983119965, Losses: L1: -0.25837501883506775, L2: 0.03686303272843361, L3: 0.06801193952560425, L4: 0.2882978320121765, L5: 0.006743930745869875
Epoch 7500, Loss: 0.033085379749536514, Losses: L1: -0.25852668285369873, L2: 0.03683438524603844, L3: 0.06789290904998779, L4: 0.28663212060928345, L5: 0.006734316237270832
Epoch 8000, Loss: 0.03229260444641113, Losses: L1: -0.25854650139808655, L2: 0.03678785264492035, L3: 0.06782346963882446, L4: 0.285406231880188, L5: 0.006736814044415951
Epoch 8500, Loss: 0.031677886843681335, Losses: L1: -0.2585567831993103, L2: 0.03673287853598595, L3: 0.0677785873413086, L4: 0.28451302647590637, L5: 0.0067338040098547935
Epoch 9000, Loss: 0.03125223517417908, Losses: L1: -0.2586009204387665, L2: 0.03672013804316521, L3: 0.06774163246154785, L4: 0.28387966752052307, L5: 0.006731406785547733
Epoch 9500, Loss: 0.030945006757974625, Losses: L1: -0.2586178779602051, L2: 0.036700546741485596, L3: 0.06771159172058105, L4: 0.28344330191612244, L5: 0.006728549022227526
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0249829292297363, Constraint losses: L1: 18.42068099975586, L2: 0.0021875135134905577, L3: 1.0021874904632568, L4: 1.0021872520446777
Epoch 500, Loss: 0.0019930133130401373, Constraint losses: L1: -1.0946221351623535, L2: 0.0, L3: 0.0025429725646972656, L4: 0.0005446629365906119
Epoch 1000, Loss: 0.0012250952422618866, Constraint losses: L1: -1.118661642074585, L2: 0.0, L3: 0.002171635627746582, L4: 0.000172121319337748
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0023202896118164, Constraint losses: L1: 6.248929500579834, L2: 0.0, L3: 0.9980356693267822, L4: 0.9980356693267822
Epoch 500, Loss: 0.0023297409061342478, Constraint losses: L1: -1.0520427227020264, L2: 0.0, L3: 0.0026900172233581543, L4: 0.0006917664431966841
Epoch 1000, Loss: 0.0013809617375954986, Constraint losses: L1: -1.0692689418792725, L2: 0.0, L3: 0.0022248029708862305, L4: 0.0002254277642350644
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 48.2908935546875, Losses: L1: 5.216404914855957, L2: 0.0, L3: 0.9945221543312073, L4: 82.5700454711914, L5: 0.3974725604057312
Epoch 500, Loss: 2.487621545791626, Losses: L1: 0.046328749507665634, L2: 0.08270878344774246, L3: 0.07747960090637207, L4: 4.182491779327393, L5: 0.05357493832707405
Epoch 1000, Loss: 2.4104461669921875, Losses: L1: 0.11039640009403229, L2: 0.06815902888774872, L3: 0.06048762798309326, L4: 4.064924240112305, L5: 0.03539099171757698
Epoch 1500, Loss: 0.9715011119842529, Losses: L1: -0.23377564549446106, L2: 0.048326872289180756, L3: 0.060309767723083496, L4: 2.057990312576294, L5: 0.009659051895141602
Epoch 2000, Loss: 0.3310157060623169, Losses: L1: -0.2591075003147125, L2: 0.05686836317181587, L3: 0.06506597995758057, L4: 0.7786658406257629, L5: 0.010993792675435543
Epoch 2500, Loss: 0.029190437868237495, Losses: L1: -0.2958022952079773, L2: 0.03894127532839775, L3: 0.056662559509277344, L4: 0.3605283796787262, L5: 0.005091712810099125
Epoch 3000, Loss: -0.048585254698991776, Losses: L1: -0.29507189989089966, L2: 0.02690110355615616, L3: 0.051107585430145264, L4: 0.264082133769989, L5: 0.00476789241656661
Epoch 3500, Loss: -0.08455175906419754, Losses: L1: -0.295107364654541, L2: 0.02467362955212593, L3: 0.05022168159484863, L4: 0.20316343009471893, L5: 0.004702480044215918
Epoch 4000, Loss: -0.12528559565544128, Losses: L1: -0.2975906729698181, L2: 0.02638409659266472, L3: 0.049514055252075195, L4: 0.12111106514930725, L5: 0.004733646288514137
Epoch 4500, Loss: -0.1292310208082199, Losses: L1: -0.29894891381263733, L2: 0.026863781735301018, L3: 0.049065232276916504, L4: 0.11500243842601776, L5: 0.004711935296654701
Epoch 5000, Loss: -0.1325899362564087, Losses: L1: -0.29850584268569946, L2: 0.02669381909072399, L3: 0.04895305633544922, L4: 0.1082901805639267, L5: 0.0047150575555861
Epoch 5500, Loss: -0.13626177608966827, Losses: L1: -0.2987441420555115, L2: 0.0266598928719759, L3: 0.04885983467102051, L4: 0.10184641182422638, L5: 0.004689778666943312
Epoch 6000, Loss: -0.1378750503063202, Losses: L1: -0.29899653792381287, L2: 0.026661479845643044, L3: 0.04879426956176758, L4: 0.0993129312992096, L5: 0.004673895891755819
Epoch 6500, Loss: -0.1388852745294571, Losses: L1: -0.2991723120212555, L2: 0.026673290878534317, L3: 0.04873627424240112, L4: 0.0977669507265091, L5: 0.004660359118133783
Epoch 7000, Loss: -0.13970789313316345, Losses: L1: -0.29940494894981384, L2: 0.026744255796074867, L3: 0.04869180917739868, L4: 0.09641312062740326, L5: 0.004655096214264631
Epoch 7500, Loss: -0.1403125822544098, Losses: L1: -0.2995034158229828, L2: 0.02675561234354973, L3: 0.04863935708999634, L4: 0.09549269080162048, L5: 0.00464694993570447
Epoch 8000, Loss: -0.14071229100227356, Losses: L1: -0.2996092140674591, L2: 0.026768963783979416, L3: 0.04862332344055176, L4: 0.09490084648132324, L5: 0.004642622545361519
Epoch 8500, Loss: -0.14099673926830292, Losses: L1: -0.2996622323989868, L2: 0.026774652302265167, L3: 0.04860168695449829, L4: 0.09447573125362396, L5: 0.004638321232050657
Epoch 9000, Loss: -0.14121189713478088, Losses: L1: -0.2996971309185028, L2: 0.026786163449287415, L3: 0.048588454723358154, L4: 0.09410243481397629, L5: 0.004636615049093962
Epoch 9500, Loss: -0.14135469496250153, Losses: L1: -0.29972705245018005, L2: 0.026798367500305176, L3: 0.048577964305877686, L4: 0.09385611861944199, L5: 0.0046348003670573235
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.026686668395996, Constraint losses: L1: 18.42068099975586, L2: 0.002755120862275362, L3: 1.0027551651000977, L4: 1.0027557611465454
Epoch 500, Loss: 0.002360631013289094, Constraint losses: L1: -1.0787134170532227, L2: 0.0, L3: 0.002718687057495117, L4: 0.0007206574082374573
Epoch 1000, Loss: 0.0013369247317314148, Constraint losses: L1: -1.117263913154602, L2: 0.0, L3: 0.0022267699241638184, L4: 0.00022741869906894863
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0024800300598145, Constraint losses: L1: 6.266438007354736, L2: 0.0, L3: 0.998106837272644, L4: 0.9981067180633545
Epoch 500, Loss: 0.0020703664049506187, Constraint losses: L1: -0.9478824734687805, L2: 0.0, L3: 0.0025082826614379883, L4: 0.0005099661648273468
Epoch 1000, Loss: 0.0012325586285442114, Constraint losses: L1: -1.064131498336792, L2: 0.0, L3: 0.002148151397705078, L4: 0.00014853879110887647
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 86.76565551757812, Losses: L1: 9.243535995483398, L2: 4.1007915569934994e-05, L3: 0.9989093542098999, L4: 76.34550476074219, L5: 0.3552572429180145
Epoch 500, Loss: 3.0717039108276367, Losses: L1: 0.3231888711452484, L2: 0.29569852352142334, L3: 0.060329318046569824, L4: 2.0863425731658936, L5: 0.020892273634672165
Epoch 1000, Loss: 3.300168991088867, Losses: L1: -0.09826381504535675, L2: 0.2370428889989853, L3: 0.0718756914138794, L4: 2.8368194103240967, L5: 0.03130397945642471
Epoch 1500, Loss: 9.005563735961914, Losses: L1: 2.630798816680908, L2: 0.46193504333496094, L3: 0.1156192421913147, L4: 5.319154262542725, L5: 0.032241687178611755
Epoch 2000, Loss: 5.671072006225586, Losses: L1: 0.9827195405960083, L2: 0.14746947586536407, L3: 0.07359123229980469, L4: 4.2970290184021, L5: 0.045586857944726944
Epoch 2500, Loss: 7.376239776611328, Losses: L1: 3.285393238067627, L2: 0.41617244482040405, L3: 0.11824148893356323, L4: 3.1283626556396484, L5: 0.02379535883665085
Epoch 3000, Loss: 12.194430351257324, Losses: L1: 4.602299213409424, L2: 0.2928546369075775, L3: 0.26432090997695923, L4: 6.725996017456055, L5: 0.032208945602178574
Epoch 3500, Loss: 1.9092795848846436, Losses: L1: 0.5827994346618652, L2: 0.0663161352276802, L3: 0.11772012710571289, L4: 1.0678706169128418, L5: 0.01651429757475853
Epoch 4000, Loss: 1.4099531173706055, Losses: L1: 0.19939292967319489, L2: 0.05179150775074959, L3: 0.11228293180465698, L4: 0.9866436719894409, L5: 0.01610107161104679
Epoch 4500, Loss: 1.3215855360031128, Losses: L1: 0.1918606460094452, L2: 0.050969842821359634, L3: 0.10899299383163452, L4: 0.9105613827705383, L5: 0.016461705788969994
Epoch 5000, Loss: 1.262268304824829, Losses: L1: 0.18829764425754547, L2: 0.050510846078395844, L3: 0.107044517993927, L4: 0.8574806451797485, L5: 0.016847582533955574
Epoch 5500, Loss: 1.2222975492477417, Losses: L1: 0.1834774911403656, L2: 0.05026515573263168, L3: 0.10539424419403076, L4: 0.8242630362510681, L5: 0.017264991998672485
Epoch 6000, Loss: 1.1700923442840576, Losses: L1: 0.17090770602226257, L2: 0.05046812444925308, L3: 0.10384100675582886, L4: 0.7856533527374268, L5: 0.01750798337161541
Epoch 6500, Loss: 1.1451771259307861, Losses: L1: 0.17317171394824982, L2: 0.05046975240111351, L3: 0.10293447971343994, L4: 0.7593169212341309, L5: 0.017629167065024376
Epoch 7000, Loss: 1.1278529167175293, Losses: L1: 0.17249293625354767, L2: 0.05037972703576088, L3: 0.10239672660827637, L4: 0.7433556914329529, L5: 0.017696093767881393
Epoch 7500, Loss: 1.1151549816131592, Losses: L1: 0.17189933359622955, L2: 0.05033157765865326, L3: 0.1019585132598877, L4: 0.7317667007446289, L5: 0.017734495922923088
Epoch 8000, Loss: 1.1058311462402344, Losses: L1: 0.17174695432186127, L2: 0.05032048001885414, L3: 0.10143470764160156, L4: 0.7231018543243408, L5: 0.01781327649950981
Epoch 8500, Loss: 1.0988019704818726, Losses: L1: 0.17139697074890137, L2: 0.05029284954071045, L3: 0.10108649730682373, L4: 0.716808557510376, L5: 0.017848391085863113
Epoch 9000, Loss: 1.0936260223388672, Losses: L1: 0.17132969200611115, L2: 0.050305336713790894, L3: 0.10079681873321533, L4: 0.7119490504264832, L5: 0.017879467457532883
Epoch 9500, Loss: 1.0898737907409668, Losses: L1: 0.17141394317150116, L2: 0.050317905843257904, L3: 0.10057008266448975, L4: 0.7083050608634949, L5: 0.017897767946124077
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.026510000228882, Constraint losses: L1: 18.42068099975586, L2: 0.002696305513381958, L3: 1.0026962757110596, L4: 1.0026967525482178
Epoch 500, Loss: 0.0021474543027579784, Constraint losses: L1: -1.0848870277404785, L2: 0.0, L3: 0.00261533260345459, L4: 0.0006170088890939951
Epoch 1000, Loss: 0.001274712267331779, Constraint losses: L1: -1.1184818744659424, L2: 0.0, L3: 0.002196371555328369, L4: 0.00019682264246512204
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0064854621887207, Constraint losses: L1: 7.471677303314209, L2: 0.0, L3: 0.9995070695877075, L4: 0.9995068311691284
Epoch 500, Loss: 0.002129649743437767, Constraint losses: L1: -0.9811328053474426, L2: 0.0, L3: 0.0025545358657836914, L4: 0.0005562468431890011
Epoch 1000, Loss: 0.0012695080367848277, Constraint losses: L1: -1.0682642459869385, L2: 0.0, L3: 0.0021686553955078125, L4: 0.00016911688726395369
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 92.84614562988281, Losses: L1: 18.42068099975586, L2: 0.0010818260489031672, L3: 1.0010818243026733, L4: 73.08848571777344, L5: 0.3337324559688568
Epoch 500, Loss: 2.895503520965576, Losses: L1: 0.07216817140579224, L2: 0.07127266377210617, L3: 0.08515375852584839, L4: 2.571882724761963, L5: 0.023753570392727852
Epoch 1000, Loss: 1.069588541984558, Losses: L1: -0.20750223100185394, L2: 0.05854592099785805, L3: 0.06763744354248047, L4: 1.0755363702774048, L5: 0.016825135797262192
Epoch 1500, Loss: 0.4341430366039276, Losses: L1: -0.2777769863605499, L2: 0.03412419930100441, L3: 0.05478203296661377, L4: 0.5823888182640076, L5: 0.006500778254121542
Epoch 2000, Loss: 0.28728383779525757, Losses: L1: -0.2856399416923523, L2: 0.037283800542354584, L3: 0.05368030071258545, L4: 0.4372245967388153, L5: 0.007451290730386972
Epoch 2500, Loss: 0.21353720128536224, Losses: L1: -0.28255316615104675, L2: 0.03567655384540558, L3: 0.0527229905128479, L4: 0.36421746015548706, L5: 0.007796809077262878
Epoch 3000, Loss: 0.0384526327252388, Losses: L1: -0.286684513092041, L2: 0.034218598157167435, L3: 0.05100315809249878, L4: 0.1993713676929474, L5: 0.0063254330307245255
Epoch 3500, Loss: 0.005947160068899393, Losses: L1: -0.28594669699668884, L2: 0.03123912215232849, L3: 0.05036723613739014, L4: 0.17346608638763428, L5: 0.005582290235906839
Epoch 4000, Loss: -0.03288545459508896, Losses: L1: -0.28612348437309265, L2: 0.030084343627095222, L3: 0.04998654127120972, L4: 0.1375371217727661, L5: 0.005545683205127716
Epoch 4500, Loss: -0.043069060891866684, Losses: L1: -0.28656211495399475, L2: 0.029936593025922775, L3: 0.049742937088012695, L4: 0.12839724123477936, L5: 0.005479680839926004
Epoch 5000, Loss: -0.0682969018816948, Losses: L1: -0.28724268078804016, L2: 0.030556701123714447, L3: 0.04927939176559448, L4: 0.10307526588439941, L5: 0.0054777199402451515
Epoch 5500, Loss: -0.06893692910671234, Losses: L1: -0.28774401545524597, L2: 0.030393371358513832, L3: 0.04910016059875488, L4: 0.10351622104644775, L5: 0.005403966177254915
Epoch 6000, Loss: -0.07570242136716843, Losses: L1: -0.28782448172569275, L2: 0.03015999309718609, L3: 0.04900383949279785, L4: 0.09737465530633926, L5: 0.005423575174063444
Epoch 6500, Loss: -0.07702251523733139, Losses: L1: -0.28807392716407776, L2: 0.03007693402469158, L3: 0.048914551734924316, L4: 0.09658069908618927, L5: 0.0054022870026528835
Epoch 7000, Loss: -0.07861488312482834, Losses: L1: -0.2881321907043457, L2: 0.02991080842912197, L3: 0.04887235164642334, L4: 0.09544410556554794, L5: 0.005379231180995703
Epoch 7500, Loss: -0.07977338880300522, Losses: L1: -0.2882847487926483, L2: 0.029861930757761, L3: 0.048822641372680664, L4: 0.09459391981363297, L5: 0.005370945669710636
Epoch 8000, Loss: -0.08041384816169739, Losses: L1: -0.2883756756782532, L2: 0.029800554737448692, L3: 0.048787474632263184, L4: 0.09420916438102722, L5: 0.005364077165722847
Epoch 8500, Loss: -0.0808994472026825, Losses: L1: -0.2884427607059479, L2: 0.02976815402507782, L3: 0.04876303672790527, L4: 0.09388765692710876, L5: 0.005356309004127979
Epoch 9000, Loss: -0.08119559288024902, Losses: L1: -0.28848403692245483, L2: 0.02974053844809532, L3: 0.04874837398529053, L4: 0.09370690584182739, L5: 0.00535207986831665
Epoch 9500, Loss: -0.0814158022403717, Losses: L1: -0.2885216772556305, L2: 0.02972758188843727, L3: 0.04873371124267578, L4: 0.09356750547885895, L5: 0.005349502433091402
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9868288040161133, Constraint losses: L1: 4.640462398529053, L2: 0.0, L3: 0.9910955429077148, L4: 0.9910928606987
Epoch 500, Loss: 0.002242992166429758, Constraint losses: L1: -1.110703706741333, L2: 0.0, L3: 0.0026760101318359375, L4: 0.0006776857771910727
Epoch 1000, Loss: 0.0013290022034198046, Constraint losses: L1: -1.1168098449707031, L2: 0.0, L3: 0.0022225379943847656, L4: 0.00022327412443701178
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9960912466049194, Constraint losses: L1: 5.343554973602295, L2: 0.0, L3: 0.9953742027282715, L4: 0.9953734874725342
Epoch 500, Loss: 0.0025168354623019695, Constraint losses: L1: -1.0415250062942505, L2: 0.0, L3: 0.002778172492980957, L4: 0.0007801878964528441
Epoch 1000, Loss: 0.001441732281818986, Constraint losses: L1: -1.070306420326233, L2: 0.0, L3: 0.002255737781524658, L4: 0.0002563009620644152
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 89.01780700683594, Losses: L1: 7.8342604637146, L2: 0.00014239762094803154, L3: 0.9963034391403198, L4: 79.4373779296875, L5: 0.3747892379760742
Epoch 500, Loss: 1.5843454599380493, Losses: L1: -0.16767331957817078, L2: 0.08883551508188248, L3: 0.07411384582519531, L4: 1.4658640623092651, L5: 0.017184916883707047
Epoch 1000, Loss: 1.017494559288025, Losses: L1: -0.16628141701221466, L2: 0.04487454146146774, L3: 0.052989184856414795, L4: 1.0172700881958008, L5: 0.011883808299899101
Epoch 1500, Loss: 1.3856523036956787, Losses: L1: -0.2546202540397644, L2: 0.040299609303474426, L3: 0.05249834060668945, L4: 1.467377781867981, L5: 0.019898613914847374
Epoch 2000, Loss: 0.44582685828208923, Losses: L1: -0.2701995074748993, L2: 0.0216287262737751, L3: 0.05172276496887207, L4: 0.6101025938987732, L5: 0.005471784621477127
Epoch 2500, Loss: 0.14779657125473022, Losses: L1: -0.25907349586486816, L2: 0.03527999669313431, L3: 0.04845738410949707, L4: 0.2751123607158661, L5: 0.00637016212567687
Epoch 3000, Loss: 0.10736780613660812, Losses: L1: -0.2783062756061554, L2: 0.029808519408106804, L3: 0.047371089458465576, L4: 0.2674066424369812, L5: 0.005639652721583843
Epoch 3500, Loss: 0.19158436357975006, Losses: L1: -0.28687959909439087, L2: 0.03146737441420555, L3: 0.04711347818374634, L4: 0.35681453347206116, L5: 0.005800597369670868
Epoch 4000, Loss: 0.023769255727529526, Losses: L1: -0.2840164601802826, L2: 0.02793755754828453, L3: 0.04748988151550293, L4: 0.19374752044677734, L5: 0.005336595233529806
Epoch 4500, Loss: -0.02738822251558304, Losses: L1: -0.28491348028182983, L2: 0.02814619056880474, L3: 0.04712677001953125, L4: 0.14380444586277008, L5: 0.00515082897618413
Epoch 5000, Loss: -0.012359989807009697, Losses: L1: -0.28278523683547974, L2: 0.026249974966049194, L3: 0.04740762710571289, L4: 0.16061653196811676, L5: 0.004950569011271
Epoch 5500, Loss: -0.06711065769195557, Losses: L1: -0.28383177518844604, L2: 0.026554204523563385, L3: 0.04725992679595947, L4: 0.10627523064613342, L5: 0.005038775969296694
Epoch 6000, Loss: -0.08712104707956314, Losses: L1: -0.28393226861953735, L2: 0.02629445120692253, L3: 0.047273993492126465, L4: 0.08696873486042023, L5: 0.004989792592823505
Epoch 6500, Loss: -0.08809199929237366, Losses: L1: -0.28415778279304504, L2: 0.026247307658195496, L3: 0.04725360870361328, L4: 0.0863533467054367, L5: 0.004982108250260353
Epoch 7000, Loss: -0.0889856219291687, Losses: L1: -0.28423818945884705, L2: 0.026224719360470772, L3: 0.04722392559051514, L4: 0.08562949299812317, L5: 0.00497485650703311
Epoch 7500, Loss: -0.08958461880683899, Losses: L1: -0.28444501757621765, L2: 0.026238039135932922, L3: 0.04721224308013916, L4: 0.08523067831993103, L5: 0.004970698617398739
Epoch 8000, Loss: -0.09001998603343964, Losses: L1: -0.2845573127269745, L2: 0.02621447667479515, L3: 0.04720586538314819, L4: 0.08496876060962677, L5: 0.004966870415955782
Epoch 8500, Loss: -0.0903363898396492, Losses: L1: -0.2846358120441437, L2: 0.026219677180051804, L3: 0.04719257354736328, L4: 0.08473718166351318, L5: 0.004965151194483042
Epoch 9000, Loss: -0.09054499864578247, Losses: L1: -0.2847016751766205, L2: 0.026211058720946312, L3: 0.04718625545501709, L4: 0.084621861577034, L5: 0.004963220097124577
Epoch 9500, Loss: -0.09073428809642792, Losses: L1: -0.2847203016281128, L2: 0.026198960840702057, L3: 0.04718130826950073, L4: 0.08448315411806107, L5: 0.004961816594004631
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0226707458496094, Constraint losses: L1: 18.42068099975586, L2: 0.0014165407046675682, L3: 1.001416563987732, L4: 1.0014169216156006
Epoch 500, Loss: 0.002321850508451462, Constraint losses: L1: -1.108987808227539, L2: 0.0, L3: 0.00271451473236084, L4: 0.0007163234986364841
Epoch 1000, Loss: 0.001351868617348373, Constraint losses: L1: -1.117869257926941, L2: 0.0, L3: 0.0022345781326293945, L4: 0.00023515973589383066
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0039191246032715, Constraint losses: L1: 6.61629056930542, L2: 0.0, L3: 0.998651385307312, L4: 0.9986514449119568
Epoch 500, Loss: 0.002084007253870368, Constraint losses: L1: -1.0288047790527344, L2: 0.0, L3: 0.0025554895401000977, L4: 0.000557322520762682
Epoch 1000, Loss: 0.001290873158723116, Constraint losses: L1: -1.0672314167022705, L2: 0.0, L3: 0.0021789073944091797, L4: 0.0001791972026694566
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 168.0253143310547, Losses: L1: 18.42068099975586, L2: 0.0032137904781848192, L3: 1.0032137632369995, L4: 74.21281433105469, L5: 0.33870193362236023
Epoch 500, Loss: 2.7281911373138428, Losses: L1: 0.16044184565544128, L2: 0.06434840708971024, L3: 0.07132619619369507, L4: 1.1805530786514282, L5: 0.013240527361631393
Epoch 1000, Loss: 8.141353607177734, Losses: L1: 0.3424694240093231, L2: 0.0904603973031044, L3: 0.08778393268585205, L4: 3.758362293243408, L5: 0.026909712702035904
Epoch 1500, Loss: 3.3331573009490967, Losses: L1: -0.24576584994792938, L2: 0.06099604442715645, L3: 0.05950284004211426, L4: 1.6946711540222168, L5: 0.016171837225556374
Epoch 2000, Loss: 1.8143792152404785, Losses: L1: -0.2576499879360199, L2: 0.0511469841003418, L3: 0.04967701435089111, L4: 0.9574719667434692, L5: 0.010228731669485569
Epoch 2500, Loss: 0.3730241656303406, Losses: L1: -0.2721623182296753, L2: 0.03907877206802368, L3: 0.04981672763824463, L4: 0.25662198662757874, L5: 0.007936469279229641
Epoch 3000, Loss: 0.9555310010910034, Losses: L1: -0.2687331438064575, L2: 0.03317052870988846, L3: 0.049428343772888184, L4: 0.5524473786354065, L5: 0.00720003480091691
Epoch 3500, Loss: 0.5500438809394836, Losses: L1: -0.2800751328468323, L2: 0.03704012185335159, L3: 0.048767924308776855, L4: 0.35173478722572327, L5: 0.007602571044117212
Epoch 4000, Loss: 0.06797423958778381, Losses: L1: -0.276883065700531, L2: 0.03191680461168289, L3: 0.04886144399642944, L4: 0.11433234810829163, L5: 0.006995111703872681
Epoch 4500, Loss: 0.06770528107881546, Losses: L1: -0.2774730920791626, L2: 0.030387846753001213, L3: 0.04851233959197998, L4: 0.11619709432125092, L5: 0.0069922893308103085
Epoch 5000, Loss: 0.03951741382479668, Losses: L1: -0.27673524618148804, L2: 0.029060397297143936, L3: 0.04836910963058472, L4: 0.10314789414405823, L5: 0.006933947559446096
Epoch 5500, Loss: 0.025653745979070663, Losses: L1: -0.27702680230140686, L2: 0.028669659048318863, L3: 0.0481448769569397, L4: 0.09685727953910828, L5: 0.006963603664189577
Epoch 6000, Loss: 0.02037741430103779, Losses: L1: -0.27687859535217285, L2: 0.028201043605804443, L3: 0.048011183738708496, L4: 0.09467772394418716, L5: 0.006974580232053995
Epoch 6500, Loss: 0.01625400222837925, Losses: L1: -0.2769526541233063, L2: 0.027938656508922577, L3: 0.047904789447784424, L4: 0.09297001361846924, L5: 0.006969051901251078
Epoch 7000, Loss: 0.01367610227316618, Losses: L1: -0.27686792612075806, L2: 0.02772386744618416, L3: 0.04781055450439453, L4: 0.09189905226230621, L5: 0.0069752843119204044
Epoch 7500, Loss: 0.011615472845733166, Losses: L1: -0.276943564414978, L2: 0.027575988322496414, L3: 0.04775893688201904, L4: 0.09108016639947891, L5: 0.006975596304982901
Epoch 8000, Loss: 0.0102393738925457, Losses: L1: -0.2770090401172638, L2: 0.02749594673514366, L3: 0.04771614074707031, L4: 0.09052613377571106, L5: 0.006976210046559572
Epoch 8500, Loss: 0.00924046989530325, Losses: L1: -0.2770478129386902, L2: 0.02744220197200775, L3: 0.04768496751785278, L4: 0.09011541306972504, L5: 0.006976170931011438
Epoch 9000, Loss: 0.008567776530981064, Losses: L1: -0.2770906984806061, L2: 0.02740839682519436, L3: 0.04766547679901123, L4: 0.08984406292438507, L5: 0.006976149510592222
Epoch 9500, Loss: 0.008073420263826847, Losses: L1: -0.27709725499153137, L2: 0.027385897934436798, L3: 0.04764902591705322, L4: 0.08963103592395782, L5: 0.006975563708692789
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.022495746612549, Constraint losses: L1: 18.42068099975586, L2: 0.0013931499561294913, L3: 1.0013409852981567, L4: 1.0013411045074463
Epoch 500, Loss: 0.0025117441546171904, Constraint losses: L1: -1.0338398218154907, L2: 0.0, L3: 0.002771615982055664, L4: 0.0007739680004306138
Epoch 1000, Loss: 0.0013629316817969084, Constraint losses: L1: -1.11762535572052, L2: 0.0, L3: 0.0022400617599487305, L4: 0.0002404952683718875
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.998576045036316, Constraint losses: L1: 5.65415620803833, L2: 0.0, L3: 0.9964611530303955, L4: 0.9964606761932373
Epoch 500, Loss: 0.002555689075961709, Constraint losses: L1: -0.9364534020423889, L2: 0.0, L3: 0.002744913101196289, L4: 0.0007472294964827597
Epoch 1000, Loss: 0.0013762818416580558, Constraint losses: L1: -1.0666887760162354, L2: 0.0, L3: 0.002221226692199707, L4: 0.00022174394689500332
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 158.9119873046875, Losses: L1: 18.42068099975586, L2: 0.005945452954620123, L3: 1.005937933921814, L4: 69.58956909179688, L5: 0.2943378686904907
Epoch 500, Loss: 7.310384273529053, Losses: L1: 0.7118077278137207, L2: 0.4234298765659332, L3: 0.11426401138305664, L4: 2.8127293586730957, L5: 0.011993653140962124
Epoch 1000, Loss: 4.546069145202637, Losses: L1: 0.11896678060293198, L2: 0.1372775286436081, L3: 0.08350473642349243, L4: 2.0274722576141357, L5: 0.014097953215241432
Epoch 1500, Loss: 1.4221456050872803, Losses: L1: -0.19105833768844604, L2: 0.08058622479438782, L3: 0.07495033740997314, L4: 0.6831374168395996, L5: 0.010806379839777946
Epoch 2000, Loss: 2.530733108520508, Losses: L1: -0.14949660003185272, L2: 0.11289029568433762, L3: 0.06810575723648071, L4: 1.1891443729400635, L5: 0.008054847829043865
Epoch 2500, Loss: 1.5742089748382568, Losses: L1: -0.12357546389102936, L2: 0.0718512237071991, L3: 0.0709490180015564, L4: 0.7372713685035706, L5: 0.008590168319642544
Epoch 3000, Loss: 0.9369009733200073, Losses: L1: -0.1354360729455948, L2: 0.07133255153894424, L3: 0.06949269771575928, L4: 0.42609065771102905, L5: 0.00799790769815445
Epoch 3500, Loss: 11.442987442016602, Losses: L1: 5.282581329345703, L2: 0.39111199975013733, L3: 0.08929991722106934, L4: 2.6317667961120605, L5: 0.025348620489239693
Epoch 4000, Loss: 1.5781289339065552, Losses: L1: 0.0073663825169205666, L2: 0.1112091988325119, L3: 0.10402631759643555, L4: 0.6156085133552551, L5: 0.013100715354084969
Epoch 4500, Loss: 1.3790440559387207, Losses: L1: -0.07254573702812195, L2: 0.09235399216413498, L3: 0.10162031650543213, L4: 0.5762063264846802, L5: 0.01284886710345745
Epoch 5000, Loss: 1.2819414138793945, Losses: L1: -0.13161414861679077, L2: 0.09008210897445679, L3: 0.1006782054901123, L4: 0.5604395866394043, L5: 0.01183395367115736
Epoch 5500, Loss: 1.242807388305664, Losses: L1: -0.1394287496805191, L2: 0.0875677615404129, L3: 0.10043734312057495, L4: 0.5478281378746033, L5: 0.011006919667124748
Epoch 6000, Loss: 1.2029151916503906, Losses: L1: -0.1591860055923462, L2: 0.08614517003297806, L3: 0.10010510683059692, L4: 0.5396277904510498, L5: 0.010450116358697414
Epoch 6500, Loss: 1.1837701797485352, Losses: L1: -0.16230811178684235, L2: 0.08507362753152847, L3: 0.10008800029754639, L4: 0.5329025983810425, L5: 0.010037857107818127
Epoch 7000, Loss: 1.1700135469436646, Losses: L1: -0.16481351852416992, L2: 0.08457854390144348, L3: 0.10001301765441895, L4: 0.5279528498649597, L5: 0.009751197881996632
Epoch 7500, Loss: 1.1596462726593018, Losses: L1: -0.16627728939056396, L2: 0.08420847356319427, L3: 0.0999559760093689, L4: 0.524008572101593, L5: 0.009533579461276531
Epoch 8000, Loss: 1.1520142555236816, Losses: L1: -0.16735731065273285, L2: 0.08397836983203888, L3: 0.09988963603973389, L4: 0.5210747718811035, L5: 0.009375720284879208
Epoch 8500, Loss: 1.1463199853897095, Losses: L1: -0.1680692732334137, L2: 0.08379274606704712, L3: 0.09983396530151367, L4: 0.5188547968864441, L5: 0.009260203689336777
Epoch 9000, Loss: 1.1420890092849731, Losses: L1: -0.16857823729515076, L2: 0.08365140110254288, L3: 0.09978795051574707, L4: 0.5171995162963867, L5: 0.009177444502711296
Epoch 9500, Loss: 1.138893485069275, Losses: L1: -0.16896849870681763, L2: 0.08355709165334702, L3: 0.09974408149719238, L4: 0.5159422755241394, L5: 0.009119127877056599
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0031063556671143, Constraint losses: L1: 6.380364418029785, L2: 0.0, L3: 0.9983630776405334, L4: 0.9983629584312439
Epoch 500, Loss: 0.002475397428497672, Constraint losses: L1: -0.9728424549102783, L2: 0.0, L3: 0.0027227401733398438, L4: 0.0007254997617565095
Epoch 1000, Loss: 0.001323904376477003, Constraint losses: L1: -1.1142891645431519, L2: 0.0, L3: 0.0022186636924743652, L4: 0.00021952978568151593
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0224623680114746, Constraint losses: L1: 18.42068099975586, L2: 0.0013470292324200273, L3: 1.0013470649719238, L4: 1.0013474225997925
Epoch 500, Loss: 0.002350783906877041, Constraint losses: L1: -1.0313135385513306, L2: 0.0, L3: 0.002690255641937256, L4: 0.0006918417639099061
Epoch 1000, Loss: 0.0013692027423530817, Constraint losses: L1: -1.0710012912750244, L2: 0.0, L3: 0.0022199153900146484, L4: 0.0002202886826125905
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 149.24063110351562, Losses: L1: 6.014754295349121, L2: 2.52880035986891e-05, L3: 0.9968738555908203, L4: 70.7960205078125, L5: 0.3184564411640167
Epoch 500, Loss: 23.89862060546875, Losses: L1: 4.2121357917785645, L2: 2.3082587718963623, L3: 0.12045347690582275, L4: 7.429014682769775, L5: 0.04574200138449669
Epoch 1000, Loss: 29.048656463623047, Losses: L1: 4.038642406463623, L2: 1.1823943853378296, L3: 0.172374427318573, L4: 11.154857635498047, L5: 0.08156731724739075
Epoch 1500, Loss: 2.031083583831787, Losses: L1: -0.13784253597259521, L2: 0.049924712628126144, L3: 0.04955124855041504, L4: 0.9984890222549438, L5: 0.011273725889623165
Epoch 2000, Loss: 1.4359914064407349, Losses: L1: -0.20041169226169586, L2: 0.06831759214401245, L3: 0.052951931953430176, L4: 0.7171868681907654, L5: 0.006221095100045204
Epoch 2500, Loss: 0.5387331247329712, Losses: L1: -0.27009353041648865, L2: 0.03859815001487732, L3: 0.05127894878387451, L4: 0.3339424431324005, L5: 0.006233278661966324
Epoch 3000, Loss: 0.4130154550075531, Losses: L1: -0.2209932655096054, L2: 0.03558770567178726, L3: 0.05010408163070679, L4: 0.25065165758132935, L5: 0.005712952930480242
Epoch 3500, Loss: 0.32222801446914673, Losses: L1: -0.21901282668113708, L2: 0.03310573473572731, L3: 0.050075411796569824, L4: 0.2078104168176651, L5: 0.004666571505367756
Epoch 4000, Loss: 0.2096041440963745, Losses: L1: -0.22260044515132904, L2: 0.03392300382256508, L3: 0.049429357051849365, L4: 0.1527455747127533, L5: 0.004719031974673271
Epoch 4500, Loss: 0.1849433034658432, Losses: L1: -0.2247404009103775, L2: 0.03322131931781769, L3: 0.0491599440574646, L4: 0.14231091737747192, L5: 0.004729640670120716
Epoch 5000, Loss: 0.17255888879299164, Losses: L1: -0.22662833333015442, L2: 0.03291017562150955, L3: 0.04895681142807007, L4: 0.13752317428588867, L5: 0.004681854043155909
Epoch 5500, Loss: 0.16836069524288177, Losses: L1: -0.22795793414115906, L2: 0.03278367966413498, L3: 0.048826634883880615, L4: 0.13628020882606506, L5: 0.004682109225541353
Epoch 6000, Loss: 0.15966013073921204, Losses: L1: -0.2285345494747162, L2: 0.03250346705317497, L3: 0.04873096942901611, L4: 0.1325664222240448, L5: 0.004661962389945984
Epoch 6500, Loss: 0.15566636621952057, Losses: L1: -0.22908198833465576, L2: 0.03246917575597763, L3: 0.04866373538970947, L4: 0.13092049956321716, L5: 0.00465263519436121
Epoch 7000, Loss: 0.15294024348258972, Losses: L1: -0.22933955490589142, L2: 0.032376475632190704, L3: 0.04861873388290405, L4: 0.1298063099384308, L5: 0.0046477485448122025
Epoch 7500, Loss: 0.15088076889514923, Losses: L1: -0.22954969108104706, L2: 0.03233718127012253, L3: 0.04858434200286865, L4: 0.12894181907176971, L5: 0.0046440609730780125
Epoch 8000, Loss: 0.1493719071149826, Losses: L1: -0.22969409823417664, L2: 0.032296620309352875, L3: 0.04856389760971069, L4: 0.12831303477287292, L5: 0.0046413978561758995
Epoch 8500, Loss: 0.14837174117565155, Losses: L1: -0.22975429892539978, L2: 0.03226083144545555, L3: 0.048545002937316895, L4: 0.12789301574230194, L5: 0.0046366676688194275
Epoch 9000, Loss: 0.14740613102912903, Losses: L1: -0.22981013357639313, L2: 0.032252099364995956, L3: 0.04852032661437988, L4: 0.12745848298072815, L5: 0.004637387581169605
Epoch 9500, Loss: 0.14683248102664948, Losses: L1: -0.22984623908996582, L2: 0.03224245086312294, L3: 0.04851067066192627, L4: 0.12720578908920288, L5: 0.0046357871033251286
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9990427494049072, Constraint losses: L1: 5.709373474121094, L2: 0.0, L3: 0.9966666102409363, L4: 0.9966668486595154
Epoch 500, Loss: 0.0023275939747691154, Constraint losses: L1: -1.1036022901535034, L2: 0.0, L3: 0.0027147531509399414, L4: 0.0007164431735873222
Epoch 1000, Loss: 0.0013520761858671904, Constraint losses: L1: -1.1185253858566284, L2: 0.0, L3: 0.002234935760498047, L4: 0.0002356658224016428
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.021395444869995, Constraint losses: L1: 18.42068099975586, L2: 0.0009914319962263107, L3: 1.0009914636611938, L4: 1.0009918212890625
Epoch 500, Loss: 0.002762080170214176, Constraint losses: L1: -0.9829543828964233, L2: 0.0, L3: 0.0028713345527648926, L4: 0.0008736999006941915
Epoch 1000, Loss: 0.001481176121160388, Constraint losses: L1: -1.0690563917160034, L2: 0.0, L3: 0.002274811267852783, L4: 0.00027542136376723647
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 44.34000778198242, Losses: L1: 4.890004634857178, L2: 9.613584552425891e-05, L3: 0.9928139448165894, L4: 74.60047149658203, L5: 0.32789960503578186
Epoch 500, Loss: 45.516937255859375, Losses: L1: 18.419239044189453, L2: 1.0016182159233722e-06, L3: 1.000000238418579, L4: 50.00001907348633, L5: 0.1953759342432022
Epoch 1000, Loss: 38.452484130859375, Losses: L1: 11.354283332824707, L2: 1.9999897631350905e-05, L3: 0.9999852180480957, L4: 50.00102615356445, L5: 0.19536150991916656
Epoch 1500, Loss: 31.165292739868164, Losses: L1: 3.246826648712158, L2: 0.015440479852259159, L3: 0.9515842795372009, L4: 51.782745361328125, L5: 0.18608735501766205
Epoch 2000, Loss: 30.895896911621094, Losses: L1: 3.108480453491211, L2: 0.00034288386814296246, L3: 0.8830674886703491, L4: 51.86781311035156, L5: 0.17337925732135773
Epoch 2500, Loss: 30.98109245300293, Losses: L1: 3.340459108352661, L2: 0.0, L3: 0.9383110404014587, L4: 51.355186462402344, L5: 0.17283473908901215
Epoch 3000, Loss: 30.191749572753906, Losses: L1: 2.4702632427215576, L2: 4.7722269300720654e-06, L3: 0.8880825638771057, L4: 51.71742248535156, L5: 0.1732025295495987
Epoch 3500, Loss: 29.707157135009766, Losses: L1: 2.2269256114959717, L2: 0.0006023697787895799, L3: 0.8534032106399536, L4: 51.37283706665039, L5: 0.17160536348819733
Epoch 4000, Loss: 14.522342681884766, Losses: L1: 8.423182487487793, L2: 0.23413296043872833, L3: 0.05551767349243164, L4: 10.887308120727539, L5: 0.1524111032485962
Epoch 4500, Loss: 10.033346176147461, Losses: L1: 4.965769290924072, L2: 0.05530916526913643, L3: 0.034550368785858154, L4: 9.706135749816895, L5: 0.06958053261041641
Epoch 5000, Loss: 7.985408306121826, Losses: L1: 3.283371686935425, L2: 0.051703330129384995, L3: 0.008805990219116211, L4: 9.104288101196289, L5: 0.05774823948740959
Epoch 5500, Loss: 7.779519081115723, Losses: L1: 3.252423048019409, L2: 0.0570019893348217, L3: 0.0011135339736938477, L4: 8.762191772460938, L5: 0.059537552297115326
Epoch 6000, Loss: 7.6653056144714355, Losses: L1: 3.2279748916625977, L2: 0.055822912603616714, L3: 0.0006371140480041504, L4: 8.589744567871094, L5: 0.059076324105262756
Epoch 6500, Loss: 7.444914817810059, Losses: L1: 3.0589561462402344, L2: 0.056250713765621185, L3: 0.0004410743713378906, L4: 8.487308502197266, L5: 0.05784188583493233
Epoch 7000, Loss: 7.3222975730896, Losses: L1: 2.9724388122558594, L2: 0.05650145187973976, L3: 0.00019282102584838867, L4: 8.416357040405273, L5: 0.05658372491598129
Epoch 7500, Loss: 7.0646162033081055, Losses: L1: 2.7324776649475098, L2: 0.06127301976084709, L3: 0.0005608797073364258, L4: 8.361554145812988, L5: 0.05538766458630562
Epoch 8000, Loss: 7.031360626220703, Losses: L1: 2.7088258266448975, L2: 0.06201139837503433, L3: 0.00029140710830688477, L4: 8.340925216674805, L5: 0.054933372884988785
Epoch 8500, Loss: 6.988034248352051, Losses: L1: 2.6710643768310547, L2: 0.06305592507123947, L3: 0.00025272369384765625, L4: 8.326196670532227, L5: 0.05450832471251488
Epoch 9000, Loss: 6.978951930999756, Losses: L1: 2.6667840480804443, L2: 0.06343930214643478, L3: 3.874301910400391e-06, L4: 8.31615924835205, L5: 0.05440417304635048
Epoch 9500, Loss: 6.9733123779296875, Losses: L1: 2.663817882537842, L2: 0.06356249749660492, L3: 0.00012135505676269531, L4: 8.309967994689941, L5: 0.05428521707653999
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9966217279434204, Constraint losses: L1: 5.418561935424805, L2: 0.0, L3: 0.9956017136573792, L4: 0.9956014156341553
Epoch 500, Loss: 0.002033836208283901, Constraint losses: L1: -1.0927116870880127, L2: 0.0, L3: 0.002562582492828369, L4: 0.0005639655282720923
Epoch 1000, Loss: 0.0012425062013790011, Constraint losses: L1: -1.1162689924240112, L2: 0.0, L3: 0.0021791458129882812, L4: 0.0001796294527594
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0052194595336914, Constraint losses: L1: 7.0276665687561035, L2: 0.0, L3: 0.9990958571434021, L4: 0.9990959167480469
Epoch 500, Loss: 0.0021429138723760843, Constraint losses: L1: -1.0502849817276, L2: 0.0, L3: 0.0025957822799682617, L4: 0.0005974167142994702
Epoch 1000, Loss: 0.001316495705395937, Constraint losses: L1: -1.071062445640564, L2: 0.0, L3: 0.002193450927734375, L4: 0.00019410724053159356
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 53.53057861328125, Losses: L1: 9.167703628540039, L2: 0.0003304782439954579, L3: 0.9978710412979126, L4: 83.90850830078125, L5: 0.4122161865234375
Epoch 500, Loss: 4.804067611694336, Losses: L1: 1.9311989545822144, L2: 0.1746935099363327, L3: 0.12820398807525635, L4: 4.482235431671143, L5: 0.025955932214856148
Epoch 1000, Loss: 4.192379474639893, Losses: L1: 0.8434442281723022, L2: 0.3141755163669586, L3: 0.09058946371078491, L4: 4.9450907707214355, L5: 0.06685981899499893
Epoch 1500, Loss: 1.1979516744613647, Losses: L1: -0.1651381254196167, L2: 0.11133351922035217, L3: 0.08657121658325195, L4: 1.9047632217407227, L5: 0.014898625202476978
Epoch 2000, Loss: 0.7585453391075134, Losses: L1: -0.269313782453537, L2: 0.057381778955459595, L3: 0.06329214572906494, L4: 1.5540374517440796, L5: 0.009492582641541958
Epoch 2500, Loss: 0.3907850980758667, Losses: L1: -0.2750258445739746, L2: 0.039693549275398254, L3: 0.06318402290344238, L4: 0.9066916704177856, L5: 0.0067099761217832565
Epoch 3000, Loss: 0.15339890122413635, Losses: L1: -0.27843597531318665, L2: 0.036635931581258774, L3: 0.06167030334472656, L4: 0.4592633545398712, L5: 0.005590722430497408
Epoch 3500, Loss: 0.2386786788702011, Losses: L1: -0.2816515564918518, L2: 0.03646933659911156, L3: 0.06022500991821289, L4: 0.6419176459312439, L5: 0.005982707720249891
Epoch 4000, Loss: 0.02885708399116993, Losses: L1: -0.280781090259552, L2: 0.03367972373962402, L3: 0.059831202030181885, L4: 0.23439419269561768, L5: 0.0054192268289625645
Epoch 4500, Loss: 0.0166613832116127, Losses: L1: -0.2813807427883148, L2: 0.033283550292253494, L3: 0.059101223945617676, L4: 0.2157290279865265, L5: 0.005408070981502533
Epoch 5000, Loss: 0.01591811329126358, Losses: L1: -0.2823902666568756, L2: 0.033095069229602814, L3: 0.05847001075744629, L4: 0.21954914927482605, L5: 0.0054036458022892475
Epoch 5500, Loss: 0.007388615980744362, Losses: L1: -0.2824387848377228, L2: 0.0326494425535202, L3: 0.058130502700805664, L4: 0.20573848485946655, L5: 0.00539826788008213
Epoch 6000, Loss: 0.004119980614632368, Losses: L1: -0.28297093510627747, L2: 0.03257651999592781, L3: 0.05779063701629639, L4: 0.20191432535648346, L5: 0.005399446468800306
Epoch 6500, Loss: 0.0018888888880610466, Losses: L1: -0.28335297107696533, L2: 0.032470542937517166, L3: 0.05755847692489624, L4: 0.19956575334072113, L5: 0.005400951020419598
Epoch 7000, Loss: 0.00027280859649181366, Losses: L1: -0.28362739086151123, L2: 0.032369859516620636, L3: 0.057368695735931396, L4: 0.1980428397655487, L5: 0.005401669070124626
Epoch 7500, Loss: -0.0009777229279279709, Losses: L1: -0.2838114798069, L2: 0.03227802738547325, L3: 0.05721956491470337, L4: 0.19687451422214508, L5: 0.005401307716965675
Epoch 8000, Loss: -0.002003336325287819, Losses: L1: -0.2840077579021454, L2: 0.03225289657711983, L3: 0.05709797143936157, L4: 0.19580136239528656, L5: 0.005402011796832085
Epoch 8500, Loss: -0.002702465746551752, Losses: L1: -0.28414595127105713, L2: 0.0322144590318203, L3: 0.057018399238586426, L4: 0.1951514184474945, L5: 0.00540205230936408
Epoch 9000, Loss: -0.003269405569881201, Losses: L1: -0.28421735763549805, L2: 0.03217483311891556, L3: 0.05695289373397827, L4: 0.19458042085170746, L5: 0.005402287933975458
Epoch 9500, Loss: -0.0036807949654757977, Losses: L1: -0.28427618741989136, L2: 0.03214209899306297, L3: 0.05691063404083252, L4: 0.19417521357536316, L5: 0.005402312148362398
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0304455757141113, Constraint losses: L1: 18.42068099975586, L2: 0.004007996525615454, L3: 1.0040080547332764, L4: 1.0040087699890137
Epoch 500, Loss: 0.0021788913290947676, Constraint losses: L1: -1.1108293533325195, L2: 0.0, L3: 0.0026441216468811035, L4: 0.0006455990951508284
Epoch 1000, Loss: 0.0013098600320518017, Constraint losses: L1: -1.116334080696106, L2: 0.0, L3: 0.0022127628326416016, L4: 0.00021343131083995104
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0303478240966797, Constraint losses: L1: 18.42068099975586, L2: 0.003975588362663984, L3: 1.0039756298065186, L4: 1.0039758682250977
Epoch 500, Loss: 0.002229222794994712, Constraint losses: L1: -1.040205955505371, L2: 0.0, L3: 0.0026338696479797363, L4: 0.0006355592631734908
Epoch 1000, Loss: 0.0013260230189189315, Constraint losses: L1: -1.0699231624603271, L2: 0.0, L3: 0.0021976828575134277, L4: 0.00019826336938422173
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 47.494651794433594, Losses: L1: 7.037052154541016, L2: 1.4837045455351472e-05, L3: 0.9991409182548523, L4: 75.52754974365234, L5: 0.34775644540786743
Epoch 500, Loss: 1.0018595457077026, Losses: L1: -0.09284786134958267, L2: 0.05135459452867508, L3: 0.05208158493041992, L4: 1.727476954460144, L5: 0.012048264965415001
Epoch 1000, Loss: 1.5210270881652832, Losses: L1: -0.2386114001274109, L2: 0.0640740841627121, L3: 0.05817246437072754, L4: 2.9260036945343018, L5: 0.02607177011668682
Epoch 1500, Loss: 0.2506791949272156, Losses: L1: -0.2604116201400757, L2: 0.027024129405617714, L3: 0.056117892265319824, L4: 0.6594949960708618, L5: 0.007529636844992638
Epoch 2000, Loss: 0.3730626106262207, Losses: L1: -0.24290645122528076, L2: 0.03169747069478035, L3: 0.06178098917007446, L4: 0.8132107257843018, L5: 0.011203397065401077
Epoch 2500, Loss: 0.20882180333137512, Losses: L1: -0.2735046148300171, L2: 0.023195428773760796, L3: 0.05783265829086304, L4: 0.6125158071517944, L5: 0.007006166502833366
Epoch 3000, Loss: 0.014920234680175781, Losses: L1: -0.2885015904903412, L2: 0.02711133286356926, L3: 0.05227160453796387, L4: 0.25997456908226013, L5: 0.007334329187870026
Epoch 3500, Loss: -0.02561105415225029, Losses: L1: -0.2892054319381714, L2: 0.026249803602695465, L3: 0.051009535789489746, L4: 0.19366231560707092, L5: 0.006122271064668894
Epoch 4000, Loss: -0.03932800889015198, Losses: L1: -0.29088252782821655, L2: 0.026284368708729744, L3: 0.05017650127410889, L4: 0.1730661392211914, L5: 0.006049857009202242
Epoch 4500, Loss: -0.05006762966513634, Losses: L1: -0.29240694642066956, L2: 0.02665519341826439, L3: 0.04957610368728638, L4: 0.15551702678203583, L5: 0.0060591003857553005
Epoch 5000, Loss: -0.0544118657708168, Losses: L1: -0.2928124666213989, L2: 0.02647850662469864, L3: 0.04928123950958252, L4: 0.14977483451366425, L5: 0.005996845196932554
Epoch 5500, Loss: -0.056977760046720505, Losses: L1: -0.2933720350265503, L2: 0.026471318677067757, L3: 0.04904884099960327, L4: 0.14669103920459747, L5: 0.00600421940907836
Epoch 6000, Loss: -0.05985882133245468, Losses: L1: -0.2936474680900574, L2: 0.02632969059050083, L3: 0.04890024662017822, L4: 0.14294040203094482, L5: 0.00592928659170866
Epoch 6500, Loss: -0.06138979271054268, Losses: L1: -0.29390984773635864, L2: 0.02631552703678608, L3: 0.04877519607543945, L4: 0.14103132486343384, L5: 0.005911475513130426
Epoch 7000, Loss: -0.06250230967998505, Losses: L1: -0.2941261827945709, L2: 0.02642630599439144, L3: 0.04864835739135742, L4: 0.13940635323524475, L5: 0.005885681137442589
Epoch 7500, Loss: -0.06346938759088516, Losses: L1: -0.29422852396965027, L2: 0.026388045400381088, L3: 0.04858577251434326, L4: 0.13819193840026855, L5: 0.005857763346284628
Epoch 8000, Loss: -0.06407289206981659, Losses: L1: -0.2943211793899536, L2: 0.026366954669356346, L3: 0.04853832721710205, L4: 0.13747496902942657, L5: 0.0058501181192696095
Epoch 8500, Loss: -0.06456036120653152, Losses: L1: -0.2944037616252899, L2: 0.026369942352175713, L3: 0.04849809408187866, L4: 0.13687561452388763, L5: 0.005834759213030338
Epoch 9000, Loss: -0.06489630043506622, Losses: L1: -0.29443612694740295, L2: 0.026358293369412422, L3: 0.048473238945007324, L4: 0.1364365667104721, L5: 0.00582923972979188
Epoch 9500, Loss: -0.06513480842113495, Losses: L1: -0.2944900095462799, L2: 0.02635715901851654, L3: 0.04845380783081055, L4: 0.13617341220378876, L5: 0.005823282524943352
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9987804889678955, Constraint losses: L1: 5.625114440917969, L2: 0.0, L3: 0.9965780973434448, L4: 0.9965772032737732
Epoch 500, Loss: 0.002348402515053749, Constraint losses: L1: -1.0882066488265991, L2: 0.0, L3: 0.002717256546020508, L4: 0.0007193525088950992
Epoch 1000, Loss: 0.0013445396907627583, Constraint losses: L1: -1.1170791387557983, L2: 0.0, L3: 0.0022304654121398926, L4: 0.00023115344811230898
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9994375705718994, Constraint losses: L1: 5.785555839538574, L2: 0.0, L3: 0.9968259334564209, L4: 0.9968261122703552
Epoch 500, Loss: 0.002452421933412552, Constraint losses: L1: -1.0457038879394531, L2: 0.0, L3: 0.0027481913566589355, L4: 0.0007499343482777476
Epoch 1000, Loss: 0.0014166689943522215, Constraint losses: L1: -1.0700546503067017, L2: 0.0, L3: 0.0022431015968322754, L4: 0.00024362205294892192
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 98.55328369140625, Losses: L1: 18.42068099975586, L2: 0.004599124193191528, L3: 1.0045990943908691, L4: 77.9271011352539, L5: 0.37420088052749634
Epoch 500, Loss: 4.735520839691162, Losses: L1: 1.3510440587997437, L2: 0.154377743601799, L3: 0.1691652536392212, L4: 2.722959041595459, L5: 0.02886299416422844
Epoch 1000, Loss: 4.481067657470703, Losses: L1: 0.04610942304134369, L2: 0.09928163886070251, L3: 0.11076247692108154, L4: 3.9963622093200684, L5: 0.037015531212091446
Epoch 1500, Loss: 3.996182441711426, Losses: L1: 0.02003747969865799, L2: 0.167953222990036, L3: 0.14298784732818604, L4: 3.3448965549468994, L5: 0.018732400611042976
Epoch 2000, Loss: 2.139622688293457, Losses: L1: -0.11224722117185593, L2: 0.10652060061693192, L3: 0.11884260177612305, L4: 1.7966673374176025, L5: 0.008952328003942966
Epoch 2500, Loss: 1.894726037979126, Losses: L1: -0.13629919290542603, L2: 0.08263147622346878, L3: 0.1159663200378418, L4: 1.6301335096359253, L5: 0.007392484694719315
Epoch 3000, Loss: 1.621065378189087, Losses: L1: -0.1603224277496338, L2: 0.08067106455564499, L3: 0.10598093271255493, L4: 1.4040908813476562, L5: 0.007985904812812805
Epoch 3500, Loss: 1.2212344408035278, Losses: L1: -0.20868293941020966, L2: 0.06714626401662827, L3: 0.10359954833984375, L4: 1.0852779150009155, L5: 0.00629575178027153
Epoch 4000, Loss: 1.0862418413162231, Losses: L1: -0.23361247777938843, L2: 0.059675317257642746, L3: 0.09942907094955444, L4: 0.9986271858215332, L5: 0.006036766339093447
Epoch 4500, Loss: 0.9655523300170898, Losses: L1: -0.23950159549713135, L2: 0.05656479299068451, L3: 0.0966331958770752, L4: 0.8956856727600098, L5: 0.005944436881691217
Epoch 5000, Loss: 0.896736741065979, Losses: L1: -0.24072308838367462, L2: 0.05372270196676254, L3: 0.09460151195526123, L4: 0.8378939628601074, L5: 0.005834775976836681
Epoch 5500, Loss: 0.8475587368011475, Losses: L1: -0.2406134158372879, L2: 0.05325520411133766, L3: 0.0926210880279541, L4: 0.7935072183609009, L5: 0.0058246999979019165
Epoch 6000, Loss: 0.8170595169067383, Losses: L1: -0.2407623529434204, L2: 0.05369217321276665, L3: 0.09057986736297607, L4: 0.7663722038269043, L5: 0.005811161827296019
Epoch 6500, Loss: 0.7990267276763916, Losses: L1: -0.23901143670082092, L2: 0.053623974323272705, L3: 0.0895310640335083, L4: 0.748818039894104, L5: 0.005820078309625387
Epoch 7000, Loss: 0.7861124277114868, Losses: L1: -0.2382442057132721, L2: 0.05385566130280495, L3: 0.08873641490936279, L4: 0.736244797706604, L5: 0.005855269264429808
Epoch 7500, Loss: 0.7776968479156494, Losses: L1: -0.23729324340820312, L2: 0.05384732037782669, L3: 0.08814561367034912, L4: 0.728062629699707, L5: 0.005883266218006611
Epoch 8000, Loss: 0.7717329263687134, Losses: L1: -0.23695601522922516, L2: 0.05395808070898056, L3: 0.08758914470672607, L4: 0.7226384878158569, L5: 0.00591204222291708
Epoch 8500, Loss: 0.7675071358680725, Losses: L1: -0.23667311668395996, L2: 0.05403077229857445, L3: 0.08720314502716064, L4: 0.7187451124191284, L5: 0.005934637505561113
Epoch 9000, Loss: 0.7645276784896851, Losses: L1: -0.23647449910640717, L2: 0.054078709334135056, L3: 0.08694654703140259, L4: 0.7159756422042847, L5: 0.005952136125415564
Epoch 9500, Loss: 0.7624204754829407, Losses: L1: -0.2363305538892746, L2: 0.05411143600940704, L3: 0.08676469326019287, L4: 0.7140165567398071, L5: 0.005964369513094425
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0210962295532227, Constraint losses: L1: 18.42068099975586, L2: 0.0008919885149225593, L3: 1.0008920431137085, L4: 1.0008915662765503
Epoch 500, Loss: 0.0024723128881305456, Constraint losses: L1: -1.0903774499893188, L2: 0.0, L3: 0.0027802586555480957, L4: 0.0007824316853657365
Epoch 1000, Loss: 0.0013883857754990458, Constraint losses: L1: -1.1165934801101685, L2: 0.0, L3: 0.0022522807121276855, L4: 0.0002526985190343112
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.000333786010742, Constraint losses: L1: 5.874483108520508, L2: 0.0, L3: 0.997229814529419, L4: 0.9972295761108398
Epoch 500, Loss: 0.0021575610153377056, Constraint losses: L1: -1.0327671766281128, L2: 0.0, L3: 0.0025944113731384277, L4: 0.0005959169939160347
Epoch 1000, Loss: 0.0013075278839096427, Constraint losses: L1: -1.070094347000122, L2: 0.0, L3: 0.002188563346862793, L4: 0.0001890589774120599
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.3706283569336, Losses: L1: 6.048429489135742, L2: 0.0, L3: 0.9977235794067383, L4: 78.95329284667969, L5: 0.37346151471138
Epoch 500, Loss: 5.786163330078125, Losses: L1: 0.05076652392745018, L2: 0.11237631738185883, L3: 0.05114102363586426, L4: 5.368072509765625, L5: 0.04028954729437828
Epoch 1000, Loss: 1.353266716003418, Losses: L1: -0.19626972079277039, L2: 0.041452523320913315, L3: 0.0645287036895752, L4: 1.3259084224700928, L5: 0.01166558638215065
Epoch 1500, Loss: 2.367981195449829, Losses: L1: 0.0360310822725296, L2: 0.14145074784755707, L3: 0.09565943479537964, L4: 1.834406852722168, L5: 0.02332289144396782
Epoch 2000, Loss: 0.8071740865707397, Losses: L1: -0.2575628459453583, L2: 0.05341276898980141, L3: 0.07304716110229492, L4: 0.8049449920654297, L5: 0.00687205558642745
Epoch 2500, Loss: 0.29481643438339233, Losses: L1: -0.25737807154655457, L2: 0.047648169100284576, L3: 0.06768542528152466, L4: 0.31439176201820374, L5: 0.007135555148124695
Epoch 3000, Loss: 0.30037394165992737, Losses: L1: -0.26514142751693726, L2: 0.04500198736786842, L3: 0.06531548500061035, L4: 0.33794960379600525, L5: 0.006930829491466284
Epoch 3500, Loss: 0.36331304907798767, Losses: L1: -0.2761092185974121, L2: 0.04646677523851395, L3: 0.06138038635253906, L4: 0.4162530303001404, L5: 0.007474934216588736
Epoch 4000, Loss: 0.12604917585849762, Losses: L1: -0.2731441855430603, L2: 0.042648643255233765, L3: 0.05991232395172119, L4: 0.18759112060070038, L5: 0.006480300799012184
Epoch 4500, Loss: 0.13233092427253723, Losses: L1: -0.275554895401001, L2: 0.042160261422395706, L3: 0.05926293134689331, L4: 0.198464497923851, L5: 0.006574938073754311
Epoch 5000, Loss: 0.09572406858205795, Losses: L1: -0.276170551776886, L2: 0.04175212234258652, L3: 0.05887103080749512, L4: 0.1643058955669403, L5: 0.006342421285808086
Epoch 5500, Loss: 0.09302680194377899, Losses: L1: -0.276590496301651, L2: 0.04141872376203537, L3: 0.058689236640930176, L4: 0.16307294368743896, L5: 0.006328434683382511
Epoch 6000, Loss: 0.08755398541688919, Losses: L1: -0.27714967727661133, L2: 0.04119816794991493, L3: 0.05858135223388672, L4: 0.15887494385242462, L5: 0.006269683130085468
Epoch 6500, Loss: 0.08545919507741928, Losses: L1: -0.2773078978061676, L2: 0.04096433147788048, L3: 0.05850929021835327, L4: 0.157570481300354, L5: 0.006249362137168646
Epoch 7000, Loss: 0.08357936888933182, Losses: L1: -0.2776240408420563, L2: 0.040896303951740265, L3: 0.058434367179870605, L4: 0.15629935264587402, L5: 0.006242715287953615
Epoch 7500, Loss: 0.08243309706449509, Losses: L1: -0.27779680490493774, L2: 0.04081277176737785, L3: 0.05838346481323242, L4: 0.1556060016155243, L5: 0.00623141648247838
Epoch 8000, Loss: 0.08151137083768845, Losses: L1: -0.27794116735458374, L2: 0.04076873138546944, L3: 0.05834197998046875, L4: 0.15500658750534058, L5: 0.006224538665264845
Epoch 8500, Loss: 0.08084684610366821, Losses: L1: -0.2780492603778839, L2: 0.040723349899053574, L3: 0.058318376541137695, L4: 0.1545904576778412, L5: 0.00622218893840909
Epoch 9000, Loss: 0.08033716678619385, Losses: L1: -0.2781293988227844, L2: 0.04069652035832405, L3: 0.05829799175262451, L4: 0.15425869822502136, L5: 0.006218846887350082
Epoch 9500, Loss: 0.0800219252705574, Losses: L1: -0.27816417813301086, L2: 0.04066995903849602, L3: 0.058283090591430664, L4: 0.15406256914138794, L5: 0.006217430345714092
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0029520988464355, Constraint losses: L1: 6.316906452178955, L2: 0.0, L3: 0.9983178377151489, L4: 0.9983172416687012
Epoch 500, Loss: 0.002084971172735095, Constraint losses: L1: -1.1002590656280518, L2: 0.0, L3: 0.0025917887687683105, L4: 0.0005934415385127068
Epoch 1000, Loss: 0.0012657522456720471, Constraint losses: L1: -1.1186338663101196, L2: 0.0, L3: 0.0021918416023254395, L4: 0.0001925445394590497
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.02445650100708, Constraint losses: L1: 18.42068099975586, L2: 0.002011789008975029, L3: 1.002011775970459, L4: 1.0020121335983276
Epoch 500, Loss: 0.0022059620823711157, Constraint losses: L1: -1.0257467031478882, L2: 0.0, L3: 0.002614915370941162, L4: 0.0006167934625409544
Epoch 1000, Loss: 0.0013239822583273053, Constraint losses: L1: -1.0692894458770752, L2: 0.0, L3: 0.002196371555328369, L4: 0.00019690021872520447
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 78.62353515625, Losses: L1: 5.25050687789917, L2: 0.0, L3: 0.9948278069496155, L4: 70.76644134521484, L5: 0.3084629476070404
Epoch 500, Loss: 2.906057357788086, Losses: L1: -0.10335315763950348, L2: 0.07392583042383194, L3: 0.05145561695098877, L4: 2.6867284774780273, L5: 0.03595954179763794
Epoch 1000, Loss: 3.352476119995117, Losses: L1: -0.11782520264387131, L2: 0.018241506069898605, L3: 0.06331753730773926, L4: 3.27993106842041, L5: 0.013626049272716045
Epoch 1500, Loss: 0.44878822565078735, Losses: L1: -0.26941293478012085, L2: 0.032152410596609116, L3: 0.04878342151641846, L4: 0.5393441915512085, L5: 0.008492646738886833
Epoch 2000, Loss: 0.4591561257839203, Losses: L1: -0.29388415813446045, L2: 0.034612711519002914, L3: 0.04631340503692627, L4: 0.5710190534591675, L5: 0.010084488429129124
Epoch 2500, Loss: 0.0008883010596036911, Losses: L1: -0.28950515389442444, L2: 0.02459866553544998, L3: 0.04637783765792847, L4: 0.13290071487426758, L5: 0.007769866846501827
Epoch 3000, Loss: 0.2809087634086609, Losses: L1: -0.2919410169124603, L2: 0.021911749616265297, L3: 0.04585075378417969, L4: 0.4253249764442444, L5: 0.005999894347041845
Epoch 3500, Loss: 0.007149788551032543, Losses: L1: -0.2988479435443878, L2: 0.02393254078924656, L3: 0.04546165466308594, L4: 0.15306423604488373, L5: 0.007072546985000372
Epoch 4000, Loss: -0.061900511384010315, Losses: L1: -0.29924139380455017, L2: 0.024370869621634483, L3: 0.04510927200317383, L4: 0.08544109761714935, L5: 0.006469755433499813
Epoch 4500, Loss: -0.06833548843860626, Losses: L1: -0.3005613684654236, L2: 0.023838426917791367, L3: 0.04493594169616699, L4: 0.08185721933841705, L5: 0.006409958470612764
Epoch 5000, Loss: -0.07669223845005035, Losses: L1: -0.3006385564804077, L2: 0.02385219745337963, L3: 0.044707655906677246, L4: 0.074257493019104, L5: 0.006284558214247227
Epoch 5500, Loss: -0.07848433405160904, Losses: L1: -0.30086037516593933, L2: 0.023827901110053062, L3: 0.0446169376373291, L4: 0.0729983001947403, L5: 0.00624403590336442
Epoch 6000, Loss: -0.0804142877459526, Losses: L1: -0.301088809967041, L2: 0.023894652724266052, L3: 0.044538021087646484, L4: 0.0713229849934578, L5: 0.006243094336241484
Epoch 6500, Loss: -0.08146809041500092, Losses: L1: -0.30123665928840637, L2: 0.023920748382806778, L3: 0.044484615325927734, L4: 0.07050877809524536, L5: 0.006224534474313259
Epoch 7000, Loss: -0.08209043741226196, Losses: L1: -0.30138611793518066, L2: 0.02394273318350315, L3: 0.044448137283325195, L4: 0.07007922232151031, L5: 0.006217353045940399
Epoch 7500, Loss: -0.08272850513458252, Losses: L1: -0.3014635145664215, L2: 0.023947127163410187, L3: 0.044419169425964355, L4: 0.06957831978797913, L5: 0.006212039850652218
Epoch 8000, Loss: -0.08318214118480682, Losses: L1: -0.3015526235103607, L2: 0.0239349864423275, L3: 0.04439747333526611, L4: 0.06929197907447815, L5: 0.006206789053976536
Epoch 8500, Loss: -0.08346372842788696, Losses: L1: -0.301628977060318, L2: 0.023946261033415794, L3: 0.0443800687789917, L4: 0.06910362839698792, L5: 0.006204484961926937
Epoch 9000, Loss: -0.08367493003606796, Losses: L1: -0.3016556203365326, L2: 0.023947302252054214, L3: 0.04436969757080078, L4: 0.06894223392009735, L5: 0.006202233023941517
Epoch 9500, Loss: -0.08382000029087067, Losses: L1: -0.30168870091438293, L2: 0.023949135094881058, L3: 0.04436302185058594, L4: 0.0688420981168747, L5: 0.006201149895787239
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0034055709838867, Constraint losses: L1: 6.381187915802002, L2: 0.0, L3: 0.9985125660896301, L4: 0.9985118508338928
Epoch 500, Loss: 0.002179664559662342, Constraint losses: L1: -1.0686814785003662, L2: 0.0, L3: 0.002623260021209717, L4: 0.0006250860169529915
Epoch 1000, Loss: 0.0012753717601299286, Constraint losses: L1: -1.1176631450653076, L2: 0.0, L3: 0.0021962523460388184, L4: 0.0001967826101463288
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0193753242492676, Constraint losses: L1: 18.42068099975586, L2: 0.00031832780223339796, L3: 1.0003182888031006, L4: 1.0003180503845215
Epoch 500, Loss: 0.0021992484107613564, Constraint losses: L1: -1.0149301290512085, L2: 0.0, L3: 0.0026061534881591797, L4: 0.0006080252351239324
Epoch 1000, Loss: 0.0013142562238499522, Constraint losses: L1: -1.0691962242126465, L2: 0.0, L3: 0.0021914243698120117, L4: 0.0001920281065395102
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 168.22340393066406, Losses: L1: 18.12857437133789, L2: 0.004348196554929018, L3: 1.0043469667434692, L4: 73.95442199707031, L5: 0.3371822237968445
Epoch 500, Loss: 9.222756385803223, Losses: L1: 3.6899049282073975, L2: 0.3638337254524231, L3: 0.0733262300491333, L4: 2.323268413543701, L5: 0.02398894540965557
Epoch 1000, Loss: 2.0685644149780273, Losses: L1: -0.1352529376745224, L2: 0.057054728269577026, L3: 0.05494767427444458, L4: 0.9838119149208069, L5: 0.02437721937894821
Epoch 1500, Loss: 1.0146536827087402, Losses: L1: -0.22409957647323608, L2: 0.035090696066617966, L3: 0.054039716720581055, L4: 0.526089072227478, L5: 0.016628500074148178
Epoch 2000, Loss: 0.49895623326301575, Losses: L1: -0.22770929336547852, L2: 0.02950228564441204, L3: 0.05113065242767334, L4: 0.27977415919303894, L5: 0.011702651157975197
Epoch 2500, Loss: 1.182641863822937, Losses: L1: -0.2454652488231659, L2: 0.03546525165438652, L3: 0.04823225736618042, L4: 0.6269923448562622, L5: 0.013454688712954521
Epoch 3000, Loss: 0.9434236884117126, Losses: L1: -0.23439091444015503, L2: 0.023328954353928566, L3: 0.04866135120391846, L4: 0.5146545171737671, L5: 0.009049918502569199
Epoch 3500, Loss: 0.2898392081260681, Losses: L1: -0.2485954463481903, L2: 0.028086503967642784, L3: 0.047476232051849365, L4: 0.19102893769741058, L5: 0.010502578690648079
Epoch 4000, Loss: 0.12539777159690857, Losses: L1: -0.2510793209075928, L2: 0.026921691372990608, L3: 0.04699575901031494, L4: 0.11197501420974731, L5: 0.009384345263242722
Epoch 4500, Loss: 0.1446104794740677, Losses: L1: -0.25068023800849915, L2: 0.02594977617263794, L3: 0.04694962501525879, L4: 0.12244340777397156, L5: 0.009210187941789627
Epoch 5000, Loss: 0.09576135128736496, Losses: L1: -0.2522011399269104, L2: 0.0261700339615345, L3: 0.04673188924789429, L4: 0.09873855859041214, L5: 0.009363073855638504
Epoch 5500, Loss: 0.07165829837322235, Losses: L1: -0.252648264169693, L2: 0.025762492790818214, L3: 0.04666399955749512, L4: 0.08741456270217896, L5: 0.00924891047179699
Epoch 6000, Loss: 0.048578809946775436, Losses: L1: -0.25259578227996826, L2: 0.025400588288903236, L3: 0.04661142826080322, L4: 0.0763029009103775, L5: 0.009089522995054722
Epoch 6500, Loss: 0.045751333236694336, Losses: L1: -0.2526809275150299, L2: 0.025416674092411995, L3: 0.04654878377914429, L4: 0.0749884694814682, L5: 0.009048820473253727
Epoch 7000, Loss: 0.04330776631832123, Losses: L1: -0.25280866026878357, L2: 0.025425199419260025, L3: 0.04651486873626709, L4: 0.07386466860771179, L5: 0.009013923816382885
Epoch 7500, Loss: 0.0413602814078331, Losses: L1: -0.25298872590065, L2: 0.02545684203505516, L3: 0.04648184776306152, L4: 0.07299111038446426, L5: 0.008978797122836113
Epoch 8000, Loss: 0.04037247225642204, Losses: L1: -0.2531178593635559, L2: 0.025472497567534447, L3: 0.04645746946334839, L4: 0.07257458567619324, L5: 0.00896244216710329
Epoch 8500, Loss: 0.03972582891583443, Losses: L1: -0.2532291114330292, L2: 0.025464026257395744, L3: 0.04644179344177246, L4: 0.07233476638793945, L5: 0.008947527967393398
Epoch 9000, Loss: 0.03931409493088722, Losses: L1: -0.253292053937912, L2: 0.025450874119997025, L3: 0.04643058776855469, L4: 0.07218699157238007, L5: 0.00893850065767765
Epoch 9500, Loss: 0.03894338756799698, Losses: L1: -0.2533363997936249, L2: 0.025441356003284454, L3: 0.04642343521118164, L4: 0.07204142212867737, L5: 0.008934720419347286
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.008610248565674, Constraint losses: L1: 9.001052856445312, L2: 1.0822496960827266e-06, L3: 0.9998040199279785, L4: 0.9998042583465576
Epoch 500, Loss: 0.002628892892971635, Constraint losses: L1: -1.110408067703247, L2: 0.0, L3: 0.00286865234375, L4: 0.0008706486551091075
Epoch 1000, Loss: 0.0014583519659936428, Constraint losses: L1: -1.11838960647583, L2: 0.0, L3: 0.00228804349899292, L4: 0.0002886980655603111
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0273666381835938, Constraint losses: L1: 18.42068099975586, L2: 0.0029820238705724478, L3: 1.0029820203781128, L4: 1.0029817819595337
Epoch 500, Loss: 0.0024539753794670105, Constraint losses: L1: -1.0609548091888428, L2: 0.0, L3: 0.0027565360069274902, L4: 0.0007583941332995892
Epoch 1000, Loss: 0.0014287566300481558, Constraint losses: L1: -1.0715696811676025, L2: 0.0, L3: 0.0022498369216918945, L4: 0.0002504894509911537
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 157.9243621826172, Losses: L1: 13.415672302246094, L2: 0.0005332257132977247, L3: 1.000231146812439, L4: 71.095947265625, L5: 0.3152616024017334
Epoch 500, Loss: 49.89471435546875, Losses: L1: 2.460935115814209, L2: 3.8580546379089355, L3: 0.13244682550430298, L4: 19.66409683227539, L5: 0.12458588182926178
Epoch 1000, Loss: 5.889235973358154, Losses: L1: -0.13953131437301636, L2: 0.04629003629088402, L3: 0.08335703611373901, L4: 2.8798458576202393, L5: 0.009781155735254288
Epoch 1500, Loss: 4.321615695953369, Losses: L1: 1.1996357440948486, L2: 0.15335503220558167, L3: 0.08208721876144409, L4: 1.3215006589889526, L5: 0.008094224147498608
Epoch 2000, Loss: 1.0466525554656982, Losses: L1: -0.21425992250442505, L2: 0.04412825033068657, L3: 0.06624191999435425, L4: 0.5155797004699707, L5: 0.00901272613555193
Epoch 2500, Loss: 1.3250446319580078, Losses: L1: -0.2349638193845749, L2: 0.049961432814598083, L3: 0.0622217059135437, L4: 0.6620941758155823, L5: 0.0114538399502635
Epoch 3000, Loss: 0.7575441002845764, Losses: L1: -0.2413719892501831, L2: 0.04519306495785713, L3: 0.06102323532104492, L4: 0.3885321617126465, L5: 0.00941914040595293
Epoch 3500, Loss: 0.408704549074173, Losses: L1: -0.23465462028980255, L2: 0.0431303046643734, L3: 0.05988985300064087, L4: 0.21446089446544647, L5: 0.008397079072892666
Epoch 4000, Loss: 0.35545241832733154, Losses: L1: -0.23642534017562866, L2: 0.04209989681839943, L3: 0.05932438373565674, L4: 0.19047138094902039, L5: 0.00808642990887165
Epoch 4500, Loss: 0.3339698612689972, Losses: L1: -0.2393060326576233, L2: 0.04112936183810234, L3: 0.05883455276489258, L4: 0.18257656693458557, L5: 0.008194911293685436
Epoch 5000, Loss: 0.32384586334228516, Losses: L1: -0.2409672886133194, L2: 0.04042838513851166, L3: 0.05852288007736206, L4: 0.17936328053474426, L5: 0.008184067904949188
Epoch 5500, Loss: 0.3152948021888733, Losses: L1: -0.24197572469711304, L2: 0.04005739837884903, L3: 0.05825245380401611, L4: 0.17623141407966614, L5: 0.008188019506633282
Epoch 6000, Loss: 0.3100200295448303, Losses: L1: -0.24263809621334076, L2: 0.03983902931213379, L3: 0.05807441473007202, L4: 0.17434151470661163, L5: 0.008148185908794403
Epoch 6500, Loss: 0.30557456612586975, Losses: L1: -0.24308164417743683, L2: 0.039681851863861084, L3: 0.057937026023864746, L4: 0.17263785004615784, L5: 0.008142742328345776
Epoch 7000, Loss: 0.3025946617126465, Losses: L1: -0.24335496127605438, L2: 0.03953634947538376, L3: 0.05783355236053467, L4: 0.17153742909431458, L5: 0.008134963922202587
Epoch 7500, Loss: 0.30033791065216064, Losses: L1: -0.2436254620552063, L2: 0.03949042037129402, L3: 0.057736873626708984, L4: 0.17069196701049805, L5: 0.008124846033751965
Epoch 8000, Loss: 0.29882511496543884, Losses: L1: -0.24369463324546814, L2: 0.039402075111866, L3: 0.057679831981658936, L4: 0.17011970281600952, L5: 0.008116512559354305
Epoch 8500, Loss: 0.2977384328842163, Losses: L1: -0.24389468133449554, L2: 0.03939313068985939, L3: 0.057621002197265625, L4: 0.1697489619255066, L5: 0.008106916211545467
Epoch 9000, Loss: 0.2967380881309509, Losses: L1: -0.24396155774593353, L2: 0.03936916962265968, L3: 0.05758512020111084, L4: 0.16934087872505188, L5: 0.008109289221465588
Epoch 9500, Loss: 0.296186625957489, Losses: L1: -0.24403241276741028, L2: 0.03934929147362709, L3: 0.057560503482818604, L4: 0.16914604604244232, L5: 0.008107354864478111
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.52060605]
 [ 0.97873798 -2.28543443]
 [ 1.86755799 -0.60937459]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9993457794189453, Constraint losses: L1: 5.731418132781982, L2: 0.0, L3: 0.9968073964118958, L4: 0.9968070387840271
Epoch 500, Loss: 0.002417705487459898, Constraint losses: L1: -0.9716664552688599, L2: 0.0, L3: 0.002693474292755127, L4: 0.0006958977319300175
Epoch 1000, Loss: 0.001293162233196199, Constraint losses: L1: -1.1142916679382324, L2: 0.0, L3: 0.0022034049034118652, L4: 0.00020404902170412242
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0261664390563965, Constraint losses: L1: 18.42068099975586, L2: 0.0025817337445914745, L3: 1.0025817155838013, L4: 1.0025821924209595
Epoch 500, Loss: 0.0022553945891559124, Constraint losses: L1: -1.037691593170166, L2: 0.0, L3: 0.002645730972290039, L4: 0.0006473551038652658
Epoch 1000, Loss: 0.001342147123068571, Constraint losses: L1: -1.0705562829971313, L2: 0.0, L3: 0.002206146717071533, L4: 0.00020655678235925734
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 187.22286987304688, Losses: L1: 18.42068099975586, L2: 0.0040186308324337006, L3: 1.0040185451507568, L4: 82.98641967773438, L5: 0.40663954615592957
Epoch 500, Loss: 5.069220542907715, Losses: L1: 1.5626112222671509, L2: 0.16210556030273438, L3: 0.08674442768096924, L4: 1.4756641387939453, L5: 0.028790419921278954
Epoch 1000, Loss: 12.949918746948242, Losses: L1: 1.2955361604690552, L2: 0.8209210634231567, L3: 0.11201655864715576, L4: 4.853787899017334, L5: 0.040465738624334335
Epoch 1500, Loss: 32.83592224121094, Losses: L1: 4.875657081604004, L2: 1.2960340976715088, L3: 0.2935342788696289, L4: 12.30572509765625, L5: 0.08483957499265671
Epoch 2000, Loss: 4.933350563049316, Losses: L1: 1.211310863494873, L2: 0.18838398158550262, L3: 0.1283954381942749, L4: 1.5174245834350586, L5: 0.02681588940322399
Epoch 2500, Loss: 3.998777389526367, Losses: L1: 0.8803085088729858, L2: 0.1649925857782364, L3: 0.12218928337097168, L4: 1.2478818893432617, L5: 0.02417057752609253
Epoch 3000, Loss: 2.802520513534546, Losses: L1: 0.8337486386299133, L2: 0.10642755776643753, L3: 0.11971819400787354, L4: 0.7342280149459839, L5: 0.024012234061956406
Epoch 3500, Loss: 2.4210188388824463, Losses: L1: 0.7366117835044861, L2: 0.08346358686685562, L3: 0.11677682399749756, L4: 0.6182242631912231, L5: 0.02373887598514557
Epoch 4000, Loss: 2.2625343799591064, Losses: L1: 0.6922745108604431, L2: 0.07842909544706345, L3: 0.11517202854156494, L4: 0.5680904984474182, L5: 0.023438293486833572
Epoch 4500, Loss: 2.218920946121216, Losses: L1: 0.6908079385757446, L2: 0.07625284790992737, L3: 0.11175048351287842, L4: 0.5529917478561401, L5: 0.023061398416757584
Epoch 5000, Loss: 2.0681874752044678, Losses: L1: 0.6288420557975769, L2: 0.07208382338285446, L3: 0.10939276218414307, L4: 0.5152130126953125, L5: 0.02298302948474884
Epoch 5500, Loss: 2.010261058807373, Losses: L1: 0.616442084312439, L2: 0.07107503712177277, L3: 0.10790634155273438, L4: 0.49524986743927, L5: 0.022678222507238388
Epoch 6000, Loss: 1.972333312034607, Losses: L1: 0.6042629480361938, L2: 0.07011676579713821, L3: 0.10698974132537842, L4: 0.4845101833343506, L5: 0.02241850271821022
Epoch 6500, Loss: 1.9482086896896362, Losses: L1: 0.593204140663147, L2: 0.06962015479803085, L3: 0.10624551773071289, L4: 0.4793892204761505, L5: 0.022247401997447014
Epoch 7000, Loss: 1.9306741952896118, Losses: L1: 0.5855696201324463, L2: 0.0692085325717926, L3: 0.10559189319610596, L4: 0.47561708092689514, L5: 0.022134777158498764
Epoch 7500, Loss: 1.9178189039230347, Losses: L1: 0.5798302292823792, L2: 0.0688900351524353, L3: 0.10514360666275024, L4: 0.4729195535182953, L5: 0.022041164338588715
Epoch 8000, Loss: 1.9084168672561646, Losses: L1: 0.5748281478881836, L2: 0.06865087151527405, L3: 0.10477685928344727, L4: 0.47138315439224243, L5: 0.02198343724012375
Epoch 8500, Loss: 1.9015132188796997, Losses: L1: 0.5718123912811279, L2: 0.06842605024576187, L3: 0.1045987606048584, L4: 0.4699079394340515, L5: 0.021917665377259254
Epoch 9000, Loss: 1.8965423107147217, Losses: L1: 0.5692875981330872, L2: 0.06825795769691467, L3: 0.10448813438415527, L4: 0.4690106213092804, L5: 0.021870603784918785
Epoch 9500, Loss: 1.893052101135254, Losses: L1: 0.5668495297431946, L2: 0.06814917922019958, L3: 0.10443484783172607, L4: 0.46868014335632324, L5: 0.021837133914232254
Training done
----------------------------------------------------------------------------
######################### Running test with dataset: FrecUpWeight ###########
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0024774074554443, Constraint losses: L1: 6.218834400177002, L2: 0.0, L3: 0.9981294870376587, L4: 0.9981290698051453
Epoch 500, Loss: 0.0023382739163935184, Constraint losses: L1: -1.0964394807815552, L2: 0.0, L3: 0.0027164816856384277, L4: 0.0007182318367995322
Epoch 1000, Loss: 0.0013466670643538237, Constraint losses: L1: -1.118198037147522, L2: 0.0, L3: 0.002232193946838379, L4: 0.00023267121287062764
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022892713546753, Constraint losses: L1: 18.42068099975586, L2: 0.0014905971474945545, L3: 1.001490592956543, L4: 1.001490831375122
Epoch 500, Loss: 0.0019747111946344376, Constraint losses: L1: -1.0668619871139526, L2: 0.0, L3: 0.0025202035903930664, L4: 0.0005213696858845651
Epoch 1000, Loss: 0.0012050792574882507, Constraint losses: L1: -1.115906000137329, L2: 0.0, L3: 0.002160310745239258, L4: 0.0001606745645403862
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 51.64030838012695, Losses: L1: 18.42068099975586, L2: 0.007037605158984661, L3: 1.00703763961792, L4: 65.21492004394531, L5: 0.21025912463665009
Epoch 500, Loss: 10.656779289245605, Losses: L1: 6.316957473754883, L2: 1.0733708143234253, L3: 0.1742200255393982, L4: 7.325734615325928, L5: 0.10631689429283142
Epoch 1000, Loss: 22.278627395629883, Losses: L1: -0.2740996181964874, L2: 0.566590428352356, L3: 0.9221275448799133, L4: 43.420005798339844, L5: 0.19673123955726624
Epoch 1500, Loss: 3.747793436050415, Losses: L1: -0.3893410861492157, L2: 0.47633567452430725, L3: 0.2738085985183716, L4: 7.463654041290283, L5: 0.060470517724752426
Epoch 2000, Loss: 2.0851211547851562, Losses: L1: -0.5614571571350098, L2: 0.365280419588089, L3: 0.25456947088241577, L4: 4.6279072761535645, L5: 0.045399487018585205
Epoch 2500, Loss: 1.2030870914459229, Losses: L1: -0.6472846865653992, L2: 0.3698476552963257, L3: 0.23352301120758057, L4: 3.060667037963867, L5: 0.03670608624815941
Epoch 3000, Loss: 0.9794490933418274, Losses: L1: -0.6832945942878723, L2: 0.36763426661491394, L3: 0.22146284580230713, L4: 2.700753688812256, L5: 0.035636600106954575
Epoch 3500, Loss: 0.8539297580718994, Losses: L1: -0.7314342856407166, L2: 0.37009164690971375, L3: 0.212540864944458, L4: 2.5526413917541504, L5: 0.03545414283871651
Epoch 4000, Loss: 0.7762312889099121, Losses: L1: -0.7709721326828003, L2: 0.3780588209629059, L3: 0.20826268196105957, L4: 2.472409248352051, L5: 0.03567614406347275
Epoch 4500, Loss: 0.724441409111023, Losses: L1: -0.8017265796661377, L2: 0.38572975993156433, L3: 0.20641064643859863, L4: 2.4243688583374023, L5: 0.03582664579153061
Epoch 5000, Loss: 0.6893333792686462, Losses: L1: -0.8220537304878235, L2: 0.39077529311180115, L3: 0.2057461142539978, L4: 2.390477180480957, L5: 0.03577559068799019
Epoch 5500, Loss: 0.6636717319488525, Losses: L1: -0.8353186249732971, L2: 0.3939899802207947, L3: 0.20488160848617554, L4: 2.363462448120117, L5: 0.03564666584134102
Epoch 6000, Loss: 0.6449683904647827, Losses: L1: -0.8466544151306152, L2: 0.39719346165657043, L3: 0.20360541343688965, L4: 2.3468713760375977, L5: 0.035575415939092636
Epoch 6500, Loss: 0.630750834941864, Losses: L1: -0.8525289297103882, L2: 0.39877721667289734, L3: 0.2030775547027588, L4: 2.329346179962158, L5: 0.035358503460884094
Epoch 7000, Loss: 0.6205368041992188, Losses: L1: -0.8583650588989258, L2: 0.40045440196990967, L3: 0.20277822017669678, L4: 2.3192050457000732, L5: 0.035366009920835495
Epoch 7500, Loss: 0.61327064037323, Losses: L1: -0.863083004951477, L2: 0.4018838405609131, L3: 0.2024383544921875, L4: 2.31308650970459, L5: 0.03529859706759453
Epoch 8000, Loss: 0.6079884171485901, Losses: L1: -0.8665858507156372, L2: 0.4026789963245392, L3: 0.2021411657333374, L4: 2.3089869022369385, L5: 0.035341497510671616
Epoch 8500, Loss: 0.6037874221801758, Losses: L1: -0.8692287802696228, L2: 0.4034847915172577, L3: 0.20216763019561768, L4: 2.3050711154937744, L5: 0.035308822989463806
Epoch 9000, Loss: 0.6008581519126892, Losses: L1: -0.8712092041969299, L2: 0.4040210247039795, L3: 0.20207273960113525, L4: 2.302730083465576, L5: 0.03531091287732124
Epoch 9500, Loss: 0.5987426042556763, Losses: L1: -0.87253338098526, L2: 0.40427103638648987, L3: 0.20195794105529785, L4: 2.301015615463257, L5: 0.0353073887526989
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0224170684814453, Constraint losses: L1: 18.42068099975586, L2: 0.00133203761652112, L3: 1.0013320446014404, L4: 1.00133216381073
Epoch 500, Loss: 0.00246972544118762, Constraint losses: L1: -1.1105904579162598, L2: 0.0, L3: 0.002789139747619629, L4: 0.0007911763386800885
Epoch 1000, Loss: 0.0014051608741283417, Constraint losses: L1: -1.1176106929779053, L2: 0.0, L3: 0.002261042594909668, L4: 0.0002617290592752397
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002094268798828, Constraint losses: L1: 6.192992210388184, L2: 0.0, L3: 0.997950553894043, L4: 0.997950553894043
Epoch 500, Loss: 0.002049165777862072, Constraint losses: L1: -1.0853981971740723, L2: 0.0, L3: 0.0025664567947387695, L4: 0.0005681072361767292
Epoch 1000, Loss: 0.0012453565141186118, Constraint losses: L1: -1.1167807579040527, L2: 0.0, L3: 0.0021808743476867676, L4: 0.00018126299255527556
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 55.32099151611328, Losses: L1: 18.42068099975586, L2: 0.007665697485208511, L3: 1.007665753364563, L4: 72.30484008789062, L5: 0.24022118747234344
Epoch 500, Loss: -1.622366189956665, Losses: L1: -3.491100311279297, L2: 1.6111656427383423, L3: 0.07198494672775269, L4: 1.9366230964660645, L5: 0.058847445994615555
Epoch 1000, Loss: 2.0170974731445312, Losses: L1: -1.627527117729187, L2: 1.3886730670928955, L3: 0.2002812623977661, L4: 5.536151885986328, L5: 0.08207155019044876
Epoch 1500, Loss: 0.5404845476150513, Losses: L1: -2.22188138961792, L2: 1.5534863471984863, L3: 0.17396759986877441, L4: 3.6725175380706787, L5: 0.062380190938711166
Epoch 2000, Loss: -0.39921754598617554, Losses: L1: -2.5480639934539795, L2: 1.7800401449203491, L3: 0.14474254846572876, L4: 2.2401084899902344, L5: 0.06640084087848663
Epoch 2500, Loss: -0.7275802493095398, Losses: L1: -2.7408454418182373, L2: 1.7947814464569092, L3: 0.13479334115982056, L4: 1.9548447132110596, L5: 0.07105549424886703
Epoch 3000, Loss: -0.7245423793792725, Losses: L1: -2.9485886096954346, L2: 1.8604694604873657, L3: 0.1263626217842102, L4: 2.3029158115386963, L5: 0.07917235791683197
Epoch 3500, Loss: -1.2235466241836548, Losses: L1: -3.1527812480926514, L2: 1.95072340965271, L3: 0.12395942211151123, L4: 1.6312575340270996, L5: 0.07626450061798096
Epoch 4000, Loss: -1.383812427520752, Losses: L1: -3.313508987426758, L2: 2.040909767150879, L3: 0.12311148643493652, L4: 1.5387859344482422, L5: 0.07829289138317108
Epoch 4500, Loss: -1.4702589511871338, Losses: L1: -3.4153599739074707, L2: 2.090911388397217, L3: 0.12324106693267822, L4: 1.5178619623184204, L5: 0.07909387350082397
Epoch 5000, Loss: -1.5294897556304932, Losses: L1: -3.489903450012207, L2: 2.1212689876556396, L3: 0.12375545501708984, L4: 1.5172617435455322, L5: 0.07927049696445465
Epoch 5500, Loss: -1.5693467855453491, Losses: L1: -3.5410518646240234, L2: 2.1467223167419434, L3: 0.12391161918640137, L4: 1.5137174129486084, L5: 0.07952957600355148
Epoch 6000, Loss: -1.5966962575912476, Losses: L1: -3.5750303268432617, L2: 2.163463592529297, L3: 0.12379252910614014, L4: 1.509863257408142, L5: 0.07977428287267685
Epoch 6500, Loss: -1.6167967319488525, Losses: L1: -3.5959458351135254, L2: 2.1721839904785156, L3: 0.1234133243560791, L4: 1.5029466152191162, L5: 0.07987730950117111
Epoch 7000, Loss: -1.630394458770752, Losses: L1: -3.609243631362915, L2: 2.1771035194396973, L3: 0.12321281433105469, L4: 1.496917963027954, L5: 0.08023200184106827
Epoch 7500, Loss: -1.6397895812988281, Losses: L1: -3.618180513381958, L2: 2.1798384189605713, L3: 0.12299025058746338, L4: 1.4932548999786377, L5: 0.08034903556108475
Epoch 8000, Loss: -1.6464523077011108, Losses: L1: -3.6242096424102783, L2: 2.1813929080963135, L3: 0.12286633253097534, L4: 1.4901262521743774, L5: 0.08056467026472092
Epoch 8500, Loss: -1.650965929031372, Losses: L1: -3.628596544265747, L2: 2.183316707611084, L3: 0.12275618314743042, L4: 1.487849473953247, L5: 0.08066950738430023
Epoch 9000, Loss: -1.6539335250854492, Losses: L1: -3.631922721862793, L2: 2.185513734817505, L3: 0.12265419960021973, L4: 1.4862611293792725, L5: 0.08077496290206909
Epoch 9500, Loss: -1.655951976776123, Losses: L1: -3.6340043544769287, L2: 2.1865289211273193, L3: 0.12258756160736084, L4: 1.485356330871582, L5: 0.08081600815057755
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.031865119934082, Constraint losses: L1: 18.42068099975586, L2: 0.004481020383536816, L3: 1.0044810771942139, L4: 1.0044825077056885
Epoch 500, Loss: 0.00218195840716362, Constraint losses: L1: -1.087554693222046, L2: 0.0, L3: 0.002633810043334961, L4: 0.0006357029778882861
Epoch 1000, Loss: 0.001284881727769971, Constraint losses: L1: -1.118326187133789, L2: 0.0, L3: 0.002201259136199951, L4: 0.00020194874377921224
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0041513442993164, Constraint losses: L1: 6.608574867248535, L2: 0.0, L3: 0.9987716674804688, L4: 0.9987711906433105
Epoch 500, Loss: 0.002033325843513012, Constraint losses: L1: -1.1103966236114502, L2: 0.0, L3: 0.00257110595703125, L4: 0.0005726165254600346
Epoch 1000, Loss: 0.0012603532522916794, Constraint losses: L1: -1.1154417991638184, L2: 0.0, L3: 0.0021875500679016113, L4: 0.00018824507424142212
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 58.07219696044922, Losses: L1: 17.567197799682617, L2: 0.004253778140991926, L3: 1.0042463541030884, L4: 78.89747619628906, L5: 0.2760048806667328
Epoch 500, Loss: -0.9412437081336975, Losses: L1: -3.2760109901428223, L2: 1.2872881889343262, L3: 0.08954298496246338, L4: 3.145214080810547, L5: 0.03687236085534096
Epoch 1000, Loss: -1.889156699180603, Losses: L1: -4.277313709259033, L2: 1.8952339887619019, L3: 0.06968080997467041, L4: 2.694477081298828, L5: 0.02923053503036499
Epoch 1500, Loss: -2.230280876159668, Losses: L1: -4.539416313171387, L2: 1.8663438558578491, L3: 0.04556906223297119, L4: 2.568114757537842, L5: 0.034560803323984146
Epoch 2000, Loss: -3.4283077716827393, Losses: L1: -4.5612359046936035, L2: 1.609524130821228, L3: 0.013611912727355957, L4: 0.547712504863739, L5: 0.02375202625989914
Epoch 2500, Loss: -3.4674479961395264, Losses: L1: -4.590937614440918, L2: 1.5805386304855347, L3: 0.015923738479614258, L4: 0.5605816841125488, L5: 0.022483859211206436
Epoch 3000, Loss: -3.5322554111480713, Losses: L1: -4.656132221221924, L2: 1.620833396911621, L3: 0.008516788482666016, L4: 0.5315678119659424, L5: 0.02170887030661106
Epoch 3500, Loss: -3.607595205307007, Losses: L1: -4.64336633682251, L2: 1.5459917783737183, L3: 0.0034079551696777344, L4: 0.4390733242034912, L5: 0.02076733112335205
Epoch 4000, Loss: -3.6279714107513428, Losses: L1: -4.632152557373047, L2: 1.5001353025436401, L3: 0.001959681510925293, L4: 0.4238692820072174, L5: 0.020599452778697014
Epoch 4500, Loss: -3.6429004669189453, Losses: L1: -4.651645660400391, L2: 1.5225517749786377, L3: 0.001241445541381836, L4: 0.4117574691772461, L5: 0.020484983921051025
Epoch 5000, Loss: -3.65320086479187, Losses: L1: -4.649492263793945, L2: 1.5060503482818604, L3: 9.119510650634766e-05, L4: 0.40533727407455444, L5: 0.02027607522904873
Epoch 5500, Loss: -3.658263921737671, Losses: L1: -4.649755001068115, L2: 1.4989773035049438, L3: 0.00022268295288085938, L4: 0.40302979946136475, L5: 0.02018805406987667
Epoch 6000, Loss: -3.6637048721313477, Losses: L1: -4.652825832366943, L2: 1.4991707801818848, L3: 0.00037288665771484375, L4: 0.39781421422958374, L5: 0.020221035927534103
Epoch 6500, Loss: -3.6669602394104004, Losses: L1: -4.649884223937988, L2: 1.4889551401138306, L3: 0.00047791004180908203, L4: 0.3958604037761688, L5: 0.020138708874583244
Epoch 7000, Loss: -3.6696479320526123, Losses: L1: -4.6538920402526855, L2: 1.4941421747207642, L3: 3.731250762939453e-05, L4: 0.39377301931381226, L5: 0.02013399265706539
Epoch 7500, Loss: -3.671191453933716, Losses: L1: -4.655224800109863, L2: 1.4947261810302734, L3: 0.00043904781341552734, L4: 0.3924309313297272, L5: 0.0201176218688488
Epoch 8000, Loss: -3.6724679470062256, Losses: L1: -4.654902935028076, L2: 1.4927560091018677, L3: 8.559226989746094e-05, L4: 0.39165735244750977, L5: 0.02009275183081627
Epoch 8500, Loss: -3.673304796218872, Losses: L1: -4.655276298522949, L2: 1.4925073385238647, L3: 1.8477439880371094e-06, L4: 0.3911099433898926, L5: 0.020080897957086563
Epoch 9000, Loss: -3.673839807510376, Losses: L1: -4.655506610870361, L2: 1.4922634363174438, L3: 7.033348083496094e-05, L4: 0.39073413610458374, L5: 0.020066456869244576
Epoch 9500, Loss: -3.6742167472839355, Losses: L1: -4.655115604400635, L2: 1.4910579919815063, L3: 1.6450881958007812e-05, L4: 0.3905089795589447, L5: 0.02005351521074772
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.033466339111328, Constraint losses: L1: 18.42068099975586, L2: 0.005015170201659203, L3: 1.0050151348114014, L4: 1.0050153732299805
Epoch 500, Loss: 0.002054915064945817, Constraint losses: L1: -1.1065239906311035, L2: 0.0, L3: 0.002579927444458008, L4: 0.0005815117037855089
Epoch 1000, Loss: 0.0012602951610460877, Constraint losses: L1: -1.1157268285751343, L2: 0.0, L3: 0.002187669277191162, L4: 0.00018835277296602726
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0069572925567627, Constraint losses: L1: 7.907561779022217, L2: 2.998835668677202e-08, L3: 0.9995246529579163, L4: 0.9995251297950745
Epoch 500, Loss: 0.002129961969330907, Constraint losses: L1: -0.9868111610412598, L2: 0.0, L3: 0.00255739688873291, L4: 0.0005593763780780137
Epoch 1000, Loss: 0.0012087943032383919, Constraint losses: L1: -1.1149815320968628, L2: 0.0, L3: 0.002161562442779541, L4: 0.000162213429575786
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.0774917602539, Losses: L1: 8.871848106384277, L2: 0.0010154747869819403, L3: 0.9955295920372009, L4: 77.57560729980469, L5: 0.2635347843170166
Epoch 500, Loss: 1.4556602239608765, Losses: L1: -2.3973045349121094, L2: 1.376417875289917, L3: 0.08140027523040771, L4: 3.0873982906341553, L5: 0.07331501692533493
Epoch 1000, Loss: -1.0465067625045776, Losses: L1: -3.2019543647766113, L2: 1.5934373140335083, L3: 0.07991147041320801, L4: 1.296892523765564, L5: 0.04376177862286568
Epoch 1500, Loss: -1.5844883918762207, Losses: L1: -3.5853464603424072, L2: 1.7520207166671753, L3: 0.06933814287185669, L4: 1.0647889375686646, L5: 0.05077916011214256
Epoch 2000, Loss: -2.1839146614074707, Losses: L1: -3.7347702980041504, L2: 1.6844990253448486, L3: 0.07051318883895874, L4: 0.6403990983963013, L5: 0.06590085476636887
Epoch 2500, Loss: -2.5516374111175537, Losses: L1: -3.9278430938720703, L2: 1.7684558629989624, L3: 0.06719493865966797, L4: 0.42450183629989624, L5: 0.06775674223899841
Epoch 3000, Loss: -2.9339609146118164, Losses: L1: -4.416388034820557, L2: 2.2132620811462402, L3: 0.06719982624053955, L4: 0.3059164583683014, L5: 0.07255952805280685
Epoch 3500, Loss: -3.1120388507843018, Losses: L1: -4.386673927307129, L2: 1.9062714576721191, L3: 0.0683283805847168, L4: 0.2528667449951172, L5: 0.06893704831600189
Epoch 4000, Loss: -3.1779098510742188, Losses: L1: -4.399120330810547, L2: 1.8602702617645264, L3: 0.06595611572265625, L4: 0.22399039566516876, L5: 0.06821324676275253
Epoch 4500, Loss: -3.2119383811950684, Losses: L1: -4.435317039489746, L2: 1.8880468606948853, L3: 0.06489861011505127, L4: 0.21315883100032806, L5: 0.0674944669008255
Epoch 5000, Loss: -3.233006477355957, Losses: L1: -4.426807880401611, L2: 1.839824914932251, L3: 0.06399405002593994, L4: 0.208368182182312, L5: 0.06704816967248917
Epoch 5500, Loss: -3.2466776371002197, Losses: L1: -4.431053161621094, L2: 1.8287622928619385, L3: 0.0634697675704956, L4: 0.20496530830860138, L5: 0.06658855080604553
Epoch 6000, Loss: -3.2561919689178467, Losses: L1: -4.434593200683594, L2: 1.8235470056533813, L3: 0.06303542852401733, L4: 0.20194955170154572, L5: 0.06632080674171448
Epoch 6500, Loss: -3.2628519535064697, Losses: L1: -4.436349868774414, L2: 1.818302869796753, L3: 0.06272071599960327, L4: 0.1999586820602417, L5: 0.06605486571788788
Epoch 7000, Loss: -3.267235517501831, Losses: L1: -4.434543132781982, L2: 1.8077176809310913, L3: 0.06252866983413696, L4: 0.1992976814508438, L5: 0.06577345728874207
Epoch 7500, Loss: -3.2711830139160156, Losses: L1: -4.434447765350342, L2: 1.802322268486023, L3: 0.062419235706329346, L4: 0.19807377457618713, L5: 0.06564018130302429
Epoch 8000, Loss: -3.273836374282837, Losses: L1: -4.434846878051758, L2: 1.7996206283569336, L3: 0.06234729290008545, L4: 0.19726769626140594, L5: 0.06551755964756012
Epoch 8500, Loss: -3.275559902191162, Losses: L1: -4.435064792633057, L2: 1.7975823879241943, L3: 0.062287092208862305, L4: 0.196843683719635, L5: 0.06545256078243256
Epoch 9000, Loss: -3.2769112586975098, Losses: L1: -4.435576915740967, L2: 1.7968569993972778, L3: 0.06225305795669556, L4: 0.19641521573066711, L5: 0.06539110839366913
Epoch 9500, Loss: -3.2778539657592773, Losses: L1: -4.435200214385986, L2: 1.7948417663574219, L3: 0.06222468614578247, L4: 0.19613702595233917, L5: 0.0653521716594696
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.997185468673706, Constraint losses: L1: 5.440636157989502, L2: 0.0, L3: 0.9958729147911072, L4: 0.9958719611167908
Epoch 500, Loss: 0.0021717557683587074, Constraint losses: L1: -1.1065412759780884, L2: 0.0, L3: 0.0026382803916931152, L4: 0.0006400167476385832
Epoch 1000, Loss: 0.0012982680927962065, Constraint losses: L1: -1.1187931299209595, L2: 0.0, L3: 0.0022082924842834473, L4: 0.00020876873168163002
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0014872550964355, Constraint losses: L1: 6.1088361740112305, L2: 0.0, L3: 0.9976891279220581, L4: 0.9976893663406372
Epoch 500, Loss: 0.001977103529497981, Constraint losses: L1: -1.1030552387237549, L2: 0.0, L3: 0.002539336681365967, L4: 0.0005408222205005586
Epoch 1000, Loss: 0.0012348047457635403, Constraint losses: L1: -1.1142009496688843, L2: 0.0, L3: 0.0021742582321166992, L4: 0.00017474760534241796
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 88.87444305419922, Losses: L1: 7.338745594024658, L2: 1.881979733298067e-05, L3: 0.9964993000030518, L4: 80.75373077392578, L5: 0.2837044894695282
Epoch 500, Loss: 8.432713508605957, Losses: L1: 4.057506084442139, L2: 0.39254456758499146, L3: 0.0986514687538147, L4: 3.9642953872680664, L5: 0.16531381011009216
Epoch 1000, Loss: 54.417518615722656, Losses: L1: 4.979861736297607, L2: 0.04424012079834938, L3: 0.9235306978225708, L4: 48.64049530029297, L5: 0.31327781081199646
Epoch 1500, Loss: 45.08686065673828, Losses: L1: 0.44711539149284363, L2: 0.13124150037765503, L3: 0.5506902933120728, L4: 44.09220886230469, L5: 0.20656947791576385
Epoch 2000, Loss: 9.849396705627441, Losses: L1: 4.931093692779541, L2: 0.32023218274116516, L3: 0.07996112108230591, L4: 4.549907207489014, L5: 0.1682998687028885
Epoch 2500, Loss: 61.994747161865234, Losses: L1: 11.164203643798828, L2: 1.2462639915611362e-06, L3: 0.9996967315673828, L4: 50.002193450927734, L5: 0.3285014033317566
Epoch 3000, Loss: 52.79764175415039, Losses: L1: 2.172678232192993, L2: 0.03835338354110718, L3: 0.16676318645477295, L4: 50.201812744140625, L5: 0.3205909729003906
Epoch 3500, Loss: 49.080204010009766, Losses: L1: -1.2867517471313477, L2: 0.9367458820343018, L3: 0.0713886022567749, L4: 49.59795379638672, L5: 0.26493412256240845
Epoch 4000, Loss: 48.70332336425781, Losses: L1: -1.69200599193573, L2: 1.1766397953033447, L3: 0.06314170360565186, L4: 49.514034271240234, L5: 0.2614056468009949
Epoch 4500, Loss: 48.55659103393555, Losses: L1: -1.8513057231903076, L2: 1.2234387397766113, L3: 0.006283998489379883, L4: 49.528987884521484, L5: 0.2640458047389984
Epoch 5000, Loss: 48.46745681762695, Losses: L1: -1.9467469453811646, L2: 1.2640879154205322, L3: 0.03606688976287842, L4: 49.499305725097656, L5: 0.2648213803768158
Epoch 5500, Loss: 48.40066909790039, Losses: L1: -2.0128605365753174, L2: 1.281179428100586, L3: 0.004144132137298584, L4: 49.50568389892578, L5: 0.2651823163032532
Epoch 6000, Loss: 48.36351013183594, Losses: L1: -2.0536153316497803, L2: 1.2921243906021118, L3: 0.005576133728027344, L4: 49.50288772583008, L5: 0.26538676023483276
Epoch 6500, Loss: 48.335994720458984, Losses: L1: -2.0786240100860596, L2: 1.2966814041137695, L3: 0.0025172829627990723, L4: 49.49951934814453, L5: 0.26549971103668213
Epoch 7000, Loss: 48.3181266784668, Losses: L1: -2.098095417022705, L2: 1.2989239692687988, L3: 0.003994762897491455, L4: 49.49913787841797, L5: 0.2656242847442627
Epoch 7500, Loss: 48.3050422668457, Losses: L1: -2.108368158340454, L2: 1.299900770187378, L3: 0.003638029098510742, L4: 49.49596405029297, L5: 0.2656802237033844
Epoch 8000, Loss: 48.294776916503906, Losses: L1: -2.1152241230010986, L2: 1.2997486591339111, L3: 0.0002225637435913086, L4: 49.49428939819336, L5: 0.2657228410243988
Epoch 8500, Loss: 48.28876495361328, Losses: L1: -2.119736433029175, L2: 1.2997037172317505, L3: 0.0011126995086669922, L4: 49.49233627319336, L5: 0.26575732231140137
Epoch 9000, Loss: 48.284053802490234, Losses: L1: -2.122606039047241, L2: 1.2995526790618896, L3: 2.2649765014648438e-06, L4: 49.4911003112793, L5: 0.2657809853553772
Epoch 9500, Loss: 48.281166076660156, Losses: L1: -2.124504327774048, L2: 1.299516201019287, L3: 9.500980377197266e-05, L4: 49.49006271362305, L5: 0.265798956155777
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0208396911621094, Constraint losses: L1: 18.42068099975586, L2: 0.0008063256391324103, L3: 1.0008063316345215, L4: 1.0008063316345215
Epoch 500, Loss: 0.0023389803245663643, Constraint losses: L1: -1.053398609161377, L2: 0.0, L3: 0.0026952624320983887, L4: 0.0006971166003495455
Epoch 1000, Loss: 0.0013068943517282605, Constraint losses: L1: -1.1180447340011597, L2: 0.0, L3: 0.002212226390838623, L4: 0.00021271276636980474
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.993193507194519, Constraint losses: L1: 5.020431041717529, L2: 0.0, L3: 0.994087815284729, L4: 0.9940852522850037
Epoch 500, Loss: 0.0025755339302122593, Constraint losses: L1: -1.101839542388916, L2: 0.0, L3: 0.0028375983238220215, L4: 0.0008397753117606044
Epoch 1000, Loss: 0.001438515493646264, Constraint losses: L1: -1.1155532598495483, L2: 0.0, L3: 0.0022766590118408203, L4: 0.000277409766567871
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 86.1207275390625, Losses: L1: 14.874078750610352, L2: 0.002317202975973487, L3: 1.0018963813781738, L4: 70.28590393066406, L5: 0.22932103276252747
Epoch 500, Loss: 2.388118028640747, Losses: L1: -0.6954994201660156, L2: 1.4254261255264282, L3: 0.11726528406143188, L4: 2.1150052547454834, L5: 0.09863325208425522
Epoch 1000, Loss: -1.4725161790847778, Losses: L1: -3.990042209625244, L2: 1.7885257005691528, L3: 0.036259233951568604, L4: 1.383732795715332, L5: 0.11070045083761215
Epoch 1500, Loss: -1.9806236028671265, Losses: L1: -4.00437593460083, L2: 1.6049377918243408, L3: 0.054105401039123535, L4: 1.0795559883117676, L5: 0.05733747407793999
Epoch 2000, Loss: -0.2777262032032013, Losses: L1: -3.4212663173675537, L2: 1.4949545860290527, L3: 0.045750975608825684, L4: 2.26944637298584, L5: 0.051870446652173996
Epoch 2500, Loss: -1.1865040063858032, Losses: L1: -2.7062838077545166, L2: 1.0421112775802612, L3: 0.07981991767883301, L4: 0.9104511737823486, L5: 0.024181408807635307
Epoch 3000, Loss: -1.6027089357376099, Losses: L1: -3.157777786254883, L2: 1.4484919309616089, L3: 0.06248408555984497, L4: 0.7459083795547485, L5: 0.02683614380657673
Epoch 3500, Loss: -1.9536672830581665, Losses: L1: -3.4812934398651123, L2: 1.660585880279541, L3: 0.07042062282562256, L4: 0.6058176159858704, L5: 0.028152618557214737
Epoch 4000, Loss: -2.267423629760742, Losses: L1: -3.7031524181365967, L2: 1.7802318334579468, L3: 0.04046738147735596, L4: 0.4669126868247986, L5: 0.029233235865831375
Epoch 4500, Loss: -2.3803865909576416, Losses: L1: -3.79849910736084, L2: 1.8325196504592896, L3: 0.027686595916748047, L4: 0.4266301989555359, L5: 0.030689580366015434
Epoch 5000, Loss: -2.4721667766571045, Losses: L1: -3.845834732055664, L2: 1.8385058641433716, L3: 0.0015940666198730469, L4: 0.3894698917865753, L5: 0.03207404538989067
Epoch 5500, Loss: -2.5183074474334717, Losses: L1: -3.87699294090271, L2: 1.8278017044067383, L3: 0.00030612945556640625, L4: 0.3794843554496765, L5: 0.03257356956601143
Epoch 6000, Loss: -2.545607805252075, Losses: L1: -3.9058151245117188, L2: 1.8334890604019165, L3: 0.00016629695892333984, L4: 0.37734556198120117, L5: 0.03301703929901123
Epoch 6500, Loss: -2.566169261932373, Losses: L1: -3.921602249145508, L2: 1.8313604593276978, L3: 8.463859558105469e-06, L4: 0.3732139468193054, L5: 0.03326721116900444
Epoch 7000, Loss: -2.579652786254883, Losses: L1: -3.932645559310913, L2: 1.8301455974578857, L3: 9.417533874511719e-05, L4: 0.370922327041626, L5: 0.033475227653980255
Epoch 7500, Loss: -2.589195728302002, Losses: L1: -3.9423751831054688, L2: 1.833155870437622, L3: 0.00010645389556884766, L4: 0.3692108392715454, L5: 0.03366871923208237
Epoch 8000, Loss: -2.595902681350708, Losses: L1: -3.9499151706695557, L2: 1.8367669582366943, L3: 2.6881694793701172e-05, L4: 0.3679676055908203, L5: 0.03382403403520584
Epoch 8500, Loss: -2.600407123565674, Losses: L1: -3.9553725719451904, L2: 1.8398325443267822, L3: 2.1457672119140625e-06, L4: 0.3671743869781494, L5: 0.033936917781829834
Epoch 9000, Loss: -2.6034293174743652, Losses: L1: -3.9591994285583496, L2: 1.8421615362167358, L3: 2.384185791015625e-07, L4: 0.36666250228881836, L5: 0.0340132974088192
Epoch 9500, Loss: -2.6053695678710938, Losses: L1: -3.961757183074951, L2: 1.8438161611557007, L3: 2.574920654296875e-05, L4: 0.3663417100906372, L5: 0.03406233713030815
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0188488960266113, Constraint losses: L1: 17.983736038208008, L2: 0.0004067438712809235, L3: 1.0002291202545166, L4: 1.0002292394638062
Epoch 500, Loss: 0.0021522734314203262, Constraint losses: L1: -1.0938133001327515, L2: 0.0, L3: 0.0026221871376037598, L4: 0.0006238995119929314
Epoch 1000, Loss: 0.0012831100029870868, Constraint losses: L1: -1.1178786754608154, L2: 0.0, L3: 0.0022001266479492188, L4: 0.0002008620649576187
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0326366424560547, Constraint losses: L1: 18.42068099975586, L2: 0.004738445393741131, L3: 1.004738450050354, L4: 1.0047389268875122
Epoch 500, Loss: 0.002248923759907484, Constraint losses: L1: -1.0801045894622803, L2: 0.0, L3: 0.002663552761077881, L4: 0.0006654757307842374
Epoch 1000, Loss: 0.001305672456510365, Constraint losses: L1: -1.1167441606521606, L2: 0.0, L3: 0.0022109150886535645, L4: 0.00021150156680960208
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 155.18125915527344, Losses: L1: 12.45587158203125, L2: 0.001288838335312903, L3: 1.000040888786316, L4: 71.05381774902344, L5: 0.23417426645755768
Epoch 500, Loss: 2.028521776199341, Losses: L1: -3.489239454269409, L2: 1.8013845682144165, L3: 0.09354573488235474, L4: 2.272740125656128, L5: 0.04963162541389465
Epoch 1000, Loss: 2.3343513011932373, Losses: L1: -1.70595383644104, L2: 0.7844069004058838, L3: 0.09659165143966675, L4: 1.7831494808197021, L5: 0.06701383739709854
Epoch 1500, Loss: 0.3769991397857666, Losses: L1: -1.879298448562622, L2: 0.983029842376709, L3: 0.05856466293334961, L4: 0.8518891930580139, L5: 0.06344388425350189
Epoch 2000, Loss: -0.9350898265838623, Losses: L1: -3.123495578765869, L2: 1.6974655389785767, L3: 0.0790255069732666, L4: 0.6323927640914917, L5: 0.07074932008981705
Epoch 2500, Loss: -1.0757867097854614, Losses: L1: -3.393662929534912, L2: 1.9957815408706665, L3: 0.07804471254348755, L4: 0.6233148574829102, L5: 0.06866661459207535
Epoch 3000, Loss: -1.6456869840621948, Losses: L1: -3.6304826736450195, L2: 2.1874613761901855, L3: 0.0745539665222168, L4: 0.4106329083442688, L5: 0.06504441797733307
Epoch 3500, Loss: -1.7796887159347534, Losses: L1: -3.7395832538604736, L2: 2.275578260421753, L3: 0.07185995578765869, L4: 0.377177357673645, L5: 0.06364186853170395
Epoch 4000, Loss: -1.8812614679336548, Losses: L1: -3.802161693572998, L2: 2.3075449466705322, L3: 0.06953203678131104, L4: 0.35026437044143677, L5: 0.06366628408432007
Epoch 4500, Loss: -1.9388360977172852, Losses: L1: -3.837498664855957, L2: 2.314553737640381, L3: 0.0673213005065918, L4: 0.3380678594112396, L5: 0.0631786361336708
Epoch 5000, Loss: -1.9894728660583496, Losses: L1: -3.8692638874053955, L2: 2.3299028873443604, L3: 0.06494295597076416, L4: 0.3254725933074951, L5: 0.0628456175327301
Epoch 5500, Loss: -2.0543036460876465, Losses: L1: -3.92792010307312, L2: 2.397399663925171, L3: 0.05998528003692627, L4: 0.3071632385253906, L5: 0.06119532138109207
Epoch 6000, Loss: -2.098536252975464, Losses: L1: -3.9619898796081543, L2: 2.432299852371216, L3: 0.056859374046325684, L4: 0.29441797733306885, L5: 0.060076046735048294
Epoch 6500, Loss: -2.128016471862793, Losses: L1: -3.981707811355591, L2: 2.4472179412841797, L3: 0.05485117435455322, L4: 0.28649958968162537, L5: 0.05931501463055611
Epoch 7000, Loss: -2.1481881141662598, Losses: L1: -3.994861602783203, L2: 2.4561781883239746, L3: 0.05312144756317139, L4: 0.28131014108657837, L5: 0.058806292712688446
Epoch 7500, Loss: -2.163135051727295, Losses: L1: -4.003055572509766, L2: 2.460428476333618, L3: 0.05170941352844238, L4: 0.27730807662010193, L5: 0.05847135931253433
Epoch 8000, Loss: -2.1732115745544434, Losses: L1: -4.0105791091918945, L2: 2.46486234664917, L3: 0.05121999979019165, L4: 0.275110125541687, L5: 0.05821206420660019
Epoch 8500, Loss: -2.1802453994750977, Losses: L1: -4.015130996704102, L2: 2.467536211013794, L3: 0.05077564716339111, L4: 0.2733581066131592, L5: 0.05802708491683006
Epoch 9000, Loss: -2.1847517490386963, Losses: L1: -4.018026828765869, L2: 2.4695003032684326, L3: 0.05053889751434326, L4: 0.27214890718460083, L5: 0.05791536718606949
Epoch 9500, Loss: -2.1877496242523193, Losses: L1: -4.019810676574707, L2: 2.4706199169158936, L3: 0.05036187171936035, L4: 0.2713226079940796, L5: 0.05784983932971954
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.001034736633301, Constraint losses: L1: 5.958431243896484, L2: 0.0, L3: 0.9975384473800659, L4: 0.9975379705429077
Epoch 500, Loss: 0.002231929451227188, Constraint losses: L1: -1.1120949983596802, L2: 0.0, L3: 0.0026712417602539062, L4: 0.0006727826548740268
Epoch 1000, Loss: 0.001328478567302227, Constraint losses: L1: -1.1183754205703735, L2: 0.0, L3: 0.0022231340408325195, L4: 0.00022371995146386325
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0049078464508057, Constraint losses: L1: 6.925508975982666, L2: 0.0, L3: 0.9989911913871765, L4: 0.9989911913871765
Epoch 500, Loss: 0.0020668567158281803, Constraint losses: L1: -1.103296160697937, L2: 0.0, L3: 0.0025842785835266113, L4: 0.0005858742515556514
Epoch 1000, Loss: 0.0012628292897716165, Constraint losses: L1: -1.1166142225265503, L2: 0.0, L3: 0.002189457416534424, L4: 0.00018998616724275053
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.73892211914062, Losses: L1: 5.619661331176758, L2: 7.818895392119884e-05, L3: 0.9971145987510681, L4: 80.6689453125, L5: 0.28278079628944397
Epoch 500, Loss: 23.61017608642578, Losses: L1: 0.662373423576355, L2: 0.5592499375343323, L3: 0.2507493495941162, L4: 11.226325035095215, L5: 0.09015274047851562
Epoch 1000, Loss: 8.528387069702148, Losses: L1: -0.11057132482528687, L2: 0.1546642929315567, L3: 0.18423259258270264, L4: 4.21771764755249, L5: 0.034075018018484116
Epoch 1500, Loss: 4.944355487823486, Losses: L1: -0.31869733333587646, L2: 0.0982721820473671, L3: 0.12749111652374268, L4: 2.557878255844116, L5: 0.03441467881202698
Epoch 2000, Loss: 2.1400294303894043, Losses: L1: -0.4036882519721985, L2: 0.14279796183109283, L3: 0.10680568218231201, L4: 1.1961957216262817, L5: 0.026524651795625687
Epoch 2500, Loss: 1.7828830480575562, Losses: L1: -0.4773675203323364, L2: 0.14620286226272583, L3: 0.10297149419784546, L4: 1.054223656654358, L5: 0.027216048911213875
Epoch 3000, Loss: 1.5604089498519897, Losses: L1: -0.5408426523208618, L2: 0.14998938143253326, L3: 0.10268354415893555, L4: 0.9721089005470276, L5: 0.030697375535964966
Epoch 3500, Loss: 1.3660038709640503, Losses: L1: -0.5855453014373779, L2: 0.16081003844738007, L3: 0.10144853591918945, L4: 0.8952441215515137, L5: 0.02993168868124485
Epoch 4000, Loss: 1.2775789499282837, Losses: L1: -0.6182929873466492, L2: 0.16952204704284668, L3: 0.10071825981140137, L4: 0.8653517365455627, L5: 0.030048303306102753
Epoch 4500, Loss: 1.2165576219558716, Losses: L1: -0.6398743987083435, L2: 0.17658405005931854, L3: 0.09981846809387207, L4: 0.8439600467681885, L5: 0.03031078353524208
Epoch 5000, Loss: 1.1835482120513916, Losses: L1: -0.6535037755966187, L2: 0.18014492094516754, L3: 0.09952354431152344, L4: 0.8331121206283569, L5: 0.030993422493338585
Epoch 5500, Loss: 1.148309350013733, Losses: L1: -0.6650680303573608, L2: 0.18387743830680847, L3: 0.09917634725570679, L4: 0.8204355239868164, L5: 0.03097943589091301
Epoch 6000, Loss: 1.128105640411377, Losses: L1: -0.6722253561019897, L2: 0.1857878863811493, L3: 0.09885042905807495, L4: 0.8134390711784363, L5: 0.031133592128753662
Epoch 6500, Loss: 1.1114404201507568, Losses: L1: -0.6782841086387634, L2: 0.18761645257472992, L3: 0.09871482849121094, L4: 0.8077367544174194, L5: 0.03108539618551731
Epoch 7000, Loss: 1.1012873649597168, Losses: L1: -0.6829373836517334, L2: 0.1888066530227661, L3: 0.0987006425857544, L4: 0.8046495914459229, L5: 0.03117191605269909
Epoch 7500, Loss: 1.0940021276474, Losses: L1: -0.6858739852905273, L2: 0.1896173059940338, L3: 0.09864366054534912, L4: 0.802280604839325, L5: 0.031184392049908638
Epoch 8000, Loss: 1.0892400741577148, Losses: L1: -0.6881945133209229, L2: 0.19025783240795135, L3: 0.09860682487487793, L4: 0.8008899092674255, L5: 0.031222404912114143
Epoch 8500, Loss: 1.0857980251312256, Losses: L1: -0.6897998452186584, L2: 0.19071811437606812, L3: 0.09859609603881836, L4: 0.7998575568199158, L5: 0.03122570365667343
Epoch 9000, Loss: 1.0835413932800293, Losses: L1: -0.6907963156700134, L2: 0.19099782407283783, L3: 0.09857606887817383, L4: 0.7991622090339661, L5: 0.03122636117041111
Epoch 9500, Loss: 1.0820660591125488, Losses: L1: -0.6914525032043457, L2: 0.191176638007164, L3: 0.09855997562408447, L4: 0.7987067699432373, L5: 0.0312366746366024
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020589828491211, Constraint losses: L1: 18.42068099975586, L2: 0.0007231104536913335, L3: 1.000723123550415, L4: 1.000722885131836
Epoch 500, Loss: 0.002236677799373865, Constraint losses: L1: -1.0993938446044922, L2: 0.0, L3: 0.0026671290397644043, L4: 0.0006689426954835653
Epoch 1000, Loss: 0.001314811292104423, Constraint losses: L1: -1.1178840398788452, L2: 0.0, L3: 0.0022161006927490234, L4: 0.00021659466437995434
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0056538581848145, Constraint losses: L1: 7.239498138427734, L2: 0.0, L3: 0.9992070198059082, L4: 0.9992072582244873
Epoch 500, Loss: 0.002766926307231188, Constraint losses: L1: -0.5233722925186157, L2: 0.0, L3: 0.0026442408561706543, L4: 0.0006460578879341483
Epoch 1000, Loss: 0.0014079243410378695, Constraint losses: L1: -1.0028513669967651, L2: 0.0, L3: 0.0022048354148864746, L4: 0.00020594033412635326
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 153.93370056152344, Losses: L1: 5.87406063079834, L2: 0.0, L3: 0.9963520765304565, L4: 73.54283142089844, L5: 0.23789626359939575
Epoch 500, Loss: 16.82356071472168, Losses: L1: 7.152839660644531, L2: 0.5654456615447998, L3: 0.18474364280700684, L4: 4.503262519836426, L5: 0.14455045759677887
Epoch 1000, Loss: 10.490119934082031, Losses: L1: 5.4296464920043945, L2: 0.9740376472473145, L3: 0.1251896619796753, L4: 2.1222033500671387, L5: 0.13322623074054718
Epoch 1500, Loss: 10.51910400390625, Losses: L1: 3.184931755065918, L2: 1.7855393886566162, L3: 0.0991869568824768, L4: 3.072892665863037, L5: 0.12301177531480789
Epoch 2000, Loss: 2.831049680709839, Losses: L1: 0.17361748218536377, L2: 0.5179156064987183, L3: 0.08301007747650146, L4: 1.1305758953094482, L5: 0.047908809036016464
Epoch 2500, Loss: 1.4761768579483032, Losses: L1: -0.11987940222024918, L2: 0.5558424592018127, L3: 0.08218330144882202, L4: 0.587444543838501, L5: 0.05107713118195534
Epoch 3000, Loss: 3.686563014984131, Losses: L1: -1.1101809740066528, L2: 0.7385359406471252, L3: 0.1760387420654297, L4: 2.123582124710083, L5: 0.04614611715078354
Epoch 3500, Loss: 2.330568790435791, Losses: L1: -1.1505863666534424, L2: 0.6512569189071655, L3: 0.16031187772750854, L4: 1.4915740489959717, L5: 0.04611135274171829
Epoch 4000, Loss: 1.847373366355896, Losses: L1: -1.2358145713806152, L2: 0.6918489336967468, L3: 0.15071207284927368, L4: 1.2852041721343994, L5: 0.04574952274560928
Epoch 4500, Loss: 1.6358330249786377, Losses: L1: -1.2900292873382568, L2: 0.7288984060287476, L3: 0.14696860313415527, L4: 1.1982593536376953, L5: 0.045705053955316544
Epoch 5000, Loss: 1.5089964866638184, Losses: L1: -1.3252984285354614, L2: 0.751661479473114, L3: 0.14410758018493652, L4: 1.147339105606079, L5: 0.045866094529628754
Epoch 5500, Loss: 1.4121885299682617, Losses: L1: -1.3515242338180542, L2: 0.7720017433166504, L3: 0.14216798543930054, L4: 1.1074607372283936, L5: 0.04585319384932518
Epoch 6000, Loss: 1.341660499572754, Losses: L1: -1.3691619634628296, L2: 0.7862851023674011, L3: 0.14069533348083496, L4: 1.0778334140777588, L5: 0.045832689851522446
Epoch 6500, Loss: 1.2886239290237427, Losses: L1: -1.381342887878418, L2: 0.7957487106323242, L3: 0.1393994688987732, L4: 1.0554068088531494, L5: 0.04578955098986626
Epoch 7000, Loss: 1.2479822635650635, Losses: L1: -1.3906357288360596, L2: 0.802214503288269, L3: 0.13844960927963257, L4: 1.0383691787719727, L5: 0.045773785561323166
Epoch 7500, Loss: 1.2178395986557007, Losses: L1: -1.3991990089416504, L2: 0.8072736859321594, L3: 0.1380864977836609, L4: 1.026439905166626, L5: 0.04573933407664299
Epoch 8000, Loss: 1.1974414587020874, Losses: L1: -1.4049263000488281, L2: 0.8104121088981628, L3: 0.13772708177566528, L4: 1.0183961391448975, L5: 0.04575291648507118
Epoch 8500, Loss: 1.1828490495681763, Losses: L1: -1.4082183837890625, L2: 0.8126646876335144, L3: 0.13746517896652222, L4: 1.0122499465942383, L5: 0.04575125128030777
Epoch 9000, Loss: 1.172682762145996, Losses: L1: -1.4106518030166626, L2: 0.8141915202140808, L3: 0.13728415966033936, L4: 1.0080418586730957, L5: 0.04575647413730621
Epoch 9500, Loss: 1.1657123565673828, Losses: L1: -1.4123051166534424, L2: 0.8152417540550232, L3: 0.13716107606887817, L4: 1.0051443576812744, L5: 0.04576367512345314
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0196495056152344, Constraint losses: L1: 18.42068099975586, L2: 0.0004095165350008756, L3: 1.000409483909607, L4: 1.000409722328186
Epoch 500, Loss: 0.00215916708111763, Constraint losses: L1: -1.0574754476547241, L2: 0.0, L3: 0.0026073455810546875, L4: 0.0006092970725148916
Epoch 1000, Loss: 0.0012534961570054293, Constraint losses: L1: -1.1181025505065918, L2: 0.0, L3: 0.002185523509979248, L4: 0.0001860752236098051
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.035226583480835, Constraint losses: L1: 18.42068099975586, L2: 0.0056017618626356125, L3: 1.0056017637252808, L4: 1.0056023597717285
Epoch 500, Loss: 0.0021944125182926655, Constraint losses: L1: -1.0981922149658203, L2: 0.0, L3: 0.002645432949066162, L4: 0.0006471718079410493
Epoch 1000, Loss: 0.001305718207731843, Constraint losses: L1: -1.1169553995132446, L2: 0.0, L3: 0.0022110342979431152, L4: 0.00021163927158340812
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 45.46491241455078, Losses: L1: 6.3055596351623535, L2: 0.0, L3: 0.9976557493209839, L4: 76.06649017333984, L5: 0.25690269470214844
Epoch 500, Loss: -2.114649772644043, Losses: L1: -4.067866325378418, L2: 1.6466875076293945, L3: 0.06683194637298584, L4: 2.0831050872802734, L5: 0.042976364493370056
Epoch 1000, Loss: -0.008381027728319168, Losses: L1: -2.4238717555999756, L2: 1.3524798154830933, L3: 0.12340366840362549, L4: 3.165412664413452, L5: 0.0662815198302269
Epoch 1500, Loss: -1.5461901426315308, Losses: L1: -3.1977193355560303, L2: 1.6180074214935303, L3: 0.06321585178375244, L4: 1.5017422437667847, L5: 0.056877389550209045
Epoch 2000, Loss: -2.38051700592041, Losses: L1: -3.5329127311706543, L2: 1.5743231773376465, L3: 0.05980408191680908, L4: 0.5748386383056641, L5: 0.03602105379104614
Epoch 2500, Loss: -2.6225779056549072, Losses: L1: -3.7641024589538574, L2: 1.6362849473953247, L3: 0.056168973445892334, L4: 0.507457435131073, L5: 0.02696872502565384
Epoch 3000, Loss: -2.814397096633911, Losses: L1: -3.982314348220825, L2: 1.6757222414016724, L3: 0.056980252265930176, L4: 0.5211789608001709, L5: 0.02497253380715847
Epoch 3500, Loss: -3.0414059162139893, Losses: L1: -4.081266403198242, L2: 1.657778263092041, L3: 0.016658663749694824, L4: 0.3650429844856262, L5: 0.02358255162835121
Epoch 4000, Loss: -3.1704158782958984, Losses: L1: -4.164921760559082, L2: 1.6396245956420898, L3: 0.0025217533111572266, L4: 0.32105201482772827, L5: 0.023291639983654022
Epoch 4500, Loss: -3.2221641540527344, Losses: L1: -4.1923828125, L2: 1.6163052320480347, L3: 0.0016291141510009766, L4: 0.29772061109542847, L5: 0.023153457790613174
Epoch 5000, Loss: -3.249358654022217, Losses: L1: -4.212589263916016, L2: 1.6115559339523315, L3: 0.002146005630493164, L4: 0.2875315248966217, L5: 0.02308165468275547
Epoch 5500, Loss: -3.268869161605835, Losses: L1: -4.225894927978516, L2: 1.6119463443756104, L3: 0.00019073486328125, L4: 0.2786392569541931, L5: 0.02308480814099312
Epoch 6000, Loss: -3.279585361480713, Losses: L1: -4.231674671173096, L2: 1.606378436088562, L3: 0.00037157535552978516, L4: 0.27397245168685913, L5: 0.02308444306254387
Epoch 6500, Loss: -3.2874865531921387, Losses: L1: -4.2361063957214355, L2: 1.603924036026001, L3: 3.17692756652832e-05, L4: 0.27016904950141907, L5: 0.023083427920937538
Epoch 7000, Loss: -3.2922372817993164, Losses: L1: -4.239333629608154, L2: 1.6030747890472412, L3: 0.0003479123115539551, L4: 0.26735296845436096, L5: 0.023068688809871674
Epoch 7500, Loss: -3.2955827713012695, Losses: L1: -4.240325450897217, L2: 1.600093960762024, L3: 0.00039899349212646484, L4: 0.2655317187309265, L5: 0.023061810061335564
Epoch 8000, Loss: -3.2979071140289307, Losses: L1: -4.241878032684326, L2: 1.6004127264022827, L3: 4.00543212890625e-05, L4: 0.2644018828868866, L5: 0.02304701879620552
Epoch 8500, Loss: -3.299060344696045, Losses: L1: -4.242658615112305, L2: 1.6002415418624878, L3: 1.5020370483398438e-05, L4: 0.263886034488678, L5: 0.02303886041045189
Epoch 9000, Loss: -3.2999157905578613, Losses: L1: -4.243117332458496, L2: 1.6000243425369263, L3: 4.011392593383789e-05, L4: 0.26326417922973633, L5: 0.023034635931253433
Epoch 9500, Loss: -3.3004636764526367, Losses: L1: -4.243332386016846, L2: 1.5997421741485596, L3: 1.9073486328125e-06, L4: 0.2629610598087311, L5: 0.023030780255794525
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0051276683807373, Constraint losses: L1: 7.020658493041992, L2: 0.0, L3: 0.999053418636322, L4: 0.9990535974502563
Epoch 500, Loss: 0.0024108076468110085, Constraint losses: L1: -1.1098476648330688, L2: 0.0, L3: 0.0027594566345214844, L4: 0.0007611985784024
Epoch 1000, Loss: 0.0013860852923244238, Constraint losses: L1: -1.118296504020691, L2: 0.0, L3: 0.002251863479614258, L4: 0.00025251839542761445
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0214500427246094, Constraint losses: L1: 18.412118911743164, L2: 0.0011225452180951834, L3: 1.0009572505950928, L4: 1.0009580850601196
Epoch 500, Loss: 0.0022321094293147326, Constraint losses: L1: -1.018328070640564, L2: 0.0, L3: 0.0026240944862365723, L4: 0.0006263431278057396
Epoch 1000, Loss: 0.0012583800125867128, Constraint losses: L1: -1.1154711246490479, L2: 0.0, L3: 0.0021866559982299805, L4: 0.00018719516810961068
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.0495491027832, Losses: L1: 10.534438133239746, L2: 6.658191705355421e-05, L3: 0.9995946288108826, L4: 74.53020477294922, L5: 0.2503824830055237
Epoch 500, Loss: -0.9545409083366394, Losses: L1: -2.3999993801116943, L2: 0.9208062291145325, L3: 0.07084649801254272, L4: 1.7580174207687378, L5: 0.03520026057958603
Epoch 1000, Loss: -2.529102325439453, Losses: L1: -3.866436719894409, L2: 1.7384839057922363, L3: 0.04212236404418945, L4: 0.7946357727050781, L5: 0.02865220047533512
Epoch 1500, Loss: -2.845033884048462, Losses: L1: -4.290462970733643, L2: 1.8260577917099, L3: 0.0022859573364257812, L4: 1.0179593563079834, L5: 0.021134670823812485
Epoch 2000, Loss: -3.0469799041748047, Losses: L1: -4.245092868804932, L2: 1.8248796463012695, L3: 0.0671195387840271, L4: 0.39647817611694336, L5: 0.02031456120312214
Epoch 2500, Loss: -3.2698960304260254, Losses: L1: -4.3483147621154785, L2: 1.8020622730255127, L3: 0.025163233280181885, L4: 0.26416364312171936, L5: 0.020142879337072372
Epoch 3000, Loss: -3.3341634273529053, Losses: L1: -4.381463050842285, L2: 1.7303413152694702, L3: 0.02608513832092285, L4: 0.2721007168292999, L5: 0.019993193447589874
Epoch 3500, Loss: -3.4295854568481445, Losses: L1: -4.417792320251465, L2: 1.6875509023666382, L3: 0.008707046508789062, L4: 0.23331218957901, L5: 0.019068146124482155
Epoch 4000, Loss: -3.478569984436035, Losses: L1: -4.4263224601745605, L2: 1.6420550346374512, L3: 0.0012070536613464355, L4: 0.21294498443603516, L5: 0.019045427441596985
Epoch 4500, Loss: -3.5023741722106934, Losses: L1: -4.434405326843262, L2: 1.6191712617874146, L3: 0.0013066530227661133, L4: 0.2042514681816101, L5: 0.019013306125998497
Epoch 5000, Loss: -3.5139811038970947, Losses: L1: -4.441566467285156, L2: 1.609920620918274, L3: 0.003505229949951172, L4: 0.19997048377990723, L5: 0.01913485676050186
Epoch 5500, Loss: -3.530308961868286, Losses: L1: -4.449052333831787, L2: 1.6075794696807861, L3: 0.0006513595581054688, L4: 0.19021475315093994, L5: 0.01919509842991829
Epoch 6000, Loss: -3.5393197536468506, Losses: L1: -4.452464580535889, L2: 1.603033423423767, L3: 0.0005238056182861328, L4: 0.183763325214386, L5: 0.019222399219870567
Epoch 6500, Loss: -3.5447731018066406, Losses: L1: -4.456700325012207, L2: 1.6039695739746094, L3: 0.00045692920684814453, L4: 0.18043266236782074, L5: 0.019269203767180443
Epoch 7000, Loss: -3.5488667488098145, Losses: L1: -4.458426475524902, L2: 1.6017916202545166, L3: 0.00014460086822509766, L4: 0.17848892509937286, L5: 0.01927522011101246
Epoch 7500, Loss: -3.551435947418213, Losses: L1: -4.459836959838867, L2: 1.6012455224990845, L3: 0.00012367963790893555, L4: 0.17674259841442108, L5: 0.019283369183540344
Epoch 8000, Loss: -3.5530405044555664, Losses: L1: -4.460444927215576, L2: 1.6003131866455078, L3: 0.0002695918083190918, L4: 0.1753469705581665, L5: 0.019304659217596054
Epoch 8500, Loss: -3.5543384552001953, Losses: L1: -4.459924221038818, L2: 1.597625494003296, L3: 0.00011050701141357422, L4: 0.17470122873783112, L5: 0.019311673939228058
Epoch 9000, Loss: -3.555119276046753, Losses: L1: -4.459917068481445, L2: 1.5965696573257446, L3: 8.428096771240234e-05, L4: 0.17421942949295044, L5: 0.01931897923350334
Epoch 9500, Loss: -3.5556576251983643, Losses: L1: -4.460172176361084, L2: 1.596423625946045, L3: 4.267692565917969e-05, L4: 0.17388209700584412, L5: 0.019319171085953712
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.027383804321289, Constraint losses: L1: 18.42068099975586, L2: 0.002987426472827792, L3: 1.0029873847961426, L4: 1.002988338470459
Epoch 500, Loss: 0.002581593580543995, Constraint losses: L1: -1.114713191986084, L2: 0.0, L3: 0.0028472542762756348, L4: 0.0008490526815876365
Epoch 1000, Loss: 0.0014479646924883127, Constraint losses: L1: -1.1185188293457031, L2: 0.0, L3: 0.0022829771041870117, L4: 0.0002835064078681171
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.035102128982544, Constraint losses: L1: 18.42068099975586, L2: 0.005559938028454781, L3: 1.0055599212646484, L4: 1.0055615901947021
Epoch 500, Loss: 0.002157096052542329, Constraint losses: L1: -1.0605629682540894, L2: 0.0, L3: 0.002607882022857666, L4: 0.000609777111094445
Epoch 1000, Loss: 0.0012615579180419445, Constraint losses: L1: -1.116758108139038, L2: 0.0, L3: 0.00218886137008667, L4: 0.0001894547458505258
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.46092987060547, Losses: L1: 6.697268009185791, L2: 9.39353703870438e-05, L3: 0.9988930821418762, L4: 88.22734832763672, L5: 0.3255229890346527
Epoch 500, Loss: -2.736274480819702, Losses: L1: -4.263551235198975, L2: 1.5358670949935913, L3: 0.0816340446472168, L4: 1.2684533596038818, L5: 0.0217412319034338
Epoch 1000, Loss: -2.7905566692352295, Losses: L1: -4.38279914855957, L2: 1.1895099878311157, L3: 0.008556127548217773, L4: 1.894530177116394, L5: 0.020833110436797142
Epoch 1500, Loss: -3.585373640060425, Losses: L1: -4.539913177490234, L2: 1.2967948913574219, L3: 0.004528701305389404, L4: 0.5519048571586609, L5: 0.012830454856157303
Epoch 2000, Loss: -3.740234136581421, Losses: L1: -4.565553188323975, L2: 1.2404158115386963, L3: 0.01665210723876953, L4: 0.32837069034576416, L5: 0.01213688775897026
Epoch 2500, Loss: -3.596705675125122, Losses: L1: -4.551595687866211, L2: 1.2489467859268188, L3: 0.003175020217895508, L4: 0.6064701080322266, L5: 0.012003318406641483
Epoch 3000, Loss: -3.863511085510254, Losses: L1: -4.52265739440918, L2: 1.1085808277130127, L3: 0.0006189346313476562, L4: 0.16576582193374634, L5: 0.010677080601453781
Epoch 3500, Loss: -3.8733468055725098, Losses: L1: -4.520853519439697, L2: 1.100121259689331, L3: 7.003545761108398e-05, L4: 0.15318123996257782, L5: 0.010392625816166401
Epoch 4000, Loss: -3.883584976196289, Losses: L1: -4.526556968688965, L2: 1.101567268371582, L3: 0.0011962652206420898, L4: 0.14104315638542175, L5: 0.010235208086669445
Epoch 4500, Loss: -3.889770269393921, Losses: L1: -4.539275646209717, L2: 1.1250030994415283, L3: 0.0021538734436035156, L4: 0.12861394882202148, L5: 0.010271534323692322
Epoch 5000, Loss: -3.896669626235962, Losses: L1: -4.532913684844971, L2: 1.1089837551116943, L3: 0.0010100603103637695, L4: 0.12069791555404663, L5: 0.01019657775759697
Epoch 5500, Loss: -3.8984127044677734, Losses: L1: -4.535184860229492, L2: 1.1109284162521362, L3: 0.0005298852920532227, L4: 0.12084171921014786, L5: 0.010178698226809502
Epoch 6000, Loss: -3.9022369384765625, Losses: L1: -4.536990642547607, L2: 1.1131261587142944, L3: 0.0005812644958496094, L4: 0.11435802280902863, L5: 0.010215104557573795
Epoch 6500, Loss: -3.9031922817230225, Losses: L1: -4.537688255310059, L2: 1.1137399673461914, L3: 0.0005593299865722656, L4: 0.11334866285324097, L5: 0.010196193121373653
Epoch 7000, Loss: -3.9043030738830566, Losses: L1: -4.537683486938477, L2: 1.1132712364196777, L3: 6.508827209472656e-05, L4: 0.11260150372982025, L5: 0.01018952950835228
Epoch 7500, Loss: -3.9047884941101074, Losses: L1: -4.5384135246276855, L2: 1.1142363548278809, L3: 1.4781951904296875e-05, L4: 0.11221230775117874, L5: 0.010193009860813618
Epoch 8000, Loss: -3.905130386352539, Losses: L1: -4.538628101348877, L2: 1.114297866821289, L3: 2.6226043701171875e-06, L4: 0.11192938685417175, L5: 0.01019068993628025
Epoch 8500, Loss: -3.905217170715332, Losses: L1: -4.538431167602539, L2: 1.1137564182281494, L3: 6.300210952758789e-05, L4: 0.11177495867013931, L5: 0.010192742571234703
Epoch 9000, Loss: -3.9054763317108154, Losses: L1: -4.538900375366211, L2: 1.1144664287567139, L3: 5.841255187988281e-06, L4: 0.1116105169057846, L5: 0.010189833119511604
Epoch 9500, Loss: -3.9055943489074707, Losses: L1: -4.538971900939941, L2: 1.1144707202911377, L3: 6.198883056640625e-06, L4: 0.11150643229484558, L5: 0.010191432200372219
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0021376609802246, Constraint losses: L1: 6.151669025421143, L2: 0.0, L3: 0.9979931116104126, L4: 0.9979928731918335
Epoch 500, Loss: 0.0025586835108697414, Constraint losses: L1: -1.111216425895691, L2: 0.0, L3: 0.0028339624404907227, L4: 0.0008359376224689186
Epoch 1000, Loss: 0.001436303835362196, Constraint losses: L1: -1.1186819076538086, L2: 0.0, L3: 0.002277076244354248, L4: 0.00027790956664830446
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001758098602295, Constraint losses: L1: 6.088954448699951, L2: 0.0, L3: 0.9978348612785339, L4: 0.9978344440460205
Epoch 500, Loss: 0.0021345471031963825, Constraint losses: L1: -1.1023824214935303, L2: 0.0, L3: 0.00261765718460083, L4: 0.000619272468611598
Epoch 1000, Loss: 0.0012852916261181235, Constraint losses: L1: -1.117038607597351, L2: 0.0, L3: 0.002200901508331299, L4: 0.00020142874564044178
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 102.81358337402344, Losses: L1: 18.42068099975586, L2: 0.004642431158572435, L3: 1.0044736862182617, L4: 83.23921966552734, L5: 0.2937793433666229
Epoch 500, Loss: 0.5486404895782471, Losses: L1: -2.587526559829712, L2: 1.121381163597107, L3: 0.08092570304870605, L4: 2.470949172973633, L5: 0.04720311984419823
Epoch 1000, Loss: 0.317779541015625, Losses: L1: -3.376659631729126, L2: 1.753065586090088, L3: 0.0764959454536438, L4: 2.716855049133301, L5: 0.04911089316010475
Epoch 1500, Loss: -1.4673843383789062, Losses: L1: -3.76430344581604, L2: 2.007185697555542, L3: 0.013441801071166992, L4: 1.261228084564209, L5: 0.037313029170036316
Epoch 2000, Loss: -2.4259424209594727, Losses: L1: -3.9006388187408447, L2: 1.8977528810501099, L3: 0.006848454475402832, L4: 0.5002083778381348, L5: 0.037526316940784454
Epoch 2500, Loss: -2.780918598175049, Losses: L1: -4.020586967468262, L2: 1.8848390579223633, L3: 0.0014547109603881836, L4: 0.27671629190444946, L5: 0.038155447691679
Epoch 3000, Loss: -2.909395456314087, Losses: L1: -4.13911771774292, L2: 1.9530354738235474, L3: 0.0012259483337402344, L4: 0.23304609954357147, L5: 0.03786538541316986
Epoch 3500, Loss: -3.0080552101135254, Losses: L1: -4.281404495239258, L2: 2.0600147247314453, L3: 0.0023474693298339844, L4: 0.22194185853004456, L5: 0.03810485824942589
Epoch 4000, Loss: -3.0973093509674072, Losses: L1: -4.335833549499512, L2: 2.019011974334717, L3: 4.929304122924805e-05, L4: 0.20992030203342438, L5: 0.03809700161218643
Epoch 4500, Loss: -3.14328932762146, Losses: L1: -4.362671375274658, L2: 1.97606360912323, L3: 0.0030727386474609375, L4: 0.20888151228427887, L5: 0.03879166394472122
Epoch 5000, Loss: -3.1808011531829834, Losses: L1: -4.377387523651123, L2: 1.9245389699935913, L3: 0.0011528730392456055, L4: 0.21331164240837097, L5: 0.039704859256744385
Epoch 5500, Loss: -3.206015110015869, Losses: L1: -4.399693489074707, L2: 1.9273706674575806, L3: 0.0007410049438476562, L4: 0.20915067195892334, L5: 0.04020318016409874
Epoch 6000, Loss: -3.222897529602051, Losses: L1: -4.405019760131836, L2: 1.913673758506775, L3: 0.00043010711669921875, L4: 0.20461004972457886, L5: 0.04049009457230568
Epoch 6500, Loss: -3.23435115814209, Losses: L1: -4.412494659423828, L2: 1.9137636423110962, L3: 0.00020867586135864258, L4: 0.20067912340164185, L5: 0.040748272091150284
Epoch 7000, Loss: -3.242227077484131, Losses: L1: -4.419494152069092, L2: 1.9187581539154053, L3: 6.985664367675781e-05, L4: 0.19738788902759552, L5: 0.04085996374487877
Epoch 7500, Loss: -3.2470862865448, Losses: L1: -4.419836044311523, L2: 1.91313898563385, L3: 8.082389831542969e-05, L4: 0.1955951303243637, L5: 0.04100886732339859
Epoch 8000, Loss: -3.249812364578247, Losses: L1: -4.41977071762085, L2: 1.90914785861969, L3: 7.49826431274414e-05, L4: 0.19477441906929016, L5: 0.041069962084293365
Epoch 8500, Loss: -3.251852035522461, Losses: L1: -4.421153545379639, L2: 1.9093003273010254, L3: 6.002187728881836e-05, L4: 0.19402962923049927, L5: 0.04112321883440018
Epoch 9000, Loss: -3.2530508041381836, Losses: L1: -4.422119617462158, L2: 1.9094337224960327, L3: 2.849102020263672e-05, L4: 0.19375038146972656, L5: 0.04114605858922005
Epoch 9500, Loss: -3.2537472248077393, Losses: L1: -4.422702789306641, L2: 1.9099358320236206, L3: 1.5079975128173828e-05, L4: 0.19339905679225922, L5: 0.04114731401205063
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.010009288787842, Constraint losses: L1: 10.177428245544434, L2: 0.00010540768562350422, L3: 0.9998632073402405, L4: 0.9998631477355957
Epoch 500, Loss: 0.0019921292550861835, Constraint losses: L1: -1.1069226264953613, L2: 0.0, L3: 0.0025487542152404785, L4: 0.0005502976127900183
Epoch 1000, Loss: 0.0012344345450401306, Constraint losses: L1: -1.117173433303833, L2: 0.0, L3: 0.0021755099296569824, L4: 0.00017609813949093223
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0087203979492188, Constraint losses: L1: 8.913605690002441, L2: 0.0, L3: 0.9999035000801086, L4: 0.9999033212661743
Epoch 500, Loss: 0.0021804356947541237, Constraint losses: L1: -1.048160195350647, L2: 0.0, L3: 0.0026134252548217773, L4: 0.0006151708075776696
Epoch 1000, Loss: 0.0012597821187227964, Constraint losses: L1: -1.1151273250579834, L2: 0.0, L3: 0.002187192440032959, L4: 0.0001877169997896999
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 79.72490692138672, Losses: L1: 6.044284343719482, L2: 3.736513826879673e-05, L3: 0.9978771805763245, L4: 72.44070434570312, L5: 0.2420220822095871
Epoch 500, Loss: 2.8866770267486572, Losses: L1: -3.4879586696624756, L2: 1.585329294204712, L3: 0.0733451247215271, L4: 5.4091572761535645, L5: 0.09946853667497635
Epoch 1000, Loss: -1.9899208545684814, Losses: L1: -4.285114288330078, L2: 2.0422074794769287, L3: 0.05218338966369629, L4: 1.16845703125, L5: 0.0534491203725338
Epoch 1500, Loss: 1.0526760816574097, Losses: L1: -0.21805518865585327, L2: 0.43171605467796326, L3: 0.07119792699813843, L4: 0.9541321396827698, L5: 0.029543133452534676
Epoch 2000, Loss: -2.240016222000122, Losses: L1: -4.1138153076171875, L2: 1.6403249502182007, L3: 0.0033864974975585938, L4: 1.0079827308654785, L5: 0.042267266660928726
Epoch 2500, Loss: -3.0290069580078125, Losses: L1: -4.2216291427612305, L2: 1.5806630849838257, L3: 0.02636086940765381, L4: 0.3313721716403961, L5: 0.04455748572945595
Epoch 3000, Loss: -3.0278658866882324, Losses: L1: -4.279447078704834, L2: 1.6095057725906372, L3: 0.025396764278411865, L4: 0.3783135414123535, L5: 0.0431179478764534
Epoch 3500, Loss: -3.20930814743042, Losses: L1: -4.327183723449707, L2: 1.5899982452392578, L3: 0.00606989860534668, L4: 0.27461254596710205, L5: 0.042193904519081116
Epoch 4000, Loss: -3.2642898559570312, Losses: L1: -4.345457077026367, L2: 1.5978004932403564, L3: 0.011182785034179688, L4: 0.2307448536157608, L5: 0.040339402854442596
Epoch 4500, Loss: -3.346695899963379, Losses: L1: -4.367796421051025, L2: 1.5920144319534302, L3: 0.001553177833557129, L4: 0.18316060304641724, L5: 0.040379781275987625
Epoch 5000, Loss: -3.3668386936187744, Losses: L1: -4.3872575759887695, L2: 1.6035977602005005, L3: 0.00018072128295898438, L4: 0.178127259016037, L5: 0.040311940014362335
Epoch 5500, Loss: -3.3810057640075684, Losses: L1: -4.389294147491455, L2: 1.5843621492385864, L3: 0.001804351806640625, L4: 0.17438197135925293, L5: 0.03992116451263428
Epoch 6000, Loss: -3.391653537750244, Losses: L1: -4.391872406005859, L2: 1.5708116292953491, L3: 0.001719057559967041, L4: 0.17343822121620178, L5: 0.0396556556224823
Epoch 6500, Loss: -3.3984367847442627, Losses: L1: -4.394387722015381, L2: 1.560088038444519, L3: 0.003861665725708008, L4: 0.1725514829158783, L5: 0.039493754506111145
Epoch 7000, Loss: -3.4062068462371826, Losses: L1: -4.395191669464111, L2: 1.5533928871154785, L3: 0.0008211135864257812, L4: 0.17205575108528137, L5: 0.03941158205270767
Epoch 7500, Loss: -3.4088478088378906, Losses: L1: -4.396320343017578, L2: 1.5510696172714233, L3: 0.0008904933929443359, L4: 0.17171327769756317, L5: 0.03933391720056534
Epoch 8000, Loss: -3.4115264415740967, Losses: L1: -4.396853923797607, L2: 1.5483150482177734, L3: 0.00034946203231811523, L4: 0.17153020203113556, L5: 0.039290253072977066
Epoch 8500, Loss: -3.412360429763794, Losses: L1: -4.397158145904541, L2: 1.5463634729385376, L3: 0.0009802579879760742, L4: 0.17138037085533142, L5: 0.03925560042262077
Epoch 9000, Loss: -3.413578510284424, Losses: L1: -4.397395133972168, L2: 1.5461392402648926, L3: 0.00021529197692871094, L4: 0.17129650712013245, L5: 0.039235107600688934
Epoch 9500, Loss: -3.4141106605529785, Losses: L1: -4.397515296936035, L2: 1.545823097229004, L3: 1.7523765563964844e-05, L4: 0.17124995589256287, L5: 0.03922564163804054
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.049039602279663, Constraint losses: L1: 18.42068099975586, L2: 0.010205713100731373, L3: 1.0102057456970215, L4: 1.0102074146270752
Epoch 500, Loss: 0.0021109278313815594, Constraint losses: L1: -1.1015154123306274, L2: 0.0, L3: 0.002605438232421875, L4: 0.0006070052040740848
Epoch 1000, Loss: 0.0012686923146247864, Constraint losses: L1: -1.118224024772644, L2: 0.0, L3: 0.0021932125091552734, L4: 0.00019370391964912415
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.021042823791504, Constraint losses: L1: 18.42068099975586, L2: 0.0008739777258597314, L3: 1.0008739233016968, L4: 1.0008742809295654
Epoch 500, Loss: 0.002683234168216586, Constraint losses: L1: -1.1018646955490112, L2: 0.0, L3: 0.0028914809226989746, L4: 0.0008936179801821709
Epoch 1000, Loss: 0.0014715029392391443, Constraint losses: L1: -1.11660897731781, L2: 0.0, L3: 0.002293705940246582, L4: 0.000294406054308638
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 79.65968322753906, Losses: L1: 6.441190719604492, L2: 1.7880473023978993e-05, L3: 0.9987255334854126, L4: 71.74394989013672, L5: 0.23790204524993896
Epoch 500, Loss: 16.233102798461914, Losses: L1: 6.606823444366455, L2: 1.0773216485977173, L3: 0.16296017169952393, L4: 8.736865043640137, L5: 0.09389697015285492
Epoch 1000, Loss: 3.830059289932251, Losses: L1: 1.2243157625198364, L2: 0.1975327581167221, L3: 0.08125698566436768, L4: 2.2945706844329834, L5: 0.06557480245828629
Epoch 1500, Loss: 1.2501875162124634, Losses: L1: -2.4828665256500244, L2: 1.1764929294586182, L3: 0.11140882968902588, L4: 2.933485984802246, L5: 0.04995638132095337
Epoch 2000, Loss: -0.4463706910610199, Losses: L1: -3.1201982498168945, L2: 1.6185027360916138, L3: 0.09260332584381104, L4: 1.668241262435913, L5: 0.05186589062213898
Epoch 2500, Loss: -0.708741307258606, Losses: L1: -3.341233730316162, L2: 1.7711695432662964, L3: 0.09169214963912964, L4: 1.5736310482025146, L5: 0.040792156010866165
Epoch 3000, Loss: -1.6631885766983032, Losses: L1: -3.501783847808838, L2: 1.8476579189300537, L3: 0.08855926990509033, L4: 0.7359911203384399, L5: 0.045107945799827576
Epoch 3500, Loss: -1.8373149633407593, Losses: L1: -3.6332101821899414, L2: 1.923163652420044, L3: 0.09232038259506226, L4: 0.6485652923583984, L5: 0.046713896095752716
Epoch 4000, Loss: -1.964705228805542, Losses: L1: -3.6964001655578613, L2: 1.9686424732208252, L3: 0.09166455268859863, L4: 0.5642102360725403, L5: 0.045749515295028687
Epoch 4500, Loss: -2.026639223098755, Losses: L1: -3.723670482635498, L2: 1.9867758750915527, L3: 0.0904659628868103, L4: 0.5234133005142212, L5: 0.04488198459148407
Epoch 5000, Loss: -2.059450387954712, Losses: L1: -3.7394919395446777, L2: 1.998407006263733, L3: 0.08943736553192139, L4: 0.5025711059570312, L5: 0.04441482201218605
Epoch 5500, Loss: -2.0775198936462402, Losses: L1: -3.7489843368530273, L2: 2.002469778060913, L3: 0.08832699060440063, L4: 0.4935373365879059, L5: 0.04418259859085083
Epoch 6000, Loss: -2.098698377609253, Losses: L1: -3.7548983097076416, L2: 2.0048201084136963, L3: 0.08768689632415771, L4: 0.4786141514778137, L5: 0.04374433308839798
Epoch 6500, Loss: -2.1122965812683105, Losses: L1: -3.760089635848999, L2: 2.0061395168304443, L3: 0.08711004257202148, L4: 0.4702923893928528, L5: 0.04366052895784378
Epoch 7000, Loss: -2.12127685546875, Losses: L1: -3.7621827125549316, L2: 2.0056705474853516, L3: 0.08666092157363892, L4: 0.4642963111400604, L5: 0.04355672374367714
Epoch 7500, Loss: -2.127739429473877, Losses: L1: -3.763850688934326, L2: 2.0050241947174072, L3: 0.08632755279541016, L4: 0.46023109555244446, L5: 0.04352034628391266
Epoch 8000, Loss: -2.132556676864624, Losses: L1: -3.765371322631836, L2: 2.0050461292266846, L3: 0.08616483211517334, L4: 0.45719778537750244, L5: 0.04346449300646782
Epoch 8500, Loss: -2.1358726024627686, Losses: L1: -3.7665328979492188, L2: 2.005183458328247, L3: 0.08604449033737183, L4: 0.4551473557949066, L5: 0.0434383898973465
Epoch 9000, Loss: -2.138129949569702, Losses: L1: -3.767184257507324, L2: 2.005236864089966, L3: 0.08596068620681763, L4: 0.45363765954971313, L5: 0.04341883584856987
Epoch 9500, Loss: -2.1396772861480713, Losses: L1: -3.7675085067749023, L2: 2.005115270614624, L3: 0.08589953184127808, L4: 0.4525749087333679, L5: 0.04339947924017906
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0077457427978516, Constraint losses: L1: 8.351462364196777, L2: 0.00020615116227418184, L3: 0.9995940923690796, L4: 0.9995941519737244
Epoch 500, Loss: 0.0022125565446913242, Constraint losses: L1: -1.0925313234329224, L2: 0.0, L3: 0.0026516318321228027, L4: 0.0006534559652209282
Epoch 1000, Loss: 0.001302788034081459, Constraint losses: L1: -1.1185139417648315, L2: 0.0, L3: 0.0022103190422058105, L4: 0.00021098295110277832
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.007596731185913, Constraint losses: L1: 8.183792114257812, L2: 0.0, L3: 0.9997064471244812, L4: 0.999706506729126
Epoch 500, Loss: 0.002294675912708044, Constraint losses: L1: -1.1109427213668823, L2: 0.0, L3: 0.0027019381523132324, L4: 0.0007036806782707572
Epoch 1000, Loss: 0.0013475700980052352, Constraint losses: L1: -1.1163545846939087, L2: 0.0, L3: 0.002231597900390625, L4: 0.00023232681269291788
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.14352416992188, Losses: L1: 10.965730667114258, L2: 0.0007088937563821673, L3: 0.9986593127250671, L4: 77.52386474609375, L5: 0.2620968222618103
Epoch 500, Loss: 107.88015747070312, Losses: L1: 5.470625400543213, L2: 1.1542487072802032e-06, L3: 0.96070796251297, L4: 50.64249038696289, L5: 0.3276899755001068
Epoch 1000, Loss: 3.0391831398010254, Losses: L1: -1.694113850593567, L2: 2.512799024581909, L3: 0.10917222499847412, L4: 1.6607799530029297, L5: 0.0923311710357666
Epoch 1500, Loss: 102.05099487304688, Losses: L1: 0.8768933415412903, L2: 0.03529162332415581, L3: 0.9981984496116638, L4: 49.99726104736328, L5: 0.32747143507003784
Epoch 2000, Loss: 98.34541320800781, Losses: L1: -3.4371395111083984, L2: 0.9935255646705627, L3: 0.9125604629516602, L4: 50.10881805419922, L5: 0.3111937344074249
Epoch 2500, Loss: 97.72303771972656, Losses: L1: -3.8349971771240234, L2: 0.9351817965507507, L3: 0.5981143116950989, L4: 50.16957092285156, L5: 0.30638042092323303
Epoch 3000, Loss: 96.80029296875, Losses: L1: -3.977937698364258, L2: 0.5145007967948914, L3: 0.008293867111206055, L4: 50.18023681640625, L5: 0.30442675948143005
Epoch 3500, Loss: 96.67086791992188, Losses: L1: -4.0054216384887695, L2: 0.48205575346946716, L3: 0.005667924880981445, L4: 50.13807678222656, L5: 0.3068895936012268
Epoch 4000, Loss: 96.6014633178711, Losses: L1: -4.0313849449157715, L2: 0.488833487033844, L3: 0.004090309143066406, L4: 50.115196228027344, L5: 0.30789080262184143
Epoch 4500, Loss: 96.5645980834961, Losses: L1: -4.045091152191162, L2: 0.48016059398651123, L3: 0.001195669174194336, L4: 50.10712432861328, L5: 0.3083324432373047
Epoch 5000, Loss: 96.55242919921875, Losses: L1: -4.0523600578308105, L2: 0.4768948256969452, L3: 0.004797697067260742, L4: 50.1036376953125, L5: 0.3085351586341858
Epoch 5500, Loss: 96.54570007324219, Losses: L1: -4.058166027069092, L2: 0.47809037566185, L3: 0.005486965179443359, L4: 50.10251998901367, L5: 0.3085895776748657
Epoch 6000, Loss: 96.53905487060547, Losses: L1: -4.06110954284668, L2: 0.4817522466182709, L3: 0.000792384147644043, L4: 50.10210037231445, L5: 0.3085867464542389
Epoch 6500, Loss: 96.53655242919922, Losses: L1: -4.064061641693115, L2: 0.4833697974681854, L3: 0.0006083250045776367, L4: 50.10201644897461, L5: 0.3085806965827942
Epoch 7000, Loss: 96.53466033935547, Losses: L1: -4.064944267272949, L2: 0.4830162823200226, L3: 0.00019109249114990234, L4: 50.101806640625, L5: 0.30857977271080017
Epoch 7500, Loss: 96.53369140625, Losses: L1: -4.0651655197143555, L2: 0.48238906264305115, L3: 7.015466690063477e-05, L4: 50.10165023803711, L5: 0.3085821568965912
Epoch 8000, Loss: 96.53319549560547, Losses: L1: -4.065315246582031, L2: 0.48202162981033325, L3: 0.00014829635620117188, L4: 50.101531982421875, L5: 0.30858558416366577
Epoch 8500, Loss: 96.53298950195312, Losses: L1: -4.065301418304443, L2: 0.48166531324386597, L3: 0.00027108192443847656, L4: 50.101444244384766, L5: 0.30858877301216125
Epoch 9000, Loss: 96.53284454345703, Losses: L1: -4.065281391143799, L2: 0.48145565390586853, L3: 0.0003342628479003906, L4: 50.101383209228516, L5: 0.3085908591747284
Epoch 9500, Loss: 96.53255462646484, Losses: L1: -4.0649895668029785, L2: 0.4811113178730011, L3: 3.7550926208496094e-05, L4: 50.10132598876953, L5: 0.3085917830467224
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0230021476745605, Constraint losses: L1: 18.42068099975586, L2: 0.00152705202344805, L3: 1.0015270709991455, L4: 1.0015273094177246
Epoch 500, Loss: 0.002261943882331252, Constraint losses: L1: -1.1142349243164062, L2: 0.0, L3: 0.0026872754096984863, L4: 0.0006889035576023161
Epoch 1000, Loss: 0.0013385469792410731, Constraint losses: L1: -1.1167807579040527, L2: 0.0, L3: 0.002227306365966797, L4: 0.00022802136663813144
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.024468183517456, Constraint losses: L1: 18.42068099975586, L2: 0.0020156833343207836, L3: 1.0020157098770142, L4: 1.0020160675048828
Epoch 500, Loss: 0.002259149681776762, Constraint losses: L1: -1.1036697626113892, L2: 0.0, L3: 0.002680540084838867, L4: 0.0006822793511673808
Epoch 1000, Loss: 0.0013309387722983956, Constraint losses: L1: -1.1155837774276733, L2: 0.0, L3: 0.0022229552268981934, L4: 0.0002235673600807786
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 160.88394165039062, Losses: L1: 4.271951675415039, L2: 0.0, L3: 0.9872026443481445, L4: 77.67941284179688, L5: 0.2659638524055481
Epoch 500, Loss: 0.6659417152404785, Losses: L1: -3.246860980987549, L2: 1.7854206562042236, L3: 0.023915886878967285, L4: 1.4390110969543457, L5: 0.11815454065799713
Epoch 1000, Loss: -1.0954338312149048, Losses: L1: -3.7779297828674316, L2: 1.9772858619689941, L3: 0.015098810195922852, L4: 0.7843469977378845, L5: 0.11006025224924088
Epoch 1500, Loss: -1.9711954593658447, Losses: L1: -4.156122207641602, L2: 2.202881097793579, L3: 0.010644316673278809, L4: 0.48442813754081726, L5: 0.1039855107665062
Epoch 2000, Loss: -2.384376049041748, Losses: L1: -4.161391735076904, L2: 1.8940662145614624, L3: 0.013533353805541992, L4: 0.35648971796035767, L5: 0.10346979647874832
Epoch 2500, Loss: -2.3632092475891113, Losses: L1: -4.20466423034668, L2: 1.8240022659301758, L3: 0.07244682312011719, L4: 0.3774995803833008, L5: 0.10200783610343933
Epoch 3000, Loss: -2.7428605556488037, Losses: L1: -4.2634687423706055, L2: 1.8696011304855347, L3: 0.009996533393859863, L4: 0.23582519590854645, L5: 0.10416074097156525
Epoch 3500, Loss: -2.9468538761138916, Losses: L1: -4.244137763977051, L2: 1.7823296785354614, L3: 0.0446171760559082, L4: 0.12944382429122925, L5: 0.10261406004428864
Epoch 4000, Loss: -2.98671555519104, Losses: L1: -4.304946422576904, L2: 1.8846155405044556, L3: 0.0005235671997070312, L4: 0.1365640014410019, L5: 0.10227152705192566
Epoch 4500, Loss: -3.0278332233428955, Losses: L1: -4.324543476104736, L2: 1.8963165283203125, L3: 0.0014916062355041504, L4: 0.12217691540718079, L5: 0.10270678251981735
Epoch 5000, Loss: -3.0968401432037354, Losses: L1: -4.335967063903809, L2: 1.9052917957305908, L3: 0.002166152000427246, L4: 0.09098617732524872, L5: 0.10234250873327255
Epoch 5500, Loss: -3.108835458755493, Losses: L1: -4.346719264984131, L2: 1.9247655868530273, L3: 0.002662956714630127, L4: 0.0853545218706131, L5: 0.1021290048956871
Epoch 6000, Loss: -3.1244328022003174, Losses: L1: -4.353860855102539, L2: 1.9282609224319458, L3: 0.0010616779327392578, L4: 0.08108097314834595, L5: 0.10207384824752808
Epoch 6500, Loss: -3.128542184829712, Losses: L1: -4.358547210693359, L2: 1.9352866411209106, L3: 0.00041669607162475586, L4: 0.07997012883424759, L5: 0.10200470685958862
Epoch 7000, Loss: -3.1313259601593018, Losses: L1: -4.360989093780518, L2: 1.9362958669662476, L3: 0.0010571479797363281, L4: 0.07925399392843246, L5: 0.10195004194974899
Epoch 7500, Loss: -3.13332200050354, Losses: L1: -4.3631439208984375, L2: 1.939160943031311, L3: 0.000667572021484375, L4: 0.07883288711309433, L5: 0.10190814733505249
Epoch 8000, Loss: -3.134685516357422, Losses: L1: -4.364255428314209, L2: 1.9406616687774658, L3: 0.00021255016326904297, L4: 0.07857666909694672, L5: 0.10187307745218277
Epoch 8500, Loss: -3.135380983352661, Losses: L1: -4.3651123046875, L2: 1.9409112930297852, L3: 0.0007941722869873047, L4: 0.07831817865371704, L5: 0.10184497386217117
Epoch 9000, Loss: -3.1363563537597656, Losses: L1: -4.365642547607422, L2: 1.9421124458312988, L3: 2.5093555450439453e-05, L4: 0.07818761467933655, L5: 0.10182980448007584
Epoch 9500, Loss: -3.136725425720215, Losses: L1: -4.365917205810547, L2: 1.9422099590301514, L3: 1.2576580047607422e-05, L4: 0.07812724262475967, L5: 0.10181954503059387
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0213143825531006, Constraint losses: L1: 18.42068099975586, L2: 0.0009646033286117017, L3: 1.000964641571045, L4: 1.0009644031524658
Epoch 500, Loss: 0.002151374239474535, Constraint losses: L1: -1.114762544631958, L2: 0.0, L3: 0.002632319927215576, L4: 0.0006338169332593679
Epoch 1000, Loss: 0.0013039734913036227, Constraint losses: L1: -1.1175740957260132, L2: 0.0, L3: 0.0022104978561401367, L4: 0.0002110497880494222
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.996841549873352, Constraint losses: L1: 5.444602966308594, L2: 0.0, L3: 0.9956986308097839, L4: 0.9956983327865601
Epoch 500, Loss: 0.0020409265998750925, Constraint losses: L1: -1.0479271411895752, L2: 0.0, L3: 0.002543628215789795, L4: 0.0005452255718410015
Epoch 1000, Loss: 0.0012154036667197943, Constraint losses: L1: -1.1158180236816406, L2: 0.0, L3: 0.002165377140045166, L4: 0.00016584456898272038
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 168.20428466796875, Losses: L1: 4.732642650604248, L2: 0.0, L3: 0.9917272329330444, L4: 80.9580078125, L5: 0.28195109963417053
Epoch 500, Loss: 0.21864992380142212, Losses: L1: -3.4444849491119385, L2: 1.9975841045379639, L3: 0.0848429799079895, L4: 1.2500684261322021, L5: 0.039681579917669296
Epoch 1000, Loss: -1.9163919687271118, Losses: L1: -4.20190954208374, L2: 2.31805419921875, L3: 0.05446732044219971, L4: 0.495059609413147, L5: 0.04095202684402466
Epoch 1500, Loss: -1.772070050239563, Losses: L1: -4.506816387176514, L2: 2.2827796936035156, L3: 0.011944770812988281, L4: 0.759875476360321, L5: 0.030830375850200653
Epoch 2000, Loss: -2.7297184467315674, Losses: L1: -4.5215559005737305, L2: 2.021442413330078, L3: 0.00032532215118408203, L4: 0.36586812138557434, L5: 0.024527473375201225
Epoch 2500, Loss: -3.1887295246124268, Losses: L1: -4.529953479766846, L2: 1.88772451877594, L3: 0.0020258426666259766, L4: 0.17515496909618378, L5: 0.02251298539340496
Epoch 3000, Loss: -3.300083637237549, Losses: L1: -4.591114521026611, L2: 1.8945820331573486, L3: 0.0005733966827392578, L4: 0.14984440803527832, L5: 0.021738877519965172
Epoch 3500, Loss: -3.072803020477295, Losses: L1: -4.508004188537598, L2: 2.0417966842651367, L3: 0.021335244178771973, L4: 0.17620587348937988, L5: 0.020277995616197586
Epoch 4000, Loss: -3.4156737327575684, Losses: L1: -4.602421283721924, L2: 1.8467917442321777, L3: 0.0017322897911071777, L4: 0.1100793108344078, L5: 0.02073035202920437
Epoch 4500, Loss: -3.4593472480773926, Losses: L1: -4.609785079956055, L2: 1.8410179615020752, L3: 0.0008026361465454102, L4: 0.09370246529579163, L5: 0.020860811695456505
Epoch 5000, Loss: -3.476707935333252, Losses: L1: -4.6062703132629395, L2: 1.823818325996399, L3: 0.0011233091354370117, L4: 0.08755075931549072, L5: 0.02071419171988964
Epoch 5500, Loss: -3.4874839782714844, Losses: L1: -4.6105055809021, L2: 1.8228203058242798, L3: 0.00028824806213378906, L4: 0.08498743176460266, L5: 0.020674260333180428
Epoch 6000, Loss: -3.493851900100708, Losses: L1: -4.610541820526123, L2: 1.8173093795776367, L3: 0.00013899803161621094, L4: 0.08328928053379059, L5: 0.02065890096127987
Epoch 6500, Loss: -3.49817156791687, Losses: L1: -4.612255573272705, L2: 1.8161535263061523, L3: 0.00012063980102539062, L4: 0.08230458199977875, L5: 0.020638706162571907
Epoch 7000, Loss: -3.5006303787231445, Losses: L1: -4.614190101623535, L2: 1.8173269033432007, L3: 0.00024366378784179688, L4: 0.08169066160917282, L5: 0.020635614171624184
Epoch 7500, Loss: -3.5022084712982178, Losses: L1: -4.61410665512085, L2: 1.8148937225341797, L3: 0.0002493858337402344, L4: 0.08147376030683517, L5: 0.020627224817872047
Epoch 8000, Loss: -3.5038087368011475, Losses: L1: -4.6143107414245605, L2: 1.8141233921051025, L3: 6.783008575439453e-05, L4: 0.08106480538845062, L5: 0.020621536299586296
Epoch 8500, Loss: -3.5047855377197266, Losses: L1: -4.6145453453063965, L2: 1.8137069940567017, L3: 5.418062210083008e-05, L4: 0.08081077039241791, L5: 0.02061530388891697
Epoch 9000, Loss: -3.5053725242614746, Losses: L1: -4.615170955657959, L2: 1.814365029335022, L3: 2.6464462280273438e-05, L4: 0.0806838870048523, L5: 0.02061086893081665
Epoch 9500, Loss: -3.5057713985443115, Losses: L1: -4.615262031555176, L2: 1.8141430616378784, L3: 2.2530555725097656e-05, L4: 0.08059044182300568, L5: 0.02060786634683609
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.003570079803467, Constraint losses: L1: 6.521682262420654, L2: 0.0, L3: 0.9985241889953613, L4: 0.9985243082046509
Epoch 500, Loss: 0.0023356503807008266, Constraint losses: L1: -1.0442758798599243, L2: 0.0, L3: 0.0026888251304626465, L4: 0.0006911011878401041
Epoch 1000, Loss: 0.0013035951415076852, Constraint losses: L1: -1.117310881614685, L2: 0.0, L3: 0.0022101402282714844, L4: 0.000210765894735232
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0202126502990723, Constraint losses: L1: 18.369176864624023, L2: 0.0006981157348491251, L3: 1.0005724430084229, L4: 1.0005728006362915
Epoch 500, Loss: 0.002339011989533901, Constraint losses: L1: -1.106083631515503, L2: 0.0, L3: 0.002721726894378662, L4: 0.0007233687210828066
Epoch 1000, Loss: 0.0013590366579592228, Constraint losses: L1: -1.1168056726455688, L2: 0.0, L3: 0.0022376179695129395, L4: 0.00023822438379283994
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 50.70424270629883, Losses: L1: 16.499406814575195, L2: 0.001486938213929534, L3: 1.0014564990997314, L4: 64.19465637207031, L5: 0.2076999396085739
Epoch 500, Loss: -1.374129056930542, Losses: L1: -3.9339356422424316, L2: 1.8079289197921753, L3: 0.06462371349334717, L4: 3.0038769245147705, L5: 0.04931227117776871
Epoch 1000, Loss: -1.2985371351242065, Losses: L1: -3.4851748943328857, L2: 2.2046072483062744, L3: 0.06391686201095581, L4: 1.8654764890670776, L5: 0.04752378910779953
Epoch 1500, Loss: -2.586634635925293, Losses: L1: -4.047267913818359, L2: 1.8946295976638794, L3: 0.05365622043609619, L4: 0.77338707447052, L5: 0.03862518072128296
Epoch 2000, Loss: -3.1476850509643555, Losses: L1: -4.212899684906006, L2: 1.5359057188034058, L3: 0.005764365196228027, L4: 0.5265763998031616, L5: 0.04488953575491905
Epoch 2500, Loss: -3.249380111694336, Losses: L1: -4.267159461975098, L2: 1.4036352634429932, L3: 0.021032094955444336, L4: 0.5087060928344727, L5: 0.03908912092447281
Epoch 3000, Loss: -3.381556749343872, Losses: L1: -4.328532695770264, L2: 1.4390984773635864, L3: 0.013511955738067627, L4: 0.36932504177093506, L5: 0.03148093819618225
Epoch 3500, Loss: -3.4748268127441406, Losses: L1: -4.346906661987305, L2: 1.381888508796692, L3: 0.006820201873779297, L4: 0.30569252371788025, L5: 0.02929789386689663
Epoch 4000, Loss: -3.497619152069092, Losses: L1: -4.341721057891846, L2: 1.322001576423645, L3: 0.007340669631958008, L4: 0.30879420042037964, L5: 0.028045693412423134
Epoch 4500, Loss: -3.5006141662597656, Losses: L1: -4.359574317932129, L2: 1.3556393384933472, L3: 0.011978745460510254, L4: 0.28720879554748535, L5: 0.027156755328178406
Epoch 5000, Loss: -3.526385545730591, Losses: L1: -4.353189468383789, L2: 1.30231773853302, L3: 0.009888172149658203, L4: 0.2853250503540039, L5: 0.0264125969260931
Epoch 5500, Loss: -3.543219804763794, Losses: L1: -4.357654571533203, L2: 1.3032333850860596, L3: 0.005132317543029785, L4: 0.2787749767303467, L5: 0.026332611218094826
Epoch 6000, Loss: -3.5567421913146973, Losses: L1: -4.361322402954102, L2: 1.3096226453781128, L3: 5.53131103515625e-05, L4: 0.273247629404068, L5: 0.02606879733502865
Epoch 6500, Loss: -3.5601131916046143, Losses: L1: -4.362693786621094, L2: 1.3077301979064941, L3: 8.821487426757812e-05, L4: 0.27111613750457764, L5: 0.025962037965655327
Epoch 7000, Loss: -3.561859607696533, Losses: L1: -4.36309289932251, L2: 1.3049339056015015, L3: 0.0005548000335693359, L4: 0.26942020654678345, L5: 0.025893352925777435
Epoch 7500, Loss: -3.561143636703491, Losses: L1: -4.364354610443115, L2: 1.3073421716690063, L3: 0.0011258125305175781, L4: 0.2687745988368988, L5: 0.025802288204431534
Epoch 8000, Loss: -3.5641210079193115, Losses: L1: -4.363783359527588, L2: 1.3037747144699097, L3: 0.00039708614349365234, L4: 0.2682092487812042, L5: 0.02575228177011013
Epoch 8500, Loss: -3.5658788681030273, Losses: L1: -4.363210201263428, L2: 1.3010835647583008, L3: 5.125999450683594e-06, L4: 0.26786530017852783, L5: 0.025693416595458984
Epoch 9000, Loss: -3.566301107406616, Losses: L1: -4.363117694854736, L2: 1.300230860710144, L3: 4.935264587402344e-05, L4: 0.26754191517829895, L5: 0.0256627406924963
Epoch 9500, Loss: -3.566556692123413, Losses: L1: -4.363224983215332, L2: 1.300122857093811, L3: 4.118680953979492e-05, L4: 0.2674100399017334, L5: 0.025638872757554054
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0226244926452637, Constraint losses: L1: 18.42068099975586, L2: 0.001401126733981073, L3: 1.0014011859893799, L4: 1.0014015436172485
Epoch 500, Loss: 0.0022756399121135473, Constraint losses: L1: -1.0984342098236084, L2: 0.0, L3: 0.002686142921447754, L4: 0.0006879311986267567
Epoch 1000, Loss: 0.0013254282530397177, Constraint losses: L1: -1.1171040534973145, L2: 0.0, L3: 0.0022209882736206055, L4: 0.00022154404723551124
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002941131591797, Constraint losses: L1: 6.360893726348877, L2: 0.0, L3: 0.9982900023460388, L4: 0.9982900619506836
Epoch 500, Loss: 0.002489800564944744, Constraint losses: L1: -1.1115142107009888, L2: 0.0, L3: 0.002799689769744873, L4: 0.0008016251958906651
Epoch 1000, Loss: 0.0014107211027294397, Constraint losses: L1: -1.1160457134246826, L2: 0.0, L3: 0.0022629499435424805, L4: 0.0002638168807607144
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.60114669799805, Losses: L1: 11.294473648071289, L2: 0.00017130329797510058, L3: 0.9993706941604614, L4: 78.07774353027344, L5: 0.26897385716438293
Epoch 500, Loss: 22.488431930541992, Losses: L1: 9.984087944030762, L2: 0.826104462146759, L3: 0.47349488735198975, L4: 22.125076293945312, L5: 0.08176307380199432
Epoch 1000, Loss: 38.33280944824219, Losses: L1: 11.008794784545898, L2: 0.0006666197441518307, L3: 0.9992702007293701, L4: 49.99336242675781, L5: 0.3284620940685272
Epoch 1500, Loss: 23.926401138305664, Losses: L1: -4.034616947174072, L2: 1.9536710977554321, L3: 0.7285870313644409, L4: 50.47699737548828, L5: 0.28850874304771423
Epoch 2000, Loss: 25.0745906829834, Losses: L1: -3.142164707183838, L2: 1.5518896579742432, L3: 0.9419763088226318, L4: 50.541385650634766, L5: 0.2861652374267578
Epoch 2500, Loss: 22.434385299682617, Losses: L1: -4.047774314880371, L2: 1.5965934991836548, L3: 0.08460581302642822, L4: 50.44530487060547, L5: 0.2919979989528656
Epoch 3000, Loss: 22.11354637145996, Losses: L1: -4.108794212341309, L2: 1.3400214910507202, L3: 0.030860424041748047, L4: 50.39398193359375, L5: 0.2936164140701294
Epoch 3500, Loss: 22.301883697509766, Losses: L1: -4.088423252105713, L2: 1.3377591371536255, L3: 0.11458373069763184, L4: 50.39740753173828, L5: 0.2935557961463928
Epoch 4000, Loss: 22.439563751220703, Losses: L1: -4.247994899749756, L2: 1.2769368886947632, L3: 0.2704245448112488, L4: 50.43045425415039, L5: 0.2930150330066681
Epoch 4500, Loss: 22.08229637145996, Losses: L1: -4.236030578613281, L2: 1.1985070705413818, L3: 0.09912562370300293, L4: 50.4580192565918, L5: 0.29181382060050964
Epoch 5000, Loss: 21.936092376708984, Losses: L1: -4.2445878982543945, L2: 1.1378015279769897, L3: 0.04765009880065918, L4: 50.44851303100586, L5: 0.2922223210334778
Epoch 5500, Loss: 21.825153350830078, Losses: L1: -4.288865566253662, L2: 1.1479073762893677, L3: 0.007659316062927246, L4: 50.466163635253906, L5: 0.29166319966316223
Epoch 6000, Loss: 21.812541961669922, Losses: L1: -4.311966419219971, L2: 1.1627264022827148, L3: 0.006449997425079346, L4: 50.477996826171875, L5: 0.2912467122077942
Epoch 6500, Loss: 21.81682586669922, Losses: L1: -4.327997207641602, L2: 1.1750431060791016, L3: 0.011765241622924805, L4: 50.4856071472168, L5: 0.29096800088882446
Epoch 7000, Loss: 21.820560455322266, Losses: L1: -4.340246677398682, L2: 1.1857256889343262, L3: 0.0156022310256958, L4: 50.492000579833984, L5: 0.2907399833202362
Epoch 7500, Loss: 21.80626678466797, Losses: L1: -4.342386722564697, L2: 1.1821202039718628, L3: 0.009584784507751465, L4: 50.495601654052734, L5: 0.29062211513519287
Epoch 8000, Loss: 21.78712272644043, Losses: L1: -4.34848165512085, L2: 1.1884732246398926, L3: 0.0008306503295898438, L4: 50.498321533203125, L5: 0.29054683446884155
Epoch 8500, Loss: 21.791217803955078, Losses: L1: -4.350698471069336, L2: 1.1891977787017822, L3: 0.0033655166625976562, L4: 50.50018310546875, L5: 0.29049521684646606
Epoch 9000, Loss: 21.78655433654785, Losses: L1: -4.352875232696533, L2: 1.191825270652771, L3: 0.0012629032135009766, L4: 50.501033782958984, L5: 0.2904737889766693
Epoch 9500, Loss: 21.7840633392334, Losses: L1: -4.353190898895264, L2: 1.1915596723556519, L3: 0.00019848346710205078, L4: 50.501216888427734, L5: 0.2904682159423828
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0186004638671875, Constraint losses: L1: 18.282773971557617, L2: 0.00012882584996987134, L3: 1.0000944137573242, L4: 1.0000944137573242
Epoch 500, Loss: 0.0023454148322343826, Constraint losses: L1: -1.1066787242889404, L2: 0.0, L3: 0.0027251839637756348, L4: 0.0007269097259268165
Epoch 1000, Loss: 0.00136143050622195, Constraint losses: L1: -1.117668867111206, L2: 0.0, L3: 0.0022392868995666504, L4: 0.00023981250706128776
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0303077697753906, Constraint losses: L1: 18.42068099975586, L2: 0.003961955197155476, L3: 1.0039619207382202, L4: 1.0039631128311157
Epoch 500, Loss: 0.0025465176440775394, Constraint losses: L1: -1.112823724746704, L2: 0.0, L3: 0.0028287768363952637, L4: 0.0008305645314976573
Epoch 1000, Loss: 0.001437633065506816, Constraint losses: L1: -1.1165803670883179, L2: 0.0, L3: 0.0022768378257751465, L4: 0.0002773756568785757
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 47.05419921875, Losses: L1: 7.6332902908325195, L2: 2.2946876470086863e-06, L3: 0.9992533326148987, L4: 73.85613250732422, L5: 0.24716679751873016
Epoch 500, Loss: -2.494194746017456, Losses: L1: -4.188632965087891, L2: 1.8133264780044556, L3: 0.015491127967834473, L4: 1.3524024486541748, L5: 0.04029577597975731
Epoch 1000, Loss: -1.539792537689209, Losses: L1: -3.5583410263061523, L2: 1.778351902961731, L3: 0.03886091709136963, L4: 1.9537577629089355, L5: 0.03738594800233841
Epoch 1500, Loss: -2.9259772300720215, Losses: L1: -4.293482780456543, L2: 1.9867913722991943, L3: 0.00471806526184082, L4: 0.6122468709945679, L5: 0.02927504852414131
Epoch 2000, Loss: -3.131775140762329, Losses: L1: -4.34012508392334, L2: 1.6295957565307617, L3: 0.014477849006652832, L4: 0.6301623582839966, L5: 0.024757640436291695
Epoch 2500, Loss: -3.30908465385437, Losses: L1: -4.3888444900512695, L2: 1.5173918008804321, L3: 0.0007014274597167969, L4: 0.5491268634796143, L5: 0.02254883386194706
Epoch 3000, Loss: -3.4143762588500977, Losses: L1: -4.435573101043701, L2: 1.5316195487976074, L3: 0.0004858970642089844, L4: 0.4199325740337372, L5: 0.022224536165595055
Epoch 3500, Loss: -3.4935662746429443, Losses: L1: -4.433227062225342, L2: 1.4700803756713867, L3: 0.0003724098205566406, L4: 0.3196667730808258, L5: 0.02202112413942814
Epoch 4000, Loss: -3.5103511810302734, Losses: L1: -4.451879024505615, L2: 1.4708364009857178, L3: 0.0012983083724975586, L4: 0.31981709599494934, L5: 0.02180214412510395
Epoch 4500, Loss: -3.5420963764190674, Losses: L1: -4.466525077819824, L2: 1.476904034614563, L3: 0.0006150007247924805, L4: 0.2827479839324951, L5: 0.021686486899852753
Epoch 5000, Loss: -3.5544679164886475, Losses: L1: -4.4695515632629395, L2: 1.4674063920974731, L3: 0.000868678092956543, L4: 0.27273911237716675, L5: 0.021636871621012688
Epoch 5500, Loss: -3.564897298812866, Losses: L1: -4.4718017578125, L2: 1.4618406295776367, L3: 0.00010180473327636719, L4: 0.2667757272720337, L5: 0.02119637094438076
Epoch 6000, Loss: -3.570592164993286, Losses: L1: -4.475552082061768, L2: 1.4619865417480469, L3: 0.00020647048950195312, L4: 0.2630516290664673, L5: 0.02101392112672329
Epoch 6500, Loss: -3.575242757797241, Losses: L1: -4.477344989776611, L2: 1.4601515531539917, L3: 6.192922592163086e-05, L4: 0.2606198191642761, L5: 0.02079634740948677
Epoch 7000, Loss: -3.5781874656677246, Losses: L1: -4.479003429412842, L2: 1.4594786167144775, L3: 9.202957153320312e-05, L4: 0.2592511773109436, L5: 0.020633630454540253
Epoch 7500, Loss: -3.580397129058838, Losses: L1: -4.480621337890625, L2: 1.4598798751831055, L3: 8.481740951538086e-05, L4: 0.25814908742904663, L5: 0.020520025864243507
Epoch 8000, Loss: -3.582021474838257, Losses: L1: -4.481505870819092, L2: 1.4596550464630127, L3: 6.842613220214844e-05, L4: 0.2572687864303589, L5: 0.02044285461306572
Epoch 8500, Loss: -3.583238124847412, Losses: L1: -4.4812421798706055, L2: 1.4577994346618652, L3: 2.8848648071289062e-05, L4: 0.2565128803253174, L5: 0.020395027473568916
Epoch 9000, Loss: -3.5839574337005615, Losses: L1: -4.480910301208496, L2: 1.4563359022140503, L3: 3.057718276977539e-05, L4: 0.25592514872550964, L5: 0.0203806571662426
Epoch 9500, Loss: -3.5844647884368896, Losses: L1: -4.480823516845703, L2: 1.455570101737976, L3: 1.2516975402832031e-05, L4: 0.25559183955192566, L5: 0.020376358181238174
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.007174015045166, Constraint losses: L1: 8.034103393554688, L2: 0.00020276758004911244, L3: 0.9994686841964722, L4: 0.9994685053825378
Epoch 500, Loss: 0.002157768700271845, Constraint losses: L1: -1.0854096412658691, L2: 0.0, L3: 0.0026208162307739258, L4: 0.0006223621312528849
Epoch 1000, Loss: 0.0012826983584091067, Constraint losses: L1: -1.1162917613983154, L2: 0.0, L3: 0.002199232578277588, L4: 0.00019975760369561613
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0207676887512207, Constraint losses: L1: 18.42068099975586, L2: 0.00078233378008008, L3: 1.0007823705673218, L4: 1.0007822513580322
Epoch 500, Loss: 0.002214340027421713, Constraint losses: L1: -1.1109634637832642, L2: 0.0, L3: 0.0026619434356689453, L4: 0.0006633602315559983
Epoch 1000, Loss: 0.001321306568570435, Constraint losses: L1: -1.1163495779037476, L2: 0.0, L3: 0.002218484878540039, L4: 0.00021917131380178034
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 93.0584945678711, Losses: L1: 18.42068099975586, L2: 0.006388828158378601, L3: 1.006388783454895, L4: 72.50082397460938, L5: 0.24203969538211823
Epoch 500, Loss: 9.976502418518066, Losses: L1: 2.9173707962036133, L2: 0.504955530166626, L3: 0.1280277967453003, L4: 6.520338535308838, L5: 0.06052033603191376
Epoch 1000, Loss: 2.5803799629211426, Losses: L1: -1.9182281494140625, L2: 1.128883957862854, L3: 0.06850957870483398, L4: 3.7704415321350098, L5: 0.053411126136779785
Epoch 1500, Loss: 0.1504422277212143, Losses: L1: -2.2211267948150635, L2: 1.225474238395691, L3: 0.07344508171081543, L4: 1.5891605615615845, L5: 0.045562244951725006
Epoch 2000, Loss: -0.4427230656147003, Losses: L1: -2.344437837600708, L2: 1.2845666408538818, L3: 0.0756368637084961, L4: 1.081126093864441, L5: 0.054063279181718826
Epoch 2500, Loss: -0.897831916809082, Losses: L1: -2.404849052429199, L2: 1.3657768964767456, L3: 0.07610160112380981, L4: 0.6432228088378906, L5: 0.057405173778533936
Epoch 3000, Loss: -1.004459023475647, Losses: L1: -2.434067964553833, L2: 1.3977277278900146, L3: 0.07509708404541016, L4: 0.5504407286643982, L5: 0.06022047623991966
Epoch 3500, Loss: -0.9773761034011841, Losses: L1: -2.4512240886688232, L2: 1.414616346359253, L3: 0.07507860660552979, L4: 0.5861398577690125, L5: 0.060485631227493286
Epoch 4000, Loss: -1.0698590278625488, Losses: L1: -2.463726758956909, L2: 1.4251208305358887, L3: 0.07458722591400146, L4: 0.5014052987098694, L5: 0.06145535781979561
Epoch 4500, Loss: -1.1271169185638428, Losses: L1: -2.4753031730651855, L2: 1.4370245933532715, L3: 0.07499039173126221, L4: 0.4485037922859192, L5: 0.06237886846065521
Epoch 5000, Loss: -1.1477569341659546, Losses: L1: -2.485165596008301, L2: 1.4494291543960571, L3: 0.07492184638977051, L4: 0.4314265847206116, L5: 0.06284791231155396
Epoch 5500, Loss: -1.1625653505325317, Losses: L1: -2.4941720962524414, L2: 1.4615044593811035, L3: 0.07488483190536499, L4: 0.4194179177284241, L5: 0.06333369016647339
Epoch 6000, Loss: -1.1720854043960571, Losses: L1: -2.5015451908111572, L2: 1.4711582660675049, L3: 0.07479214668273926, L4: 0.4124928116798401, L5: 0.06360706686973572
Epoch 6500, Loss: -1.1787986755371094, Losses: L1: -2.5070078372955322, L2: 1.4786441326141357, L3: 0.0747455358505249, L4: 0.40749862790107727, L5: 0.06379488110542297
Epoch 7000, Loss: -1.1831536293029785, Losses: L1: -2.510789155960083, L2: 1.48361074924469, L3: 0.07468366622924805, L4: 0.40449440479278564, L5: 0.06393706053495407
Epoch 7500, Loss: -1.186590552330017, Losses: L1: -2.513572931289673, L2: 1.4872105121612549, L3: 0.07466447353363037, L4: 0.40201836824417114, L5: 0.06405944377183914
Epoch 8000, Loss: -1.188948392868042, Losses: L1: -2.5152201652526855, L2: 1.4892852306365967, L3: 0.07467567920684814, L4: 0.4002108871936798, L5: 0.06413378566503525
Epoch 8500, Loss: -1.190516710281372, Losses: L1: -2.5163023471832275, L2: 1.4905723333358765, L3: 0.07467663288116455, L4: 0.39904528856277466, L5: 0.06420174241065979
Epoch 9000, Loss: -1.1915687322616577, Losses: L1: -2.5169453620910645, L2: 1.4912936687469482, L3: 0.07466447353363037, L4: 0.3982844054698944, L5: 0.06423283368349075
Epoch 9500, Loss: -1.192304015159607, Losses: L1: -2.517312526702881, L2: 1.4916962385177612, L3: 0.07465857267379761, L4: 0.3977162539958954, L5: 0.0642538070678711
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0058302879333496, Constraint losses: L1: 7.105498313903809, L2: 1.3808545418214635e-08, L3: 0.9993627667427063, L4: 0.9993619322776794
Epoch 500, Loss: 0.0018581795739009976, Constraint losses: L1: -1.1002602577209473, L2: 0.0, L3: 0.0024785399436950684, L4: 0.00047989992890506983
Epoch 1000, Loss: 0.0011901066172868013, Constraint losses: L1: -1.1184428930282593, L2: 0.0, L3: 0.0021539926528930664, L4: 0.00015455693937838078
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.020392656326294, Constraint losses: L1: 18.42068099975586, L2: 0.0006572313141077757, L3: 1.0006572008132935, L4: 1.000657558441162
Epoch 500, Loss: 0.002134899143129587, Constraint losses: L1: -1.1114270687103271, L2: 0.0, L3: 0.0026224255561828613, L4: 0.0006239005597308278
Epoch 1000, Loss: 0.001295052352361381, Constraint losses: L1: -1.1162989139556885, L2: 0.0, L3: 0.002205371856689453, L4: 0.00020597942057065666
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 91.04672241210938, Losses: L1: 15.133996963500977, L2: 0.0002701800549402833, L3: 1.0000276565551758, L4: 73.66644287109375, L5: 0.2460906207561493
Epoch 500, Loss: 0.7935693264007568, Losses: L1: -3.4482836723327637, L2: 1.6515358686447144, L3: 0.07823532819747925, L4: 3.2221405506134033, L5: 0.037473682314157486
Epoch 1000, Loss: -0.9609338045120239, Losses: L1: -3.0560553073883057, L2: 1.7939527034759521, L3: 0.07996392250061035, L4: 1.0017173290252686, L5: 0.03650008514523506
Epoch 1500, Loss: -1.2303367853164673, Losses: L1: -3.755905866622925, L2: 2.0626018047332764, L3: 0.062337517738342285, L4: 1.340753197669983, L5: 0.028840014711022377
Epoch 2000, Loss: -2.168710947036743, Losses: L1: -3.98776912689209, L2: 1.8482412099838257, L3: 0.06745809316635132, L4: 0.734967827796936, L5: 0.025053640827536583
Epoch 2500, Loss: -2.6231160163879395, Losses: L1: -3.997053861618042, L2: 1.5580594539642334, L3: 0.07069587707519531, L4: 0.43121814727783203, L5: 0.022298455238342285
Epoch 3000, Loss: -2.790095329284668, Losses: L1: -4.04069185256958, L2: 1.4902750253677368, L3: 0.07424229383468628, L4: 0.335381418466568, L5: 0.021593138575553894
Epoch 3500, Loss: -2.978584051132202, Losses: L1: -4.0727858543396, L2: 1.4897067546844482, L3: 0.07391029596328735, L4: 0.18082544207572937, L5: 0.02070247381925583
Epoch 4000, Loss: -3.0149993896484375, Losses: L1: -4.091926097869873, L2: 1.4860647916793823, L3: 0.07233273983001709, L4: 0.16845703125, L5: 0.020771721377968788
Epoch 4500, Loss: -3.0408897399902344, Losses: L1: -4.105752468109131, L2: 1.4795043468475342, L3: 0.07197713851928711, L4: 0.16044169664382935, L5: 0.020714575424790382
Epoch 5000, Loss: -3.0603320598602295, Losses: L1: -4.113394737243652, L2: 1.4702143669128418, L3: 0.07150495052337646, L4: 0.1544674038887024, L5: 0.020478203892707825
Epoch 5500, Loss: -3.0748047828674316, Losses: L1: -4.120823383331299, L2: 1.4635754823684692, L3: 0.07137644290924072, L4: 0.1511334776878357, L5: 0.020344508811831474
Epoch 6000, Loss: -3.0850307941436768, Losses: L1: -4.126159191131592, L2: 1.4586987495422363, L3: 0.0713077187538147, L4: 0.14895100891590118, L5: 0.020212341099977493
Epoch 6500, Loss: -3.0929486751556396, Losses: L1: -4.131080150604248, L2: 1.4558007717132568, L3: 0.07130926847457886, L4: 0.14751558005809784, L5: 0.020096780732274055
Epoch 7000, Loss: -3.0987281799316406, Losses: L1: -4.133239269256592, L2: 1.4516044855117798, L3: 0.07115954160690308, L4: 0.1463625133037567, L5: 0.020027372986078262
Epoch 7500, Loss: -3.1029863357543945, Losses: L1: -4.135615348815918, L2: 1.4499105215072632, L3: 0.07110273838043213, L4: 0.14549458026885986, L5: 0.019973840564489365
Epoch 8000, Loss: -3.1059679985046387, Losses: L1: -4.137333393096924, L2: 1.448775053024292, L3: 0.07106494903564453, L4: 0.14492365717887878, L5: 0.019924232736229897
Epoch 8500, Loss: -3.107977867126465, Losses: L1: -4.138752460479736, L2: 1.4481409788131714, L3: 0.07106280326843262, L4: 0.14467568695545197, L5: 0.019902728497982025
Epoch 9000, Loss: -3.1095223426818848, Losses: L1: -4.1401238441467285, L2: 1.4484905004501343, L3: 0.07107210159301758, L4: 0.14432483911514282, L5: 0.019887104630470276
Epoch 9500, Loss: -3.110478162765503, Losses: L1: -4.1410980224609375, L2: 1.4487519264221191, L3: 0.07110089063644409, L4: 0.14416515827178955, L5: 0.019877292215824127
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0026626586914062, Constraint losses: L1: 6.299929141998291, L2: 0.0, L3: 0.9981813430786133, L4: 0.9981812238693237
Epoch 500, Loss: 0.002130419947206974, Constraint losses: L1: -1.1008126735687256, L2: 0.0, L3: 0.0026147961616516113, L4: 0.0006164363585412502
Epoch 1000, Loss: 0.0012911106459796429, Constraint losses: L1: -1.1141613721847534, L2: 0.0, L3: 0.002202272415161133, L4: 0.0002029996830970049
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0074069499969482, Constraint losses: L1: 8.051889419555664, L2: 0.0, L3: 0.9996775388717651, L4: 0.9996775984764099
Epoch 500, Loss: 0.002093486487865448, Constraint losses: L1: -1.1051344871520996, L2: 0.0, L3: 0.002598583698272705, L4: 0.0006000373978167772
Epoch 1000, Loss: 0.0012812195345759392, Constraint losses: L1: -1.114973783493042, L2: 0.0, L3: 0.002197742462158203, L4: 0.00019845092901960015
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 104.36158752441406, Losses: L1: 18.42068099975586, L2: 0.001308989361859858, L3: 1.0011296272277832, L4: 83.34272766113281, L5: 0.29763084650039673
Epoch 500, Loss: 25.15152931213379, Losses: L1: -0.4859384298324585, L2: 4.676187992095947, L3: 0.09264874458312988, L4: 22.675762176513672, L5: 0.21915678679943085
Epoch 1000, Loss: 1.6643950939178467, Losses: L1: -1.962647557258606, L2: 1.3597092628479004, L3: 0.15245455503463745, L4: 2.5198864936828613, L5: 0.061196181923151016
Epoch 1500, Loss: 1.8227548599243164, Losses: L1: -2.2357349395751953, L2: 1.6663867235183716, L3: 0.13449019193649292, L4: 2.8123626708984375, L5: 0.07197674363851547
Epoch 2000, Loss: 1.034660816192627, Losses: L1: -2.36283802986145, L2: 1.8138487339019775, L3: 0.14173763990402222, L4: 2.067434072494507, L5: 0.06983256340026855
Epoch 2500, Loss: 0.48460084199905396, Losses: L1: -2.355745315551758, L2: 1.6220892667770386, L3: 0.15945672988891602, L4: 1.5697994232177734, L5: 0.07029428333044052
Epoch 3000, Loss: 0.41479063034057617, Losses: L1: -2.40681791305542, L2: 1.6494214534759521, L3: 0.15703505277633667, L4: 1.5398099422454834, L5: 0.07150888442993164
Epoch 3500, Loss: 0.32933151721954346, Losses: L1: -2.4482827186584473, L2: 1.6630104780197144, L3: 0.15378618240356445, L4: 1.492322325706482, L5: 0.07310713082551956
Epoch 4000, Loss: 0.2811083495616913, Losses: L1: -2.477919578552246, L2: 1.6756960153579712, L3: 0.15195000171661377, L4: 1.469085931777954, L5: 0.07409702241420746
Epoch 4500, Loss: 0.241795152425766, Losses: L1: -2.5037364959716797, L2: 1.684988260269165, L3: 0.15039300918579102, L4: 1.4521459341049194, L5: 0.07505278289318085
Epoch 5000, Loss: 0.21318703889846802, Losses: L1: -2.5179460048675537, L2: 1.6877377033233643, L3: 0.1491129994392395, L4: 1.437044620513916, L5: 0.07599678635597229
Epoch 5500, Loss: 0.19169843196868896, Losses: L1: -2.534055233001709, L2: 1.697657823562622, L3: 0.1480797529220581, L4: 1.4275949001312256, L5: 0.07658517360687256
Epoch 6000, Loss: 0.17600858211517334, Losses: L1: -2.5453546047210693, L2: 1.703700304031372, L3: 0.1476004719734192, L4: 1.4203951358795166, L5: 0.07695847749710083
Epoch 6500, Loss: 0.1655697524547577, Losses: L1: -2.5525543689727783, L2: 1.70663321018219, L3: 0.14753711223602295, L4: 1.4151567220687866, L5: 0.07728831470012665
Epoch 7000, Loss: 0.15685871243476868, Losses: L1: -2.5581603050231934, L2: 1.7092398405075073, L3: 0.14750778675079346, L4: 1.4104491472244263, L5: 0.07746715843677521
Epoch 7500, Loss: 0.1508411169052124, Losses: L1: -2.5620923042297363, L2: 1.7112659215927124, L3: 0.14736998081207275, L4: 1.407228708267212, L5: 0.07766586542129517
Epoch 8000, Loss: 0.1467389464378357, Losses: L1: -2.565103054046631, L2: 1.713005781173706, L3: 0.14733898639678955, L4: 1.405093789100647, L5: 0.07778367400169373
Epoch 8500, Loss: 0.14347240328788757, Losses: L1: -2.5674195289611816, L2: 1.7144343852996826, L3: 0.14728409051895142, L4: 1.403283953666687, L5: 0.07791130244731903
Epoch 9000, Loss: 0.1413470208644867, Losses: L1: -2.568995237350464, L2: 1.7155238389968872, L3: 0.1472339630126953, L4: 1.402142882347107, L5: 0.07798479497432709
Epoch 9500, Loss: 0.139931783080101, Losses: L1: -2.5700161457061768, L2: 1.7162331342697144, L3: 0.14721250534057617, L4: 1.4013499021530151, L5: 0.07802819460630417
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0169291496276855, Constraint losses: L1: 16.601457595825195, L2: 0.00027723261155188084, L3: 1.0000249147415161, L4: 1.0000255107879639
Epoch 500, Loss: 0.0024008024483919144, Constraint losses: L1: -1.106030821800232, L2: 0.0, L3: 0.002752542495727539, L4: 0.000754290958866477
Epoch 1000, Loss: 0.0013825490605086088, Constraint losses: L1: -1.1185232400894165, L2: 0.0, L3: 0.0022502541542053223, L4: 0.0002508181787561625
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0027554035186768, Constraint losses: L1: 6.2835283279418945, L2: 4.182691918686032e-05, L3: 0.9982150793075562, L4: 0.9982149004936218
Epoch 500, Loss: 0.0024039882700890303, Constraint losses: L1: -1.065529704093933, L2: 0.0, L3: 0.0027337074279785156, L4: 0.0007358106086030602
Epoch 1000, Loss: 0.0013472861610352993, Constraint losses: L1: -1.1159746646881104, L2: 0.0, L3: 0.002231419086456299, L4: 0.00023184187011793256
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 188.43162536621094, Losses: L1: 18.216550827026367, L2: 0.001985030248761177, L3: 1.0019278526306152, L4: 84.02970123291016, L5: 0.30165523290634155
Epoch 500, Loss: 1.9818520545959473, Losses: L1: -2.8967995643615723, L2: 2.1433448791503906, L3: 0.0791940689086914, L4: 1.80911123752594, L5: 0.06073712185025215
Epoch 1000, Loss: 9.671128273010254, Losses: L1: 1.371123194694519, L2: 0.3052017390727997, L3: 0.059300243854522705, L4: 4.006860256195068, L5: 0.030167052522301674
Epoch 1500, Loss: 1.316150188446045, Losses: L1: -1.165099024772644, L2: 0.9129689335823059, L3: 0.056212782859802246, L4: 0.9483028054237366, L5: 0.031467288732528687
Epoch 2000, Loss: 0.5194568634033203, Losses: L1: -3.133946418762207, L2: 1.5697782039642334, L3: 0.08220255374908447, L4: 1.3439860343933105, L5: 0.03227371349930763
Epoch 2500, Loss: -1.5459171533584595, Losses: L1: -3.4035377502441406, L2: 1.76333749294281, L3: 0.05896127223968506, L4: 0.41804176568984985, L5: 0.04389150068163872
Epoch 3000, Loss: -1.9007400274276733, Losses: L1: -3.596757411956787, L2: 1.8072850704193115, L3: 0.056624531745910645, L4: 0.3276599645614624, L5: 0.0476115457713604
Epoch 3500, Loss: -2.1626665592193604, Losses: L1: -3.728449821472168, L2: 1.8010913133621216, L3: 0.054296135902404785, L4: 0.26571017503738403, L5: 0.05044994503259659
Epoch 4000, Loss: -2.244556427001953, Losses: L1: -3.8347373008728027, L2: 1.8183372020721436, L3: 0.04801297187805176, L4: 0.27968913316726685, L5: 0.05121634900569916
Epoch 4500, Loss: -2.468330144882202, Losses: L1: -3.9312503337860107, L2: 1.857897162437439, L3: 0.03662276268005371, L4: 0.21722695231437683, L5: 0.052544016391038895
Epoch 5000, Loss: -2.5819976329803467, Losses: L1: -4.0141801834106445, L2: 1.906800389289856, L3: 0.01893174648284912, L4: 0.20717455446720123, L5: 0.05313991382718086
Epoch 5500, Loss: -2.676393508911133, Losses: L1: -4.073521614074707, L2: 1.93716299533844, L3: 6.9141387939453125e-06, L4: 0.20085255801677704, L5: 0.05365557223558426
Epoch 6000, Loss: -2.7031357288360596, Losses: L1: -4.0315117835998535, L2: 1.8226468563079834, L3: 3.218650817871094e-05, L4: 0.1947963535785675, L5: 0.054791100323200226
Epoch 6500, Loss: -2.715667724609375, Losses: L1: -4.018301486968994, L2: 1.780095100402832, L3: 2.2292137145996094e-05, L4: 0.19241292774677277, L5: 0.05543137714266777
Epoch 7000, Loss: -2.7233216762542725, Losses: L1: -4.011838436126709, L2: 1.7571535110473633, L3: 0.00012755393981933594, L4: 0.19089889526367188, L5: 0.05577417463064194
Epoch 7500, Loss: -2.72845196723938, Losses: L1: -4.0106306076049805, L2: 1.74789297580719, L3: 5.9604644775390625e-06, L4: 0.19010017812252045, L5: 0.056039877235889435
Epoch 8000, Loss: -2.732113838195801, Losses: L1: -4.009915828704834, L2: 1.7419532537460327, L3: 7.152557373046875e-07, L4: 0.18935999274253845, L5: 0.05620774254202843
Epoch 8500, Loss: -2.7344603538513184, Losses: L1: -4.009659767150879, L2: 1.7382543087005615, L3: 9.059906005859375e-06, L4: 0.1889447271823883, L5: 0.056329064071178436
Epoch 9000, Loss: -2.735858201980591, Losses: L1: -4.0097270011901855, L2: 1.7363978624343872, L3: 4.589557647705078e-06, L4: 0.1887313723564148, L5: 0.05639582499861717
Epoch 9500, Loss: -2.736882209777832, Losses: L1: -4.009762287139893, L2: 1.7352170944213867, L3: 9.775161743164062e-06, L4: 0.18851318955421448, L5: 0.05645109713077545
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9985456466674805, Constraint losses: L1: 5.62017822265625, L2: 0.0, L3: 0.996462881565094, L4: 0.9964625835418701
Epoch 500, Loss: 0.002140587195754051, Constraint losses: L1: -1.0945078134536743, L2: 0.0, L3: 0.0026167631149291992, L4: 0.00061833206564188
Epoch 1000, Loss: 0.0012789813335984945, Constraint losses: L1: -1.1133569478988647, L2: 0.0, L3: 0.002195894718170166, L4: 0.00019644366693682969
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.034759044647217, Constraint losses: L1: 18.42068099975586, L2: 0.005445695947855711, L3: 1.0054457187652588, L4: 1.0054467916488647
Epoch 500, Loss: 0.002207965822890401, Constraint losses: L1: -1.1060906648635864, L2: 0.0, L3: 0.002656102180480957, L4: 0.0006579544278793037
Epoch 1000, Loss: 0.001308345003053546, Constraint losses: L1: -1.1172808408737183, L2: 0.0, L3: 0.0022124648094177246, L4: 0.00021316108177416027
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 158.7633819580078, Losses: L1: 6.996518135070801, L2: 0.0, L3: 0.9991204142570496, L4: 74.75840759277344, L5: 0.25182294845581055
Epoch 500, Loss: 116.53492736816406, Losses: L1: 14.204414367675781, L2: 4.432963578437921e-06, L3: 1.000000238418579, L4: 50.000579833984375, L5: 0.329352468252182
Epoch 1000, Loss: 22.980764389038086, Losses: L1: 6.700201511383057, L2: 0.6471595168113708, L3: 0.29972392320632935, L4: 7.59597110748291, L5: 0.16559457778930664
Epoch 1500, Loss: 20.485158920288086, Losses: L1: 5.287750244140625, L2: 0.4397043287754059, L3: 0.16250574588775635, L4: 7.2315521240234375, L5: 0.1894393414258957
Epoch 2000, Loss: 9.772054672241211, Losses: L1: 5.267421245574951, L2: 0.3799132704734802, L3: 0.12565267086029053, L4: 1.9544144868850708, L5: 0.15454325079917908
Epoch 2500, Loss: 10.359386444091797, Losses: L1: 5.325287818908691, L2: 0.21312084794044495, L3: 0.1578020453453064, L4: 2.226978302001953, L5: 0.15797822177410126
Epoch 3000, Loss: 113.42082214355469, Losses: L1: 11.110125541687012, L2: 0.0006594832520931959, L3: 0.9994395971298218, L4: 49.99128723144531, L5: 0.3289133608341217
Epoch 3500, Loss: 19.600452423095703, Losses: L1: 7.122805118560791, L2: 0.43041396141052246, L3: 0.27503395080566406, L4: 5.777350425720215, L5: 0.15767033398151398
Epoch 4000, Loss: 15.80846881866455, Losses: L1: 6.480151653289795, L2: 0.31345105171203613, L3: 0.2374511957168579, L4: 4.26772928237915, L5: 0.161231130361557
Epoch 4500, Loss: 12.944128036499023, Losses: L1: 5.917362689971924, L2: 0.2601114809513092, L3: 0.18904131650924683, L4: 3.178522825241089, L5: 0.1615811139345169
Epoch 5000, Loss: 11.921966552734375, Losses: L1: 5.583914279937744, L2: 0.2465878576040268, L3: 0.17431646585464478, L4: 2.853412389755249, L5: 0.15930089354515076
Epoch 5500, Loss: 11.658123016357422, Losses: L1: 5.51400899887085, L2: 0.23738993704319, L3: 0.17641490697860718, L4: 2.757495403289795, L5: 0.15759849548339844
Epoch 6000, Loss: 11.522741317749023, Losses: L1: 5.495547771453857, L2: 0.23112423717975616, L3: 0.17824101448059082, L4: 2.699204921722412, L5: 0.15674054622650146
Epoch 6500, Loss: 11.436424255371094, Losses: L1: 5.489075660705566, L2: 0.22598300874233246, L3: 0.1796671748161316, L4: 2.6594040393829346, L5: 0.15621508657932281
Epoch 7000, Loss: 11.340794563293457, Losses: L1: 5.440527439117432, L2: 0.22351303696632385, L3: 0.1787242889404297, L4: 2.6372909545898438, L5: 0.15648026764392853
Epoch 7500, Loss: 11.301488876342773, Losses: L1: 5.435454845428467, L2: 0.2206948697566986, L3: 0.1787264347076416, L4: 2.6208927631378174, L5: 0.15644866228103638
Epoch 8000, Loss: 11.276251792907715, Losses: L1: 5.434269905090332, L2: 0.21910634636878967, L3: 0.17903423309326172, L4: 2.609048843383789, L5: 0.1562621295452118
Epoch 8500, Loss: 11.258626937866211, Losses: L1: 5.433427333831787, L2: 0.21806283295154572, L3: 0.1792067289352417, L4: 2.600841522216797, L5: 0.15607185661792755
Epoch 9000, Loss: 11.246030807495117, Losses: L1: 5.432648658752441, L2: 0.21720224618911743, L3: 0.17930275201797485, L4: 2.5951080322265625, L5: 0.15595996379852295
Epoch 9500, Loss: 11.237227439880371, Losses: L1: 5.432181358337402, L2: 0.2166108638048172, L3: 0.17936402559280396, L4: 2.5910656452178955, L5: 0.15588094294071198
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.00663161277771, Constraint losses: L1: 7.585958480834961, L2: 3.4242304536746815e-05, L3: 0.9995058178901672, L4: 0.9995056390762329
Epoch 500, Loss: 0.0024190261028707027, Constraint losses: L1: -1.0677369832992554, L2: 0.0, L3: 0.0027423501014709473, L4: 0.0007444131188094616
Epoch 1000, Loss: 0.0013584517873823643, Constraint losses: L1: -1.1179192066192627, L2: 0.0, L3: 0.002237856388092041, L4: 0.00023851457808632404
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0168468952178955, Constraint losses: L1: 16.49388885498047, L2: 0.0002991814981214702, L3: 1.0000265836715698, L4: 1.0000271797180176
Epoch 500, Loss: 0.002152353059500456, Constraint losses: L1: -1.049847960472107, L2: 0.0, L3: 0.00260007381439209, L4: 0.0006021272274665534
Epoch 1000, Loss: 0.0012526472564786673, Constraint losses: L1: -1.1162534952163696, L2: 0.0, L3: 0.0021842122077941895, L4: 0.00018468854250386357
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 181.1385955810547, Losses: L1: 8.400848388671875, L2: 4.5112621592124924e-05, L3: 0.9972738027572632, L4: 85.06256866455078, L5: 0.3090176284313202
Epoch 500, Loss: 25.394865036010742, Losses: L1: 1.4987218379974365, L2: 0.8221457004547119, L3: 0.28505462408065796, L4: 11.349264144897461, L5: 0.10821661353111267
Epoch 1000, Loss: 16.87936782836914, Losses: L1: -0.5459930896759033, L2: 1.637395977973938, L3: 0.26239776611328125, L4: 7.895795822143555, L5: 0.14513824880123138
Epoch 1500, Loss: 2.0421085357666016, Losses: L1: -1.6696417331695557, L2: 1.132227897644043, L3: 0.10940027236938477, L4: 1.3770772218704224, L5: 0.08634062111377716
Epoch 2000, Loss: 0.7848952412605286, Losses: L1: -1.7646974325180054, L2: 1.0980360507965088, L3: 0.0901327133178711, L4: 0.8362908959388733, L5: 0.07386370748281479
Epoch 2500, Loss: 0.33142122626304626, Losses: L1: -1.8370963335037231, L2: 1.1098295450210571, L3: 0.08269357681274414, L4: 0.6518217325210571, L5: 0.07228605449199677
Epoch 3000, Loss: 0.3723266124725342, Losses: L1: -1.897747278213501, L2: 1.1390283107757568, L3: 0.08041483163833618, L4: 0.6990266442298889, L5: 0.07083839178085327
Epoch 3500, Loss: 0.09858302772045135, Losses: L1: -1.9320567846298218, L2: 1.1572223901748657, L3: 0.07922697067260742, L4: 0.5759481191635132, L5: 0.07083918899297714
Epoch 4000, Loss: 0.01839415729045868, Losses: L1: -1.9683198928833008, L2: 1.1738258600234985, L3: 0.07819873094558716, L4: 0.551535964012146, L5: 0.07016589492559433
Epoch 4500, Loss: -0.024418234825134277, Losses: L1: -1.984193205833435, L2: 1.179409384727478, L3: 0.07818245887756348, L4: 0.5371062755584717, L5: 0.06974643468856812
Epoch 5000, Loss: -0.06355354189872742, Losses: L1: -1.9965099096298218, L2: 1.1868547201156616, L3: 0.0774034857749939, L4: 0.523248553276062, L5: 0.06911249458789825
Epoch 5500, Loss: -0.09314116835594177, Losses: L1: -2.007906436920166, L2: 1.1963355541229248, L3: 0.07524007558822632, L4: 0.5145243406295776, L5: 0.06853432953357697
Epoch 6000, Loss: -0.11552272737026215, Losses: L1: -2.017651081085205, L2: 1.2060515880584717, L3: 0.0720442533493042, L4: 0.5091865658760071, L5: 0.06832046061754227
Epoch 6500, Loss: -0.13344377279281616, Losses: L1: -2.026367425918579, L2: 1.2154837846755981, L3: 0.06888413429260254, L4: 0.505702555179596, L5: 0.06800422072410583
Epoch 7000, Loss: -0.14609891176223755, Losses: L1: -2.0327401161193848, L2: 1.2227637767791748, L3: 0.06624066829681396, L4: 0.5035822987556458, L5: 0.06780669093132019
Epoch 7500, Loss: -0.15483570098876953, Losses: L1: -2.0373198986053467, L2: 1.2280848026275635, L3: 0.06422996520996094, L4: 0.5023221373558044, L5: 0.06766879558563232
Epoch 8000, Loss: -0.16085009276866913, Losses: L1: -2.0402424335479736, L2: 1.2319061756134033, L3: 0.06281077861785889, L4: 0.5012774467468262, L5: 0.06763140112161636
Epoch 8500, Loss: -0.1648668348789215, Losses: L1: -2.042019844055176, L2: 1.2339822053909302, L3: 0.06194239854812622, L4: 0.5005371570587158, L5: 0.06760142743587494
Epoch 9000, Loss: -0.16750968992710114, Losses: L1: -2.0434391498565674, L2: 1.2356171607971191, L3: 0.06135571002960205, L4: 0.500141441822052, L5: 0.06756328791379929
Epoch 9500, Loss: -0.16929474472999573, Losses: L1: -2.0443999767303467, L2: 1.2368860244750977, L3: 0.06095004081726074, L4: 0.4998214542865753, L5: 0.067559614777565
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0090532302856445, Constraint losses: L1: 9.322908401489258, L2: 7.183419802458957e-05, L3: 0.9998293519020081, L4: 0.9998292922973633
Epoch 500, Loss: 0.002574492944404483, Constraint losses: L1: -1.107000708580017, L2: 0.0, L3: 0.002839803695678711, L4: 0.0008416900527663529
Epoch 1000, Loss: 0.001441125525161624, Constraint losses: L1: -1.1182719469070435, L2: 0.0, L3: 0.0022794008255004883, L4: 0.00027999660233035684
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0052542686462402, Constraint losses: L1: 6.992086410522461, L2: 0.0, L3: 0.9991311430931091, L4: 0.9991310238838196
Epoch 500, Loss: 0.0025278814136981964, Constraint losses: L1: -0.9436282515525818, L2: 0.0, L3: 0.002734661102294922, L4: 0.0007368485676124692
Epoch 1000, Loss: 0.0013231869088485837, Constraint losses: L1: -1.1099728345870972, L2: 0.0, L3: 0.002216339111328125, L4: 0.00021682069927919656
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.13053512573242, Losses: L1: 10.34603214263916, L2: 0.00033804375561885536, L3: 0.9989411234855652, L4: 76.31208801269531, L5: 0.25730159878730774
Epoch 500, Loss: 0.5461120009422302, Losses: L1: -2.161396026611328, L2: 0.8579736351966858, L3: 0.10817813873291016, L4: 3.5363218784332275, L5: 0.05456884577870369
Epoch 1000, Loss: -0.5953096747398376, Losses: L1: -2.618833541870117, L2: 0.7566370368003845, L3: 0.08037745952606201, L4: 2.4094648361206055, L5: 0.04393116384744644
Epoch 1500, Loss: -1.8574093580245972, Losses: L1: -2.920907497406006, L2: 0.740065336227417, L3: 0.07111167907714844, L4: 0.5580980777740479, L5: 0.017655938863754272
Epoch 2000, Loss: -1.9911608695983887, Losses: L1: -3.112860679626465, L2: 0.711688756942749, L3: 0.06293648481369019, L4: 0.7380900382995605, L5: 0.018995817750692368
Epoch 2500, Loss: -2.191634178161621, Losses: L1: -3.2427451610565186, L2: 0.7390247583389282, L3: 0.06106215715408325, L4: 0.5470205545425415, L5: 0.0160896684974432
Epoch 3000, Loss: -2.408172607421875, Losses: L1: -3.3141744136810303, L2: 0.7358365654945374, L3: 0.05921304225921631, L4: 0.2662617564201355, L5: 0.014855848625302315
Epoch 3500, Loss: -2.5250396728515625, Losses: L1: -3.401517629623413, L2: 0.7239652872085571, L3: 0.05727732181549072, L4: 0.23476558923721313, L5: 0.01298241876065731
Epoch 4000, Loss: -2.649043560028076, Losses: L1: -3.4732110500335693, L2: 0.6881201267242432, L3: 0.054621100425720215, L4: 0.20431318879127502, L5: 0.01316028367727995
Epoch 4500, Loss: -2.7669684886932373, Losses: L1: -3.5811948776245117, L2: 0.6837068796157837, L3: 0.051980018615722656, L4: 0.19600169360637665, L5: 0.013057537376880646
Epoch 5000, Loss: -2.854729175567627, Losses: L1: -3.6523895263671875, L2: 0.669675350189209, L3: 0.049453914165496826, L4: 0.19356085360050201, L5: 0.012954986654222012
Epoch 5500, Loss: -2.9125874042510986, Losses: L1: -3.701564073562622, L2: 0.6639452576637268, L3: 0.04743850231170654, L4: 0.18993119895458221, L5: 0.012692997232079506
Epoch 6000, Loss: -2.9554460048675537, Losses: L1: -3.7423439025878906, L2: 0.6640989780426025, L3: 0.046108245849609375, L4: 0.18692633509635925, L5: 0.012563192285597324
Epoch 6500, Loss: -2.9868240356445312, Losses: L1: -3.780808687210083, L2: 0.6723558306694031, L3: 0.044855475425720215, L4: 0.18591567873954773, L5: 0.012486374005675316
Epoch 7000, Loss: -3.010305166244507, Losses: L1: -3.8158438205718994, L2: 0.6829959154129028, L3: 0.04367804527282715, L4: 0.1890648901462555, L5: 0.012342158704996109
Epoch 7500, Loss: -3.0278549194335938, Losses: L1: -3.840693950653076, L2: 0.6888830661773682, L3: 0.04268467426300049, L4: 0.19296926259994507, L5: 0.012257960624992847
Epoch 8000, Loss: -3.040558099746704, Losses: L1: -3.8572428226470947, L2: 0.6930971145629883, L3: 0.04166477918624878, L4: 0.19331064820289612, L5: 0.012199903838336468
Epoch 8500, Loss: -3.04923152923584, Losses: L1: -3.8656671047210693, L2: 0.6929280161857605, L3: 0.040836870670318604, L4: 0.19401158392429352, L5: 0.012166541069746017
Epoch 9000, Loss: -3.055131673812866, Losses: L1: -3.872882604598999, L2: 0.6944636702537537, L3: 0.04027140140533447, L4: 0.1941494643688202, L5: 0.012153608724474907
Epoch 9500, Loss: -3.0591139793395996, Losses: L1: -3.879693031311035, L2: 0.6975564360618591, L3: 0.039865970611572266, L4: 0.1940215677022934, L5: 0.012157272547483444
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9994066953659058, Constraint losses: L1: 5.7349138259887695, L2: 0.0, L3: 0.9968361258506775, L4: 0.9968357086181641
Epoch 500, Loss: 0.0022962414659559727, Constraint losses: L1: -1.0741082429885864, L2: 0.0, L3: 0.0026842355728149414, L4: 0.0006861141882836819
Epoch 1000, Loss: 0.0013112042797729373, Constraint losses: L1: -1.1180555820465088, L2: 0.0, L3: 0.002214372158050537, L4: 0.00021488775382749736
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019803762435913, Constraint losses: L1: 18.42068099975586, L2: 0.0004610254254657775, L3: 1.0004609823226929, L4: 1.0004611015319824
Epoch 500, Loss: 0.0023974725045263767, Constraint losses: L1: -1.1054580211639404, L2: 0.0, L3: 0.0027505159378051758, L4: 0.0007524146931245923
Epoch 1000, Loss: 0.0013778099091723561, Constraint losses: L1: -1.1170873641967773, L2: 0.0, L3: 0.0022470951080322266, L4: 0.0002478022361174226
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 53.741233825683594, Losses: L1: 17.457075119018555, L2: 0.00216159806586802, L3: 1.0021531581878662, L4: 71.09359741210938, L5: 0.23412367701530457
Epoch 500, Loss: -0.02021746337413788, Losses: L1: -2.5052270889282227, L2: 0.9106525182723999, L3: 0.10573774576187134, L4: 2.9494552612304688, L5: 0.04676063358783722
Epoch 1000, Loss: -1.7266947031021118, Losses: L1: -3.487521171569824, L2: 0.5734999179840088, L3: 0.07104665040969849, L4: 2.252013921737671, L5: 0.025796202942728996
Epoch 1500, Loss: -1.4071335792541504, Losses: L1: -2.461413621902466, L2: 0.5284267067909241, L3: 0.06789690256118774, L4: 0.9549476504325867, L5: 0.01443108357489109
Epoch 2000, Loss: -1.9059895277023315, Losses: L1: -2.8614890575408936, L2: 0.5586780309677124, L3: 0.05995190143585205, L4: 0.7078766822814941, L5: 0.012907430529594421
Epoch 2500, Loss: -2.221264123916626, Losses: L1: -3.095947027206421, L2: 0.5986896753311157, L3: 0.05997931957244873, L4: 0.4650906026363373, L5: 0.013458034954965115
Epoch 3000, Loss: -2.3830411434173584, Losses: L1: -3.171738386154175, L2: 0.6169235110282898, L3: 0.05702805519104004, L4: 0.2612438201904297, L5: 0.012637965381145477
Epoch 3500, Loss: -2.4499239921569824, Losses: L1: -3.2387938499450684, L2: 0.6325888633728027, L3: 0.05611574649810791, L4: 0.23010225594043732, L5: 0.013172158040106297
Epoch 4000, Loss: -2.4867379665374756, Losses: L1: -3.2830488681793213, L2: 0.6452158093452454, L3: 0.05548560619354248, L4: 0.2197665572166443, L5: 0.013469012454152107
Epoch 4500, Loss: -2.5095975399017334, Losses: L1: -3.307422637939453, L2: 0.6487100124359131, L3: 0.0547909140586853, L4: 0.21630381047725677, L5: 0.013567605055868626
Epoch 5000, Loss: -2.5281872749328613, Losses: L1: -3.320586681365967, L2: 0.6428540945053101, L3: 0.054497480392456055, L4: 0.21719372272491455, L5: 0.013699505478143692
Epoch 5500, Loss: -2.5428504943847656, Losses: L1: -3.334937572479248, L2: 0.6420789957046509, L3: 0.054195523262023926, L4: 0.2182525396347046, L5: 0.013784096576273441
Epoch 6000, Loss: -2.553849697113037, Losses: L1: -3.3440189361572266, L2: 0.6391322016716003, L3: 0.054130613803863525, L4: 0.2202574908733368, L5: 0.013842999003827572
Epoch 6500, Loss: -2.5617973804473877, Losses: L1: -3.3547275066375732, L2: 0.641737699508667, L3: 0.053891658782958984, L4: 0.22061631083488464, L5: 0.013938361778855324
Epoch 7000, Loss: -2.567495584487915, Losses: L1: -3.3606090545654297, L2: 0.6417071223258972, L3: 0.05379897356033325, L4: 0.22102855145931244, L5: 0.013992510735988617
Epoch 7500, Loss: -2.571638584136963, Losses: L1: -3.367372512817383, L2: 0.644294023513794, L3: 0.05375015735626221, L4: 0.22099578380584717, L5: 0.014066834934055805
Epoch 8000, Loss: -2.5746119022369385, Losses: L1: -3.369845151901245, L2: 0.6438502669334412, L3: 0.05369460582733154, L4: 0.22083935141563416, L5: 0.014115865342319012
Epoch 8500, Loss: -2.5766265392303467, Losses: L1: -3.371485710144043, L2: 0.6433997750282288, L3: 0.05366617441177368, L4: 0.22096693515777588, L5: 0.014143066480755806
Epoch 9000, Loss: -2.5779881477355957, Losses: L1: -3.3724253177642822, L2: 0.6429068446159363, L3: 0.053643226623535156, L4: 0.22108958661556244, L5: 0.014164025895297527
Epoch 9500, Loss: -2.5788631439208984, Losses: L1: -3.3735716342926025, L2: 0.6431959867477417, L3: 0.05362063646316528, L4: 0.22105388343334198, L5: 0.014175277203321457
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0317564010620117, Constraint losses: L1: 18.42068099975586, L2: 0.004445056430995464, L3: 1.0044450759887695, L4: 1.0044455528259277
Epoch 500, Loss: 0.002389156026765704, Constraint losses: L1: -1.0657159090042114, L2: 0.0, L3: 0.002726316452026367, L4: 0.0007285555475391448
Epoch 1000, Loss: 0.0013415502617135644, Constraint losses: L1: -1.118295431137085, L2: 0.0, L3: 0.0022295713424682617, L4: 0.0002302743523614481
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0040230751037598, Constraint losses: L1: 6.600297451019287, L2: 0.0, L3: 0.9987115263938904, L4: 0.9987112283706665
Epoch 500, Loss: 0.0019514883169904351, Constraint losses: L1: -1.0846824645996094, L2: 0.0, L3: 0.0025172829627990723, L4: 0.0005188878858461976
Epoch 1000, Loss: 0.0012117126025259495, Constraint losses: L1: -1.116778016090393, L2: 0.0, L3: 0.002164006233215332, L4: 0.00016448443057015538
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.7501220703125, Losses: L1: 15.104680061340332, L2: 0.0009214485762640834, L3: 1.000852108001709, L4: 77.22395324707031, L5: 0.26606056094169617
Epoch 500, Loss: -1.042738676071167, Losses: L1: -3.196146249771118, L2: 0.7373989820480347, L3: 0.06585603952407837, L4: 2.658916711807251, L5: 0.02681119553744793
Epoch 1000, Loss: -0.6019893288612366, Losses: L1: -2.6129558086395264, L2: 0.4736679494380951, L3: 0.06164032220840454, L4: 2.8676369190216064, L5: 0.03633001074194908
Epoch 1500, Loss: -2.8803551197052, Losses: L1: -3.9057583808898926, L2: 0.7018881440162659, L3: 0.05432426929473877, L4: 0.5350135564804077, L5: 0.014423159882426262
Epoch 2000, Loss: -3.0971426963806152, Losses: L1: -3.930955171585083, L2: 0.5357969403266907, L3: 0.04706186056137085, L4: 0.49718740582466125, L5: 0.01294540986418724
Epoch 2500, Loss: -3.116550922393799, Losses: L1: -3.9076638221740723, L2: 0.4641129672527313, L3: 0.04343235492706299, L4: 0.5600839257240295, L5: 0.01262087095528841
Epoch 3000, Loss: -3.225817918777466, Losses: L1: -3.9553420543670654, L2: 0.4387405216693878, L3: 0.04092717170715332, L4: 0.49466246366500854, L5: 0.01149449311196804
Epoch 3500, Loss: -3.3004610538482666, Losses: L1: -3.972160577774048, L2: 0.4337300658226013, L3: 0.03909468650817871, L4: 0.39525166153907776, L5: 0.010398192331194878
Epoch 4000, Loss: -3.3410141468048096, Losses: L1: -3.9800453186035156, L2: 0.42581337690353394, L3: 0.03848296403884888, L4: 0.34405550360679626, L5: 0.010974184609949589
Epoch 4500, Loss: -3.352710247039795, Losses: L1: -3.9867665767669678, L2: 0.4243946671485901, L3: 0.03730201721191406, L4: 0.3377224802970886, L5: 0.011074764654040337
Epoch 5000, Loss: -3.3630759716033936, Losses: L1: -3.996134042739868, L2: 0.4285867512226105, L3: 0.03663522005081177, L4: 0.3276650607585907, L5: 0.011160644702613354
Epoch 5500, Loss: -3.368602991104126, Losses: L1: -3.991995334625244, L2: 0.4208838641643524, L3: 0.03608602285385132, L4: 0.32375413179397583, L5: 0.011294178664684296
Epoch 6000, Loss: -3.3741865158081055, Losses: L1: -3.9940919876098633, L2: 0.4205564260482788, L3: 0.03550612926483154, L4: 0.31831181049346924, L5: 0.011220022104680538
Epoch 6500, Loss: -3.377417802810669, Losses: L1: -3.996758460998535, L2: 0.4216208755970001, L3: 0.03507030010223389, L4: 0.31527313590049744, L5: 0.011274010874330997
Epoch 7000, Loss: -3.3797736167907715, Losses: L1: -3.9974122047424316, L2: 0.42103612422943115, L3: 0.034717857837677, L4: 0.31347572803497314, L5: 0.01125274132937193
Epoch 7500, Loss: -3.381563901901245, Losses: L1: -3.9981801509857178, L2: 0.42084696888923645, L3: 0.03443688154220581, L4: 0.3121131956577301, L5: 0.011247183196246624
Epoch 8000, Loss: -3.382727861404419, Losses: L1: -3.9990451335906982, L2: 0.42103105783462524, L3: 0.034265339374542236, L4: 0.3113037943840027, L5: 0.011250817216932774
Epoch 8500, Loss: -3.3834986686706543, Losses: L1: -3.9987714290618896, L2: 0.42035144567489624, L3: 0.034157752990722656, L4: 0.3106757402420044, L5: 0.011252264492213726
Epoch 9000, Loss: -3.384018898010254, Losses: L1: -3.9988903999328613, L2: 0.42016494274139404, L3: 0.03407961130142212, L4: 0.3102983236312866, L5: 0.01125873252749443
Epoch 9500, Loss: -3.3843777179718018, Losses: L1: -3.9990079402923584, L2: 0.4200970232486725, L3: 0.03402817249298096, L4: 0.31001001596450806, L5: 0.011257012374699116
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.02502179145813, Constraint losses: L1: 18.42068099975586, L2: 0.0022001818288117647, L3: 1.0022001266479492, L4: 1.0022008419036865
Epoch 500, Loss: 0.0023955581709742546, Constraint losses: L1: -1.0947624444961548, L2: 0.0, L3: 0.0027442574501037598, L4: 0.0007460630731657147
Epoch 1000, Loss: 0.001357372268103063, Constraint losses: L1: -1.1161755323410034, L2: 0.0, L3: 0.0022365450859069824, L4: 0.0002370027214055881
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0087249279022217, Constraint losses: L1: 8.963451385498047, L2: 2.5551319140504347e-06, L3: 0.9998794794082642, L4: 0.9998794794082642
Epoch 500, Loss: 0.002476093824952841, Constraint losses: L1: -1.07405424118042, L2: 0.0, L3: 0.0027740001678466797, L4: 0.0007761480519548059
Epoch 1000, Loss: 0.0013859602622687817, Constraint losses: L1: -1.1162807941436768, L2: 0.0, L3: 0.0022507905960083008, L4: 0.0002514504885766655
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 78.15560913085938, Losses: L1: 6.080798149108887, L2: 0.0, L3: 0.997536838054657, L4: 71.45843505859375, L5: 0.23522040247917175
Epoch 500, Loss: 3.288149356842041, Losses: L1: -1.9572021961212158, L2: 0.9197160005569458, L3: 0.12909096479415894, L4: 4.228907585144043, L5: 0.06436499953269958
Epoch 1000, Loss: -1.1650387048721313, Losses: L1: -3.210822820663452, L2: 0.9459273219108582, L3: 0.06398701667785645, L4: 1.0210607051849365, L5: 0.09360519796609879
Epoch 1500, Loss: -1.7622524499893188, Losses: L1: -3.5104598999023438, L2: 0.8936149477958679, L3: 0.052347421646118164, L4: 0.7753271460533142, L5: 0.10618280619382858
Epoch 2000, Loss: -1.655766487121582, Losses: L1: -3.754880666732788, L2: 0.9137958884239197, L3: 0.04959207773208618, L4: 1.1074033975601196, L5: 0.10623760521411896
Epoch 2500, Loss: -2.4639527797698975, Losses: L1: -3.79429292678833, L2: 0.8516213893890381, L3: 0.04616379737854004, L4: 0.4018698036670685, L5: 0.10753379762172699
Epoch 3000, Loss: -2.665698528289795, Losses: L1: -3.8165719509124756, L2: 0.8362791538238525, L3: 0.04412853717803955, L4: 0.24205337464809418, L5: 0.10095340013504028
Epoch 3500, Loss: -2.7983360290527344, Losses: L1: -3.8179900646209717, L2: 0.8144176006317139, L3: 0.04393702745437622, L4: 0.13524216413497925, L5: 0.09605138748884201
Epoch 4000, Loss: -2.775930881500244, Losses: L1: -3.8196680545806885, L2: 0.8007432818412781, L3: 0.04460102319717407, L4: 0.1735670268535614, L5: 0.09425253421068192
Epoch 4500, Loss: -2.8451955318450928, Losses: L1: -3.8222906589508057, L2: 0.7924433350563049, L3: 0.045067667961120605, L4: 0.116205133497715, L5: 0.09182555973529816
Epoch 5000, Loss: -2.85805344581604, Losses: L1: -3.8213143348693848, L2: 0.7857062220573425, L3: 0.044934630393981934, L4: 0.1093701720237732, L5: 0.09143391251564026
Epoch 5500, Loss: -2.8671305179595947, Losses: L1: -3.823765277862549, L2: 0.7834311127662659, L3: 0.04525882005691528, L4: 0.10513977706432343, L5: 0.09086901694536209
Epoch 6000, Loss: -2.8716371059417725, Losses: L1: -3.8243985176086426, L2: 0.7801243662834167, L3: 0.04553639888763428, L4: 0.10478047281503677, L5: 0.09017674624919891
Epoch 6500, Loss: -2.877743721008301, Losses: L1: -3.8242790699005127, L2: 0.7771347761154175, L3: 0.04567307233810425, L4: 0.10181973874568939, L5: 0.08948878198862076
Epoch 7000, Loss: -2.8805220127105713, Losses: L1: -3.822737455368042, L2: 0.7740522623062134, L3: 0.04565608501434326, L4: 0.10083024203777313, L5: 0.08900927752256393
Epoch 7500, Loss: -2.8831703662872314, Losses: L1: -3.823056221008301, L2: 0.7731083035469055, L3: 0.04570937156677246, L4: 0.0995793342590332, L5: 0.08868718892335892
Epoch 8000, Loss: -2.8848793506622314, Losses: L1: -3.822968006134033, L2: 0.7718456387519836, L3: 0.04578220844268799, L4: 0.09914928674697876, L5: 0.08840564638376236
Epoch 8500, Loss: -2.8861405849456787, Losses: L1: -3.82190203666687, L2: 0.7699418067932129, L3: 0.04578882455825806, L4: 0.09881433099508286, L5: 0.08822217583656311
Epoch 9000, Loss: -2.88696551322937, Losses: L1: -3.8220956325531006, L2: 0.7695261240005493, L3: 0.04577493667602539, L4: 0.09866879135370255, L5: 0.08809495717287064
Epoch 9500, Loss: -2.8875691890716553, Losses: L1: -3.8225040435791016, L2: 0.7695558071136475, L3: 0.04576390981674194, L4: 0.09849357604980469, L5: 0.08800704032182693
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0029730796813965, Constraint losses: L1: 6.367080211639404, L2: 0.0, L3: 0.9983031153678894, L4: 0.9983029365539551
Epoch 500, Loss: 0.0025044921785593033, Constraint losses: L1: -1.11172616481781, L2: 0.0, L3: 0.0028071999549865723, L4: 0.0008090183837339282
Epoch 1000, Loss: 0.0014169326750561595, Constraint losses: L1: -1.1177842617034912, L2: 0.0, L3: 0.0022670626640319824, L4: 0.0002676543372217566
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0235137939453125, Constraint losses: L1: 18.42068099975586, L2: 0.0016976214246824384, L3: 1.0016976594924927, L4: 1.0016977787017822
Epoch 500, Loss: 0.0021610730327665806, Constraint losses: L1: -1.106840968132019, L2: 0.0, L3: 0.0026331543922424316, L4: 0.0006347596063278615
Epoch 1000, Loss: 0.0013003548374399543, Constraint losses: L1: -1.1154179573059082, L2: 0.0, L3: 0.0022075772285461426, L4: 0.00020819561905227602
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 88.02568054199219, Losses: L1: 14.072473526000977, L2: 0.002211658051237464, L3: 1.001050591468811, L4: 73.20645141601562, L5: 0.24401997029781342
Epoch 500, Loss: 0.9750771522521973, Losses: L1: -2.786809206008911, L2: 0.9096158146858215, L3: 0.07074534893035889, L4: 2.7758004665374756, L5: 0.04109739884734154
Epoch 1000, Loss: 1.5769528150558472, Losses: L1: -0.9270652532577515, L2: 0.2063501626253128, L3: 0.08076012134552002, L4: 2.2320313453674316, L5: 0.025256525725126266
Epoch 1500, Loss: -0.3711433410644531, Losses: L1: -1.5623332262039185, L2: 0.4788995087146759, L3: 0.06373333930969238, L4: 0.6459723711013794, L5: 0.03445136547088623
Epoch 2000, Loss: -0.6554797887802124, Losses: L1: -1.7886277437210083, L2: 0.5022613406181335, L3: 0.05725419521331787, L4: 0.573662281036377, L5: 0.02859722264111042
Epoch 2500, Loss: -1.229784607887268, Losses: L1: -2.148707628250122, L2: 0.5093197822570801, L3: 0.05422496795654297, L4: 0.3540552854537964, L5: 0.028435437008738518
Epoch 3000, Loss: -2.72052001953125, Losses: L1: -3.919480085372925, L2: 0.7776609063148499, L3: 0.005472421646118164, L4: 0.39439505338668823, L5: 0.024167867377400398
Epoch 3500, Loss: -2.8331680297851562, Losses: L1: -3.9449656009674072, L2: 0.7646703720092773, L3: 1.049041748046875e-05, L4: 0.32484570145606995, L5: 0.022276179865002632
Epoch 4000, Loss: -2.8937184810638428, Losses: L1: -3.949662923812866, L2: 0.7543014287948608, L3: 0.0017074346542358398, L4: 0.27901870012283325, L5: 0.0217706598341465
Epoch 4500, Loss: -2.9739134311676025, Losses: L1: -3.9584062099456787, L2: 0.7542960047721863, L3: 0.00020265579223632812, L4: 0.20879846811294556, L5: 0.021297043189406395
Epoch 5000, Loss: -2.9865472316741943, Losses: L1: -3.9613804817199707, L2: 0.7497525215148926, L3: 5.1021575927734375e-05, L4: 0.20389534533023834, L5: 0.021159958094358444
Epoch 5500, Loss: -2.9965758323669434, Losses: L1: -3.964092493057251, L2: 0.7473790049552917, L3: 0.0002664327621459961, L4: 0.19911225140094757, L5: 0.020892249420285225
Epoch 6000, Loss: -3.004542589187622, Losses: L1: -3.966369390487671, L2: 0.7453575730323792, L3: 7.039308547973633e-05, L4: 0.195623517036438, L5: 0.02081042341887951
Epoch 6500, Loss: -3.008728265762329, Losses: L1: -3.9685418605804443, L2: 0.7447810173034668, L3: 0.00011396408081054688, L4: 0.19424082338809967, L5: 0.020734891295433044
Epoch 7000, Loss: -3.0130534172058105, Losses: L1: -3.9689464569091797, L2: 0.7432560920715332, L3: 5.900859832763672e-05, L4: 0.19192269444465637, L5: 0.02068476378917694
Epoch 7500, Loss: -3.0156493186950684, Losses: L1: -3.969229221343994, L2: 0.7423830032348633, L3: 3.838539123535156e-05, L4: 0.19051887094974518, L5: 0.020659025758504868
Epoch 8000, Loss: -3.017338991165161, Losses: L1: -3.969078779220581, L2: 0.741354763507843, L3: 1.3709068298339844e-06, L4: 0.1897323727607727, L5: 0.020651958882808685
Epoch 8500, Loss: -3.018535852432251, Losses: L1: -3.969163656234741, L2: 0.7408181428909302, L3: 3.8743019104003906e-05, L4: 0.1891525685787201, L5: 0.020637737587094307
Epoch 9000, Loss: -3.019296884536743, Losses: L1: -3.9694020748138428, L2: 0.7406607270240784, L3: 1.3113021850585938e-05, L4: 0.18880817294120789, L5: 0.02062991075217724
Epoch 9500, Loss: -3.019782066345215, Losses: L1: -3.9696033000946045, L2: 0.740601658821106, L3: 1.3709068298339844e-06, L4: 0.18859870731830597, L5: 0.020620040595531464
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020841360092163, Constraint losses: L1: 18.42068099975586, L2: 0.0008069048635661602, L3: 1.0008069276809692, L4: 1.0008068084716797
Epoch 500, Loss: 0.0018631296698004007, Constraint losses: L1: -1.0748924016952515, L2: 0.0, L3: 0.0024682283401489258, L4: 0.0004697938566096127
Epoch 1000, Loss: 0.0011744137154892087, Constraint losses: L1: -1.1184451580047607, L2: 0.0, L3: 0.0021461844444274902, L4: 0.00014667448704130948
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.029536724090576, Constraint losses: L1: 18.42068099975586, L2: 0.0037054773420095444, L3: 1.0037055015563965, L4: 1.0037051439285278
Epoch 500, Loss: 0.0021663284860551357, Constraint losses: L1: -1.042181134223938, L2: 0.0, L3: 0.0026033520698547363, L4: 0.0006051576929166913
Epoch 1000, Loss: 0.0012437279801815748, Constraint losses: L1: -1.1158679723739624, L2: 0.0, L3: 0.0021795034408569336, L4: 0.00018009250925388187
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 92.17825317382812, Losses: L1: 12.043402671813965, L2: 9.410054190084338e-05, L3: 0.9997977614402771, L4: 79.08821868896484, L5: 0.2733179032802582
Epoch 500, Loss: 1.741162896156311, Losses: L1: -1.3938664197921753, L2: 0.4564625024795532, L3: 0.09568333625793457, L4: 2.5410430431365967, L5: 0.04484106972813606
Epoch 1000, Loss: -0.07856158912181854, Losses: L1: -1.7831389904022217, L2: 0.4801934063434601, L3: 0.10112082958221436, L4: 1.1178239583969116, L5: 0.027999797835946083
Epoch 1500, Loss: -0.5280315279960632, Losses: L1: -2.2201969623565674, L2: 0.7108086347579956, L3: 0.06790775060653687, L4: 0.8827375769615173, L5: 0.03233266621828079
Epoch 2000, Loss: -1.095599889755249, Losses: L1: -2.5786216259002686, L2: 0.6258076429367065, L3: 0.0636492371559143, L4: 0.7673698663711548, L5: 0.02900981344282627
Epoch 2500, Loss: -1.3532358407974243, Losses: L1: -2.6765921115875244, L2: 0.5847371220588684, L3: 0.060253143310546875, L4: 0.655081033706665, L5: 0.02670581266283989
Epoch 3000, Loss: -1.7258837223052979, Losses: L1: -2.730267286300659, L2: 0.5716980695724487, L3: 0.058143556118011475, L4: 0.34754079580307007, L5: 0.028036486357450485
Epoch 3500, Loss: -1.870737910270691, Losses: L1: -2.778904438018799, L2: 0.586396336555481, L3: 0.056556880474090576, L4: 0.23964807391166687, L5: 0.026921911165118217
Epoch 4000, Loss: -1.9227714538574219, Losses: L1: -2.800952672958374, L2: 0.5854800939559937, L3: 0.05646103620529175, L4: 0.2106088101863861, L5: 0.026930980384349823
Epoch 4500, Loss: -1.9480847120285034, Losses: L1: -2.816408634185791, L2: 0.5821883082389832, L3: 0.0562782883644104, L4: 0.20438794791698456, L5: 0.026804281398653984
Epoch 5000, Loss: -1.969545602798462, Losses: L1: -2.8318722248077393, L2: 0.5838140249252319, L3: 0.05587363243103027, L4: 0.19757631421089172, L5: 0.02649972401559353
Epoch 5500, Loss: -1.9844402074813843, Losses: L1: -2.8447959423065186, L2: 0.5854116678237915, L3: 0.055553436279296875, L4: 0.19446277618408203, L5: 0.026352202519774437
Epoch 6000, Loss: -1.995335340499878, Losses: L1: -2.8540563583374023, L2: 0.5856361985206604, L3: 0.05540108680725098, L4: 0.19290843605995178, L5: 0.02623794786632061
Epoch 6500, Loss: -2.003253221511841, Losses: L1: -2.8574845790863037, L2: 0.5822824239730835, L3: 0.05533629655838013, L4: 0.19196994602680206, L5: 0.026155464351177216
Epoch 7000, Loss: -2.0094265937805176, Losses: L1: -2.8662221431732178, L2: 0.586435854434967, L3: 0.055108606815338135, L4: 0.1906351000070572, L5: 0.026085078716278076
Epoch 7500, Loss: -2.013665199279785, Losses: L1: -2.869278907775879, L2: 0.5859637260437012, L3: 0.055051326751708984, L4: 0.19004149734973907, L5: 0.026041418313980103
Epoch 8000, Loss: -2.0167770385742188, Losses: L1: -2.8712005615234375, L2: 0.5853090882301331, L3: 0.05503934621810913, L4: 0.1895083338022232, L5: 0.026043187826871872
Epoch 8500, Loss: -2.018876075744629, Losses: L1: -2.872715950012207, L2: 0.5851601958274841, L3: 0.05500364303588867, L4: 0.1891007274389267, L5: 0.026038585230708122
Epoch 9000, Loss: -2.0202512741088867, Losses: L1: -2.8739542961120605, L2: 0.5853868126869202, L3: 0.05497407913208008, L4: 0.18877220153808594, L5: 0.02602856419980526
Epoch 9500, Loss: -2.0211453437805176, Losses: L1: -2.8749327659606934, L2: 0.5857020020484924, L3: 0.054952144622802734, L4: 0.1885679066181183, L5: 0.02602073922753334
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.02311372756958, Constraint losses: L1: 18.42068099975586, L2: 0.0015644100494682789, L3: 1.001564383506775, L4: 1.0015642642974854
Epoch 500, Loss: 0.00253551104106009, Constraint losses: L1: -1.0633794069290161, L2: 0.0, L3: 0.00279843807220459, L4: 0.0008004524279385805
Epoch 1000, Loss: 0.0013887216337025166, Constraint losses: L1: -1.116284728050232, L2: 0.0, L3: 0.0022521615028381348, L4: 0.0002528448821976781
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0063610076904297, Constraint losses: L1: 7.449236869812012, L2: 2.019230350924772e-06, L3: 0.9994548559188843, L4: 0.9994547367095947
Epoch 500, Loss: 0.001952436869032681, Constraint losses: L1: -1.1079026460647583, L2: 0.0, L3: 0.002529442310333252, L4: 0.0005308972904458642
Epoch 1000, Loss: 0.00122943299356848, Constraint losses: L1: -1.1161248683929443, L2: 0.0, L3: 0.0021724700927734375, L4: 0.00017308782844338566
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.8137664794922, Losses: L1: 5.865941524505615, L2: 0.0004506714176386595, L3: 0.997868537902832, L4: 80.65298461914062, L5: 0.2849496603012085
Epoch 500, Loss: 3.6456027030944824, Losses: L1: -1.728380560874939, L2: 0.6423215866088867, L3: 0.0929100513458252, L4: 2.3348937034606934, L5: 0.030838292092084885
Epoch 1000, Loss: 1.9122809171676636, Losses: L1: -2.1856353282928467, L2: 0.7574459910392761, L3: 0.0760430097579956, L4: 1.64432954788208, L5: 0.02757916785776615
Epoch 1500, Loss: -0.2503742575645447, Losses: L1: -2.488525390625, L2: 0.8106650114059448, L3: 0.0738222599029541, L4: 0.6897607445716858, L5: 0.02210698276758194
Epoch 2000, Loss: 0.03935759887099266, Losses: L1: -2.6223151683807373, L2: 0.8432611227035522, L3: 0.07078146934509277, L4: 0.8864019513130188, L5: 0.02043401449918747
Epoch 2500, Loss: -0.7341775894165039, Losses: L1: -2.6894049644470215, L2: 0.8146352171897888, L3: 0.07074439525604248, L4: 0.5483534932136536, L5: 0.017025666311383247
Epoch 3000, Loss: -0.7780139446258545, Losses: L1: -2.7144720554351807, L2: 0.8025588393211365, L3: 0.06871241331100464, L4: 0.545475959777832, L5: 0.017182083800435066
Epoch 3500, Loss: -1.2601571083068848, Losses: L1: -2.735008478164673, L2: 0.7853643298149109, L3: 0.06860464811325073, L4: 0.3234109878540039, L5: 0.016725359484553337
Epoch 4000, Loss: -1.3441433906555176, Losses: L1: -2.7407047748565674, L2: 0.7686050534248352, L3: 0.06774014234542847, L4: 0.29297345876693726, L5: 0.016278674826025963
Epoch 4500, Loss: -1.401185393333435, Losses: L1: -2.7529141902923584, L2: 0.7616240382194519, L3: 0.06688857078552246, L4: 0.2743913531303406, L5: 0.015755468979477882
Epoch 5000, Loss: -1.4438930749893188, Losses: L1: -2.766206979751587, L2: 0.7628737688064575, L3: 0.06591898202896118, L4: 0.259346604347229, L5: 0.015574787743389606
Epoch 5500, Loss: -1.4756174087524414, Losses: L1: -2.775099039077759, L2: 0.762813925743103, L3: 0.06515610218048096, L4: 0.24820613861083984, L5: 0.015355156734585762
Epoch 6000, Loss: -1.4974356889724731, Losses: L1: -2.784996747970581, L2: 0.7667400240898132, L3: 0.06454217433929443, L4: 0.24045047163963318, L5: 0.015297768637537956
Epoch 6500, Loss: -1.513873815536499, Losses: L1: -2.78995943069458, L2: 0.767744243144989, L3: 0.06421387195587158, L4: 0.23430956900119781, L5: 0.01523054763674736
Epoch 7000, Loss: -1.522143006324768, Losses: L1: -2.795372247695923, L2: 0.7708495855331421, L3: 0.06381702423095703, L4: 0.2314382642507553, L5: 0.015189510770142078
Epoch 7500, Loss: -1.5311864614486694, Losses: L1: -2.79803729057312, L2: 0.7720826268196106, L3: 0.06365501880645752, L4: 0.2276701182126999, L5: 0.015201198868453503
Epoch 8000, Loss: -1.535362720489502, Losses: L1: -2.799381971359253, L2: 0.7725916504859924, L3: 0.06350380182266235, L4: 0.22603978216648102, L5: 0.01519239041954279
Epoch 8500, Loss: -1.5372140407562256, Losses: L1: -2.800433397293091, L2: 0.7731069326400757, L3: 0.06339937448501587, L4: 0.22541123628616333, L5: 0.015180874615907669
Epoch 9000, Loss: -1.5397182703018188, Losses: L1: -2.8011972904205322, L2: 0.7734623551368713, L3: 0.0633467435836792, L4: 0.22437897324562073, L5: 0.015170802362263203
Epoch 9500, Loss: -1.5407472848892212, Losses: L1: -2.8016178607940674, L2: 0.7737287282943726, L3: 0.06329107284545898, L4: 0.22395555675029755, L5: 0.015170502476394176
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020470380783081, Constraint losses: L1: 18.42068099975586, L2: 0.0007174808997660875, L3: 1.0006660223007202, L4: 1.0006661415100098
Epoch 500, Loss: 0.0024931849911808968, Constraint losses: L1: -1.1061255931854248, L2: 0.0, L3: 0.002798736095428467, L4: 0.0008005744311958551
Epoch 1000, Loss: 0.0014098887331783772, Constraint losses: L1: -1.1186926364898682, L2: 0.0, L3: 0.002263963222503662, L4: 0.00026461813831701875
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0233678817749023, Constraint losses: L1: 18.42068099975586, L2: 0.0016488897381350398, L3: 1.0016489028930664, L4: 1.001649260520935
Epoch 500, Loss: 0.0024357717484235764, Constraint losses: L1: -1.1025770902633667, L2: 0.0, L3: 0.002768218517303467, L4: 0.0007701304275542498
Epoch 1000, Loss: 0.0013868946116417646, Constraint losses: L1: -1.117089867591858, L2: 0.0, L3: 0.0022516846656799316, L4: 0.0002522998838685453
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 183.46316528320312, Losses: L1: 18.42068099975586, L2: 0.002363251755014062, L3: 1.0023630857467651, L4: 82.12462615966797, L5: 0.289693146944046
Epoch 500, Loss: 9.346076011657715, Losses: L1: 2.0311310291290283, L2: 0.31957197189331055, L3: 0.126029372215271, L4: 3.4224963188171387, L5: 0.0873652845621109
Epoch 1000, Loss: 9.871132850646973, Losses: L1: 0.526877760887146, L2: 0.17562837898731232, L3: 0.07450497150421143, L4: 4.548770904541016, L5: 0.03383273258805275
Epoch 1500, Loss: 4.743780612945557, Losses: L1: -1.3680479526519775, L2: 0.4366583824157715, L3: 0.10933226346969604, L4: 2.792712688446045, L5: 0.035078465938568115
Epoch 2000, Loss: 0.8754144310951233, Losses: L1: -1.6394375562667847, L2: 0.6029281616210938, L3: 0.08084255456924438, L4: 0.9152584075927734, L5: 0.04098575934767723
Epoch 2500, Loss: 0.17370375990867615, Losses: L1: -1.75197172164917, L2: 0.6626906991004944, L3: 0.07420355081558228, L4: 0.5921979546546936, L5: 0.041487183421850204
Epoch 3000, Loss: -0.2285882830619812, Losses: L1: -1.8093270063400269, L2: 0.67267906665802, L3: 0.07208561897277832, L4: 0.41431161761283875, L5: 0.043393611907958984
Epoch 3500, Loss: -0.34456753730773926, Losses: L1: -1.8247648477554321, L2: 0.6883870959281921, L3: 0.07024991512298584, L4: 0.3565822243690491, L5: 0.043520793318748474
Epoch 4000, Loss: -0.4202689230442047, Losses: L1: -1.8379977941513062, L2: 0.690798819065094, L3: 0.06910872459411621, L4: 0.324474573135376, L5: 0.04342649504542351
Epoch 4500, Loss: -0.46070125699043274, Losses: L1: -1.8460968732833862, L2: 0.6948747634887695, L3: 0.06814825534820557, L4: 0.3067184090614319, L5: 0.04300985112786293
Epoch 5000, Loss: -0.4827461540699005, Losses: L1: -1.8544842004776, L2: 0.6988464593887329, L3: 0.06738603115081787, L4: 0.29805421829223633, L5: 0.043090078979730606
Epoch 5500, Loss: -0.49646252393722534, Losses: L1: -1.8611255884170532, L2: 0.7017305493354797, L3: 0.0668993592262268, L4: 0.2931177318096161, L5: 0.04324735701084137
Epoch 6000, Loss: -0.5059096813201904, Losses: L1: -1.8650544881820679, L2: 0.7027797698974609, L3: 0.06649130582809448, L4: 0.2898785173892975, L5: 0.043362319469451904
Epoch 6500, Loss: -0.512909471988678, Losses: L1: -1.8676153421401978, L2: 0.7034779191017151, L3: 0.06617140769958496, L4: 0.28738558292388916, L5: 0.04337099939584732
Epoch 7000, Loss: -0.5182710289955139, Losses: L1: -1.8699465990066528, L2: 0.7042655944824219, L3: 0.0659436583518982, L4: 0.2855164408683777, L5: 0.04340523108839989
Epoch 7500, Loss: -0.5219407677650452, Losses: L1: -1.8715428113937378, L2: 0.7049986124038696, L3: 0.06577181816101074, L4: 0.2841455936431885, L5: 0.043426308780908585
Epoch 8000, Loss: -0.5245744585990906, Losses: L1: -1.8727481365203857, L2: 0.705479621887207, L3: 0.06565535068511963, L4: 0.28321537375450134, L5: 0.04343566671013832
Epoch 8500, Loss: -0.5262055397033691, Losses: L1: -1.8736170530319214, L2: 0.7058884501457214, L3: 0.06556922197341919, L4: 0.2826477289199829, L5: 0.04344308003783226
Epoch 9000, Loss: -0.5275070071220398, Losses: L1: -1.8740811347961426, L2: 0.7061223387718201, L3: 0.06550675630569458, L4: 0.2821291387081146, L5: 0.043440110981464386
Epoch 9500, Loss: -0.5282604098320007, Losses: L1: -1.8743911981582642, L2: 0.706266462802887, L3: 0.06546527147293091, L4: 0.2818433344364166, L5: 0.04344501718878746
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0305259227752686, Constraint losses: L1: 18.42068099975586, L2: 0.004034807439893484, L3: 1.0040347576141357, L4: 1.0040357112884521
Epoch 500, Loss: 0.002242353279143572, Constraint losses: L1: -1.0901970863342285, L2: 0.0, L3: 0.0026653409004211426, L4: 0.0006672093877568841
Epoch 1000, Loss: 0.0012986809015274048, Constraint losses: L1: -1.1154773235321045, L2: 0.0, L3: 0.002206742763519287, L4: 0.00020741554908454418
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0258915424346924, Constraint losses: L1: 18.42068099975586, L2: 0.002490005688741803, L3: 1.0024900436401367, L4: 1.002490758895874
Epoch 500, Loss: 0.0020726267248392105, Constraint losses: L1: -0.9651254415512085, L2: 0.0, L3: 0.0025180578231811523, L4: 0.0005196945276111364
Epoch 1000, Loss: 0.0011602252488955855, Constraint losses: L1: -1.1155242919921875, L2: 0.0, L3: 0.0021376609802246094, L4: 0.0001380885805701837
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 175.44403076171875, Losses: L1: 11.413605690002441, L2: 0.0006258420762605965, L3: 0.9997696876525879, L4: 81.47819519042969, L5: 0.28675761818885803
Epoch 500, Loss: 8.455815315246582, Losses: L1: 2.709439992904663, L2: 0.11121965199708939, L3: 0.10932326316833496, L4: 2.673464298248291, L5: 0.11678270250558853
Epoch 1000, Loss: 4.666574478149414, Losses: L1: -0.5686455368995667, L2: 0.2299456000328064, L3: 0.1369154453277588, L4: 2.4385035037994385, L5: 0.02990487590432167
Epoch 1500, Loss: 6.736809253692627, Losses: L1: -1.0028115510940552, L2: 0.2629597783088684, L3: 0.11604928970336914, L4: 3.6753571033477783, L5: 0.033961016684770584
Epoch 2000, Loss: 1.1940443515777588, Losses: L1: -1.0611743927001953, L2: 0.25824618339538574, L3: 0.09529346227645874, L4: 0.9550467133522034, L5: 0.019616160541772842
Epoch 2500, Loss: 0.852695882320404, Losses: L1: -1.1920603513717651, L2: 0.2645709812641144, L3: 0.09387695789337158, L4: 0.849013090133667, L5: 0.017610324546694756
Epoch 3000, Loss: 0.9549022316932678, Losses: L1: -1.2366182804107666, L2: 0.2736315429210663, L3: 0.0893547534942627, L4: 0.9176428318023682, L5: 0.018962962552905083
Epoch 3500, Loss: 0.21753236651420593, Losses: L1: -1.2578741312026978, L2: 0.28606942296028137, L3: 0.08547025918960571, L4: 0.5552158951759338, L5: 0.018085109069943428
Epoch 4000, Loss: 0.14920863509178162, Losses: L1: -1.272119164466858, L2: 0.28930944204330444, L3: 0.08484464883804321, L4: 0.5261989831924438, L5: 0.018599018454551697
Epoch 4500, Loss: 0.11015436053276062, Losses: L1: -1.2800981998443604, L2: 0.29471057653427124, L3: 0.08385157585144043, L4: 0.5084260106086731, L5: 0.018382089212536812
Epoch 5000, Loss: 0.07682971656322479, Losses: L1: -1.2864996194839478, L2: 0.29895374178886414, L3: 0.08299970626831055, L4: 0.49325814843177795, L5: 0.01817970722913742
Epoch 5500, Loss: 0.05907924845814705, Losses: L1: -1.2916228771209717, L2: 0.302482008934021, L3: 0.08219790458679199, L4: 0.48542320728302, L5: 0.01813737489283085
Epoch 6000, Loss: 0.04217756912112236, Losses: L1: -1.295755386352539, L2: 0.3040618598461151, L3: 0.0818558931350708, L4: 0.4783252775669098, L5: 0.01814628206193447
Epoch 6500, Loss: 0.031048540025949478, Losses: L1: -1.2999497652053833, L2: 0.3057593107223511, L3: 0.0816429853439331, L4: 0.474107950925827, L5: 0.01810079999268055
Epoch 7000, Loss: 0.02351384609937668, Losses: L1: -1.3028095960617065, L2: 0.30722156167030334, L3: 0.08139258623123169, L4: 0.4711350202560425, L5: 0.018067803233861923
Epoch 7500, Loss: 0.017937645316123962, Losses: L1: -1.3049932718276978, L2: 0.3082875907421112, L3: 0.08120709657669067, L4: 0.46897566318511963, L5: 0.018044225871562958
Epoch 8000, Loss: 0.014128468930721283, Losses: L1: -1.3065320253372192, L2: 0.30895429849624634, L3: 0.08111405372619629, L4: 0.4675496816635132, L5: 0.018024902790784836
Epoch 8500, Loss: 0.011721942573785782, Losses: L1: -1.307422399520874, L2: 0.30931156873703003, L3: 0.08103561401367188, L4: 0.46663761138916016, L5: 0.018019871786236763
Epoch 9000, Loss: 0.0097508504986763, Losses: L1: -1.3079637289047241, L2: 0.30956217646598816, L3: 0.08095443248748779, L4: 0.465823769569397, L5: 0.018013808876276016
Epoch 9500, Loss: 0.00859888643026352, Losses: L1: -1.3083491325378418, L2: 0.30971887707710266, L3: 0.08091729879379272, L4: 0.4653762876987457, L5: 0.01800895854830742
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.00728178024292, Constraint losses: L1: 7.9091057777404785, L2: 2.5362893211422488e-05, L3: 0.9996738433837891, L4: 0.9996735453605652
Epoch 500, Loss: 0.0027972026728093624, Constraint losses: L1: -0.901554524898529, L2: 0.0, L3: 0.0028480887413024902, L4: 0.0008506684098392725
Epoch 1000, Loss: 0.0013899719342589378, Constraint losses: L1: -1.113289713859558, L2: 0.0, L3: 0.002251267433166504, L4: 0.0002519942936487496
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.030148983001709, Constraint losses: L1: 18.42068099975586, L2: 0.003909051883965731, L3: 1.0039091110229492, L4: 1.0039103031158447
Epoch 500, Loss: 0.0026607478503137827, Constraint losses: L1: -1.045841097831726, L2: 0.0, L3: 0.0028520822525024414, L4: 0.0008545067976228893
Epoch 1000, Loss: 0.0014072773046791553, Constraint losses: L1: -1.1167958974838257, L2: 0.0, L3: 0.002261638641357422, L4: 0.00026243465254083276
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 41.0523681640625, Losses: L1: 4.6445159912109375, L2: 0.0, L3: 0.98895663022995, L4: 70.608642578125, L5: 0.22914984822273254
Epoch 500, Loss: -0.4976118505001068, Losses: L1: -2.561396598815918, L2: 0.6969333291053772, L3: 0.10030728578567505, L4: 2.5072197914123535, L5: 0.02586873061954975
Epoch 1000, Loss: 4.311304569244385, Losses: L1: -2.4588024616241455, L2: 4.896007061004639, L3: 0.054317474365234375, L4: 3.528684139251709, L5: 0.11088129878044128
Epoch 1500, Loss: -2.4170358180999756, Losses: L1: -3.80660080909729, L2: 0.6861529350280762, L3: 0.08681362867355347, L4: 1.2131470441818237, L5: 0.02004951797425747
Epoch 2000, Loss: -2.924314260482788, Losses: L1: -3.8804640769958496, L2: 0.6595567464828491, L3: 0.030803680419921875, L4: 0.5197681784629822, L5: 0.011810122057795525
Epoch 2500, Loss: -3.0830190181732178, Losses: L1: -3.930471181869507, L2: 0.5997862219810486, L3: 0.0068520307540893555, L4: 0.47082650661468506, L5: 0.010801408439874649
Epoch 3000, Loss: -3.1173765659332275, Losses: L1: -3.955941677093506, L2: 0.575672447681427, L3: 0.023287415504455566, L4: 0.4690287709236145, L5: 0.010181568562984467
Epoch 3500, Loss: -3.2031099796295166, Losses: L1: -3.9834988117218018, L2: 0.5734884738922119, L3: 0.007162690162658691, L4: 0.3896135985851288, L5: 0.009861715137958527
Epoch 4000, Loss: -3.2383720874786377, Losses: L1: -3.9915900230407715, L2: 0.5681614875793457, L3: 0.004168868064880371, L4: 0.3522976338863373, L5: 0.009477056562900543
Epoch 4500, Loss: -3.231290102005005, Losses: L1: -4.001560688018799, L2: 0.5658940672874451, L3: 0.017873764038085938, L4: 0.3636110723018646, L5: 0.00939413346350193
Epoch 5000, Loss: -3.25813627243042, Losses: L1: -3.996063232421875, L2: 0.5567197203636169, L3: 0.007773160934448242, L4: 0.3375745415687561, L5: 0.009293324314057827
Epoch 5500, Loss: -3.2691187858581543, Losses: L1: -3.9909415245056152, L2: 0.5491329431533813, L3: 0.0009363889694213867, L4: 0.3342277407646179, L5: 0.00927945040166378
Epoch 6000, Loss: -3.269209861755371, Losses: L1: -3.9942569732666016, L2: 0.5494356751441956, L3: 0.0025970935821533203, L4: 0.3367519974708557, L5: 0.009276960976421833
Epoch 6500, Loss: -3.275111436843872, Losses: L1: -3.993396520614624, L2: 0.5476268529891968, L3: 0.0014324188232421875, L4: 0.3291979432106018, L5: 0.00925387255847454
Epoch 7000, Loss: -3.277278423309326, Losses: L1: -3.993107318878174, L2: 0.5465396642684937, L3: 0.0006753206253051758, L4: 0.32796967029571533, L5: 0.009258318692445755
Epoch 7500, Loss: -3.278897762298584, Losses: L1: -3.993872880935669, L2: 0.5465213656425476, L3: 0.0004570484161376953, L4: 0.3267386555671692, L5: 0.00925447791814804
Epoch 8000, Loss: -3.279909372329712, Losses: L1: -3.9938855171203613, L2: 0.546064555644989, L3: 7.43865966796875e-05, L4: 0.3264182209968567, L5: 0.009255753830075264
Epoch 8500, Loss: -3.280613899230957, Losses: L1: -3.994023561477661, L2: 0.5459124445915222, L3: 7.474422454833984e-05, L4: 0.3255884647369385, L5: 0.00925650168210268
Epoch 9000, Loss: -3.280992031097412, Losses: L1: -3.9940848350524902, L2: 0.5457355380058289, L3: 7.402896881103516e-05, L4: 0.32531237602233887, L5: 0.00925369281321764
Epoch 9500, Loss: -3.281256914138794, Losses: L1: -3.9940741062164307, L2: 0.5455979704856873, L3: 5.167722702026367e-05, L4: 0.3250812590122223, L5: 0.00925333984196186
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.002467632293701, Constraint losses: L1: 6.216568470001221, L2: 0.0, L3: 0.9981257915496826, L4: 0.9981253147125244
Epoch 500, Loss: 0.0021043275482952595, Constraint losses: L1: -1.0958585739135742, L2: 0.0, L3: 0.0025992989540100098, L4: 0.000600887113250792
Epoch 1000, Loss: 0.0012641256907954812, Constraint losses: L1: -1.1178776025772095, L2: 0.0, L3: 0.002190709114074707, L4: 0.00019129420979879797
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0053741931915283, Constraint losses: L1: 7.070960521697998, L2: 0.0, L3: 0.9991515874862671, L4: 0.9991515278816223
Epoch 500, Loss: 0.002167243743315339, Constraint losses: L1: -1.0261666774749756, L2: 0.0, L3: 0.0025957822799682617, L4: 0.0005976281827315688
Epoch 1000, Loss: 0.0012368349125608802, Constraint losses: L1: -1.1161412000656128, L2: 0.0, L3: 0.0021761059761047363, L4: 0.000176870176801458
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 63.353416442871094, Losses: L1: 18.42068099975586, L2: 0.005571291781961918, L3: 1.0055712461471558, L4: 87.20099639892578, L5: 0.32109564542770386
Epoch 500, Loss: -1.2716639041900635, Losses: L1: -3.6445484161376953, L2: 0.7196415066719055, L3: 0.06725329160690308, L4: 3.101717948913574, L5: 0.035130731761455536
Epoch 1000, Loss: -1.586382269859314, Losses: L1: -2.9481446743011475, L2: 0.6949135661125183, L3: 0.05841189622879028, L4: 1.1889533996582031, L5: 0.013960209675133228
Epoch 1500, Loss: -0.8264168500900269, Losses: L1: -1.7388560771942139, L2: 0.2730562388896942, L3: 0.06607949733734131, L4: 1.1188386678695679, L5: 0.01388410571962595
Epoch 2000, Loss: -1.2263388633728027, Losses: L1: -1.9986664056777954, L2: 0.30496400594711304, L3: 0.05513417720794678, L4: 0.7950342893600464, L5: 0.014712358824908733
Epoch 2500, Loss: -1.584761381149292, Losses: L1: -2.131042003631592, L2: 0.33986133337020874, L3: 0.04174768924713135, L4: 0.2989528775215149, L5: 0.015195144340395927
Epoch 3000, Loss: -1.6828463077545166, Losses: L1: -2.196165084838867, L2: 0.3411608934402466, L3: 0.029312968254089355, L4: 0.2569715678691864, L5: 0.014359082095324993
Epoch 3500, Loss: -1.765459418296814, Losses: L1: -2.2694051265716553, L2: 0.36267775297164917, L3: 0.009879708290100098, L4: 0.23436239361763, L5: 0.01420704647898674
Epoch 4000, Loss: -1.8078323602676392, Losses: L1: -2.3124887943267822, L2: 0.3794546127319336, L3: 0.0003082752227783203, L4: 0.22124972939491272, L5: 0.014268618077039719
Epoch 4500, Loss: -1.8330354690551758, Losses: L1: -2.33634614944458, L2: 0.3873979449272156, L3: 0.0006226301193237305, L4: 0.2020426243543625, L5: 0.01426874939352274
Epoch 5000, Loss: -1.8469094038009644, Losses: L1: -2.351788282394409, L2: 0.3912780284881592, L3: 1.621246337890625e-05, L4: 0.1987416297197342, L5: 0.01421381626278162
Epoch 5500, Loss: -1.8565740585327148, Losses: L1: -2.365604877471924, L2: 0.397844523191452, L3: 5.435943603515625e-05, L4: 0.19377358257770538, L5: 0.014245211146771908
Epoch 6000, Loss: -1.8626623153686523, Losses: L1: -2.3736515045166016, L2: 0.4005703628063202, L3: 0.00013399124145507812, L4: 0.1920865774154663, L5: 0.014241510070860386
Epoch 6500, Loss: -1.8670859336853027, Losses: L1: -2.379122734069824, L2: 0.402378648519516, L3: 2.4557113647460938e-05, L4: 0.19090010225772858, L5: 0.014183503575623035
Epoch 7000, Loss: -1.8701140880584717, Losses: L1: -2.382185459136963, L2: 0.4029076397418976, L3: 5.6862831115722656e-05, L4: 0.18986645340919495, L5: 0.014173575676977634
Epoch 7500, Loss: -1.8722940683364868, Losses: L1: -2.384767532348633, L2: 0.4033859670162201, L3: 4.3272972106933594e-05, L4: 0.1897960603237152, L5: 0.014146236702799797
Epoch 8000, Loss: -1.8738764524459839, Losses: L1: -2.386890172958374, L2: 0.40425601601600647, L3: 5.066394805908203e-06, L4: 0.18921075761318207, L5: 0.01414730679243803
Epoch 8500, Loss: -1.874908685684204, Losses: L1: -2.3883893489837646, L2: 0.404877632856369, L3: 8.106231689453125e-06, L4: 0.1888885200023651, L5: 0.014150675386190414
Epoch 9000, Loss: -1.8755782842636108, Losses: L1: -2.389482259750366, L2: 0.40540990233421326, L3: 1.0251998901367188e-05, L4: 0.1886625736951828, L5: 0.014152578078210354
Epoch 9500, Loss: -1.8760402202606201, Losses: L1: -2.3901002407073975, L2: 0.4055930972099304, L3: 5.245208740234375e-06, L4: 0.18862710893154144, L5: 0.014148136600852013
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0024948120117188, Constraint losses: L1: 6.2816996574401855, L2: 0.0, L3: 0.9981064200401306, L4: 0.9981065988540649
Epoch 500, Loss: 0.0020966343581676483, Constraint losses: L1: -1.0946699380874634, L2: 0.0, L3: 0.002594888210296631, L4: 0.0005964162992313504
Epoch 1000, Loss: 0.0012604836374521255, Constraint losses: L1: -1.1171034574508667, L2: 0.0, L3: 0.0021886229515075684, L4: 0.0001889641280286014
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0266776084899902, Constraint losses: L1: 18.42068099975586, L2: 0.0027521750889718533, L3: 1.0027521848678589, L4: 1.002752423286438
Epoch 500, Loss: 0.0030207191593945026, Constraint losses: L1: -0.9775151610374451, L2: 0.0, L3: 0.0029976963996887207, L4: 0.0010005378862842917
Epoch 1000, Loss: 0.0015025509055703878, Constraint losses: L1: -1.1103549003601074, L2: 0.0, L3: 0.0023061037063598633, L4: 0.0003068021615035832
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 45.23568344116211, Losses: L1: 5.496396064758301, L2: 0.0, L3: 0.9948246479034424, L4: 76.46165466308594, L5: 0.25681933760643005
Epoch 500, Loss: 1.864372968673706, Losses: L1: -1.2362229824066162, L2: 0.38546842336654663, L3: 0.09639817476272583, L4: 4.995626449584961, L5: 0.06045806035399437
Epoch 1000, Loss: -1.2026287317276, Losses: L1: -2.288327217102051, L2: 0.493533730506897, L3: 0.06804978847503662, L4: 0.9485315084457397, L5: 0.02492457441985607
Epoch 1500, Loss: -0.9761574268341064, Losses: L1: -2.495759963989258, L2: 0.49038153886795044, L3: 0.06831479072570801, L4: 1.824521780014038, L5: 0.024322692304849625
Epoch 2000, Loss: -1.7263520956039429, Losses: L1: -2.611436128616333, L2: 0.5105024576187134, L3: 0.05951130390167236, L4: 0.5710816979408264, L5: 0.014764702878892422
Epoch 2500, Loss: -1.9147350788116455, Losses: L1: -2.680091142654419, L2: 0.5025240778923035, L3: 0.060969531536102295, L4: 0.34581518173217773, L5: 0.014477354474365711
Epoch 3000, Loss: -1.9386310577392578, Losses: L1: -2.7388875484466553, L2: 0.5096397995948792, L3: 0.060320138931274414, L4: 0.40050292015075684, L5: 0.01502254605293274
Epoch 3500, Loss: -2.039926052093506, Losses: L1: -2.7764854431152344, L2: 0.5203794240951538, L3: 0.05967754125595093, L4: 0.2523678243160248, L5: 0.015159083530306816
Epoch 4000, Loss: -2.0674612522125244, Losses: L1: -2.804036855697632, L2: 0.5257481336593628, L3: 0.05933654308319092, L4: 0.24254712462425232, L5: 0.01510864868760109
Epoch 4500, Loss: -2.0872373580932617, Losses: L1: -2.8306455612182617, L2: 0.5353996157646179, L3: 0.05909848213195801, L4: 0.23712192475795746, L5: 0.015174479223787785
Epoch 5000, Loss: -2.1028549671173096, Losses: L1: -2.8405709266662598, L2: 0.5334255695343018, L3: 0.05922055244445801, L4: 0.2295723259449005, L5: 0.015141896903514862
Epoch 5500, Loss: -2.1134331226348877, Losses: L1: -2.849738359451294, L2: 0.5340825915336609, L3: 0.05903065204620361, L4: 0.22667300701141357, L5: 0.014927688054740429
Epoch 6000, Loss: -2.1210668087005615, Losses: L1: -2.8566277027130127, L2: 0.5346057415008545, L3: 0.05889320373535156, L4: 0.2246396243572235, L5: 0.01487112045288086
Epoch 6500, Loss: -2.126540184020996, Losses: L1: -2.8611817359924316, L2: 0.534653902053833, L3: 0.05870771408081055, L4: 0.22329181432724, L5: 0.014816982671618462
Epoch 7000, Loss: -2.130622625350952, Losses: L1: -2.8653018474578857, L2: 0.5354107022285461, L3: 0.05852419137954712, L4: 0.22235126793384552, L5: 0.014784487895667553
Epoch 7500, Loss: -2.133657932281494, Losses: L1: -2.8680782318115234, L2: 0.5356040000915527, L3: 0.05849027633666992, L4: 0.22160997986793518, L5: 0.014760453253984451
Epoch 8000, Loss: -2.1358494758605957, Losses: L1: -2.8702778816223145, L2: 0.5360696911811829, L3: 0.05842161178588867, L4: 0.2208840548992157, L5: 0.014747651293873787
Epoch 8500, Loss: -2.137397527694702, Losses: L1: -2.871563673019409, L2: 0.5360427498817444, L3: 0.05840080976486206, L4: 0.2205127328634262, L5: 0.014733076095581055
Epoch 9000, Loss: -2.1384823322296143, Losses: L1: -2.8727176189422607, L2: 0.5362589955329895, L3: 0.058384835720062256, L4: 0.2202485203742981, L5: 0.01473354734480381
Epoch 9500, Loss: -2.1391966342926025, Losses: L1: -2.873642683029175, L2: 0.5365747213363647, L3: 0.05836331844329834, L4: 0.22009782493114471, L5: 0.014729507267475128
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9924129247665405, Constraint losses: L1: 5.051878929138184, L2: 0.0, L3: 0.9936808347702026, L4: 0.9936802387237549
Epoch 500, Loss: 0.002039833925664425, Constraint losses: L1: -1.0397586822509766, L2: 0.0, L3: 0.002538919448852539, L4: 0.0005406731506809592
Epoch 1000, Loss: 0.0012073972029611468, Constraint losses: L1: -1.1180269718170166, L2: 0.0, L3: 0.0021625161170959473, L4: 0.00016290813800878823
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0073797702789307, Constraint losses: L1: 8.080879211425781, L2: 0.0, L3: 0.9996494054794312, L4: 0.9996495246887207
Epoch 500, Loss: 0.0022761612199246883, Constraint losses: L1: -1.0718275308609009, L2: 0.0, L3: 0.0026730895042419434, L4: 0.0006748993182554841
Epoch 1000, Loss: 0.0013009354006499052, Constraint losses: L1: -1.1164809465408325, L2: 0.0, L3: 0.0022084712982177734, L4: 0.00020894517365377396
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 82.16969299316406, Losses: L1: 6.233752250671387, L2: 7.283395098056644e-05, L3: 0.9980561137199402, L4: 74.8120346069336, L5: 0.2515560984611511
Epoch 500, Loss: 1.985887050628662, Losses: L1: -1.9450610876083374, L2: 1.1211273670196533, L3: 0.11223965883255005, L4: 2.664128065109253, L5: 0.06690604239702225
Epoch 1000, Loss: 0.6756042838096619, Losses: L1: -2.3013341426849365, L2: 1.292707920074463, L3: 0.10853570699691772, L4: 1.5431474447250366, L5: 0.06509476155042648
Epoch 1500, Loss: 0.5532166957855225, Losses: L1: -2.335878610610962, L2: 1.2544082403182983, L3: 0.10540056228637695, L4: 1.4994498491287231, L5: 0.05967327579855919
Epoch 2000, Loss: 0.07453964650630951, Losses: L1: -2.3131749629974365, L2: 1.2288870811462402, L3: 0.10324621200561523, L4: 1.0259318351745605, L5: 0.05929896607995033
Epoch 2500, Loss: -0.18800422549247742, Losses: L1: -2.304046392440796, L2: 1.211556077003479, L3: 0.1014178991317749, L4: 0.7734380960464478, L5: 0.05926017835736275
Epoch 3000, Loss: -0.3126504123210907, Losses: L1: -2.2832794189453125, L2: 1.1770451068878174, L3: 0.10614848136901855, L4: 0.6587044596672058, L5: 0.05746189504861832
Epoch 3500, Loss: -0.32726773619651794, Losses: L1: -2.273632287979126, L2: 1.1625442504882812, L3: 0.10638201236724854, L4: 0.6487095355987549, L5: 0.05745752900838852
Epoch 4000, Loss: -0.3651029169559479, Losses: L1: -2.2689192295074463, L2: 1.1558318138122559, L3: 0.10653436183929443, L4: 0.6125247478485107, L5: 0.057850778102874756
Epoch 4500, Loss: -0.3750826418399811, Losses: L1: -2.265076160430908, L2: 1.1485413312911987, L3: 0.10662120580673218, L4: 0.6059906482696533, L5: 0.05768075957894325
Epoch 5000, Loss: -0.3864877223968506, Losses: L1: -2.263735294342041, L2: 1.144690752029419, L3: 0.10654783248901367, L4: 0.5970810055732727, L5: 0.05785594880580902
Epoch 5500, Loss: -0.39743539690971375, Losses: L1: -2.2633755207061768, L2: 1.1431069374084473, L3: 0.10656541585922241, L4: 0.58741295337677, L5: 0.05770949646830559
Epoch 6000, Loss: -0.4027129113674164, Losses: L1: -2.2636759281158447, L2: 1.141865611076355, L3: 0.10665082931518555, L4: 0.5836055278778076, L5: 0.057682104408741
Epoch 6500, Loss: -0.40566468238830566, Losses: L1: -2.264246702194214, L2: 1.1410561800003052, L3: 0.10664606094360352, L4: 0.5820598602294922, L5: 0.05763980746269226
Epoch 7000, Loss: -0.4079405665397644, Losses: L1: -2.2644717693328857, L2: 1.1401232481002808, L3: 0.1066209077835083, L4: 0.580970287322998, L5: 0.057633545249700546
Epoch 7500, Loss: -0.40981513261795044, Losses: L1: -2.2645630836486816, L2: 1.1396288871765137, L3: 0.1065826416015625, L4: 0.5797094702720642, L5: 0.05765390396118164
Epoch 8000, Loss: -0.4109927713871002, Losses: L1: -2.264611005783081, L2: 1.138933539390564, L3: 0.10654443502426147, L4: 0.5793119668960571, L5: 0.05765668302774429
Epoch 8500, Loss: -0.41184061765670776, Losses: L1: -2.264652729034424, L2: 1.1385520696640015, L3: 0.10653805732727051, L4: 0.5788997411727905, L5: 0.05764450505375862
Epoch 9000, Loss: -0.41241520643234253, Losses: L1: -2.26471209526062, L2: 1.138330340385437, L3: 0.10653072595596313, L4: 0.5786119699478149, L5: 0.057647593319416046
Epoch 9500, Loss: -0.41284528374671936, Losses: L1: -2.264711856842041, L2: 1.138145923614502, L3: 0.10650908946990967, L4: 0.5783858299255371, L5: 0.05765148252248764
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9981153011322021, Constraint losses: L1: 5.608400821685791, L2: 0.0, L3: 0.9962531924247742, L4: 0.9962537288665771
Epoch 500, Loss: 0.00227361754514277, Constraint losses: L1: -1.1125599145889282, L2: 0.0, L3: 0.0026923418045043945, L4: 0.0006938357255421579
Epoch 1000, Loss: 0.0013397576985880733, Constraint losses: L1: -1.1168345212936401, L2: 0.0, L3: 0.002227962017059326, L4: 0.00022863024787511677
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002775192260742, Constraint losses: L1: 6.329240322113037, L2: 0.0, L3: 0.9982230067253113, L4: 0.998223066329956
Epoch 500, Loss: 0.002214958658441901, Constraint losses: L1: -1.1114699840545654, L2: 0.0, L3: 0.002662479877471924, L4: 0.0006639488274231553
Epoch 1000, Loss: 0.001326097408309579, Constraint losses: L1: -1.1157612800598145, L2: 0.0, L3: 0.0022206902503967285, L4: 0.00022116850595921278
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 80.34672546386719, Losses: L1: 5.838273048400879, L2: 0.0, L3: 0.9970034956932068, L4: 73.26629638671875, L5: 0.24515439569950104
Epoch 500, Loss: -1.4340893030166626, Losses: L1: -3.423614978790283, L2: 0.7272595763206482, L3: 0.06560248136520386, L4: 1.1743334531784058, L5: 0.02233009785413742
Epoch 1000, Loss: -1.6576238870620728, Losses: L1: -3.6928913593292236, L2: 0.69642174243927, L3: 0.05853152275085449, L4: 1.2653547525405884, L5: 0.014959318563342094
Epoch 1500, Loss: -2.752413272857666, Losses: L1: -3.728423595428467, L2: 0.49753841757774353, L3: 0.09443390369415283, L4: 0.37337809801101685, L5: 0.010660044848918915
Epoch 2000, Loss: -2.715057373046875, Losses: L1: -3.6616852283477783, L2: 0.571636974811554, L3: 0.05150759220123291, L4: 0.31350404024124146, L5: 0.009979384019970894
Epoch 2500, Loss: -3.1523096561431885, Losses: L1: -3.9295949935913086, L2: 0.46044084429740906, L3: 0.052225708961486816, L4: 0.25471264123916626, L5: 0.009906080551445484
Epoch 3000, Loss: -3.251678705215454, Losses: L1: -3.9648849964141846, L2: 0.38671863079071045, L3: 0.03714919090270996, L4: 0.2789780795574188, L5: 0.010360429994761944
Epoch 3500, Loss: -3.3743042945861816, Losses: L1: -3.9844486713409424, L2: 0.3867923617362976, L3: 0.02047210931777954, L4: 0.19352413713932037, L5: 0.009355854243040085
Epoch 4000, Loss: -3.424530029296875, Losses: L1: -4.007662296295166, L2: 0.39652854204177856, L3: 0.0013091564178466797, L4: 0.1760500967502594, L5: 0.009244556538760662
Epoch 4500, Loss: -3.4699952602386475, Losses: L1: -4.00304651260376, L2: 0.3865211009979248, L3: 0.0004534721374511719, L4: 0.1370154321193695, L5: 0.009061306715011597
Epoch 5000, Loss: -3.4964466094970703, Losses: L1: -4.000756740570068, L2: 0.38098523020744324, L3: 9.065866470336914e-05, L4: 0.11436688154935837, L5: 0.008867479860782623
Epoch 5500, Loss: -3.50203537940979, Losses: L1: -4.001266956329346, L2: 0.3791149854660034, L3: 6.031990051269531e-05, L4: 0.1112651377916336, L5: 0.008790955878794193
Epoch 6000, Loss: -3.5048739910125732, Losses: L1: -4.001036643981934, L2: 0.37724441289901733, L3: 8.237361907958984e-05, L4: 0.11008266359567642, L5: 0.00875307060778141
Epoch 6500, Loss: -3.508443832397461, Losses: L1: -4.001267910003662, L2: 0.3762185573577881, L3: 1.3828277587890625e-05, L4: 0.10787750035524368, L5: 0.00871413666754961
Epoch 7000, Loss: -3.5101430416107178, Losses: L1: -4.001702785491943, L2: 0.37575599551200867, L3: 1.2755393981933594e-05, L4: 0.10709962248802185, L5: 0.008691598661243916
Epoch 7500, Loss: -3.5114331245422363, Losses: L1: -4.001967906951904, L2: 0.3754296600818634, L3: 1.430511474609375e-06, L4: 0.10642274469137192, L5: 0.0086811613291502
Epoch 8000, Loss: -3.512545347213745, Losses: L1: -4.002074718475342, L2: 0.37507885694503784, L3: 1.1920928955078125e-05, L4: 0.10577070713043213, L5: 0.008667671121656895
Epoch 8500, Loss: -3.5131804943084717, Losses: L1: -4.002266883850098, L2: 0.3749285340309143, L3: 4.76837158203125e-06, L4: 0.10549404472112656, L5: 0.00865904986858368
Epoch 9000, Loss: -3.513705015182495, Losses: L1: -4.002140522003174, L2: 0.3745831847190857, L3: 1.3709068298339844e-06, L4: 0.10519734025001526, L5: 0.008653461933135986
Epoch 9500, Loss: -3.5140252113342285, Losses: L1: -4.0023112297058105, L2: 0.3745836913585663, L3: 4.649162292480469e-06, L4: 0.1050492525100708, L5: 0.008648413233458996
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0233774185180664, Constraint losses: L1: 18.42068099975586, L2: 0.001652053208090365, L3: 1.0016520023345947, L4: 1.001652717590332
Epoch 500, Loss: 0.00222715362906456, Constraint losses: L1: -1.0815025568008423, L2: 0.0, L3: 0.0026534199714660645, L4: 0.0006552363047376275
Epoch 1000, Loss: 0.0012934686383232474, Constraint losses: L1: -1.1178208589553833, L2: 0.0, L3: 0.002205371856689453, L4: 0.0002059177350020036
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0287961959838867, Constraint losses: L1: 18.42068099975586, L2: 0.003458396065980196, L3: 1.0034583806991577, L4: 1.0034586191177368
Epoch 500, Loss: 0.0024537716526538134, Constraint losses: L1: -1.1046059131622314, L2: 0.0, L3: 0.0027782320976257324, L4: 0.0007801455212756991
Epoch 1000, Loss: 0.0013952821027487516, Constraint losses: L1: -1.1166155338287354, L2: 0.0, L3: 0.002255558967590332, L4: 0.00025633868062868714
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 99.74646759033203, Losses: L1: 18.42068099975586, L2: 0.001566799939610064, L3: 1.001566767692566, L4: 79.76443481445312, L5: 0.2791081368923187
Epoch 500, Loss: 3.792473554611206, Losses: L1: -0.6525355577468872, L2: 0.3066508173942566, L3: 0.19889140129089355, L4: 3.8742613792419434, L5: 0.03260276839137077
Epoch 1000, Loss: 1.9200845956802368, Losses: L1: -1.098103404045105, L2: 0.30297884345054626, L3: 0.06417560577392578, L4: 2.578702926635742, L5: 0.0361652709543705
Epoch 1500, Loss: -0.25027626752853394, Losses: L1: -1.3402234315872192, L2: 0.288057416677475, L3: 0.06807756423950195, L4: 0.6958112716674805, L5: 0.019000446423888206
Epoch 2000, Loss: -0.408181756734848, Losses: L1: -1.443566083908081, L2: 0.32138755917549133, L3: 0.06642115116119385, L4: 0.6100472211837769, L5: 0.018764212727546692
Epoch 2500, Loss: -0.5737059116363525, Losses: L1: -1.5217503309249878, L2: 0.35372570157051086, L3: 0.06668037176132202, L4: 0.48875826597213745, L5: 0.019440099596977234
Epoch 3000, Loss: -0.606523334980011, Losses: L1: -1.5714170932769775, L2: 0.37193596363067627, L3: 0.0673796534538269, L4: 0.48472461104393005, L5: 0.02042677067220211
Epoch 3500, Loss: -0.6437762975692749, Losses: L1: -1.599579095840454, L2: 0.3816639482975006, L3: 0.0672764778137207, L4: 0.46363401412963867, L5: 0.021614188328385353
Epoch 4000, Loss: -0.7317214608192444, Losses: L1: -1.612769603729248, L2: 0.3927132785320282, L3: 0.06602060794830322, L4: 0.37954583764076233, L5: 0.02138420008122921
Epoch 4500, Loss: -0.7603439688682556, Losses: L1: -1.6284055709838867, L2: 0.3985896110534668, L3: 0.06617552042007446, L4: 0.3592442572116852, L5: 0.02202616259455681
Epoch 5000, Loss: -0.7678340673446655, Losses: L1: -1.6352084875106812, L2: 0.39954429864883423, L3: 0.06648111343383789, L4: 0.3569003939628601, L5: 0.022224267944693565
Epoch 5500, Loss: -0.7773186564445496, Losses: L1: -1.6392302513122559, L2: 0.4007936716079712, L3: 0.06637752056121826, L4: 0.3502821624279022, L5: 0.02222910337150097
Epoch 6000, Loss: -0.782184898853302, Losses: L1: -1.6433191299438477, L2: 0.4017200469970703, L3: 0.06639033555984497, L4: 0.3483816385269165, L5: 0.022321131080389023
Epoch 6500, Loss: -0.7862375378608704, Losses: L1: -1.645926594734192, L2: 0.4023468792438507, L3: 0.06632804870605469, L4: 0.34637853503227234, L5: 0.022317787632346153
Epoch 7000, Loss: -0.7893307209014893, Losses: L1: -1.6473333835601807, L2: 0.4022780954837799, L3: 0.0662875771522522, L4: 0.34473833441734314, L5: 0.022349312901496887
Epoch 7500, Loss: -0.7910736799240112, Losses: L1: -1.6480520963668823, L2: 0.4020806849002838, L3: 0.06627881526947021, L4: 0.34389495849609375, L5: 0.022361991927027702
Epoch 8000, Loss: -0.7922331690788269, Losses: L1: -1.6485587358474731, L2: 0.4020581543445587, L3: 0.06622672080993652, L4: 0.34328579902648926, L5: 0.022377464920282364
Epoch 8500, Loss: -0.793260931968689, Losses: L1: -1.6490774154663086, L2: 0.4021000564098358, L3: 0.06623131036758423, L4: 0.3427145183086395, L5: 0.022385312244296074
Epoch 9000, Loss: -0.7939059734344482, Losses: L1: -1.6494736671447754, L2: 0.40218308568000793, L3: 0.06622672080993652, L4: 0.3423789143562317, L5: 0.022389506921172142
Epoch 9500, Loss: -0.794334352016449, Losses: L1: -1.649661898612976, L2: 0.40220576524734497, L3: 0.06621766090393066, L4: 0.34212028980255127, L5: 0.022391891106963158
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0272634029388428, Constraint losses: L1: 18.42068099975586, L2: 0.002947554225102067, L3: 1.0029475688934326, L4: 1.0029475688934326
Epoch 500, Loss: 0.0022290414199233055, Constraint losses: L1: -1.0722758769989014, L2: 0.0, L3: 0.0026496052742004395, L4: 0.0006517120636999607
Epoch 1000, Loss: 0.0012868131743744016, Constraint losses: L1: -1.1163082122802734, L2: 0.0, L3: 0.0022011995315551758, L4: 0.00020192192459944636
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0024399757385254, Constraint losses: L1: 6.26216459274292, L2: 0.0, L3: 0.9980890154838562, L4: 0.9980888366699219
Epoch 500, Loss: 0.0023437822237610817, Constraint losses: L1: -1.1009521484375, L2: 0.0, L3: 0.0027213692665100098, L4: 0.0007233652286231518
Epoch 1000, Loss: 0.0013589038280770183, Constraint losses: L1: -1.1162856817245483, L2: 0.0, L3: 0.002237260341644287, L4: 0.00023792912543285638
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 158.2945556640625, Losses: L1: 6.131827354431152, L2: 0.0, L3: 0.9973116517066956, L4: 75.51873779296875, L5: 0.2558896541595459
Epoch 500, Loss: 4.800274848937988, Losses: L1: -2.9181931018829346, L2: 0.9382263422012329, L3: 0.07067233324050903, L4: 3.3456320762634277, L5: 0.03660988062620163
Epoch 1000, Loss: 0.016583051532506943, Losses: L1: -3.36303973197937, L2: 0.8833815455436707, L3: 0.0626823902130127, L4: 1.2102062702178955, L5: 0.026292497292160988
Epoch 1500, Loss: -0.36660680174827576, Losses: L1: -3.6786108016967773, L2: 0.9771421551704407, L3: 0.05486863851547241, L4: 1.1322517395019531, L5: 0.030979478731751442
Epoch 2000, Loss: -0.9327160120010376, Losses: L1: -3.7937934398651123, L2: 0.708773136138916, L3: 0.059332966804504395, L4: 1.0401523113250732, L5: 0.025333132594823837
Epoch 2500, Loss: -2.3303768634796143, Losses: L1: -3.900348663330078, L2: 0.7168946266174316, L3: 0.052813053131103516, L4: 0.39513516426086426, L5: 0.019987445324659348
Epoch 3000, Loss: -2.8088550567626953, Losses: L1: -3.997591972351074, L2: 0.6456823945045471, L3: 0.0006471872329711914, L4: 0.2669673562049866, L5: 0.016945937648415565
Epoch 3500, Loss: -3.043044090270996, Losses: L1: -4.029766082763672, L2: 0.6170400977134705, L3: 0.0013034343719482422, L4: 0.18011467158794403, L5: 0.01629818044602871
Epoch 4000, Loss: -3.108976364135742, Losses: L1: -4.014649391174316, L2: 0.5657238364219666, L3: 0.005650997161865234, L4: 0.16321134567260742, L5: 0.015751101076602936
Epoch 4500, Loss: -3.1497974395751953, Losses: L1: -4.034621238708496, L2: 0.5689446926116943, L3: 0.0039980411529541016, L4: 0.1520777940750122, L5: 0.015450716949999332
Epoch 5000, Loss: -3.1700565814971924, Losses: L1: -4.050851345062256, L2: 0.5798088908195496, L3: 0.0016211271286010742, L4: 0.14592230319976807, L5: 0.015040582045912743
Epoch 5500, Loss: -3.184082269668579, Losses: L1: -4.054360389709473, L2: 0.5778664350509644, L3: 0.0003504753112792969, L4: 0.14232029020786285, L5: 0.01484131719917059
Epoch 6000, Loss: -3.1945531368255615, Losses: L1: -4.053683280944824, L2: 0.5708694458007812, L3: 0.0007060766220092773, L4: 0.14011123776435852, L5: 0.014664269983768463
Epoch 6500, Loss: -3.201131582260132, Losses: L1: -4.057252883911133, L2: 0.571714460849762, L3: 0.0004253387451171875, L4: 0.13835394382476807, L5: 0.01454729400575161
Epoch 7000, Loss: -3.2063283920288086, Losses: L1: -4.057713031768799, L2: 0.569739043712616, L3: 0.00022840499877929688, L4: 0.1370931714773178, L5: 0.014461715705692768
Epoch 7500, Loss: -3.2098276615142822, Losses: L1: -4.05842924118042, L2: 0.5688392519950867, L3: 0.00012135505676269531, L4: 0.13621780276298523, L5: 0.014410470612347126
Epoch 8000, Loss: -3.2121357917785645, Losses: L1: -4.058660507202148, L2: 0.5677714943885803, L3: 0.00016832351684570312, L4: 0.13569754362106323, L5: 0.014379458501935005
Epoch 8500, Loss: -3.213773012161255, Losses: L1: -4.059097766876221, L2: 0.5675206184387207, L3: 3.123283386230469e-05, L4: 0.13529829680919647, L5: 0.014352889731526375
Epoch 9000, Loss: -3.2148401737213135, Losses: L1: -4.05877161026001, L2: 0.5664609670639038, L3: 0.00012958049774169922, L4: 0.13508599996566772, L5: 0.014337272383272648
Epoch 9500, Loss: -3.2155420780181885, Losses: L1: -4.0589399337768555, L2: 0.5663387775421143, L3: 5.710124969482422e-05, L4: 0.13491925597190857, L5: 0.01432714518159628
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0253257751464844, Constraint losses: L1: 18.42068099975586, L2: 0.002301316475495696, L3: 1.0023013353347778, L4: 1.0023024082183838
Epoch 500, Loss: 0.002375447889789939, Constraint losses: L1: -1.0921602249145508, L2: 0.0, L3: 0.00273287296295166, L4: 0.000734735163860023
Epoch 1000, Loss: 0.0013430400285869837, Constraint losses: L1: -1.1047776937484741, L2: 0.0, L3: 0.002223670482635498, L4: 0.0002241473994217813
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0052578449249268, Constraint losses: L1: 7.002227783203125, L2: 0.0, L3: 0.9991278648376465, L4: 0.9991277456283569
Epoch 500, Loss: 0.0020998409017920494, Constraint losses: L1: -1.1036468744277954, L2: 0.0, L3: 0.002601027488708496, L4: 0.0006024604081176221
Epoch 1000, Loss: 0.0012734970077872276, Constraint losses: L1: -1.1170293092727661, L2: 0.0, L3: 0.002195000648498535, L4: 0.00019552564481273293
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 139.2095489501953, Losses: L1: 5.762502193450928, L2: 0.0014944766880944371, L3: 0.9974104762077332, L4: 66.1177978515625, L5: 0.21254335343837738
Epoch 500, Loss: 5.614380359649658, Losses: L1: 0.9076988697052002, L2: 0.20533370971679688, L3: 0.09401899576187134, L4: 2.181746006011963, L5: 0.04383711889386177
Epoch 1000, Loss: 1.8074607849121094, Losses: L1: -2.8899660110473633, L2: 0.9254662990570068, L3: 0.07870042324066162, L4: 1.8162425756454468, L5: 0.06077497452497482
Epoch 1500, Loss: 2.0040833950042725, Losses: L1: -0.5988210439682007, L2: 0.22344322502613068, L3: 0.0966765284538269, L4: 1.1263002157211304, L5: 0.03018435649573803
Epoch 2000, Loss: 0.7866911888122559, Losses: L1: -0.8160249590873718, L2: 0.25935643911361694, L3: 0.08578258752822876, L4: 0.6135314702987671, L5: 0.030514171347022057
Epoch 2500, Loss: 0.9004170298576355, Losses: L1: -0.9005991816520691, L2: 0.28962305188179016, L3: 0.08223742246627808, L4: 0.6988299489021301, L5: 0.03149581700563431
Epoch 3000, Loss: 0.30472832918167114, Losses: L1: -0.9426438212394714, L2: 0.3030187487602234, L3: 0.07881748676300049, L4: 0.41709744930267334, L5: 0.03134102374315262
Epoch 3500, Loss: 0.18869607150554657, Losses: L1: -0.9797481894493103, L2: 0.31937241554260254, L3: 0.07696127891540527, L4: 0.37029391527175903, L5: 0.03152273967862129
Epoch 4000, Loss: 0.12900839745998383, Losses: L1: -1.0083796977996826, L2: 0.32990020513534546, L3: 0.07557272911071777, L4: 0.3502461314201355, L5: 0.03142290189862251
Epoch 4500, Loss: 0.06083466857671738, Losses: L1: -1.0309240818023682, L2: 0.33927416801452637, L3: 0.0748375654220581, L4: 0.3230782151222229, L5: 0.03149058669805527
Epoch 5000, Loss: 0.03236805275082588, Losses: L1: -1.0439130067825317, L2: 0.3449818193912506, L3: 0.07407557964324951, L4: 0.3128276467323303, L5: 0.03156839683651924
Epoch 5500, Loss: 0.007499869912862778, Losses: L1: -1.0543510913848877, L2: 0.34841200709342957, L3: 0.07364767789840698, L4: 0.30412739515304565, L5: 0.03153645619750023
Epoch 6000, Loss: -0.00932181254029274, Losses: L1: -1.0621455907821655, L2: 0.35111483931541443, L3: 0.07330000400543213, L4: 0.2984485626220703, L5: 0.03151177987456322
Epoch 6500, Loss: -0.02033843845129013, Losses: L1: -1.0678114891052246, L2: 0.3531244397163391, L3: 0.07310384511947632, L4: 0.2948892414569855, L5: 0.0314662829041481
Epoch 7000, Loss: -0.028989430516958237, Losses: L1: -1.0720384120941162, L2: 0.3544849157333374, L3: 0.07289612293243408, L4: 0.29211103916168213, L5: 0.03144586458802223
Epoch 7500, Loss: -0.0349564254283905, Losses: L1: -1.075441598892212, L2: 0.3556634187698364, L3: 0.07275092601776123, L4: 0.2903217673301697, L5: 0.0314272940158844
Epoch 8000, Loss: -0.03954164683818817, Losses: L1: -1.0774834156036377, L2: 0.35635823011398315, L3: 0.07263445854187012, L4: 0.288761168718338, L5: 0.03142674267292023
Epoch 8500, Loss: -0.04267822578549385, Losses: L1: -1.0793060064315796, L2: 0.356858491897583, L3: 0.07258445024490356, L4: 0.2878805994987488, L5: 0.03142363950610161
Epoch 9000, Loss: -0.04497542232275009, Losses: L1: -1.080552339553833, L2: 0.3572884202003479, L3: 0.07252579927444458, L4: 0.28717222809791565, L5: 0.03141824156045914
Epoch 9500, Loss: -0.0465417206287384, Losses: L1: -1.081425428390503, L2: 0.3575950562953949, L3: 0.07248443365097046, L4: 0.28669458627700806, L5: 0.03141501545906067
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.000779628753662, Constraint losses: L1: 5.941555500030518, L2: 0.0, L3: 0.9974191784858704, L4: 0.9974189400672913
Epoch 500, Loss: 0.002333076437935233, Constraint losses: L1: -0.9816329479217529, L2: 0.0, L3: 0.0026563405990600586, L4: 0.0006583688082173467
Epoch 1000, Loss: 0.001265272032469511, Constraint losses: L1: -1.1159878969192505, L2: 0.0, L3: 0.0021902918815612793, L4: 0.00019096808682661504
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0000431537628174, Constraint losses: L1: 5.785220146179199, L2: 0.0, L3: 0.9971293807029724, L4: 0.9971286058425903
Epoch 500, Loss: 0.0021938199643045664, Constraint losses: L1: -1.08724844455719, L2: 0.0, L3: 0.0026397109031677246, L4: 0.000641357502900064
Epoch 1000, Loss: 0.0012932490790262818, Constraint losses: L1: -1.116868019104004, L2: 0.0, L3: 0.0022048354148864746, L4: 0.00020528178720269352
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 159.00392150878906, Losses: L1: 11.091064453125, L2: 0.0002901017141994089, L3: 0.9991475939750671, L4: 73.21478271484375, L5: 0.24192796647548676
Epoch 500, Loss: 6.10612678527832, Losses: L1: -2.481003999710083, L2: 1.1216886043548584, L3: 0.12339174747467041, L4: 3.629216432571411, L5: 0.04180888086557388
Epoch 1000, Loss: 0.9004762768745422, Losses: L1: -2.582277297973633, L2: 0.7922819256782532, L3: 0.0701414942741394, L4: 1.2776036262512207, L5: 0.03256145119667053
Epoch 1500, Loss: 0.696390688419342, Losses: L1: -2.716771364212036, L2: 0.826884925365448, L3: 0.0655066967010498, L4: 1.2318577766418457, L5: 0.028527403250336647
Epoch 2000, Loss: -0.9178829789161682, Losses: L1: -2.7199575901031494, L2: 0.7159384489059448, L3: 0.06364178657531738, L4: 0.48489734530448914, L5: 0.026349902153015137
Epoch 2500, Loss: -1.2101143598556519, Losses: L1: -2.804065227508545, L2: 0.715544581413269, L3: 0.05617445707321167, L4: 0.38762813806533813, L5: 0.023487702012062073
Epoch 3000, Loss: -1.183872938156128, Losses: L1: -2.842576026916504, L2: 0.6823912262916565, L3: 0.01862621307373047, L4: 0.45811736583709717, L5: 0.02072547934949398
Epoch 3500, Loss: -1.5145007371902466, Losses: L1: -2.871628999710083, L2: 0.6624137759208679, L3: 0.004147052764892578, L4: 0.327286958694458, L5: 0.01799674704670906
Epoch 4000, Loss: -1.6156742572784424, Losses: L1: -2.8904738426208496, L2: 0.6558093428611755, L3: 0.0016024112701416016, L4: 0.29198503494262695, L5: 0.016708843410015106
Epoch 4500, Loss: -1.613535761833191, Losses: L1: -2.900725841522217, L2: 0.6506946086883545, L3: 0.0005781650543212891, L4: 0.30193763971328735, L5: 0.016021020710468292
Epoch 5000, Loss: -1.6866455078125, Losses: L1: -2.909045696258545, L2: 0.6464993357658386, L3: 0.0011581778526306152, L4: 0.2717882990837097, L5: 0.0155829768627882
Epoch 5500, Loss: -1.7161260843276978, Losses: L1: -2.915595054626465, L2: 0.6443821787834167, L3: 0.0007897615432739258, L4: 0.26177898049354553, L5: 0.015369453467428684
Epoch 6000, Loss: -1.728535771369934, Losses: L1: -2.9192490577697754, L2: 0.6431609988212585, L3: 8.928775787353516e-05, L4: 0.2585065960884094, L5: 0.015224790200591087
Epoch 6500, Loss: -1.7355129718780518, Losses: L1: -2.9234068393707275, L2: 0.6435650587081909, L3: 1.4901161193847656e-06, L4: 0.2570332884788513, L5: 0.01513045746833086
Epoch 7000, Loss: -1.7426185607910156, Losses: L1: -2.9262607097625732, L2: 0.6440330743789673, L3: 0.00010645389556884766, L4: 0.25467556715011597, L5: 0.015075772069394588
Epoch 7500, Loss: -1.7465087175369263, Losses: L1: -2.927574396133423, L2: 0.6438890695571899, L3: 0.00010538101196289062, L4: 0.2534995377063751, L5: 0.015036038123071194
Epoch 8000, Loss: -1.7492282390594482, Losses: L1: -2.928926944732666, L2: 0.6440955996513367, L3: 8.493661880493164e-05, L4: 0.25274795293807983, L5: 0.01501115970313549
Epoch 8500, Loss: -1.7511932849884033, Losses: L1: -2.930009603500366, L2: 0.6443964838981628, L3: 2.2649765014648438e-06, L4: 0.25222063064575195, L5: 0.01498809177428484
Epoch 9000, Loss: -1.752524495124817, Losses: L1: -2.9306206703186035, L2: 0.6445109248161316, L3: 1.71661376953125e-05, L4: 0.2518070340156555, L5: 0.014976955950260162
Epoch 9500, Loss: -1.7534024715423584, Losses: L1: -2.9308035373687744, L2: 0.6443538665771484, L3: 9.5367431640625e-07, L4: 0.25155651569366455, L5: 0.014966589398682117
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0066404342651367, Constraint losses: L1: 7.546369552612305, L2: 3.935757194994949e-05, L3: 0.9995275735855103, L4: 0.9995271563529968
Epoch 500, Loss: 0.002628900809213519, Constraint losses: L1: -0.9850227236747742, L2: 0.0, L3: 0.0028057098388671875, L4: 0.0008082137792371213
Epoch 1000, Loss: 0.0013808500953018665, Constraint losses: L1: -1.114737868309021, L2: 0.0, L3: 0.0022475123405456543, L4: 0.00024807575391605496
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.006380796432495, Constraint losses: L1: 7.463026523590088, L2: 2.8215648853802122e-05, L3: 0.9994449019432068, L4: 0.9994446039199829
Epoch 500, Loss: 0.002077157376334071, Constraint losses: L1: -1.0744590759277344, L2: 0.0, L3: 0.002574920654296875, L4: 0.0005766958929598331
Epoch 1000, Loss: 0.0012374089565128088, Constraint losses: L1: -1.116016149520874, L2: 0.0, L3: 0.0021764636039733887, L4: 0.00017696156282909214
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 51.85176086425781, Losses: L1: 6.579621315002441, L2: 6.354475044645369e-05, L3: 0.9989573359489441, L4: 86.23554229736328, L5: 0.3127841353416443
Epoch 500, Loss: -1.5386288166046143, Losses: L1: -3.038346290588379, L2: 0.7986380457878113, L3: 0.06306535005569458, L4: 1.1178432703018188, L5: 0.03205396980047226
Epoch 1000, Loss: -2.3580286502838135, Losses: L1: -3.6650118827819824, L2: 0.6531049609184265, L3: 0.04012328386306763, L4: 1.1324491500854492, L5: 0.014814119786024094
Epoch 1500, Loss: -3.201575756072998, Losses: L1: -3.894770622253418, L2: 0.34540578722953796, L3: 0.014051496982574463, L4: 0.6259294152259827, L5: 0.013442355208098888
Epoch 2000, Loss: 0.23815859854221344, Losses: L1: -1.2137730121612549, L2: 0.3744228780269623, L3: 0.062372565269470215, L4: 1.8697596788406372, L5: 0.03576746582984924
Epoch 2500, Loss: -0.5805251002311707, Losses: L1: -1.377761960029602, L2: 0.3888670802116394, L3: 0.06966078281402588, L4: 0.5106563568115234, L5: 0.02744007110595703
Epoch 3000, Loss: -0.6784010529518127, Losses: L1: -1.4398689270019531, L2: 0.40975961089134216, L3: 0.0654941201210022, L4: 0.4104585647583008, L5: 0.030981414020061493
Epoch 3500, Loss: -0.757193922996521, Losses: L1: -1.4864062070846558, L2: 0.4231700003147125, L3: 0.0660097599029541, L4: 0.3177904188632965, L5: 0.030255164951086044
Epoch 4000, Loss: -0.8037016987800598, Losses: L1: -1.515344262123108, L2: 0.4340224862098694, L3: 0.06495058536529541, L4: 0.26433518528938293, L5: 0.031102575361728668
Epoch 4500, Loss: -0.8270869851112366, Losses: L1: -1.5369020700454712, L2: 0.4385611116886139, L3: 0.06426072120666504, L4: 0.2538377642631531, L5: 0.031627263873815536
Epoch 5000, Loss: -0.8477280139923096, Losses: L1: -1.555592656135559, L2: 0.4410800039768219, L3: 0.06425988674163818, L4: 0.24462786316871643, L5: 0.0319020040333271
Epoch 5500, Loss: -0.8633295297622681, Losses: L1: -1.5707532167434692, L2: 0.44297879934310913, L3: 0.0644305944442749, L4: 0.2390487790107727, L5: 0.0321187749505043
Epoch 6000, Loss: -0.874263346195221, Losses: L1: -1.5830134153366089, L2: 0.44632700085639954, L3: 0.06436246633529663, L4: 0.23503778874874115, L5: 0.03235848248004913
Epoch 6500, Loss: -0.882051408290863, Losses: L1: -1.5928412675857544, L2: 0.44989824295043945, L3: 0.06425297260284424, L4: 0.23224809765815735, L5: 0.03252328559756279
Epoch 7000, Loss: -0.8876494765281677, Losses: L1: -1.5994160175323486, L2: 0.4521248936653137, L3: 0.06426537036895752, L4: 0.2295701801776886, L5: 0.03265175223350525
Epoch 7500, Loss: -0.8916173577308655, Losses: L1: -1.6039918661117554, L2: 0.4537603259086609, L3: 0.06419861316680908, L4: 0.22765742242336273, L5: 0.03277662396430969
Epoch 8000, Loss: -0.8943880796432495, Losses: L1: -1.6073600053787231, L2: 0.4550440311431885, L3: 0.06414246559143066, L4: 0.22643405199050903, L5: 0.0328519232571125
Epoch 8500, Loss: -0.8963705897331238, Losses: L1: -1.6097155809402466, L2: 0.45584383606910706, L3: 0.06411540508270264, L4: 0.2256360501050949, L5: 0.03290478140115738
Epoch 9000, Loss: -0.8977208733558655, Losses: L1: -1.611274242401123, L2: 0.45642030239105225, L3: 0.06408822536468506, L4: 0.2249782681465149, L5: 0.032935064285993576
Epoch 9500, Loss: -0.8986060619354248, Losses: L1: -1.6123106479644775, L2: 0.45676952600479126, L3: 0.06406563520431519, L4: 0.22465260326862335, L5: 0.032955102622509
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0251379013061523, Constraint losses: L1: 18.42068099975586, L2: 0.00223896699026227, L3: 1.0022389888763428, L4: 1.0022392272949219
Epoch 500, Loss: 0.002565177157521248, Constraint losses: L1: -0.9098037481307983, L2: 0.0, L3: 0.0027361512184143066, L4: 0.0007388298399746418
Epoch 1000, Loss: 0.0012886278564110398, Constraint losses: L1: -1.1150439977645874, L2: 0.0, L3: 0.0022014379501342773, L4: 0.0002022339031100273
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001791000366211, Constraint losses: L1: 6.09666633605957, L2: 0.0, L3: 0.997847318649292, L4: 0.9978468418121338
Epoch 500, Loss: 0.002118166768923402, Constraint losses: L1: -1.1069926023483276, L2: 0.0, L3: 0.0026117563247680664, L4: 0.0006134030409157276
Epoch 1000, Loss: 0.0012887726770713925, Constraint losses: L1: -1.1168252229690552, L2: 0.0, L3: 0.0022025108337402344, L4: 0.00020308708189986646
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.435302734375, Losses: L1: 6.555649280548096, L2: 0.0, L3: 0.9987174868583679, L4: 81.1931381225586, L5: 0.28564900159835815
Epoch 500, Loss: 1.059800148010254, Losses: L1: -2.0396103858947754, L2: 1.0675603151321411, L3: 0.10619556903839111, L4: 3.5009372234344482, L5: 0.06899051368236542
Epoch 1000, Loss: -2.5324807167053223, Losses: L1: -3.6369948387145996, L2: 0.5334070324897766, L3: 0.055727601051330566, L4: 0.8967916369438171, L5: 0.011256333440542221
Epoch 1500, Loss: -2.3060271739959717, Losses: L1: -3.895681381225586, L2: 0.5264649391174316, L3: 0.020087063312530518, L4: 2.0029754638671875, L5: 0.021527547389268875
Epoch 2000, Loss: -3.256744146347046, Losses: L1: -4.011001110076904, L2: 0.49465975165367126, L3: 0.003560304641723633, L4: 0.4861624240875244, L5: 0.00939537025988102
Epoch 2500, Loss: -3.135162353515625, Losses: L1: -4.017513275146484, L2: 0.46846678853034973, L3: 0.004732012748718262, L4: 0.7929994463920593, L5: 0.007920544594526291
Epoch 3000, Loss: -2.781165361404419, Losses: L1: -3.6206676959991455, L2: 0.5708985328674316, L3: 0.03473252058029175, L4: 0.3803790807723999, L5: 0.00894917268306017
Epoch 3500, Loss: -3.496095657348633, Losses: L1: -4.004135608673096, L2: 0.3921472430229187, L3: 0.002282261848449707, L4: 0.2072906345129013, L5: 0.007682861294597387
Epoch 4000, Loss: -3.5160393714904785, Losses: L1: -4.013791561126709, L2: 0.38474002480506897, L3: 0.002229452133178711, L4: 0.20267826318740845, L5: 0.007214020937681198
Epoch 4500, Loss: -3.554616689682007, Losses: L1: -4.0191850662231445, L2: 0.38263359665870667, L3: 0.0020885467529296875, L4: 0.14120268821716309, L5: 0.0071562062948942184
Epoch 5000, Loss: -3.565380334854126, Losses: L1: -4.009913444519043, L2: 0.36762937903404236, L3: 0.00035691261291503906, L4: 0.13823336362838745, L5: 0.0070734708569943905
Epoch 5500, Loss: -3.5704057216644287, Losses: L1: -4.016262054443359, L2: 0.3699430525302887, L3: 0.0004774332046508789, L4: 0.13584500551223755, L5: 0.007035806309431791
Epoch 6000, Loss: -3.5741028785705566, Losses: L1: -4.016270160675049, L2: 0.36728501319885254, L3: 0.00026297569274902344, L4: 0.1347639262676239, L5: 0.006974461022764444
Epoch 6500, Loss: -3.5766801834106445, Losses: L1: -4.017751693725586, L2: 0.36675354838371277, L3: 0.00020575523376464844, L4: 0.13394108414649963, L5: 0.006935880985110998
Epoch 7000, Loss: -3.5785317420959473, Losses: L1: -4.017037391662598, L2: 0.3647345006465912, L3: 0.00010275840759277344, L4: 0.13332168757915497, L5: 0.006904930807650089
Epoch 7500, Loss: -3.5798532962799072, Losses: L1: -4.017590522766113, L2: 0.36442503333091736, L3: 8.976459503173828e-05, L4: 0.13247430324554443, L5: 0.0068955253809690475
Epoch 8000, Loss: -3.5807647705078125, Losses: L1: -4.0172648429870605, L2: 0.36348381638526917, L3: 8.106231689453125e-06, L4: 0.13222341239452362, L5: 0.006888061296194792
Epoch 8500, Loss: -3.5812666416168213, Losses: L1: -4.017568111419678, L2: 0.36338362097740173, L3: 2.205371856689453e-05, L4: 0.1319904625415802, L5: 0.006878638174384832
Epoch 9000, Loss: -3.581609010696411, Losses: L1: -4.017716884613037, L2: 0.36327657103538513, L3: 1.7642974853515625e-05, L4: 0.13184426724910736, L5: 0.006874173413962126
Epoch 9500, Loss: -3.5818397998809814, Losses: L1: -4.017557144165039, L2: 0.3629600405693054, L3: 1.1622905731201172e-05, L4: 0.13172738254070282, L5: 0.0068705580197274685
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9958746433258057, Constraint losses: L1: 5.326018810272217, L2: 0.0, L3: 0.9952746629714966, L4: 0.9952739477157593
Epoch 500, Loss: 0.002280785236507654, Constraint losses: L1: -1.094740629196167, L2: 0.0, L3: 0.002686798572540283, L4: 0.0006887273630127311
Epoch 1000, Loss: 0.0013295349199324846, Constraint losses: L1: -1.116943359375, L2: 0.0, L3: 0.0022228360176086426, L4: 0.0002236423606518656
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.025935173034668, Constraint losses: L1: 18.42068099975586, L2: 0.002505038632079959, L3: 1.0025050640106201, L4: 1.0025043487548828
Epoch 500, Loss: 0.0022902272175997496, Constraint losses: L1: -1.076841115951538, L2: 0.0, L3: 0.002682507038116455, L4: 0.0006845613243058324
Epoch 1000, Loss: 0.0013078065821900964, Constraint losses: L1: -1.1166850328445435, L2: 0.0, L3: 0.002211928367614746, L4: 0.00021256327454466373
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 50.27836608886719, Losses: L1: 5.697693824768066, L2: 0.0, L3: 0.9968952536582947, L4: 83.97203063964844, L5: 0.3004331886768341
Epoch 500, Loss: -0.6382195353507996, Losses: L1: -3.346792221069336, L2: 0.9427998065948486, L3: 0.04254424571990967, L4: 3.2431108951568604, L5: 0.029564479365944862
Epoch 1000, Loss: 0.47648054361343384, Losses: L1: -1.269067406654358, L2: 0.3508562743663788, L3: 0.08253002166748047, L4: 2.287480115890503, L5: 0.042945776134729385
Epoch 1500, Loss: -0.08042450249195099, Losses: L1: -1.4977374076843262, L2: 0.4048076570034027, L3: 0.07612669467926025, L4: 1.5436064004898071, L5: 0.04422431439161301
Epoch 2000, Loss: -0.6298805475234985, Losses: L1: -1.625585675239563, L2: 0.4590202867984772, L3: 0.07608622312545776, L4: 0.6343597173690796, L5: 0.03366629406809807
Epoch 2500, Loss: -0.571432888507843, Losses: L1: -1.6669319868087769, L2: 0.47624167799949646, L3: 0.06960529088973999, L4: 0.8146564960479736, L5: 0.036359284073114395
Epoch 3000, Loss: -0.7019162178039551, Losses: L1: -1.694498896598816, L2: 0.48822253942489624, L3: 0.06624221801757812, L4: 0.6025747060775757, L5: 0.03529419004917145
Epoch 3500, Loss: -0.819221019744873, Losses: L1: -1.714748501777649, L2: 0.4964367151260376, L3: 0.06685727834701538, L4: 0.3949103355407715, L5: 0.033960532397031784
Epoch 4000, Loss: -0.8296439051628113, Losses: L1: -1.7246522903442383, L2: 0.4992305636405945, L3: 0.06645476818084717, L4: 0.38938286900520325, L5: 0.034088410437107086
Epoch 4500, Loss: -0.8474505543708801, Losses: L1: -1.730825424194336, L2: 0.5004749894142151, L3: 0.06614458560943604, L4: 0.3663032352924347, L5: 0.03372958302497864
Epoch 5000, Loss: -0.8546268939971924, Losses: L1: -1.7340130805969238, L2: 0.5003779530525208, L3: 0.06551229953765869, L4: 0.36142653226852417, L5: 0.033635202795267105
Epoch 5500, Loss: -0.8597217798233032, Losses: L1: -1.7365834712982178, L2: 0.5003566145896912, L3: 0.06504720449447632, L4: 0.3586766719818115, L5: 0.03353612497448921
Epoch 6000, Loss: -0.8638302087783813, Losses: L1: -1.7387232780456543, L2: 0.5005097389221191, L3: 0.06458240747451782, L4: 0.35663148760795593, L5: 0.03345136716961861
Epoch 6500, Loss: -0.8667691946029663, Losses: L1: -1.7404026985168457, L2: 0.5007486939430237, L3: 0.06417793035507202, L4: 0.35557714104652405, L5: 0.03337021544575691
Epoch 7000, Loss: -0.8689404726028442, Losses: L1: -1.7413424253463745, L2: 0.5007686614990234, L3: 0.06386888027191162, L4: 0.3543927073478699, L5: 0.03334958851337433
Epoch 7500, Loss: -0.8705157041549683, Losses: L1: -1.741847038269043, L2: 0.5006438493728638, L3: 0.0636017918586731, L4: 0.3536040186882019, L5: 0.0333409309387207
Epoch 8000, Loss: -0.871633768081665, Losses: L1: -1.7423462867736816, L2: 0.5006404519081116, L3: 0.06338071823120117, L4: 0.35330289602279663, L5: 0.033329613506793976
Epoch 8500, Loss: -0.8724769949913025, Losses: L1: -1.7426649332046509, L2: 0.500577986240387, L3: 0.06325781345367432, L4: 0.3529312014579773, L5: 0.033314310014247894
Epoch 9000, Loss: -0.8730223178863525, Losses: L1: -1.7429293394088745, L2: 0.500600278377533, L3: 0.0631566047668457, L4: 0.3527665138244629, L5: 0.03330517187714577
Epoch 9500, Loss: -0.8734287023544312, Losses: L1: -1.7431206703186035, L2: 0.5006158947944641, L3: 0.06308519840240479, L4: 0.3526148200035095, L5: 0.03329916298389435
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0222158432006836, Constraint losses: L1: 18.42068099975586, L2: 0.001264807302504778, L3: 1.0012648105621338, L4: 1.0012654066085815
Epoch 500, Loss: 0.0025173532776534557, Constraint losses: L1: -1.0857319831848145, L2: 0.0, L3: 0.002800464630126953, L4: 0.0008026206633076072
Epoch 1000, Loss: 0.0014029163867235184, Constraint losses: L1: -1.1172144412994385, L2: 0.0, L3: 0.0022597312927246094, L4: 0.0002603995380923152
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0283169746398926, Constraint losses: L1: 18.42068099975586, L2: 0.003298819065093994, L3: 1.0032987594604492, L4: 1.0032986402511597
Epoch 500, Loss: 0.0022194036282598972, Constraint losses: L1: -1.085279941558838, L2: 0.0, L3: 0.002651393413543701, L4: 0.0006532901898026466
Epoch 1000, Loss: 0.0013030435657128692, Constraint losses: L1: -1.116668462753296, L2: 0.0, L3: 0.0022095441818237305, L4: 0.00021016792743466794
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.38572692871094, Losses: L1: 8.760069847106934, L2: 9.100765601033345e-05, L3: 0.9973585605621338, L4: 83.48150634765625, L5: 0.29868999123573303
Epoch 500, Loss: 0.8775607347488403, Losses: L1: -1.4243781566619873, L2: 0.5657801628112793, L3: 0.09921771287918091, L4: 1.5201445817947388, L5: 0.035157401114702225
Epoch 1000, Loss: 0.3599109649658203, Losses: L1: -2.5367653369903564, L2: 0.7173469662666321, L3: 0.0778093934059143, L4: 2.0000157356262207, L5: 0.04738974571228027
Epoch 1500, Loss: -1.624335527420044, Losses: L1: -3.018904447555542, L2: 0.732844889163971, L3: 0.06502771377563477, L4: 0.5043097734451294, L5: 0.05471782013773918
Epoch 2000, Loss: -1.9292583465576172, Losses: L1: -3.316256523132324, L2: 0.7627571821212769, L3: 0.05904132127761841, L4: 0.478082537651062, L5: 0.056151531636714935
Epoch 2500, Loss: -2.0140652656555176, Losses: L1: -3.4447813034057617, L2: 0.7240827679634094, L3: 0.056996285915374756, L4: 0.5649937987327576, L5: 0.05529400333762169
Epoch 3000, Loss: -2.3680789470672607, Losses: L1: -3.5621602535247803, L2: 0.7300687432289124, L3: 0.05508697032928467, L4: 0.3243597149848938, L5: 0.05895789712667465
Epoch 3500, Loss: -2.5165562629699707, Losses: L1: -3.6240906715393066, L2: 0.7190004587173462, L3: 0.05533355474472046, L4: 0.24938014149665833, L5: 0.056973423808813095
Epoch 4000, Loss: -2.6109657287597656, Losses: L1: -3.6837029457092285, L2: 0.7256043553352356, L3: 0.05451017618179321, L4: 0.2103244960308075, L5: 0.055575620383024216
Epoch 4500, Loss: -2.6759631633758545, Losses: L1: -3.7397773265838623, L2: 0.7360639572143555, L3: 0.05361354351043701, L4: 0.19311387836933136, L5: 0.054818738251924515
Epoch 5000, Loss: -2.7281970977783203, Losses: L1: -3.779677391052246, L2: 0.7373201251029968, L3: 0.05295759439468384, L4: 0.18085439503192902, L5: 0.054780758917331696
Epoch 5500, Loss: -2.7672436237335205, Losses: L1: -3.806326150894165, L2: 0.7328986525535583, L3: 0.05228513479232788, L4: 0.1741710901260376, L5: 0.05488516017794609
Epoch 6000, Loss: -2.7983579635620117, Losses: L1: -3.823032855987549, L2: 0.7245773673057556, L3: 0.05144011974334717, L4: 0.16970773041248322, L5: 0.05501875653862953
Epoch 6500, Loss: -2.8211801052093506, Losses: L1: -3.843890905380249, L2: 0.7271092534065247, L3: 0.0507388710975647, L4: 0.16655772924423218, L5: 0.05513244494795799
Epoch 7000, Loss: -2.8357248306274414, Losses: L1: -3.85300612449646, L2: 0.7249286770820618, L3: 0.050068020820617676, L4: 0.16468235850334167, L5: 0.055068716406822205
Epoch 7500, Loss: -2.8458878993988037, Losses: L1: -3.8650293350219727, L2: 0.7292745113372803, L3: 0.04943275451660156, L4: 0.16350115835666656, L5: 0.055000174790620804
Epoch 8000, Loss: -2.8528971672058105, Losses: L1: -3.869310140609741, L2: 0.7279822826385498, L3: 0.04902446269989014, L4: 0.16292692720890045, L5: 0.05490978807210922
Epoch 8500, Loss: -2.8577182292938232, Losses: L1: -3.870447874069214, L2: 0.7252840995788574, L3: 0.048712074756622314, L4: 0.16260309517383575, L5: 0.05483648553490639
Epoch 9000, Loss: -2.860987424850464, Losses: L1: -3.872021436691284, L2: 0.724301815032959, L3: 0.048456788063049316, L4: 0.1624213457107544, L5: 0.05479493364691734
Epoch 9500, Loss: -2.8631722927093506, Losses: L1: -3.8735475540161133, L2: 0.7240698337554932, L3: 0.048274993896484375, L4: 0.1623706817626953, L5: 0.05476938933134079
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9971585273742676, Constraint losses: L1: 5.465917110443115, L2: 0.0, L3: 0.9958464503288269, L4: 0.9958460927009583
Epoch 500, Loss: 0.0022734031081199646, Constraint losses: L1: -1.0465551614761353, L2: 0.0, L3: 0.002659022808074951, L4: 0.0006609355332329869
Epoch 1000, Loss: 0.0012917290441691875, Constraint losses: L1: -1.1175373792648315, L2: 0.0, L3: 0.002204418182373047, L4: 0.00020484827109612525
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9997360706329346, Constraint losses: L1: 5.794343948364258, L2: 0.0, L3: 0.9969708323478699, L4: 0.9969709515571594
Epoch 500, Loss: 0.0023905751295387745, Constraint losses: L1: -1.0548757314682007, L2: 0.0, L3: 0.002721726894378662, L4: 0.0007237239042297006
Epoch 1000, Loss: 0.0013438314199447632, Constraint losses: L1: -1.1161894798278809, L2: 0.0, L3: 0.002229750156402588, L4: 0.00023027084534987807
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 85.9128646850586, Losses: L1: 6.1887102127075195, L2: 0.0012830110499635339, L3: 0.9987461566925049, L4: 77.46159362792969, L5: 0.2637893855571747
Epoch 500, Loss: 0.8239907026290894, Losses: L1: -1.4407627582550049, L2: 0.4376257658004761, L3: 0.09666872024536133, L4: 1.6030821800231934, L5: 0.0307080689817667
Epoch 1000, Loss: 0.9043734669685364, Losses: L1: -2.4918692111968994, L2: 1.011972188949585, L3: 0.06527787446975708, L4: 2.2090985774993896, L5: 0.04461616650223732
Epoch 1500, Loss: -1.3492501974105835, Losses: L1: -2.8244435787200928, L2: 0.7256491780281067, L3: 0.054408907890319824, L4: 0.624228298664093, L5: 0.016498247161507607
Epoch 2000, Loss: -0.731249988079071, Losses: L1: -3.055466890335083, L2: 0.8926056623458862, L3: 0.04734385013580322, L4: 1.3214144706726074, L5: 0.015509177930653095
Epoch 2500, Loss: -2.032985210418701, Losses: L1: -2.8409013748168945, L2: 0.39391401410102844, L3: 0.05236846208572388, L4: 0.29483431577682495, L5: 0.014430651441216469
Epoch 3000, Loss: -2.1652755737304688, Losses: L1: -2.949315071105957, L2: 0.43096786737442017, L3: 0.048593997955322266, L4: 0.24314071238040924, L5: 0.012742968276143074
Epoch 3500, Loss: -2.234006643295288, Losses: L1: -2.9914894104003906, L2: 0.42216750979423523, L3: 0.04733741283416748, L4: 0.22907987236976624, L5: 0.011560509912669659
Epoch 4000, Loss: -2.27783203125, Losses: L1: -3.0389411449432373, L2: 0.43220004439353943, L3: 0.04655575752258301, L4: 0.22464393079280853, L5: 0.011153641156852245
Epoch 4500, Loss: -2.305414915084839, Losses: L1: -3.0613813400268555, L2: 0.4306866228580475, L3: 0.046212077140808105, L4: 0.22174611687660217, L5: 0.011109264567494392
Epoch 5000, Loss: -2.3297958374023438, Losses: L1: -3.0995519161224365, L2: 0.4535056948661804, L3: 0.04555732011795044, L4: 0.21418845653533936, L5: 0.010947178117930889
Epoch 5500, Loss: -2.34696364402771, Losses: L1: -3.1128029823303223, L2: 0.4516623020172119, L3: 0.04554617404937744, L4: 0.21208764612674713, L5: 0.01099711935967207
Epoch 6000, Loss: -2.360157012939453, Losses: L1: -3.125293254852295, L2: 0.45201337337493896, L3: 0.04548537731170654, L4: 0.2110777199268341, L5: 0.011074247770011425
Epoch 6500, Loss: -2.3704283237457275, Losses: L1: -3.141523838043213, L2: 0.45921790599823, L3: 0.04535198211669922, L4: 0.21004551649093628, L5: 0.011127876117825508
Epoch 7000, Loss: -2.3778772354125977, Losses: L1: -3.1494922637939453, L2: 0.4603783190250397, L3: 0.04528099298477173, L4: 0.20955008268356323, L5: 0.011124427430331707
Epoch 7500, Loss: -2.383347272872925, Losses: L1: -3.1565005779266357, L2: 0.4625548720359802, L3: 0.04522061347961426, L4: 0.2090286761522293, L5: 0.011128404177725315
Epoch 8000, Loss: -2.387164831161499, Losses: L1: -3.1632986068725586, L2: 0.4659917950630188, L3: 0.04517930746078491, L4: 0.20866328477859497, L5: 0.011120354756712914
Epoch 8500, Loss: -2.3896849155426025, Losses: L1: -3.16752552986145, L2: 0.46796855330467224, L3: 0.045160651206970215, L4: 0.2084248960018158, L5: 0.01112605445086956
Epoch 9000, Loss: -2.39143967628479, Losses: L1: -3.1700241565704346, L2: 0.469031423330307, L3: 0.04513716697692871, L4: 0.208151713013649, L5: 0.011126894503831863
Epoch 9500, Loss: -2.3925552368164062, Losses: L1: -3.1712377071380615, L2: 0.4693416357040405, L3: 0.04512035846710205, L4: 0.20797772705554962, L5: 0.011122518219053745
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.003476619720459, Constraint losses: L1: 6.505614280700684, L2: 0.0, L3: 0.9984853863716125, L4: 0.9984855651855469
Epoch 500, Loss: 0.0022698636166751385, Constraint losses: L1: -1.1046509742736816, L2: 0.0, L3: 0.0026863813400268555, L4: 0.0006881332374177873
Epoch 1000, Loss: 0.0013287813635542989, Constraint losses: L1: -1.1171705722808838, L2: 0.0, L3: 0.002222716808319092, L4: 0.00022323524171952158
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.02429461479187, Constraint losses: L1: 18.42068099975586, L2: 0.001957747619599104, L3: 1.0019577741622925, L4: 1.0019583702087402
Epoch 500, Loss: 0.0023973898496478796, Constraint losses: L1: -1.1034951210021973, L2: 0.0, L3: 0.0027495622634887695, L4: 0.0007513226591981947
Epoch 1000, Loss: 0.0013758765999227762, Constraint losses: L1: -1.1168752908706665, L2: 0.0, L3: 0.0022461414337158203, L4: 0.0002466105215717107
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 88.63831329345703, Losses: L1: 18.42068099975586, L2: 0.0021998651791363955, L3: 1.0021998882293701, L4: 67.77308654785156, L5: 0.2189762145280838
Epoch 500, Loss: 23.682178497314453, Losses: L1: 3.7283146381378174, L2: 0.30720776319503784, L3: 0.24515151977539062, L4: 18.722837448120117, L5: 0.2167574167251587
Epoch 1000, Loss: 57.882781982421875, Losses: L1: 4.283194541931152, L2: 0.0, L3: 0.9710407853126526, L4: 51.023582458496094, L5: 0.31696102023124695
Epoch 1500, Loss: 57.78759002685547, Losses: L1: 4.160577774047852, L2: 0.0, L3: 0.9675986170768738, L4: 51.056480407714844, L5: 0.3176661431789398
Epoch 2000, Loss: 57.752220153808594, Losses: L1: 4.117221832275391, L2: 0.0, L3: 0.9660288095474243, L4: 51.06707000732422, L5: 0.31793588399887085
Epoch 2500, Loss: 57.7281379699707, Losses: L1: 4.089188098907471, L2: 0.0, L3: 0.9649692177772522, L4: 51.07268524169922, L5: 0.31816336512565613
Epoch 3000, Loss: 57.7089958190918, Losses: L1: 4.067689418792725, L2: 0.0, L3: 0.964148223400116, L4: 51.07621383666992, L5: 0.31839707493782043
Epoch 3500, Loss: 57.693233489990234, Losses: L1: 4.050361156463623, L2: 0.0, L3: 0.9634817838668823, L4: 51.07862854003906, L5: 0.3186396360397339
Epoch 4000, Loss: 57.68015670776367, Losses: L1: 4.0362043380737305, L2: 0.0, L3: 0.9629380106925964, L4: 51.0803108215332, L5: 0.3188813030719757
Epoch 4500, Loss: 57.6693000793457, Losses: L1: 4.024539470672607, L2: 0.0, L3: 0.9624959826469421, L4: 51.08154296875, L5: 0.31911206245422363
Epoch 5000, Loss: 57.66028594970703, Losses: L1: 4.0149078369140625, L2: 0.0, L3: 0.9621395468711853, L4: 51.08244705200195, L5: 0.3193266987800598
Epoch 5500, Loss: 57.652793884277344, Losses: L1: 4.006924152374268, L2: 0.0, L3: 0.9618547558784485, L4: 51.08312225341797, L5: 0.31951993703842163
Epoch 6000, Loss: 57.6465950012207, Losses: L1: 4.000243186950684, L2: 0.0, L3: 0.9616284370422363, L4: 51.083717346191406, L5: 0.31968870759010315
Epoch 6500, Loss: 57.6414794921875, Losses: L1: 3.9947667121887207, L2: 0.0, L3: 0.9614519476890564, L4: 51.08414077758789, L5: 0.3198338747024536
Epoch 7000, Loss: 57.63729476928711, Losses: L1: 3.9902751445770264, L2: 0.0, L3: 0.9613147974014282, L4: 51.08448028564453, L5: 0.3199560046195984
Epoch 7500, Loss: 57.6338996887207, Losses: L1: 3.98663067817688, L2: 0.0, L3: 0.961209774017334, L4: 51.08473587036133, L5: 0.320056676864624
Epoch 8000, Loss: 57.63118362426758, Losses: L1: 3.9837043285369873, L2: 0.0, L3: 0.9611298441886902, L4: 51.08494186401367, L5: 0.32013800740242004
Epoch 8500, Loss: 57.62904357910156, Losses: L1: 3.9814321994781494, L2: 0.0, L3: 0.9610716104507446, L4: 51.08506393432617, L5: 0.32020267844200134
Epoch 9000, Loss: 57.62739181518555, Losses: L1: 3.979687452316284, L2: 0.0, L3: 0.9610291719436646, L4: 51.085140228271484, L5: 0.3202528655529022
Epoch 9500, Loss: 57.62614440917969, Losses: L1: 3.9784128665924072, L2: 0.0, L3: 0.9610002636909485, L4: 51.085147857666016, L5: 0.3202909529209137
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.003248453140259, Constraint losses: L1: 6.419750213623047, L2: 0.0, L3: 0.9984144568443298, L4: 0.9984142780303955
Epoch 500, Loss: 0.0025025696959346533, Constraint losses: L1: -1.040027379989624, L2: 0.0, L3: 0.002770066261291504, L4: 0.0007725309114903212
Epoch 1000, Loss: 0.0013621493708342314, Constraint losses: L1: -1.117424488067627, L2: 0.0, L3: 0.0022394657135009766, L4: 0.0002401082601863891
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.003175973892212, Constraint losses: L1: 6.386724472045898, L2: 0.0, L3: 0.998394787311554, L4: 0.9983944296836853
Epoch 500, Loss: 0.0026616333052515984, Constraint losses: L1: -1.1062456369400024, L2: 0.0, L3: 0.0028827786445617676, L4: 0.0008851003367453814
Epoch 1000, Loss: 0.0014677585568279028, Constraint losses: L1: -1.117013931274414, L2: 0.0, L3: 0.0022919178009033203, L4: 0.0002928547910414636
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.05833435058594, Losses: L1: 13.390006065368652, L2: 0.001125648501329124, L3: 1.0005476474761963, L4: 75.7687759399414, L5: 0.25712263584136963
Epoch 500, Loss: 2.088517189025879, Losses: L1: -2.6129722595214844, L2: 1.0812844038009644, L3: 0.07113468647003174, L4: 1.7148324251174927, L5: 0.09654124081134796
Epoch 1000, Loss: 1.0532996654510498, Losses: L1: -3.1256439685821533, L2: 1.0093343257904053, L3: 0.05330610275268555, L4: 1.5065364837646484, L5: 0.0998481810092926
Epoch 1500, Loss: -0.4589506983757019, Losses: L1: -3.5226621627807617, L2: 1.0285764932632446, L3: 0.05059611797332764, L4: 0.9448644518852234, L5: 0.08842789381742477
Epoch 2000, Loss: -2.233579397201538, Losses: L1: -3.8459572792053223, L2: 1.088333010673523, L3: 0.05064237117767334, L4: 0.19121360778808594, L5: 0.08066557347774506
Epoch 2500, Loss: -2.377224922180176, Losses: L1: -3.854776620864868, L2: 0.9861999750137329, L3: 0.05087536573410034, L4: 0.1762532889842987, L5: 0.07418838143348694
Epoch 3000, Loss: -2.3109536170959473, Losses: L1: -3.8427257537841797, L2: 0.9485122561454773, L3: 0.04666072130203247, L4: 0.2282535433769226, L5: 0.06686224043369293
Epoch 3500, Loss: -2.079557418823242, Losses: L1: -3.8523430824279785, L2: 0.9020472168922424, L3: 0.04751020669937134, L4: 0.37239018082618713, L5: 0.061875950545072556
Epoch 4000, Loss: -2.6449928283691406, Losses: L1: -3.8493142127990723, L2: 0.8761497735977173, L3: 0.04684460163116455, L4: 0.10181157290935516, L5: 0.061718933284282684
Epoch 4500, Loss: -2.67059588432312, Losses: L1: -3.848773241043091, L2: 0.8625721335411072, L3: 0.046315670013427734, L4: 0.09641716629266739, L5: 0.06027868017554283
Epoch 5000, Loss: -2.6867427825927734, Losses: L1: -3.8512258529663086, L2: 0.8550517559051514, L3: 0.04590785503387451, L4: 0.09400813281536102, L5: 0.05919872224330902
Epoch 5500, Loss: -2.6999528408050537, Losses: L1: -3.849749803543091, L2: 0.84698486328125, L3: 0.045861124992370605, L4: 0.090879887342453, L5: 0.05866013467311859
Epoch 6000, Loss: -2.7069334983825684, Losses: L1: -3.8552486896514893, L2: 0.8470301628112793, L3: 0.04566323757171631, L4: 0.09042654931545258, L5: 0.05821075290441513
Epoch 6500, Loss: -2.7136473655700684, Losses: L1: -3.8560397624969482, L2: 0.8443313241004944, L3: 0.04556971788406372, L4: 0.08898869901895523, L5: 0.05788843333721161
Epoch 7000, Loss: -2.717606544494629, Losses: L1: -3.8565094470977783, L2: 0.8422912955284119, L3: 0.04552185535430908, L4: 0.08836953341960907, L5: 0.05765794590115547
Epoch 7500, Loss: -2.7207441329956055, Losses: L1: -3.8554675579071045, L2: 0.8394304513931274, L3: 0.04542529582977295, L4: 0.08784405142068863, L5: 0.0575086772441864
Epoch 8000, Loss: -2.7226920127868652, Losses: L1: -3.856304883956909, L2: 0.839043140411377, L3: 0.045370280742645264, L4: 0.08756755292415619, L5: 0.0573883056640625
Epoch 8500, Loss: -2.724045753479004, Losses: L1: -3.855963945388794, L2: 0.8378605246543884, L3: 0.04534912109375, L4: 0.08734782785177231, L5: 0.05732731893658638
Epoch 9000, Loss: -2.7250232696533203, Losses: L1: -3.8560314178466797, L2: 0.8373748064041138, L3: 0.04529893398284912, L4: 0.08719886839389801, L5: 0.05727590247988701
Epoch 9500, Loss: -2.7256546020507812, Losses: L1: -3.8562350273132324, L2: 0.8371874094009399, L3: 0.0452883243560791, L4: 0.08709686994552612, L5: 0.05724501982331276
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.003093719482422, Constraint losses: L1: 6.425647735595703, L2: 0.0, L3: 0.9983339905738831, L4: 0.9983341097831726
Epoch 500, Loss: 0.0024717438500374556, Constraint losses: L1: -1.1117061376571655, L2: 0.0, L3: 0.0027908682823181152, L4: 0.0007925817044451833
Epoch 1000, Loss: 0.0014102172572165728, Constraint losses: L1: -1.117222547531128, L2: 0.0, L3: 0.0022634267807006836, L4: 0.00026401301147416234
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.003103733062744, Constraint losses: L1: 6.451923370361328, L2: 0.0, L3: 0.9983257055282593, L4: 0.9983261227607727
Epoch 500, Loss: 0.002209558617323637, Constraint losses: L1: -1.0630147457122803, L2: 0.0, L3: 0.0026353001594543457, L4: 0.0006372734205797315
Epoch 1000, Loss: 0.001279215095564723, Constraint losses: L1: -1.115830421447754, L2: 0.0, L3: 0.0021972060203552246, L4: 0.000197839573957026
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 162.0376739501953, Losses: L1: 6.439942836761475, L2: 0.0, L3: 0.9980258345603943, L4: 76.66893005371094, L5: 0.26382312178611755
Epoch 500, Loss: 108.30561065673828, Losses: L1: 5.252039432525635, L2: 0.0, L3: 0.9919673204421997, L4: 50.371124267578125, L5: 0.32738518714904785
Epoch 1000, Loss: 107.92736053466797, Losses: L1: 4.61403226852417, L2: 0.0, L3: 0.9792961478233337, L4: 50.51420211791992, L5: 0.3263345956802368
Epoch 1500, Loss: 107.76530456542969, Losses: L1: 4.438263893127441, L2: 4.172760327492142e-06, L3: 0.9767695665359497, L4: 50.52372360229492, L5: 0.3260533809661865
Epoch 2000, Loss: 111.96751403808594, Losses: L1: 9.280200958251953, L2: 0.0007365198689512908, L3: 0.9979074597358704, L4: 50.18146514892578, L5: 0.3278377950191498
Epoch 2500, Loss: 107.85810852050781, Losses: L1: 4.531559944152832, L2: 0.0, L3: 0.9820603728294373, L4: 50.51824951171875, L5: 0.32592928409576416
Epoch 3000, Loss: 23.384418487548828, Losses: L1: 6.454096794128418, L2: 0.23341774940490723, L3: 0.17590618133544922, L4: 8.109508514404297, L5: 0.12607569992542267
Epoch 3500, Loss: 16.26200294494629, Losses: L1: 5.87592887878418, L2: 0.19294843077659607, L3: 0.2334950566291809, L4: 4.79497766494751, L5: 0.13618133962154388
Epoch 4000, Loss: 14.43187427520752, Losses: L1: 5.693856716156006, L2: 0.18281735479831696, L3: 0.21987801790237427, L4: 3.9913949966430664, L5: 0.13265372812747955
Epoch 4500, Loss: 13.039724349975586, Losses: L1: 5.551901817321777, L2: 0.1419006586074829, L3: 0.21533095836639404, L4: 3.3918561935424805, L5: 0.13154816627502441
Epoch 5000, Loss: 12.027233123779297, Losses: L1: 5.444950580596924, L2: 0.11942753940820694, L3: 0.20437610149383545, L4: 2.962031364440918, L5: 0.1300397664308548
Epoch 5500, Loss: 11.109007835388184, Losses: L1: 5.25893497467041, L2: 0.10546734184026718, L3: 0.19330060482025146, L4: 2.6149086952209473, L5: 0.12818732857704163
Epoch 6000, Loss: 10.60876750946045, Losses: L1: 5.215980529785156, L2: 0.10089513659477234, L3: 0.18325567245483398, L4: 2.398792266845703, L5: 0.1277962327003479
Epoch 6500, Loss: 10.389152526855469, Losses: L1: 5.203181266784668, L2: 0.10204903036355972, L3: 0.17650973796844482, L4: 2.3016715049743652, L5: 0.12755991518497467
Epoch 7000, Loss: 10.27757453918457, Losses: L1: 5.194972038269043, L2: 0.10171650350093842, L3: 0.1736752986907959, L4: 2.2532036304473877, L5: 0.1271287351846695
Epoch 7500, Loss: 10.201712608337402, Losses: L1: 5.1728105545043945, L2: 0.10055675357580185, L3: 0.1726365089416504, L4: 2.2280664443969727, L5: 0.1269391030073166
Epoch 8000, Loss: 10.103086471557617, Losses: L1: 5.101439476013184, L2: 0.09941625595092773, L3: 0.1722988486289978, L4: 2.215428113937378, L5: 0.1267770528793335
Epoch 8500, Loss: 10.090977668762207, Losses: L1: 5.095905780792236, L2: 0.09953679889440536, L3: 0.17197227478027344, L4: 2.2124595642089844, L5: 0.1266716867685318
Epoch 9000, Loss: 10.060691833496094, Losses: L1: 5.049526214599609, L2: 0.0981205627322197, L3: 0.17310506105422974, L4: 2.219989061355591, L5: 0.1268572062253952
Epoch 9500, Loss: 10.046091079711914, Losses: L1: 5.052452564239502, L2: 0.0981760323047638, L3: 0.17239558696746826, L4: 2.2119431495666504, L5: 0.12678508460521698
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0237064361572266, Constraint losses: L1: 18.42068099975586, L2: 0.0017618475249037147, L3: 1.001761794090271, L4: 1.0017621517181396
Epoch 500, Loss: 0.0020975142251700163, Constraint losses: L1: -1.0624539852142334, L2: 0.0, L3: 0.0025791525840759277, L4: 0.0005808157729916275
Epoch 1000, Loss: 0.0012378337560221553, Constraint losses: L1: -1.1172566413879395, L2: 0.0, L3: 0.002177298069000244, L4: 0.00017779236077331007
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.045872449874878, Constraint losses: L1: 18.42068099975586, L2: 0.009149898774921894, L3: 1.0091499090194702, L4: 1.0091519355773926
Epoch 500, Loss: 0.002086800057440996, Constraint losses: L1: -1.0788003206253052, L2: 0.0, L3: 0.0025818347930908203, L4: 0.0005837657954543829
Epoch 1000, Loss: 0.0012454561656340957, Constraint losses: L1: -1.1167691946029663, L2: 0.0, L3: 0.002180814743041992, L4: 0.00018141066539101303
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 162.99295043945312, Losses: L1: 18.104938507080078, L2: 0.00044877405161969364, L3: 1.00044846534729, L4: 71.20964050292969, L5: 0.23369435966014862
Epoch 500, Loss: 8.223596572875977, Losses: L1: -2.2451515197753906, L2: 0.6242297291755676, L3: 0.099659264087677, L4: 4.774771690368652, L5: 0.047828178852796555
Epoch 1000, Loss: 0.59696364402771, Losses: L1: -3.1278507709503174, L2: 0.8437256813049316, L3: 0.06234574317932129, L4: 1.3496127128601074, L5: 0.028585897758603096
Epoch 1500, Loss: -1.5046342611312866, Losses: L1: -3.6479485034942627, L2: 0.8519813418388367, L3: 0.05784106254577637, L4: 0.5718736052513123, L5: 0.015951769426465034
Epoch 2000, Loss: -1.6002602577209473, Losses: L1: -3.898998260498047, L2: 0.7715598344802856, L3: 0.05679309368133545, L4: 0.6919065713882446, L5: 0.014889475889503956
Epoch 2500, Loss: -2.6267998218536377, Losses: L1: -3.896402597427368, L2: 0.575498104095459, L3: 0.053435325622558594, L4: 0.28165876865386963, L5: 0.011958273127675056
Epoch 3000, Loss: -2.7972264289855957, Losses: L1: -3.9122722148895264, L2: 0.5102534294128418, L3: 0.05060875415802002, L4: 0.24100559949874878, L5: 0.010781754739582539
Epoch 3500, Loss: -3.041733980178833, Losses: L1: -3.916626214981079, L2: 0.4850013554096222, L3: 0.048595130443573, L4: 0.13637614250183105, L5: 0.009974148124456406
Epoch 4000, Loss: -3.080591917037964, Losses: L1: -3.9207444190979004, L2: 0.47189661860466003, L3: 0.04730546474456787, L4: 0.12707799673080444, L5: 0.009744532406330109
Epoch 4500, Loss: -3.1059658527374268, Losses: L1: -3.9261937141418457, L2: 0.4653927683830261, L3: 0.04648059606552124, L4: 0.12143893539905548, L5: 0.0094979889690876
Epoch 5000, Loss: -3.125356435775757, Losses: L1: -3.927164077758789, L2: 0.4590000510215759, L3: 0.0455622673034668, L4: 0.11642351001501083, L5: 0.009417984634637833
Epoch 5500, Loss: -3.1348626613616943, Losses: L1: -3.9319238662719727, L2: 0.45778220891952515, L3: 0.04506182670593262, L4: 0.11516441404819489, L5: 0.009413260035216808
Epoch 6000, Loss: -3.1481213569641113, Losses: L1: -3.9321064949035645, L2: 0.45382678508758545, L3: 0.04466450214385986, L4: 0.11105979979038239, L5: 0.009354852139949799
Epoch 6500, Loss: -3.153991937637329, Losses: L1: -3.932227373123169, L2: 0.4513428211212158, L3: 0.04425632953643799, L4: 0.10987187922000885, L5: 0.009318074211478233
Epoch 7000, Loss: -3.1585235595703125, Losses: L1: -3.933290958404541, L2: 0.4504644274711609, L3: 0.044026076793670654, L4: 0.10882210731506348, L5: 0.009303329512476921
Epoch 7500, Loss: -3.1615071296691895, Losses: L1: -3.933201551437378, L2: 0.44892263412475586, L3: 0.043903350830078125, L4: 0.10820373147726059, L5: 0.009278744459152222
Epoch 8000, Loss: -3.1636550426483154, Losses: L1: -3.933090925216675, L2: 0.4478815793991089, L3: 0.043774187564849854, L4: 0.10773435235023499, L5: 0.00926879607141018
Epoch 8500, Loss: -3.165112257003784, Losses: L1: -3.9342141151428223, L2: 0.4483448266983032, L3: 0.04369252920150757, L4: 0.10742850601673126, L5: 0.009257393889129162
Epoch 9000, Loss: -3.166008949279785, Losses: L1: -3.934431314468384, L2: 0.4481073021888733, L3: 0.04362994432449341, L4: 0.10727845132350922, L5: 0.009249101392924786
Epoch 9500, Loss: -3.166680335998535, Losses: L1: -3.9349727630615234, L2: 0.44832128286361694, L3: 0.043587684631347656, L4: 0.10715351998806, L5: 0.009244358167052269
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021805763244629, Constraint losses: L1: 18.42068099975586, L2: 0.0011284507345408201, L3: 1.0011284351348877, L4: 1.0011283159255981
Epoch 500, Loss: 0.0024774638004601, Constraint losses: L1: -1.1153281927108765, L2: 0.0, L3: 0.0027955174446105957, L4: 0.0007972745224833488
Epoch 1000, Loss: 0.0014153572265058756, Constraint losses: L1: -1.1181905269622803, L2: 0.0, L3: 0.002266407012939453, L4: 0.0002671408001333475
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0184545516967773, Constraint losses: L1: 18.42068099975586, L2: 1.2647878975258209e-05, L3: 1.00001060962677, L4: 1.0000107288360596
Epoch 500, Loss: 0.0023935725912451744, Constraint losses: L1: -1.0535932779312134, L2: 0.0, L3: 0.002722501754760742, L4: 0.0007246640743687749
Epoch 1000, Loss: 0.001331151695922017, Constraint losses: L1: -1.1160552501678467, L2: 0.0, L3: 0.0022232532501220703, L4: 0.00022395368432626128
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.116329193115234, Losses: L1: 18.42068099975586, L2: 0.0017205898184329271, L3: 1.0017205476760864, L4: 74.13218688964844, L5: 0.2505144476890564
Epoch 500, Loss: -0.5994572043418884, Losses: L1: -2.346045970916748, L2: 0.1424100697040558, L3: 0.0890125036239624, L4: 2.7897186279296875, L5: 0.04480608552694321
Epoch 1000, Loss: -2.734973192214966, Losses: L1: -3.607506513595581, L2: 0.21364662051200867, L3: 0.07191270589828491, L4: 0.8075902462005615, L5: 0.010977281257510185
Epoch 1500, Loss: -2.7649970054626465, Losses: L1: -3.6052234172821045, L2: 0.13568153977394104, L3: 0.05774873495101929, L4: 1.0700719356536865, L5: 0.009905954822897911
Epoch 2000, Loss: -3.1240243911743164, Losses: L1: -3.719402551651001, L2: 0.1516159623861313, L3: 0.048625946044921875, L4: 0.5278050303459167, L5: 0.007861689664423466
Epoch 2500, Loss: -3.1791584491729736, Losses: L1: -3.7198472023010254, L2: 0.14325208961963654, L3: 0.041577279567718506, L4: 0.45909690856933594, L5: 0.007694943808019161
Epoch 3000, Loss: -3.226945161819458, Losses: L1: -3.690859794616699, L2: 0.11683695763349533, L3: 0.04197978973388672, L4: 0.4112785756587982, L5: 0.007223231252282858
Epoch 3500, Loss: -3.3120198249816895, Losses: L1: -3.7575583457946777, L2: 0.13552524149417877, L3: 0.03506112098693848, L4: 0.306732714176178, L5: 0.0071825734339654446
Epoch 4000, Loss: -3.3354899883270264, Losses: L1: -3.7484166622161865, L2: 0.12329322099685669, L3: 0.033924639225006104, L4: 0.2917736768722534, L5: 0.006981814280152321
Epoch 4500, Loss: -3.348057270050049, Losses: L1: -3.7433385848999023, L2: 0.11714249849319458, L3: 0.03339099884033203, L4: 0.2817228138446808, L5: 0.006878793239593506
Epoch 5000, Loss: -3.3563199043273926, Losses: L1: -3.7465693950653076, L2: 0.11656759679317474, L3: 0.032822489738464355, L4: 0.2746109068393707, L5: 0.006794758606702089
Epoch 5500, Loss: -3.361544132232666, Losses: L1: -3.7494454383850098, L2: 0.11630228906869888, L3: 0.032465457916259766, L4: 0.27141329646110535, L5: 0.006714693270623684
Epoch 6000, Loss: -3.366727828979492, Losses: L1: -3.7486062049865723, L2: 0.11467458307743073, L3: 0.032318174839019775, L4: 0.26609310507774353, L5: 0.0066472976468503475
Epoch 6500, Loss: -3.37001371383667, Losses: L1: -3.7487285137176514, L2: 0.11390839517116547, L3: 0.032079100608825684, L4: 0.263094425201416, L5: 0.006622288376092911
Epoch 7000, Loss: -3.372314214706421, Losses: L1: -3.7503297328948975, L2: 0.11412619054317474, L3: 0.031937479972839355, L4: 0.26099568605422974, L5: 0.006592884659767151
Epoch 7500, Loss: -3.37391996383667, Losses: L1: -3.750619411468506, L2: 0.11391308158636093, L3: 0.03181689977645874, L4: 0.25935110449790955, L5: 0.0065782153978943825
Epoch 8000, Loss: -3.375140905380249, Losses: L1: -3.7511794567108154, L2: 0.11389610171318054, L3: 0.0317041277885437, L4: 0.2582189440727234, L5: 0.006570098921656609
Epoch 8500, Loss: -3.375936985015869, Losses: L1: -3.7517340183258057, L2: 0.1139773428440094, L3: 0.03164017200469971, L4: 0.2574816942214966, L5: 0.006563072092831135
Epoch 9000, Loss: -3.3764779567718506, Losses: L1: -3.751530408859253, L2: 0.11372770369052887, L3: 0.03161895275115967, L4: 0.2570180892944336, L5: 0.00655713863670826
Epoch 9500, Loss: -3.3768327236175537, Losses: L1: -3.7516720294952393, L2: 0.11371484398841858, L3: 0.03157615661621094, L4: 0.2566863000392914, L5: 0.006557145621627569
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0045695304870605, Constraint losses: L1: 6.802981853485107, L2: 0.0, L3: 0.9988832473754883, L4: 0.9988832473754883
Epoch 500, Loss: 0.0021223509684205055, Constraint losses: L1: -1.0889021158218384, L2: 0.0, L3: 0.0026047825813293457, L4: 0.0006064706249162555
Epoch 1000, Loss: 0.0012562210904434323, Constraint losses: L1: -1.1183207035064697, L2: 0.0, L3: 0.002187013626098633, L4: 0.0001875281595857814
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0122859477996826, Constraint losses: L1: 12.233713150024414, L2: 9.535588469589129e-05, L3: 0.9999784231185913, L4: 0.9999783635139465
Epoch 500, Loss: 0.002122471109032631, Constraint losses: L1: -1.0947142839431763, L2: 0.0, L3: 0.0026077628135681152, L4: 0.0006094225682318211
Epoch 1000, Loss: 0.0012756926007568836, Constraint losses: L1: -1.1165447235107422, L2: 0.0, L3: 0.0021957755088806152, L4: 0.00019646191503852606
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 58.763309478759766, Losses: L1: 18.42068099975586, L2: 0.004585443530231714, L3: 1.0045853853225708, L4: 79.11167907714844, L5: 0.27532652020454407
Epoch 500, Loss: 44.253597259521484, Losses: L1: 18.42068099975586, L2: 0.0003204486274626106, L3: 1.0002648830413818, L4: 50.00602340698242, L5: 0.3291332423686981
Epoch 1000, Loss: 44.25137710571289, Losses: L1: 18.42068099975586, L2: 4.439408075995743e-05, L3: 1.0000426769256592, L4: 50.00286102294922, L5: 0.32915547490119934
Epoch 1500, Loss: 44.25111770629883, Losses: L1: 18.42068099975586, L2: 2.239840614493005e-05, L3: 1.000022292137146, L4: 50.002342224121094, L5: 0.32921332120895386
Epoch 2000, Loss: 44.25101089477539, Losses: L1: 18.42068099975586, L2: 1.5562949556624517e-05, L3: 1.0000154972076416, L4: 50.00208282470703, L5: 0.3292520344257355
Epoch 2500, Loss: 44.250953674316406, Losses: L1: 18.42068099975586, L2: 1.2347146366664674e-05, L3: 1.0000122785568237, L4: 50.001930236816406, L5: 0.32927846908569336
Epoch 3000, Loss: 44.250919342041016, Losses: L1: 18.42068099975586, L2: 1.053823325491976e-05, L3: 1.0000104904174805, L4: 50.001827239990234, L5: 0.3292970657348633
Epoch 3500, Loss: 44.25088882446289, Losses: L1: 18.42068099975586, L2: 9.416455213795416e-06, L3: 1.0000094175338745, L4: 50.00175094604492, L5: 0.32931047677993774
Epoch 4000, Loss: 44.25087356567383, Losses: L1: 18.42068099975586, L2: 8.675357094034553e-06, L3: 1.0000085830688477, L4: 50.001705169677734, L5: 0.3293202519416809
Epoch 4500, Loss: 44.25086212158203, Losses: L1: 18.42068099975586, L2: 8.16441206552554e-06, L3: 1.0000081062316895, L4: 50.00166702270508, L5: 0.3293275833129883
Epoch 5000, Loss: 44.250850677490234, Losses: L1: 18.42068099975586, L2: 7.800987987138797e-06, L3: 1.0000077486038208, L4: 50.00163650512695, L5: 0.32933303713798523
Epoch 5500, Loss: 44.25084686279297, Losses: L1: 18.42068099975586, L2: 7.536983957834309e-06, L3: 1.0000075101852417, L4: 50.001617431640625, L5: 0.3293372094631195
Epoch 6000, Loss: 44.2508430480957, Losses: L1: 18.42068099975586, L2: 7.341824129980523e-06, L3: 1.0000072717666626, L4: 50.0015983581543, L5: 0.3293403685092926
Epoch 6500, Loss: 44.25083541870117, Losses: L1: 18.42068099975586, L2: 7.195521902758628e-06, L3: 1.000007152557373, L4: 50.001590728759766, L5: 0.329342782497406
Epoch 7000, Loss: 44.250831604003906, Losses: L1: 18.42068099975586, L2: 7.085303877829574e-06, L3: 1.0000070333480835, L4: 50.0015754699707, L5: 0.32934463024139404
Epoch 7500, Loss: 44.250831604003906, Losses: L1: 18.42068099975586, L2: 7.001590347499587e-06, L3: 1.000006914138794, L4: 50.00157165527344, L5: 0.32934609055519104
Epoch 8000, Loss: 44.250823974609375, Losses: L1: 18.42068099975586, L2: 6.938078058738029e-06, L3: 1.000006914138794, L4: 50.001564025878906, L5: 0.329347163438797
Epoch 8500, Loss: 44.25082778930664, Losses: L1: 18.42068099975586, L2: 6.888936241011834e-06, L3: 1.000006914138794, L4: 50.00156021118164, L5: 0.32934802770614624
Epoch 9000, Loss: 44.25082778930664, Losses: L1: 18.42068099975586, L2: 6.851534180896124e-06, L3: 1.0000067949295044, L4: 50.001556396484375, L5: 0.32934868335723877
Epoch 9500, Loss: 44.250823974609375, Losses: L1: 18.42068099975586, L2: 6.822157502028858e-06, L3: 1.0000067949295044, L4: 50.00155258178711, L5: 0.32934921979904175
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.026085376739502, Constraint losses: L1: 18.42068099975586, L2: 0.0025548480916768312, L3: 1.0025548934936523, L4: 1.0025548934936523
Epoch 500, Loss: 0.002883385866880417, Constraint losses: L1: -0.6472693681716919, L2: 0.0, L3: 0.0027642250061035156, L4: 0.0007664303993806243
Epoch 1000, Loss: 0.0014510889304801822, Constraint losses: L1: -1.0230295658111572, L2: 0.0, L3: 0.002236485481262207, L4: 0.00023763305216562003
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0187997817993164, Constraint losses: L1: 18.027746200561523, L2: 0.0003562742786016315, L3: 1.000207781791687, L4: 1.0002081394195557
Epoch 500, Loss: 0.002482181414961815, Constraint losses: L1: -1.0991041660308838, L2: 0.0, L3: 0.0027896761894226074, L4: 0.0007916092872619629
Epoch 1000, Loss: 0.0014036472421139479, Constraint losses: L1: -1.11702299118042, L2: 0.0, L3: 0.0022600293159484863, L4: 0.00026064092526212335
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 50.25716018676758, Losses: L1: 6.049732685089111, L2: 0.0008658807491883636, L3: 0.9979346990585327, L4: 86.18768310546875, L5: 0.30644336342811584
Epoch 500, Loss: 6.549108028411865, Losses: L1: -0.06620297580957413, L2: 0.2192784547805786, L3: 0.2637366056442261, L4: 11.78470516204834, L5: 0.07626646757125854
Epoch 1000, Loss: 6.145083427429199, Losses: L1: -0.5587460994720459, L2: 0.08193929493427277, L3: 0.21614307165145874, L4: 12.450533866882324, L5: 0.10330619663000107
Epoch 1500, Loss: 1.2820266485214233, Losses: L1: -0.9063745737075806, L2: 0.15638665854930878, L3: 0.1223609447479248, L4: 3.492990732192993, L5: 0.03397601842880249
Epoch 2000, Loss: 0.3242158889770508, Losses: L1: -1.0083316564559937, L2: 0.18014836311340332, L3: 0.11355811357498169, L4: 1.743964672088623, L5: 0.02174472063779831
Epoch 2500, Loss: 0.2640269994735718, Losses: L1: -1.0442434549331665, L2: 0.17706574499607086, L3: 0.1129118800163269, L4: 1.7116590738296509, L5: 0.020926741883158684
Epoch 3000, Loss: 0.1205625832080841, Losses: L1: -1.0754656791687012, L2: 0.1714591085910797, L3: 0.11728620529174805, L4: 1.4943406581878662, L5: 0.023648304864764214
Epoch 3500, Loss: 0.06931889057159424, Losses: L1: -1.0881155729293823, L2: 0.1701207011938095, L3: 0.11586672067642212, L4: 1.423365831375122, L5: 0.023788394406437874
Epoch 4000, Loss: 0.03720377758145332, Losses: L1: -1.1008579730987549, L2: 0.16784195601940155, L3: 0.11643028259277344, L4: 1.3914828300476074, L5: 0.024210626259446144
Epoch 4500, Loss: 0.014647595584392548, Losses: L1: -1.107593059539795, L2: 0.16563721001148224, L3: 0.11712896823883057, L4: 1.3663756847381592, L5: 0.024606969207525253
Epoch 5000, Loss: -0.00023355334997177124, Losses: L1: -1.116159439086914, L2: 0.16642946004867554, L3: 0.11673259735107422, L4: 1.3506375551223755, L5: 0.024690944701433182
Epoch 5500, Loss: -0.01341477781534195, Losses: L1: -1.1218937635421753, L2: 0.165679469704628, L3: 0.11722850799560547, L4: 1.3371145725250244, L5: 0.024974267929792404
Epoch 6000, Loss: -0.02233978360891342, Losses: L1: -1.1257935762405396, L2: 0.16529250144958496, L3: 0.117084801197052, L4: 1.32768976688385, L5: 0.025240767747163773
Epoch 6500, Loss: -0.028648260980844498, Losses: L1: -1.1304880380630493, L2: 0.16585591435432434, L3: 0.11717510223388672, L4: 1.322218418121338, L5: 0.025215594097971916
Epoch 7000, Loss: -0.03315271809697151, Losses: L1: -1.1336599588394165, L2: 0.1663886457681656, L3: 0.11708539724349976, L4: 1.3173717260360718, L5: 0.025250693783164024
Epoch 7500, Loss: -0.03626101091504097, Losses: L1: -1.1356204748153687, L2: 0.16662277281284332, L3: 0.11706244945526123, L4: 1.3142075538635254, L5: 0.025239473208785057
Epoch 8000, Loss: -0.03859814256429672, Losses: L1: -1.1372005939483643, L2: 0.1668112725019455, L3: 0.11704528331756592, L4: 1.3118120431900024, L5: 0.02527560666203499
Epoch 8500, Loss: -0.04025747999548912, Losses: L1: -1.1382547616958618, L2: 0.16691391170024872, L3: 0.11706149578094482, L4: 1.3100697994232178, L5: 0.025301890447735786
Epoch 9000, Loss: -0.04137914255261421, Losses: L1: -1.1389763355255127, L2: 0.16695816814899445, L3: 0.11707830429077148, L4: 1.3089325428009033, L5: 0.02533773146569729
Epoch 9500, Loss: -0.04213506728410721, Losses: L1: -1.1393623352050781, L2: 0.16696201264858246, L3: 0.11706650257110596, L4: 1.3081321716308594, L5: 0.025351937860250473
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0033440589904785, Constraint losses: L1: 6.431053161621094, L2: 0.0, L3: 0.998456597328186, L4: 0.9984562397003174
Epoch 500, Loss: 0.002310651820152998, Constraint losses: L1: -1.059145212173462, L2: 0.0, L3: 0.0026838183403015137, L4: 0.000685978913679719
Epoch 1000, Loss: 0.0013114928733557463, Constraint losses: L1: -1.1168396472930908, L2: 0.0, L3: 0.002213895320892334, L4: 0.00021443722653202713
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0213661193847656, Constraint losses: L1: 18.42068099975586, L2: 0.0009817919926717877, L3: 1.0009818077087402, L4: 1.0009818077087402
Epoch 500, Loss: 0.0027070229407399893, Constraint losses: L1: -0.8344013690948486, L2: 0.0, L3: 0.00276947021484375, L4: 0.0007719541899859905
Epoch 1000, Loss: 0.0012910434743389487, Constraint losses: L1: -1.1079075336456299, L2: 0.0, L3: 0.0021991729736328125, L4: 0.0001997781073441729
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.54751586914062, Losses: L1: 16.66724967956543, L2: 0.0006844155141152442, L3: 1.0000439882278442, L4: 77.24708557128906, L5: 0.2635843753814697
Epoch 500, Loss: 1.8204760551452637, Losses: L1: -1.7159560918807983, L2: 0.24875499308109283, L3: 0.11596667766571045, L4: 2.9632620811462402, L5: 0.035353660583496094
Epoch 1000, Loss: -0.1208379864692688, Losses: L1: -2.684195041656494, L2: 0.3237817585468292, L3: 0.08146536350250244, L4: 1.8512911796569824, L5: 0.0475395992398262
Epoch 1500, Loss: -1.300482153892517, Losses: L1: -2.8809361457824707, L2: 0.2420700639486313, L3: 0.06911861896514893, L4: 1.0463218688964844, L5: 0.030865434557199478
Epoch 2000, Loss: -1.8633381128311157, Losses: L1: -3.1524136066436768, L2: 0.24402907490730286, L3: 0.08690345287322998, L4: 0.7447760105133057, L5: 0.02557927556335926
Epoch 2500, Loss: -2.193392515182495, Losses: L1: -3.1660282611846924, L2: 0.2223113477230072, L3: 0.08366405963897705, L4: 0.4758504629135132, L5: 0.020660994574427605
Epoch 3000, Loss: -2.397108554840088, Losses: L1: -3.199894905090332, L2: 0.2179294377565384, L3: 0.08686840534210205, L4: 0.3147071897983551, L5: 0.017572160810232162
Epoch 3500, Loss: -2.459909439086914, Losses: L1: -3.2153425216674805, L2: 0.2133619636297226, L3: 0.08616292476654053, L4: 0.2777658700942993, L5: 0.015723226591944695
Epoch 4000, Loss: -2.5003561973571777, Losses: L1: -3.2307300567626953, L2: 0.21085475385189056, L3: 0.08613157272338867, L4: 0.2580115795135498, L5: 0.015173941850662231
Epoch 4500, Loss: -2.5329699516296387, Losses: L1: -3.2398815155029297, L2: 0.20678065717220306, L3: 0.08550292253494263, L4: 0.2432599663734436, L5: 0.014677396975457668
Epoch 5000, Loss: -2.5636489391326904, Losses: L1: -3.2562267780303955, L2: 0.2051454782485962, L3: 0.08364665508270264, L4: 0.233418270945549, L5: 0.014090521261096
Epoch 5500, Loss: -2.581791877746582, Losses: L1: -3.2629528045654297, L2: 0.20338977873325348, L3: 0.0826725959777832, L4: 0.22611312568187714, L5: 0.013864144682884216
Epoch 6000, Loss: -2.5920419692993164, Losses: L1: -3.260267734527588, L2: 0.1992076188325882, L3: 0.0822601318359375, L4: 0.22179138660430908, L5: 0.01377782691270113
Epoch 6500, Loss: -2.598144292831421, Losses: L1: -3.259042501449585, L2: 0.19679877161979675, L3: 0.082131028175354, L4: 0.21938347816467285, L5: 0.013703268021345139
Epoch 7000, Loss: -2.6023316383361816, Losses: L1: -3.258582830429077, L2: 0.19541212916374207, L3: 0.08212590217590332, L4: 0.21752424538135529, L5: 0.013679251074790955
Epoch 7500, Loss: -2.6047985553741455, Losses: L1: -3.2587568759918213, L2: 0.19476690888404846, L3: 0.08217930793762207, L4: 0.21651650965213776, L5: 0.013636849820613861
Epoch 8000, Loss: -2.6064515113830566, Losses: L1: -3.2592501640319824, L2: 0.19446341693401337, L3: 0.08217304944992065, L4: 0.21598650515079498, L5: 0.013598141260445118
Epoch 8500, Loss: -2.6077375411987305, Losses: L1: -3.2592623233795166, L2: 0.19416961073875427, L3: 0.08214235305786133, L4: 0.21532607078552246, L5: 0.013576522469520569
Epoch 9000, Loss: -2.6085565090179443, Losses: L1: -3.2592506408691406, L2: 0.1939384788274765, L3: 0.0821414589881897, L4: 0.21496731042861938, L5: 0.013558625243604183
Epoch 9500, Loss: -2.6091206073760986, Losses: L1: -3.259342908859253, L2: 0.19383515417575836, L3: 0.08213698863983154, L4: 0.21471062302589417, L5: 0.01354549266397953
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9992058277130127, Constraint losses: L1: 5.691758155822754, L2: 0.0, L3: 0.996757447719574, L4: 0.9967566728591919
Epoch 500, Loss: 0.0021332341711968184, Constraint losses: L1: -1.114819049835205, L2: 0.0, L3: 0.002623260021209717, L4: 0.0006247931742109358
Epoch 1000, Loss: 0.0012947145150974393, Constraint losses: L1: -1.1175075769424438, L2: 0.0, L3: 0.0022058486938476562, L4: 0.00020637335546780378
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9954121112823486, Constraint losses: L1: 5.264625072479248, L2: 0.0, L3: 0.9950742721557617, L4: 0.9950731992721558
Epoch 500, Loss: 0.0019965930841863155, Constraint losses: L1: -1.047911286354065, L2: 0.0, L3: 0.0025214552879333496, L4: 0.0005230491515249014
Epoch 1000, Loss: 0.0012057023122906685, Constraint losses: L1: -1.1149013042449951, L2: 0.0, L3: 0.002160012722015381, L4: 0.000160590949235484
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 98.4703369140625, Losses: L1: 17.611848831176758, L2: 0.0005428961594589055, L3: 1.0005192756652832, L4: 80.07711791992188, L5: 0.2800297439098358
Epoch 500, Loss: -0.3062397241592407, Losses: L1: -2.417628526687622, L2: 0.2213726043701172, L3: 0.06056010723114014, L4: 1.6239793300628662, L5: 0.014384138397872448
Epoch 1000, Loss: -0.1714111864566803, Losses: L1: -2.9561212062835693, L2: 0.1541798710823059, L3: 0.06791990995407104, L4: 2.4130074977874756, L5: 0.02938278764486313
Epoch 1500, Loss: -1.5100445747375488, Losses: L1: -3.372345447540283, L2: 0.1635257452726364, L3: 0.0585402250289917, L4: 1.4818416833877563, L5: 0.024137645959854126
Epoch 2000, Loss: -2.7835912704467773, Losses: L1: -3.5295467376708984, L2: 0.16030004620552063, L3: 0.04411280155181885, L4: 0.39128053188323975, L5: 0.01201867125928402
Epoch 2500, Loss: -2.717846393585205, Losses: L1: -3.633315086364746, L2: 0.24611063301563263, L3: 0.006959378719329834, L4: 0.4037496745586395, L5: 0.01601795293390751
Epoch 3000, Loss: -3.182435989379883, Losses: L1: -3.66703724861145, L2: 0.12009771168231964, L3: 0.05235648155212402, L4: 0.20402611792087555, L5: 0.014201264828443527
Epoch 3500, Loss: -3.250824451446533, Losses: L1: -3.7223124504089355, L2: 0.12032035738229752, L3: 0.11045658588409424, L4: 0.16211654245853424, L5: 0.013502509333193302
Epoch 4000, Loss: -3.313255786895752, Losses: L1: -3.762028455734253, L2: 0.10560961812734604, L3: 0.1622631549835205, L4: 0.14292441308498383, L5: 0.013497289270162582
Epoch 4500, Loss: -3.3305504322052, Losses: L1: -3.787853717803955, L2: 0.10533527284860611, L3: 0.19360947608947754, L4: 0.13598209619522095, L5: 0.013846093788743019
Epoch 5000, Loss: -3.3524656295776367, Losses: L1: -3.811197519302368, L2: 0.103146992623806, L3: 0.21552693843841553, L4: 0.1306868940591812, L5: 0.013987190090119839
Epoch 5500, Loss: -3.366466999053955, Losses: L1: -3.824080228805542, L2: 0.09999439120292664, L3: 0.23067545890808105, L4: 0.12815481424331665, L5: 0.014131964184343815
Epoch 6000, Loss: -3.373934745788574, Losses: L1: -3.8327853679656982, L2: 0.09943888336420059, L3: 0.23923420906066895, L4: 0.12613734602928162, L5: 0.014218244701623917
Epoch 6500, Loss: -3.379368782043457, Losses: L1: -3.8366596698760986, L2: 0.09802894294261932, L3: 0.24476683139801025, L4: 0.12463147938251495, L5: 0.014218227937817574
Epoch 7000, Loss: -3.3830044269561768, Losses: L1: -3.839580535888672, L2: 0.09707365185022354, L3: 0.24848651885986328, L4: 0.12390197813510895, L5: 0.014283498749136925
Epoch 7500, Loss: -3.3855323791503906, Losses: L1: -3.841611385345459, L2: 0.09641734510660172, L3: 0.25117027759552, L4: 0.12335754930973053, L5: 0.014301714487373829
Epoch 8000, Loss: -3.387324571609497, Losses: L1: -3.84334397315979, L2: 0.09602782875299454, L3: 0.2531580924987793, L4: 0.12305781245231628, L5: 0.014326906763017178
Epoch 8500, Loss: -3.388516664505005, Losses: L1: -3.844628095626831, L2: 0.09582547843456268, L3: 0.25467395782470703, L4: 0.1227840781211853, L5: 0.014339431189000607
Epoch 9000, Loss: -3.3893046379089355, Losses: L1: -3.8458449840545654, L2: 0.09582637995481491, L3: 0.2558177709579468, L4: 0.12262988090515137, L5: 0.014348738826811314
Epoch 9500, Loss: -3.3898439407348633, Losses: L1: -3.8464772701263428, L2: 0.09574703872203827, L3: 0.25657057762145996, L4: 0.12249957025051117, L5: 0.014354701153934002
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.022691249847412, Constraint losses: L1: 18.42068099975586, L2: 0.001423480804078281, L3: 1.0014234781265259, L4: 1.0014235973358154
Epoch 500, Loss: 0.0021142961923033, Constraint losses: L1: -1.102746844291687, L2: 0.0, L3: 0.0026077628135681152, L4: 0.0006092803669162095
Epoch 1000, Loss: 0.001277152099646628, Constraint losses: L1: -1.117807388305664, L2: 0.0, L3: 0.0021972060203552246, L4: 0.0001977535430341959
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.000826597213745, Constraint losses: L1: 5.955734729766846, L2: 0.0, L3: 0.9974355101585388, L4: 0.9974353909492493
Epoch 500, Loss: 0.0020927591249346733, Constraint losses: L1: -1.088789463043213, L2: 0.0, L3: 0.0025899410247802734, L4: 0.0005916075315326452
Epoch 1000, Loss: 0.001261028810404241, Constraint losses: L1: -1.1166400909423828, L2: 0.0, L3: 0.002188563346862793, L4: 0.00018910563085228205
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 97.19842529296875, Losses: L1: 11.801260948181152, L2: 0.0013483797665685415, L3: 1.0000642538070679, L4: 84.2895278930664, L5: 0.30245184898376465
Epoch 500, Loss: -0.8286588788032532, Losses: L1: -2.4286110401153564, L2: 0.23779474198818207, L3: 0.06762373447418213, L4: 1.0575697422027588, L5: 0.016490556299686432
Epoch 1000, Loss: -1.3680580854415894, Losses: L1: -2.9732651710510254, L2: 0.2517692744731903, L3: 0.053978800773620605, L4: 1.0465028285980225, L5: 0.014088093303143978
Epoch 1500, Loss: -2.305837869644165, Losses: L1: -3.363445281982422, L2: 0.1840364933013916, L3: 0.05030280351638794, L4: 0.6402308940887451, L5: 0.012076064944267273
Epoch 2000, Loss: -2.2957448959350586, Losses: L1: -3.489720582962036, L2: 0.1469975858926773, L3: 0.04158836603164673, L4: 0.8594789505004883, L5: 0.00985370110720396
Epoch 2500, Loss: -2.723264217376709, Losses: L1: -3.601640224456787, L2: 0.16144675016403198, L3: 0.028043627738952637, L4: 0.5221452116966248, L5: 0.009657599031925201
Epoch 3000, Loss: -3.1335582733154297, Losses: L1: -3.6465163230895996, L2: 0.15857002139091492, L3: 0.013743996620178223, L4: 0.17230427265167236, L5: 0.008320748805999756
Epoch 3500, Loss: -3.169551134109497, Losses: L1: -3.667452812194824, L2: 0.1545746773481369, L3: 0.0016227960586547852, L4: 0.17177796363830566, L5: 0.008081569336354733
Epoch 4000, Loss: -3.211289644241333, Losses: L1: -3.669046640396118, L2: 0.143116295337677, L3: 6.139278411865234e-05, L4: 0.1551014631986618, L5: 0.008196028880774975
Epoch 4500, Loss: -3.247798442840576, Losses: L1: -3.6658482551574707, L2: 0.13541312515735626, L3: 7.319450378417969e-05, L4: 0.13044922053813934, L5: 0.00836869329214096
Epoch 5000, Loss: -3.2594594955444336, Losses: L1: -3.6671817302703857, L2: 0.13224636018276215, L3: 0.00018483400344848633, L4: 0.12631496787071228, L5: 0.008411099202930927
Epoch 5500, Loss: -3.262563467025757, Losses: L1: -3.670975923538208, L2: 0.1315128207206726, L3: 1.1920928955078125e-06, L4: 0.1285860538482666, L5: 0.00840019341558218
Epoch 6000, Loss: -3.2718539237976074, Losses: L1: -3.6740825176239014, L2: 0.1312135010957718, L3: 0.00016129016876220703, L4: 0.12306352704763412, L5: 0.008328720927238464
Epoch 6500, Loss: -3.27516770362854, Losses: L1: -3.67581844329834, L2: 0.1308622509241104, L3: 7.843971252441406e-05, L4: 0.12234317511320114, L5: 0.008272074162960052
Epoch 7000, Loss: -3.277423620223999, Losses: L1: -3.6780221462249756, L2: 0.13100434839725494, L3: 2.6345252990722656e-05, L4: 0.12208184599876404, L5: 0.008247477933764458
Epoch 7500, Loss: -3.2793118953704834, Losses: L1: -3.6780314445495605, L2: 0.13034896552562714, L3: 1.2040138244628906e-05, L4: 0.12154819071292877, L5: 0.008233741857111454
Epoch 8000, Loss: -3.2806754112243652, Losses: L1: -3.6785900592803955, L2: 0.1301306188106537, L3: 4.172325134277344e-07, L4: 0.12118999660015106, L5: 0.008231502957642078
Epoch 8500, Loss: -3.2815189361572266, Losses: L1: -3.678950071334839, L2: 0.12996721267700195, L3: 1.4543533325195312e-05, L4: 0.12103840708732605, L5: 0.008225490339100361
Epoch 9000, Loss: -3.282088041305542, Losses: L1: -3.6793107986450195, L2: 0.12991923093795776, L3: 2.3365020751953125e-05, L4: 0.12092550098896027, L5: 0.008223493583500385
Epoch 9500, Loss: -3.2825570106506348, Losses: L1: -3.6794068813323975, L2: 0.1298111081123352, L3: 4.5299530029296875e-06, L4: 0.12078222632408142, L5: 0.008221449330449104
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0014750957489014, Constraint losses: L1: 6.111324787139893, L2: 0.0, L3: 0.9976816177368164, L4: 0.9976821541786194
Epoch 500, Loss: 0.002334819408133626, Constraint losses: L1: -1.0690503120422363, L2: 0.0, L3: 0.002701103687286377, L4: 0.0007027661195024848
Epoch 1000, Loss: 0.0013229880714789033, Constraint losses: L1: -1.1172200441360474, L2: 0.0, L3: 0.0022199153900146484, L4: 0.00022029280080460012
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0338635444641113, Constraint losses: L1: 18.42068099975586, L2: 0.005147233139723539, L3: 1.0051472187042236, L4: 1.0051484107971191
Epoch 500, Loss: 0.002083473140373826, Constraint losses: L1: -1.106323480606079, L2: 0.0, L3: 0.002593994140625, L4: 0.0005958024994470179
Epoch 1000, Loss: 0.0012747093569487333, Constraint losses: L1: -1.1171740293502808, L2: 0.0, L3: 0.0021956562995910645, L4: 0.00019622710533440113
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 152.49217224121094, Losses: L1: 9.77833366394043, L2: 5.898457675357349e-05, L3: 0.9989684224128723, L4: 71.04875183105469, L5: 0.23345966637134552
Epoch 500, Loss: 5.588588237762451, Losses: L1: 0.7070786952972412, L2: 0.39298251271247864, L3: 0.11828094720840454, L4: 2.0039353370666504, L5: 0.05706655606627464
Epoch 1000, Loss: 12.55449104309082, Losses: L1: -1.3901646137237549, L2: 0.4440530240535736, L3: 0.14461493492126465, L4: 6.469112396240234, L5: 0.09203499555587769
Epoch 1500, Loss: 2.645700693130493, Losses: L1: -1.4946147203445435, L2: 0.38882508873939514, L3: 0.08186143636703491, L4: 1.6508537530899048, L5: 0.040053632110357285
Epoch 2000, Loss: 2.049083948135376, Losses: L1: -1.5010699033737183, L2: 0.3293755054473877, L3: 0.07498645782470703, L4: 1.417006254196167, L5: 0.03979438543319702
Epoch 2500, Loss: 0.04644939303398132, Losses: L1: -1.4828999042510986, L2: 0.2897495627403259, L3: 0.0736762285232544, L4: 0.443973183631897, L5: 0.050131380558013916
Epoch 3000, Loss: 0.6509026288986206, Losses: L1: -1.5102431774139404, L2: 0.2939052879810333, L3: 0.06919950246810913, L4: 0.7582384943962097, L5: 0.04451699182391167
Epoch 3500, Loss: -0.17628490924835205, Losses: L1: -1.5008256435394287, L2: 0.27471619844436646, L3: 0.07026141881942749, L4: 0.35725995898246765, L5: 0.050915345549583435
Epoch 4000, Loss: -0.2258608639240265, Losses: L1: -1.5003474950790405, L2: 0.26862025260925293, L3: 0.06961941719055176, L4: 0.33818596601486206, L5: 0.05212896689772606
Epoch 4500, Loss: -0.29974713921546936, Losses: L1: -1.504811406135559, L2: 0.26766344904899597, L3: 0.06874281167984009, L4: 0.3047744631767273, L5: 0.05163399502635002
Epoch 5000, Loss: -0.3199174404144287, Losses: L1: -1.5043309926986694, L2: 0.26492395997047424, L3: 0.0682026743888855, L4: 0.29723647236824036, L5: 0.05198274552822113
Epoch 5500, Loss: -0.3350859582424164, Losses: L1: -1.505761742591858, L2: 0.26285722851753235, L3: 0.06794887781143188, L4: 0.2924721837043762, L5: 0.052084971219301224
Epoch 6000, Loss: -0.34563422203063965, Losses: L1: -1.505328893661499, L2: 0.2604048252105713, L3: 0.06781691312789917, L4: 0.289447546005249, L5: 0.05216290056705475
Epoch 6500, Loss: -0.3524557054042816, Losses: L1: -1.505323886871338, L2: 0.25872740149497986, L3: 0.0677146315574646, L4: 0.28775668144226074, L5: 0.05208544805645943
Epoch 7000, Loss: -0.3583008348941803, Losses: L1: -1.5045099258422852, L2: 0.2572140693664551, L3: 0.06761050224304199, L4: 0.28595298528671265, L5: 0.05213946849107742
Epoch 7500, Loss: -0.3619369566440582, Losses: L1: -1.504197359085083, L2: 0.2562190294265747, L3: 0.0675458312034607, L4: 0.2849922478199005, L5: 0.05212981998920441
Epoch 8000, Loss: -0.3646083176136017, Losses: L1: -1.5042051076889038, L2: 0.2555577754974365, L3: 0.06750941276550293, L4: 0.2843335270881653, L5: 0.0521189421415329
Epoch 8500, Loss: -0.36643508076667786, Losses: L1: -1.5039341449737549, L2: 0.25504350662231445, L3: 0.06746137142181396, L4: 0.28381073474884033, L5: 0.05211979150772095
Epoch 9000, Loss: -0.36765819787979126, Losses: L1: -1.5038264989852905, L2: 0.25469228625297546, L3: 0.06744009256362915, L4: 0.2835047245025635, L5: 0.05210838466882706
Epoch 9500, Loss: -0.36846446990966797, Losses: L1: -1.5037097930908203, L2: 0.25444290041923523, L3: 0.06742393970489502, L4: 0.2833014130592346, L5: 0.052089475095272064
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0225117206573486, Constraint losses: L1: 18.42068099975586, L2: 0.0013638007221743464, L3: 1.001363754272461, L4: 1.0013635158538818
Epoch 500, Loss: 0.0023082501720637083, Constraint losses: L1: -1.0691320896148682, L2: 0.0, L3: 0.0026877522468566895, L4: 0.0006896300474181771
Epoch 1000, Loss: 0.0013157539069652557, Constraint losses: L1: -1.1179815530776978, L2: 0.0, L3: 0.0022165775299072266, L4: 0.0002171580563299358
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0226035118103027, Constraint losses: L1: 18.42068099975586, L2: 0.0013943148078396916, L3: 1.001394271850586, L4: 1.0013943910598755
Epoch 500, Loss: 0.002174923662096262, Constraint losses: L1: -1.0761439800262451, L2: 0.0, L3: 0.002624690532684326, L4: 0.0006263771210797131
Epoch 1000, Loss: 0.0012707158457487822, Constraint losses: L1: -1.1169344186782837, L2: 0.0, L3: 0.0021935701370239258, L4: 0.0001940802321769297
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 148.38583374023438, Losses: L1: 17.552230834960938, L2: 0.006569129880517721, L3: 1.0065617561340332, L4: 65.05386352539062, L5: 0.209452822804451
Epoch 500, Loss: 13.375306129455566, Losses: L1: -0.8511067628860474, L2: 0.6945562362670898, L3: 0.2187190055847168, L4: 6.337189674377441, L5: 0.05356080085039139
Epoch 1000, Loss: 2.124711751937866, Losses: L1: -1.824018120765686, L2: 0.39590078592300415, L3: 0.09327185153961182, L4: 1.5444051027297974, L5: 0.021482281386852264
Epoch 1500, Loss: 0.8487113118171692, Losses: L1: -2.0041732788085938, L2: 0.3416311740875244, L3: 0.07863163948059082, L4: 1.0541462898254395, L5: 0.022013863548636436
Epoch 2000, Loss: 1.4212983846664429, Losses: L1: -2.117856502532959, L2: 0.3347710967063904, L3: 0.0716058611869812, L4: 1.4061329364776611, L5: 0.021543875336647034
Epoch 2500, Loss: 0.7754454612731934, Losses: L1: -2.151777982711792, L2: 0.3129115104675293, L3: 0.06833624839782715, L4: 1.1209495067596436, L5: 0.02533329464495182
Epoch 3000, Loss: -0.3175920844078064, Losses: L1: -2.2432687282562256, L2: 0.3239218592643738, L3: 0.0687980055809021, L4: 0.6073194146156311, L5: 0.028795070946216583
Epoch 3500, Loss: -0.7297301292419434, Losses: L1: -2.2673609256744385, L2: 0.32034406065940857, L3: 0.06866717338562012, L4: 0.41482964158058167, L5: 0.03294973075389862
Epoch 4000, Loss: -0.8448700904846191, Losses: L1: -2.2761342525482178, L2: 0.31544119119644165, L3: 0.06783229112625122, L4: 0.36677485704421997, L5: 0.03291597589850426
Epoch 4500, Loss: -0.8959143161773682, Losses: L1: -2.2809290885925293, L2: 0.3081895112991333, L3: 0.0674659013748169, L4: 0.35065218806266785, L5: 0.03359847143292427
Epoch 5000, Loss: -0.9518800973892212, Losses: L1: -2.2830581665039062, L2: 0.3031553030014038, L3: 0.06713467836380005, L4: 0.3289199471473694, L5: 0.033460281789302826
Epoch 5500, Loss: -0.9787591099739075, Losses: L1: -2.287534236907959, L2: 0.3002874553203583, L3: 0.06658726930618286, L4: 0.32068806886672974, L5: 0.03353038802742958
Epoch 6000, Loss: -1.0023192167282104, Losses: L1: -2.2879414558410645, L2: 0.2970373332500458, L3: 0.06636267900466919, L4: 0.3124579191207886, L5: 0.033450376242399216
Epoch 6500, Loss: -1.0152440071105957, Losses: L1: -2.290231943130493, L2: 0.295700341463089, L3: 0.06605684757232666, L4: 0.30852821469306946, L5: 0.03350258618593216
Epoch 7000, Loss: -1.0246262550354004, Losses: L1: -2.29250431060791, L2: 0.2949209213256836, L3: 0.06585550308227539, L4: 0.3057282567024231, L5: 0.03365195915102959
Epoch 7500, Loss: -1.03080415725708, Losses: L1: -2.294663190841675, L2: 0.2942894399166107, L3: 0.06577903032302856, L4: 0.30436378717422485, L5: 0.03366299346089363
Epoch 8000, Loss: -1.0352870225906372, Losses: L1: -2.2965571880340576, L2: 0.29422876238822937, L3: 0.06564432382583618, L4: 0.30312156677246094, L5: 0.033747266978025436
Epoch 8500, Loss: -1.0384340286254883, Losses: L1: -2.2972257137298584, L2: 0.2937321066856384, L3: 0.06556600332260132, L4: 0.30237480998039246, L5: 0.03379485756158829
Epoch 9000, Loss: -1.0404765605926514, Losses: L1: -2.2979629039764404, L2: 0.2934945821762085, L3: 0.06551522016525269, L4: 0.30196496844291687, L5: 0.03380969539284706
Epoch 9500, Loss: -1.0417560338974, Losses: L1: -2.2988715171813965, L2: 0.29360532760620117, L3: 0.06548142433166504, L4: 0.30167311429977417, L5: 0.03381788730621338
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9988582134246826, Constraint losses: L1: 5.657533645629883, L2: 0.0, L3: 0.9966005682945251, L4: 0.9966001510620117
Epoch 500, Loss: 0.0022669569589197636, Constraint losses: L1: -1.097028136253357, L2: 0.0, L3: 0.0026810765266418457, L4: 0.0006829084595665336
Epoch 1000, Loss: 0.0013217809610068798, Constraint losses: L1: -1.1176990270614624, L2: 0.0, L3: 0.002219557762145996, L4: 0.00021992225083522499
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0075020790100098, Constraint losses: L1: 8.109472274780273, L2: 0.0, L3: 0.9996961951255798, L4: 0.9996962547302246
Epoch 500, Loss: 0.002520417794585228, Constraint losses: L1: -1.0279484987258911, L2: 0.0, L3: 0.002772986888885498, L4: 0.0007753795362077653
Epoch 1000, Loss: 0.0013639731332659721, Constraint losses: L1: -1.1164939403533936, L2: 0.0, L3: 0.0022399425506591797, L4: 0.00024052454682532698
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 170.10899353027344, Losses: L1: 17.4278564453125, L2: 0.001617357018403709, L3: 1.0016140937805176, L4: 75.8299560546875, L5: 0.25858819484710693
Epoch 500, Loss: 4.942901134490967, Losses: L1: -1.584801197052002, L2: 0.3047822117805481, L3: 0.08397078514099121, L4: 2.8952291011810303, L5: 0.042847245931625366
Epoch 1000, Loss: 0.914986789226532, Losses: L1: -2.062608003616333, L2: 0.21113255620002747, L3: 0.06894642114639282, L4: 1.2446178197860718, L5: 0.015810463577508926
Epoch 1500, Loss: -1.0803683996200562, Losses: L1: -2.332367181777954, L2: 0.22113652527332306, L3: 0.05935722589492798, L4: 0.38113513588905334, L5: 0.00888840015977621
Epoch 2000, Loss: -1.2013925313949585, Losses: L1: -2.5844409465789795, L2: 0.2257366180419922, L3: 0.05497145652770996, L4: 0.43955934047698975, L5: 0.012485458515584469
Epoch 2500, Loss: -1.617248296737671, Losses: L1: -2.697263240814209, L2: 0.1970733255147934, L3: 0.05177944898605347, L4: 0.3168209195137024, L5: 0.013168416917324066
Epoch 3000, Loss: -1.8187209367752075, Losses: L1: -2.8372466564178467, L2: 0.19930265843868256, L3: 0.04672461748123169, L4: 0.28438329696655273, L5: 0.013895687647163868
Epoch 3500, Loss: -1.9018853902816772, Losses: L1: -2.9445576667785645, L2: 0.1912531554698944, L3: 0.04651719331741333, L4: 0.3034595847129822, L5: 0.01499403640627861
Epoch 4000, Loss: -2.304112672805786, Losses: L1: -3.008822441101074, L2: 0.18224553763866425, L3: 0.04568713903427124, L4: 0.14524680376052856, L5: 0.013440691865980625
Epoch 4500, Loss: -2.3745405673980713, Losses: L1: -3.0635929107666016, L2: 0.18044666945934296, L3: 0.04569464921951294, L4: 0.1390765905380249, L5: 0.013579209335148335
Epoch 5000, Loss: -2.4363529682159424, Losses: L1: -3.106365442276001, L2: 0.18061022460460663, L3: 0.04544931650161743, L4: 0.1297258585691452, L5: 0.013307896442711353
Epoch 5500, Loss: -2.4817469120025635, Losses: L1: -3.151665687561035, L2: 0.18527944386005402, L3: 0.04559171199798584, L4: 0.1250068098306656, L5: 0.013275176286697388
Epoch 6000, Loss: -2.5124282836914062, Losses: L1: -3.1797661781311035, L2: 0.18598788976669312, L3: 0.04567432403564453, L4: 0.12310518324375153, L5: 0.013157290406525135
Epoch 6500, Loss: -2.5364975929260254, Losses: L1: -3.205536365509033, L2: 0.18910102546215057, L3: 0.04573875665664673, L4: 0.12094659358263016, L5: 0.013037127442657948
Epoch 7000, Loss: -2.553689956665039, Losses: L1: -3.221269130706787, L2: 0.18974173069000244, L3: 0.04578053951263428, L4: 0.11966395378112793, L5: 0.01293878722935915
Epoch 7500, Loss: -2.565993309020996, Losses: L1: -3.235240936279297, L2: 0.1914590299129486, L3: 0.045840680599212646, L4: 0.11880480498075485, L5: 0.012899703346192837
Epoch 8000, Loss: -2.5744757652282715, Losses: L1: -3.2447218894958496, L2: 0.19255922734737396, L3: 0.04588353633880615, L4: 0.11822599172592163, L5: 0.0128670334815979
Epoch 8500, Loss: -2.5804026126861572, Losses: L1: -3.248936176300049, L2: 0.1922483891248703, L3: 0.045909225940704346, L4: 0.1176888644695282, L5: 0.012852133251726627
Epoch 9000, Loss: -2.584141254425049, Losses: L1: -3.2510826587677, L2: 0.1917439103126526, L3: 0.045925021171569824, L4: 0.11739997565746307, L5: 0.01284547708928585
Epoch 9500, Loss: -2.5865516662597656, Losses: L1: -3.2521471977233887, L2: 0.19127115607261658, L3: 0.045935869216918945, L4: 0.11720111966133118, L5: 0.012841437943279743
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0273666381835938, Constraint losses: L1: 18.42068099975586, L2: 0.0029819284100085497, L3: 1.0029819011688232, L4: 1.002982258796692
Epoch 500, Loss: 0.002274087630212307, Constraint losses: L1: -0.9551098346710205, L2: 0.0, L3: 0.002613246440887451, L4: 0.0006159510230645537
Epoch 1000, Loss: 0.0012334123020991683, Constraint losses: L1: -1.1151357889175415, L2: 0.0, L3: 0.002173900604248047, L4: 0.0001746475463733077
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022714376449585, Constraint losses: L1: 18.42068099975586, L2: 0.001431076554581523, L3: 1.0014311075210571, L4: 1.0014314651489258
Epoch 500, Loss: 0.002376594115048647, Constraint losses: L1: -1.1066153049468994, L2: 0.0, L3: 0.0027407407760620117, L4: 0.0007424686336889863
Epoch 1000, Loss: 0.0013729066122323275, Constraint losses: L1: -1.1158897876739502, L2: 0.0, L3: 0.002244114875793457, L4: 0.00024468160700052977
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 58.516475677490234, Losses: L1: 18.42068099975586, L2: 0.0016061608912423253, L3: 1.001594066619873, L4: 77.91543579101562, L5: 0.26653891801834106
Epoch 500, Loss: -0.623293399810791, Losses: L1: -1.991377592086792, L2: 0.2923770248889923, L3: 0.06538522243499756, L4: 1.4060102701187134, L5: 0.029879698529839516
Epoch 1000, Loss: -1.3058364391326904, Losses: L1: -2.363546848297119, L2: 0.24515601992607117, L3: 0.016044020652770996, L4: 1.0798120498657227, L5: 0.022896431386470795
Epoch 1500, Loss: -1.524010419845581, Losses: L1: -2.6109020709991455, L2: 0.24576620757579803, L3: 0.016869783401489258, L4: 1.135915994644165, L5: 0.021063029766082764
Epoch 2000, Loss: -1.898427128791809, Losses: L1: -2.788886308670044, L2: 0.2281486541032791, L3: 0.014858722686767578, L4: 0.8192622065544128, L5: 0.019343741238117218
Epoch 2500, Loss: -2.1147146224975586, Losses: L1: -2.9282290935516357, L2: 0.2552397847175598, L3: 0.0006288290023803711, L4: 0.5890794396400452, L5: 0.015732523053884506
Epoch 3000, Loss: -2.3957817554473877, Losses: L1: -3.056523323059082, L2: 0.21996435523033142, L3: 0.023874521255493164, L4: 0.375495046377182, L5: 0.01838167943060398
Epoch 3500, Loss: -2.495629072189331, Losses: L1: -3.2299582958221436, L2: 0.1881328523159027, L3: 0.13962554931640625, L4: 0.4184165894985199, L5: 0.018459150567650795
Epoch 4000, Loss: -2.6246747970581055, Losses: L1: -3.326197862625122, L2: 0.1535508632659912, L3: 0.2295982837677002, L4: 0.3089517056941986, L5: 0.02069428749382496
Epoch 4500, Loss: -2.675889492034912, Losses: L1: -3.383385419845581, L2: 0.12794671952724457, L3: 0.29610133171081543, L4: 0.289872944355011, L5: 0.021129116415977478
Epoch 5000, Loss: -2.707911968231201, Losses: L1: -3.4186031818389893, L2: 0.11354169994592667, L3: 0.3310365676879883, L4: 0.2836056649684906, L5: 0.021536730229854584
Epoch 5500, Loss: -2.7258732318878174, Losses: L1: -3.441953182220459, L2: 0.10493621230125427, L3: 0.3549114465713501, L4: 0.28106799721717834, L5: 0.021524133160710335
Epoch 6000, Loss: -2.7375710010528564, Losses: L1: -3.4585490226745605, L2: 0.09873983263969421, L3: 0.3734896183013916, L4: 0.27855247259140015, L5: 0.021464617922902107
Epoch 6500, Loss: -2.7442750930786133, Losses: L1: -3.473489999771118, L2: 0.09713158011436462, L3: 0.38587892055511475, L4: 0.27672743797302246, L5: 0.021417412906885147
Epoch 7000, Loss: -2.748882532119751, Losses: L1: -3.483733654022217, L2: 0.09548663347959518, L3: 0.3954564332962036, L4: 0.2754736840724945, L5: 0.02136963978409767
Epoch 7500, Loss: -2.7518608570098877, Losses: L1: -3.488760232925415, L2: 0.09357035905122757, L3: 0.4018592834472656, L4: 0.27444255352020264, L5: 0.021356312558054924
Epoch 8000, Loss: -2.7539379596710205, Losses: L1: -3.492736339569092, L2: 0.09261289983987808, L3: 0.4061164855957031, L4: 0.27355170249938965, L5: 0.021361015737056732
Epoch 8500, Loss: -2.755342483520508, Losses: L1: -3.4953858852386475, L2: 0.09197365492582321, L3: 0.4089202880859375, L4: 0.27298134565353394, L5: 0.021370336413383484
Epoch 9000, Loss: -2.7562625408172607, Losses: L1: -3.497044801712036, L2: 0.09164337813854218, L3: 0.4105253219604492, L4: 0.2725704610347748, L5: 0.021369732916355133
Epoch 9500, Loss: -2.7568631172180176, Losses: L1: -3.498098134994507, L2: 0.09129639714956284, L3: 0.411820650100708, L4: 0.27227678894996643, L5: 0.021366311237215996
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0053343772888184, Constraint losses: L1: 7.11354923248291, L2: 0.0, L3: 0.9991102814674377, L4: 0.9991106390953064
Epoch 500, Loss: 0.0023673027753829956, Constraint losses: L1: -1.1028425693511963, L2: 0.0, L3: 0.0027341246604919434, L4: 0.0007360208546742797
Epoch 1000, Loss: 0.0013643816346302629, Constraint losses: L1: -1.118598222732544, L2: 0.0, L3: 0.0022411346435546875, L4: 0.00024184523499570787
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0313305854797363, Constraint losses: L1: 18.42068099975586, L2: 0.004303152207285166, L3: 1.0043030977249146, L4: 1.0043035745620728
Epoch 500, Loss: 0.0022944225929677486, Constraint losses: L1: -1.102002501487732, L2: 0.0, L3: 0.0026973485946655273, L4: 0.0006990764522925019
Epoch 1000, Loss: 0.0013392033288255334, Constraint losses: L1: -1.1171457767486572, L2: 0.0, L3: 0.0022278428077697754, L4: 0.00022850639652460814
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 48.214210510253906, Losses: L1: 12.184696197509766, L2: 0.000526229792740196, L3: 0.9990915656089783, L4: 69.60835266113281, L5: 0.22519360482692719
Epoch 500, Loss: -0.4022584557533264, Losses: L1: -2.277111053466797, L2: 0.3292538821697235, L3: 0.08843040466308594, L4: 2.1784298419952393, L5: 0.0386994443833828
Epoch 1000, Loss: 0.5485267043113708, Losses: L1: -1.3773113489151, L2: 0.25307947397232056, L3: 0.12656641006469727, L4: 2.4967756271362305, L5: 0.04472486302256584
Epoch 1500, Loss: -0.19538533687591553, Losses: L1: -1.5557154417037964, L2: 0.2502622902393341, L3: 0.1017807126045227, L4: 1.4529078006744385, L5: 0.031570859253406525
Epoch 2000, Loss: -0.5689220428466797, Losses: L1: -1.7244713306427002, L2: 0.2464207261800766, L3: 0.09432506561279297, L4: 1.090251088142395, L5: 0.02325722575187683
Epoch 2500, Loss: -0.7424928545951843, Losses: L1: -1.8393570184707642, L2: 0.25368374586105347, L3: 0.08785921335220337, L4: 0.9668977856636047, L5: 0.018188683316111565
Epoch 3000, Loss: -0.9309015870094299, Losses: L1: -1.8942855596542358, L2: 0.2322942018508911, L3: 0.08651596307754517, L4: 0.7957731485366821, L5: 0.014392977580428123
Epoch 3500, Loss: -0.9786145091056824, Losses: L1: -1.9279085397720337, L2: 0.22843831777572632, L3: 0.081412672996521, L4: 0.7980442643165588, L5: 0.011982628144323826
Epoch 4000, Loss: -1.1016358137130737, Losses: L1: -1.943454384803772, L2: 0.2201426923274994, L3: 0.08066374063491821, L4: 0.6177568435668945, L5: 0.011991090141236782
Epoch 4500, Loss: -1.1351886987686157, Losses: L1: -1.9529553651809692, L2: 0.21400019526481628, L3: 0.07995820045471191, L4: 0.5956885814666748, L5: 0.011963865719735622
Epoch 5000, Loss: -1.1623049974441528, Losses: L1: -1.9613792896270752, L2: 0.21004386246204376, L3: 0.07910257577896118, L4: 0.5764094591140747, L5: 0.011679267510771751
Epoch 5500, Loss: -1.180895209312439, Losses: L1: -1.9696706533432007, L2: 0.20790380239486694, L3: 0.07856380939483643, L4: 0.5656967163085938, L5: 0.011555621400475502
Epoch 6000, Loss: -1.1953368186950684, Losses: L1: -1.976069450378418, L2: 0.20611681044101715, L3: 0.07810485363006592, L4: 0.5577023029327393, L5: 0.011543004773557186
Epoch 6500, Loss: -1.205930471420288, Losses: L1: -1.9810718297958374, L2: 0.2049538791179657, L3: 0.07790529727935791, L4: 0.5517324209213257, L5: 0.011462234891951084
Epoch 7000, Loss: -1.213868498802185, Losses: L1: -1.984973669052124, L2: 0.20423069596290588, L3: 0.07766944169998169, L4: 0.5471724271774292, L5: 0.011388204991817474
Epoch 7500, Loss: -1.2196247577667236, Losses: L1: -1.988003134727478, L2: 0.20368199050426483, L3: 0.0774695873260498, L4: 0.5443809032440186, L5: 0.011354382149875164
Epoch 8000, Loss: -1.2237778902053833, Losses: L1: -1.990015983581543, L2: 0.20322361588478088, L3: 0.07730323076248169, L4: 0.542334258556366, L5: 0.011320644989609718
Epoch 8500, Loss: -1.2268182039260864, Losses: L1: -1.991196870803833, L2: 0.20264941453933716, L3: 0.07721447944641113, L4: 0.5411282181739807, L5: 0.011301223188638687
Epoch 9000, Loss: -1.2289646863937378, Losses: L1: -1.9918662309646606, L2: 0.20220063626766205, L3: 0.07712662220001221, L4: 0.5401716232299805, L5: 0.011287849396467209
Epoch 9500, Loss: -1.230385184288025, Losses: L1: -1.992356777191162, L2: 0.20194017887115479, L3: 0.07708525657653809, L4: 0.5394541025161743, L5: 0.011278989724814892
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0069527626037598, Constraint losses: L1: 7.770509243011475, L2: 3.626328179962002e-05, L3: 0.9995730519294739, L4: 0.9995728731155396
Epoch 500, Loss: 0.002305918373167515, Constraint losses: L1: -1.0917478799819946, L2: 0.0, L3: 0.002697885036468506, L4: 0.000699781347066164
Epoch 1000, Loss: 0.0013338050339370966, Constraint losses: L1: -1.1182721853256226, L2: 0.0, L3: 0.002225637435913086, L4: 0.00022643982083536685
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0358400344848633, Constraint losses: L1: 18.42068099975586, L2: 0.005806519649922848, L3: 1.005806565284729, L4: 1.00580632686615
Epoch 500, Loss: 0.0025239179376512766, Constraint losses: L1: -1.0975042581558228, L2: 0.0, L3: 0.0028096437454223633, L4: 0.0008117784163914621
Epoch 1000, Loss: 0.0014125700108706951, Constraint losses: L1: -1.1170313358306885, L2: 0.0, L3: 0.0022644996643066406, L4: 0.00026510184397920966
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.48844528198242, Losses: L1: 12.760457038879395, L2: 0.0006663869135081768, L3: 1.000054955482483, L4: 70.52625274658203, L5: 0.2317379266023636
Epoch 500, Loss: -1.037363052368164, Losses: L1: -2.9091720581054688, L2: 0.24248644709587097, L3: 0.06563282012939453, L4: 2.586150646209717, L5: 0.01406395249068737
Epoch 1000, Loss: -0.27464428544044495, Losses: L1: -1.8294811248779297, L2: 0.23675315082073212, L3: 0.09939414262771606, L4: 1.899815320968628, L5: 0.016014328226447105
Epoch 1500, Loss: -1.6808762550354004, Losses: L1: -2.7798047065734863, L2: 0.1788664311170578, L3: 0.06694680452346802, L4: 1.3179351091384888, L5: 0.007640701252967119
Epoch 2000, Loss: -2.5234029293060303, Losses: L1: -3.1899876594543457, L2: 0.15204554796218872, L3: 0.06543385982513428, L4: 0.5615948438644409, L5: 0.008131173439323902
Epoch 2500, Loss: -2.7750303745269775, Losses: L1: -3.398179054260254, L2: 0.16227123141288757, L3: 0.07673478126525879, L4: 0.41636329889297485, L5: 0.006844845600426197
Epoch 3000, Loss: -2.950500011444092, Losses: L1: -3.4130871295928955, L2: 0.1033080443739891, L3: 0.08419942855834961, L4: 0.3132346570491791, L5: 0.007577026262879372
Epoch 3500, Loss: -2.989936113357544, Losses: L1: -3.436492443084717, L2: 0.09827645123004913, L3: 0.0875016450881958, L4: 0.29650041460990906, L5: 0.007125717122107744
Epoch 4000, Loss: -3.014153242111206, Losses: L1: -3.4471261501312256, L2: 0.09415587782859802, L3: 0.08809304237365723, L4: 0.2843906283378601, L5: 0.007186432369053364
Epoch 4500, Loss: -3.0295979976654053, Losses: L1: -3.447333812713623, L2: 0.0885949358344078, L3: 0.08821624517440796, L4: 0.2762414813041687, L5: 0.007104558404535055
Epoch 5000, Loss: -3.0400772094726562, Losses: L1: -3.4502317905426025, L2: 0.08640308678150177, L3: 0.0883551836013794, L4: 0.26938238739967346, L5: 0.007150907535105944
Epoch 5500, Loss: -3.0491819381713867, Losses: L1: -3.454035520553589, L2: 0.08552977442741394, L3: 0.08843624591827393, L4: 0.2625309228897095, L5: 0.0070461248978972435
Epoch 6000, Loss: -3.054567337036133, Losses: L1: -3.456418514251709, L2: 0.08493150770664215, L3: 0.08834350109100342, L4: 0.2591526508331299, L5: 0.007034278474748135
Epoch 6500, Loss: -3.0586438179016113, Losses: L1: -3.458008289337158, L2: 0.08449562638998032, L3: 0.08819699287414551, L4: 0.2561657428741455, L5: 0.007046668790280819
Epoch 7000, Loss: -3.061476945877075, Losses: L1: -3.4596080780029297, L2: 0.08443108946084976, L3: 0.08804136514663696, L4: 0.2542506456375122, L5: 0.00705118291079998
Epoch 7500, Loss: -3.0635342597961426, Losses: L1: -3.460824489593506, L2: 0.08443911373615265, L3: 0.08793967962265015, L4: 0.2527225911617279, L5: 0.007055384572595358
Epoch 8000, Loss: -3.065014362335205, Losses: L1: -3.462048053741455, L2: 0.08462902903556824, L3: 0.08786004781723022, L4: 0.2516407370567322, L5: 0.0070475018583238125
Epoch 8500, Loss: -3.066023111343384, Losses: L1: -3.4627697467803955, L2: 0.08468744903802872, L3: 0.08782553672790527, L4: 0.2509031593799591, L5: 0.007047329563647509
Epoch 9000, Loss: -3.066638231277466, Losses: L1: -3.463038206100464, L2: 0.08463278412818909, L3: 0.08779251575469971, L4: 0.25049251317977905, L5: 0.007047859951853752
Epoch 9500, Loss: -3.0670456886291504, Losses: L1: -3.4631693363189697, L2: 0.08458872139453888, L3: 0.08775192499160767, L4: 0.25019869208335876, L5: 0.007047399878501892
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021880865097046, Constraint losses: L1: 18.42068099975586, L2: 0.0011534076184034348, L3: 1.0011533498764038, L4: 1.0011534690856934
Epoch 500, Loss: 0.0026550882030278444, Constraint losses: L1: -1.1011675596237183, L2: 0.0, L3: 0.00287705659866333, L4: 0.000879199244081974
Epoch 1000, Loss: 0.0014619582798331976, Constraint losses: L1: -1.118359923362732, L2: 0.0, L3: 0.002289891242980957, L4: 0.0002904269495047629
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0186610221862793, Constraint losses: L1: 18.42068099975586, L2: 8.625633199699223e-05, L3: 1.0000768899917603, L4: 1.0000771284103394
Epoch 500, Loss: 0.002529220189899206, Constraint losses: L1: -1.0998045206069946, L2: 0.0, L3: 0.002813577651977539, L4: 0.000815447187051177
Epoch 1000, Loss: 0.0014111858326941729, Constraint losses: L1: -1.1157945394515991, L2: 0.0, L3: 0.002263188362121582, L4: 0.0002637921425048262
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 85.08333587646484, Losses: L1: 14.942410469055176, L2: 0.001651740982197225, L3: 1.001378059387207, L4: 69.02330017089844, L5: 0.22588813304901123
Epoch 500, Loss: 4.822742938995361, Losses: L1: -0.7593935132026672, L2: 0.31422024965286255, L3: 0.09195369482040405, L4: 4.835183143615723, L5: 0.05311857908964157
Epoch 1000, Loss: 4.6171441078186035, Losses: L1: -1.1361064910888672, L2: 0.236850768327713, L3: 0.10015839338302612, L4: 5.1595048904418945, L5: 0.03977125510573387
Epoch 1500, Loss: 0.10879038274288177, Losses: L1: -1.1786737442016602, L2: 0.22538307309150696, L3: 0.07444244623184204, L4: 0.7537725567817688, L5: 0.016965962946414948
Epoch 2000, Loss: -0.03594311326742172, Losses: L1: -1.227246642112732, L2: 0.22020971775054932, L3: 0.07359135150909424, L4: 0.6684871912002563, L5: 0.017611104995012283
Epoch 2500, Loss: -0.23553580045700073, Losses: L1: -1.255832552909851, L2: 0.21740880608558655, L3: 0.06984418630599976, L4: 0.5071882009506226, L5: 0.01689349301159382
Epoch 3000, Loss: -0.3481302857398987, Losses: L1: -1.2766942977905273, L2: 0.21744246780872345, L3: 0.06960141658782959, L4: 0.41615307331085205, L5: 0.01584920845925808
Epoch 3500, Loss: -0.34806305170059204, Losses: L1: -1.2790552377700806, L2: 0.21776200830936432, L3: 0.06772863864898682, L4: 0.4197596311569214, L5: 0.015959853306412697
Epoch 4000, Loss: -0.4051766097545624, Losses: L1: -1.2876923084259033, L2: 0.21896348893642426, L3: 0.06750142574310303, L4: 0.36926665902137756, L5: 0.015641193836927414
Epoch 4500, Loss: -0.4294123649597168, Losses: L1: -1.289125680923462, L2: 0.21870267391204834, L3: 0.06687331199645996, L4: 0.34763702750205994, L5: 0.015595275908708572
Epoch 5000, Loss: -0.44043922424316406, Losses: L1: -1.291648030281067, L2: 0.21874672174453735, L3: 0.06651860475540161, L4: 0.33944275975227356, L5: 0.015507976524531841
Epoch 5500, Loss: -0.4495938718318939, Losses: L1: -1.2942994832992554, L2: 0.2185768038034439, L3: 0.06635034084320068, L4: 0.3334461450576782, L5: 0.015511088073253632
Epoch 6000, Loss: -0.45533713698387146, Losses: L1: -1.2963465452194214, L2: 0.21849310398101807, L3: 0.06624561548233032, L4: 0.3300250768661499, L5: 0.01550501212477684
Epoch 6500, Loss: -0.4595254957675934, Losses: L1: -1.2970279455184937, L2: 0.21841205656528473, L3: 0.06610417366027832, L4: 0.3268279433250427, L5: 0.015492519363760948
Epoch 7000, Loss: -0.46290868520736694, Losses: L1: -1.2980676889419556, L2: 0.21840831637382507, L3: 0.06603574752807617, L4: 0.32457202672958374, L5: 0.015469204634428024
Epoch 7500, Loss: -0.4652169942855835, Losses: L1: -1.2988436222076416, L2: 0.21836604177951813, L3: 0.0659792423248291, L4: 0.32318583130836487, L5: 0.01545900572091341
Epoch 8000, Loss: -0.466776043176651, Losses: L1: -1.2992373704910278, L2: 0.2183254361152649, L3: 0.0659327507019043, L4: 0.32215380668640137, L5: 0.015447811223566532
Epoch 8500, Loss: -0.4678313136100769, Losses: L1: -1.2995166778564453, L2: 0.21827055513858795, L3: 0.0659019947052002, L4: 0.32152169942855835, L5: 0.015441169030964375
Epoch 9000, Loss: -0.46857085824012756, Losses: L1: -1.2995485067367554, L2: 0.21815639734268188, L3: 0.06588941812515259, L4: 0.3210541307926178, L5: 0.015442617237567902
Epoch 9500, Loss: -0.46906033158302307, Losses: L1: -1.2996042966842651, L2: 0.21808302402496338, L3: 0.06588160991668701, L4: 0.32077497243881226, L5: 0.015442662872374058
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0242817401885986, Constraint losses: L1: 18.42068099975586, L2: 0.001953675178810954, L3: 1.0019537210464478, L4: 1.0019537210464478
Epoch 500, Loss: 0.0022151325829327106, Constraint losses: L1: -1.0363049507141113, L2: 0.0, L3: 0.002624690532684326, L4: 0.00062674714718014
Epoch 1000, Loss: 0.0012602700153365731, Constraint losses: L1: -1.11637282371521, L2: 0.0, L3: 0.00218808650970459, L4: 0.00018855638336390257
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.027195453643799, Constraint losses: L1: 18.42068099975586, L2: 0.0029248280916363, L3: 1.0029247999191284, L4: 1.0029250383377075
Epoch 500, Loss: 0.0023374417796730995, Constraint losses: L1: -1.093056559562683, L2: 0.0, L3: 0.0027143359184265137, L4: 0.0007161624962463975
Epoch 1000, Loss: 0.0013400227762758732, Constraint losses: L1: -1.1165190935134888, L2: 0.0, L3: 0.002227962017059326, L4: 0.00022857982548885047
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 81.44552612304688, Losses: L1: 12.94796085357666, L2: 0.001434427802450955, L3: 1.0001956224441528, L4: 67.27626037597656, L5: 0.2182413935661316
Epoch 500, Loss: -0.44386300444602966, Losses: L1: -2.111156940460205, L2: 0.23848865926265717, L3: 0.06480646133422852, L4: 1.1044609546661377, L5: 0.02104916051030159
Epoch 1000, Loss: -0.7962363958358765, Losses: L1: -2.652020215988159, L2: 0.27472805976867676, L3: 0.07149732112884521, L4: 1.218885064125061, L5: 0.015945427119731903
Epoch 1500, Loss: -1.8479177951812744, Losses: L1: -2.949728012084961, L2: 0.30220574140548706, L3: 0.062346816062927246, L4: 0.4133536219596863, L5: 0.02169797383248806
Epoch 2000, Loss: -2.063025951385498, Losses: L1: -2.969146966934204, L2: 0.2618063986301422, L3: 0.06027156114578247, L4: 0.2993689775466919, L5: 0.022867748513817787
Epoch 2500, Loss: -2.0159029960632324, Losses: L1: -3.1162075996398926, L2: 0.28643032908439636, L3: 0.056396484375, L4: 0.4456031918525696, L5: 0.025444330647587776
Epoch 3000, Loss: -2.2314531803131104, Losses: L1: -3.2651748657226562, L2: 0.31722143292427063, L3: 0.052384257316589355, L4: 0.32368481159210205, L5: 0.023209722712635994
Epoch 3500, Loss: -2.4539902210235596, Losses: L1: -3.445444345474243, L2: 0.3618161678314209, L3: 0.041410863399505615, L4: 0.20416724681854248, L5: 0.022243637591600418
Epoch 4000, Loss: -2.54481840133667, Losses: L1: -3.494445562362671, L2: 0.3586795926094055, L3: 0.027474582195281982, L4: 0.18242844939231873, L5: 0.02236485481262207
Epoch 4500, Loss: -2.5966031551361084, Losses: L1: -3.504438638687134, L2: 0.3503434956073761, L3: 0.014719605445861816, L4: 0.16942477226257324, L5: 0.023004069924354553
Epoch 5000, Loss: -2.6299757957458496, Losses: L1: -3.5129010677337646, L2: 0.3457736372947693, L3: 0.00047397613525390625, L4: 0.16726800799369812, L5: 0.023636166006326675
Epoch 5500, Loss: -2.6479971408843994, Losses: L1: -3.5090177059173584, L2: 0.33720195293426514, L3: 3.886222839355469e-05, L4: 0.1627240777015686, L5: 0.02385375089943409
Epoch 6000, Loss: -2.658658742904663, Losses: L1: -3.505800247192383, L2: 0.33158475160598755, L3: 0.00016707181930541992, L4: 0.1598290503025055, L5: 0.023975804448127747
Epoch 6500, Loss: -2.66570782661438, Losses: L1: -3.50411057472229, L2: 0.328131765127182, L3: 0.00020205974578857422, L4: 0.157867893576622, L5: 0.024069136008620262
Epoch 7000, Loss: -2.6705827713012695, Losses: L1: -3.5034563541412354, L2: 0.326030433177948, L3: 6.365776062011719e-05, L4: 0.15660488605499268, L5: 0.024144256487488747
Epoch 7500, Loss: -2.674008369445801, Losses: L1: -3.506175994873047, L2: 0.3261360824108124, L3: 4.00543212890625e-05, L4: 0.15557944774627686, L5: 0.02427571266889572
Epoch 8000, Loss: -2.6762993335723877, Losses: L1: -3.5070598125457764, L2: 0.32577213644981384, L3: 9.715557098388672e-06, L4: 0.15485072135925293, L5: 0.024355744943022728
Epoch 8500, Loss: -2.6777889728546143, Losses: L1: -3.5069851875305176, L2: 0.3251737654209137, L3: 9.238719940185547e-06, L4: 0.1544293612241745, L5: 0.024410059675574303
Epoch 9000, Loss: -2.6787800788879395, Losses: L1: -3.5076823234558105, L2: 0.3251822292804718, L3: 1.4066696166992188e-05, L4: 0.15407155454158783, L5: 0.024452243000268936
Epoch 9500, Loss: -2.679426431655884, Losses: L1: -3.5082359313964844, L2: 0.3252333402633667, L3: 9.5367431640625e-07, L4: 0.15386763215065002, L5: 0.024474089965224266
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023181676864624, Constraint losses: L1: 18.42068099975586, L2: 0.0015869520138949156, L3: 1.0015869140625, L4: 1.001587152481079
Epoch 500, Loss: 0.0024083710741251707, Constraint losses: L1: -1.1008329391479492, L2: 0.0, L3: 0.002753615379333496, L4: 0.0007555886404588819
Epoch 1000, Loss: 0.0013759374851360917, Constraint losses: L1: -1.1185137033462524, L2: 0.0, L3: 0.0022469162940979004, L4: 0.00024753494653850794
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0341739654541016, Constraint losses: L1: 18.42068099975586, L2: 0.005251013673841953, L3: 1.0052510499954224, L4: 1.005251169204712
Epoch 500, Loss: 0.002532809507101774, Constraint losses: L1: -0.9512925148010254, L2: 0.0, L3: 0.0027408599853515625, L4: 0.0007432419806718826
Epoch 1000, Loss: 0.0012976907892152667, Constraint losses: L1: -1.1130297183990479, L2: 0.0, L3: 0.0022049546241760254, L4: 0.0002057659294223413
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.00672149658203, Losses: L1: 14.33169174194336, L2: 0.001290302025154233, L3: 1.0010653734207153, L4: 78.13301849365234, L5: 0.26918333768844604
Epoch 500, Loss: 4.651553153991699, Losses: L1: -2.083169937133789, L2: 0.4144172668457031, L3: 0.14036548137664795, L4: 5.648876667022705, L5: 0.058323197066783905
Epoch 1000, Loss: -0.03119203820824623, Losses: L1: -2.6415488719940186, L2: 0.4742528200149536, L3: 0.1130414605140686, L4: 1.4881539344787598, L5: 0.03032792918384075
Epoch 1500, Loss: -0.3658526837825775, Losses: L1: -2.967482089996338, L2: 0.33939993381500244, L3: 0.09811556339263916, L4: 1.7822837829589844, L5: 0.02121504209935665
Epoch 2000, Loss: -1.4524822235107422, Losses: L1: -3.1039090156555176, L2: 0.2573806047439575, L3: 0.09602701663970947, L4: 0.9916648864746094, L5: 0.02448677085340023
Epoch 2500, Loss: -2.113044261932373, Losses: L1: -3.555595874786377, L2: 0.23360897600650787, L3: 0.09359574317932129, L4: 0.8584706783294678, L5: 0.011633672751486301
Epoch 3000, Loss: -2.404660940170288, Losses: L1: -3.597630023956299, L2: 0.20993643999099731, L3: 0.09660947322845459, L4: 0.655760645866394, L5: 0.010362974368035793
Epoch 3500, Loss: -2.434035539627075, Losses: L1: -3.6184284687042236, L2: 0.2139263153076172, L3: 0.08670395612716675, L4: 0.6536280512809753, L5: 0.008104032836854458
Epoch 4000, Loss: -2.555035352706909, Losses: L1: -3.6247220039367676, L2: 0.19954949617385864, L3: 0.0891147255897522, L4: 0.5655971169471741, L5: 0.0079380227252841
Epoch 4500, Loss: -2.5991475582122803, Losses: L1: -3.6344704627990723, L2: 0.201125830411911, L3: 0.08486449718475342, L4: 0.5326277017593384, L5: 0.007789516821503639
Epoch 5000, Loss: -2.61897611618042, Losses: L1: -3.640143632888794, L2: 0.1997338980436325, L3: 0.08363211154937744, L4: 0.5230218172073364, L5: 0.007523025386035442
Epoch 5500, Loss: -2.6396572589874268, Losses: L1: -3.643080234527588, L2: 0.19955101609230042, L3: 0.08024293184280396, L4: 0.5092789530754089, L5: 0.007399535737931728
Epoch 6000, Loss: -2.65558123588562, Losses: L1: -3.6446423530578613, L2: 0.19885481894016266, L3: 0.07850652933120728, L4: 0.4980098009109497, L5: 0.0074175032787024975
Epoch 6500, Loss: -2.662755012512207, Losses: L1: -3.6476364135742188, L2: 0.19919635355472565, L3: 0.07740896940231323, L4: 0.4943135380744934, L5: 0.00738305039703846
Epoch 7000, Loss: -2.668336868286133, Losses: L1: -3.6507151126861572, L2: 0.19996899366378784, L3: 0.07610929012298584, L4: 0.4916646480560303, L5: 0.0073331305757164955
Epoch 7500, Loss: -2.672201156616211, Losses: L1: -3.652761697769165, L2: 0.20046557486057281, L3: 0.07532632350921631, L4: 0.4896807074546814, L5: 0.0073110791854560375
Epoch 8000, Loss: -2.674975872039795, Losses: L1: -3.6538379192352295, L2: 0.2004975974559784, L3: 0.07488179206848145, L4: 0.48839622735977173, L5: 0.007294361479580402
Epoch 8500, Loss: -2.6769962310791016, Losses: L1: -3.6546003818511963, L2: 0.20049816370010376, L3: 0.07452338933944702, L4: 0.4874919056892395, L5: 0.0072962394915521145
Epoch 9000, Loss: -2.6785330772399902, Losses: L1: -3.6551148891448975, L2: 0.20053957402706146, L3: 0.07418322563171387, L4: 0.48671817779541016, L5: 0.007300674449652433
Epoch 9500, Loss: -2.679595708847046, Losses: L1: -3.6555330753326416, L2: 0.20058652758598328, L3: 0.0739203691482544, L4: 0.4862366318702698, L5: 0.0073036071844398975
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0042409896850586, Constraint losses: L1: 6.683626651763916, L2: 0.0, L3: 0.9987788200378418, L4: 0.9987787008285522
Epoch 500, Loss: 0.002600486157462001, Constraint losses: L1: -0.9137062430381775, L2: 0.0, L3: 0.002756059169769287, L4: 0.000758133246563375
Epoch 1000, Loss: 0.0013312415685504675, Constraint losses: L1: -1.113852858543396, L2: 0.0, L3: 0.0022222399711608887, L4: 0.00022285454906523228
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0028247833251953, Constraint losses: L1: 6.281122207641602, L2: 0.0, L3: 0.9982721209526062, L4: 0.9982715845108032
Epoch 500, Loss: 0.0025989655405282974, Constraint losses: L1: -0.9516099095344543, L2: 0.0, L3: 0.0027742385864257812, L4: 0.0007763368776068091
Epoch 1000, Loss: 0.0013354268157854676, Constraint losses: L1: -1.1139074563980103, L2: 0.0, L3: 0.0022243261337280273, L4: 0.00022500821796711534
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 163.03659057617188, Losses: L1: 18.42068099975586, L2: 0.006219064816832542, L3: 1.0062190294265747, L4: 71.74014282226562, L5: 0.23393705487251282
Epoch 500, Loss: 12.446611404418945, Losses: L1: 1.11908757686615, L2: 0.09158538281917572, L3: 0.08776092529296875, L4: 5.498931884765625, L5: 0.11745696514844894
Epoch 1000, Loss: 39.87070083618164, Losses: L1: -0.26478272676467896, L2: 0.22646117210388184, L3: 0.3521585464477539, L4: 19.623836517333984, L5: 0.16545844078063965
Epoch 1500, Loss: 18.658859252929688, Losses: L1: 2.1446189880371094, L2: 0.2737124562263489, L3: 0.2326803207397461, L4: 7.849674224853516, L5: 0.06957272440195084
Epoch 2000, Loss: 10.80231761932373, Losses: L1: 1.207324504852295, L2: 0.13069729506969452, L3: 0.19558191299438477, L4: 4.558135032653809, L5: 0.04349357262253761
Epoch 2500, Loss: 7.214441299438477, Losses: L1: 0.4924812912940979, L2: 0.07101798057556152, L3: 0.16284668445587158, L4: 3.20004940032959, L5: 0.03395743668079376
Epoch 3000, Loss: 6.483433246612549, Losses: L1: 0.4917195737361908, L2: 0.06153525412082672, L3: 0.15152853727340698, L4: 2.8504796028137207, L5: 0.03231026232242584
Epoch 3500, Loss: 6.104149341583252, Losses: L1: 0.42615556716918945, L2: 0.059935618191957474, L3: 0.14875245094299316, L4: 2.696880340576172, L5: 0.03121894784271717
Epoch 4000, Loss: 5.866801738739014, Losses: L1: 0.43227991461753845, L2: 0.060139529407024384, L3: 0.14442986249923706, L4: 2.5774197578430176, L5: 0.02994660660624504
Epoch 4500, Loss: 5.703638076782227, Losses: L1: 0.41461873054504395, L2: 0.06212623044848442, L3: 0.1424647569656372, L4: 2.5038692951202393, L5: 0.029126672074198723
Epoch 5000, Loss: 5.590853691101074, Losses: L1: 0.40533992648124695, L2: 0.06416051089763641, L3: 0.14095556735992432, L4: 2.4511029720306396, L5: 0.028062870725989342
Epoch 5500, Loss: 5.500066757202148, Losses: L1: 0.3973665237426758, L2: 0.06543592363595963, L3: 0.1406283974647522, L4: 2.4086925983428955, L5: 0.0276299100369215
Epoch 6000, Loss: 5.436604022979736, Losses: L1: 0.39100778102874756, L2: 0.06651180237531662, L3: 0.14020788669586182, L4: 2.3793280124664307, L5: 0.02741675265133381
Epoch 6500, Loss: 5.389522552490234, Losses: L1: 0.39124932885169983, L2: 0.06724347919225693, L3: 0.1395249366760254, L4: 2.3553338050842285, L5: 0.027187392115592957
Epoch 7000, Loss: 5.3568243980407715, Losses: L1: 0.3860601484775543, L2: 0.06772442907094955, L3: 0.13942569494247437, L4: 2.3411622047424316, L5: 0.027131469920277596
Epoch 7500, Loss: 5.332888126373291, Losses: L1: 0.3886168897151947, L2: 0.06798974424600601, L3: 0.1390523910522461, L4: 2.3278634548187256, L5: 0.027025124058127403
Epoch 8000, Loss: 5.316433429718018, Losses: L1: 0.38554373383522034, L2: 0.06816083192825317, L3: 0.13906735181808472, L4: 2.321000337600708, L5: 0.027000848203897476
Epoch 8500, Loss: 5.3048577308654785, Losses: L1: 0.3853302299976349, L2: 0.06825707852840424, L3: 0.13897931575775146, L4: 2.3152737617492676, L5: 0.026972893625497818
Epoch 9000, Loss: 5.296893119812012, Losses: L1: 0.38666650652885437, L2: 0.06830928474664688, L3: 0.13886183500289917, L4: 2.310638904571533, L5: 0.026936592534184456
Epoch 9500, Loss: 5.291504859924316, Losses: L1: 0.38518986105918884, L2: 0.06835866719484329, L3: 0.13891154527664185, L4: 2.3086092472076416, L5: 0.026935333386063576
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021451950073242, Constraint losses: L1: 18.42068099975586, L2: 0.0010104365646839142, L3: 1.0010104179382324, L4: 1.0010104179382324
Epoch 500, Loss: 0.002499635796993971, Constraint losses: L1: -1.1119632720947266, L2: 0.0, L3: 0.002804875373840332, L4: 0.0008067238377407193
Epoch 1000, Loss: 0.0014169705100357533, Constraint losses: L1: -1.1178210973739624, L2: 0.0, L3: 0.0022670626640319824, L4: 0.0002677291049621999
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0011634826660156, Constraint losses: L1: 5.984180927276611, L2: 0.0, L3: 0.9975898265838623, L4: 0.9975893497467041
Epoch 500, Loss: 0.0025866315700113773, Constraint losses: L1: -1.01912260055542, L2: 0.0, L3: 0.0028017163276672363, L4: 0.0008040378452278674
Epoch 1000, Loss: 0.0013866015942767262, Constraint losses: L1: -1.115917444229126, L2: 0.0, L3: 0.0022509098052978516, L4: 0.00025160927907563746
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 159.49713134765625, Losses: L1: 6.28085994720459, L2: 2.4506509817001643e-06, L3: 0.9944977164268494, L4: 75.98304748535156, L5: 0.2556772530078888
Epoch 500, Loss: 119.75452423095703, Losses: L1: 18.42068099975586, L2: 0.0002287795505253598, L3: 1.000106692314148, L4: 50.00185012817383, L5: 0.32958224415779114
Epoch 1000, Loss: 119.75042724609375, Losses: L1: 18.420677185058594, L2: 6.766022742077382e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 1500, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.762352344757971e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 2000, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.762984061658983e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 2500, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.763516413599291e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 3000, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.763851145841215e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 3500, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764145354942741e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 4000, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764340199083563e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 4500, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764434012929144e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 5000, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764472315623493e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 5500, Loss: 119.75042724609375, Losses: L1: 18.420677185058594, L2: 6.764490634303399e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 6000, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764538373893458e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 6500, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764535043224384e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 7000, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.76453393300136e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 7500, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.76453393300136e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 8000, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764533377889848e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 8500, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764532267666823e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 9000, Loss: 119.75042724609375, Losses: L1: 18.420677185058594, L2: 6.764531712555311e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Epoch 9500, Loss: 119.75042724609375, Losses: L1: 18.420679092407227, L2: 6.764531712555311e-10, L3: 1.0, L4: 50.00004577636719, L5: 0.3296622037887573
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0021371841430664, Constraint losses: L1: 6.147596836090088, L2: 0.0, L3: 0.9979950189590454, L4: 0.9979944229125977
Epoch 500, Loss: 0.0021897824481129646, Constraint losses: L1: -1.0999000072479248, L2: 0.0, L3: 0.0026440024375915527, L4: 0.0006456801202148199
Epoch 1000, Loss: 0.0013000706676393747, Constraint losses: L1: -1.1172456741333008, L2: 0.0, L3: 0.002208411693572998, L4: 0.00020890474843326956
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9931485652923584, Constraint losses: L1: 5.099148750305176, L2: 0.0, L3: 0.994024932384491, L4: 0.9940245151519775
Epoch 500, Loss: 0.0023466330021619797, Constraint losses: L1: -0.9395154118537903, L2: 0.0, L3: 0.002641916275024414, L4: 0.0006442321464419365
Epoch 1000, Loss: 0.001261436496861279, Constraint losses: L1: -1.109342336654663, L2: 0.0, L3: 0.0021851062774658203, L4: 0.00018567265942692757
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 149.43898010253906, Losses: L1: 6.711680889129639, L2: 4.510246071731672e-05, L3: 0.9987199902534485, L4: 70.6336669921875, L5: 0.23057855665683746
Epoch 500, Loss: 3.8109002113342285, Losses: L1: -1.8008402585983276, L2: 0.22446826100349426, L3: 0.10982143878936768, L4: 2.481489896774292, L5: 0.04500122740864754
Epoch 1000, Loss: 0.061553746461868286, Losses: L1: -2.2477025985717773, L2: 0.28601834177970886, L3: 0.06904232501983643, L4: 0.8097654581069946, L5: 0.024323180317878723
Epoch 1500, Loss: 0.21335361897945404, Losses: L1: -2.259899854660034, L2: 0.2287277728319168, L3: 0.0654478669166565, L4: 0.945368766784668, L5: 0.02980624884366989
Epoch 2000, Loss: -0.7645087838172913, Losses: L1: -2.4792885780334473, L2: 0.27551302313804626, L3: 0.06116068363189697, L4: 0.5254335403442383, L5: 0.025862960144877434
Epoch 2500, Loss: -0.6855294108390808, Losses: L1: -2.593080520629883, L2: 0.3160537779331207, L3: 0.05642271041870117, L4: 0.5892789959907532, L5: 0.020231444388628006
Epoch 3000, Loss: -1.471328616142273, Losses: L1: -2.6174018383026123, L2: 0.3040127456188202, L3: 0.056180357933044434, L4: 0.21579356491565704, L5: 0.02514009177684784
Epoch 3500, Loss: -1.59418523311615, Losses: L1: -2.6594972610473633, L2: 0.3089817464351654, L3: 0.05481159687042236, L4: 0.17133751511573792, L5: 0.024930907413363457
Epoch 4000, Loss: -1.6734412908554077, Losses: L1: -2.700446844100952, L2: 0.3183176815509796, L3: 0.05418276786804199, L4: 0.14239120483398438, L5: 0.025702526792883873
Epoch 4500, Loss: -1.705282211303711, Losses: L1: -2.7198894023895264, L2: 0.32060596346855164, L3: 0.053758978843688965, L4: 0.13370291888713837, L5: 0.02611524611711502
Epoch 5000, Loss: -1.7305351495742798, Losses: L1: -2.725614547729492, L2: 0.31821101903915405, L3: 0.05335742235183716, L4: 0.12646201252937317, L5: 0.026187945157289505
Epoch 5500, Loss: -1.7400661706924438, Losses: L1: -2.7281436920166016, L2: 0.3169032037258148, L3: 0.05322730541229248, L4: 0.12422019988298416, L5: 0.02630172297358513
Epoch 6000, Loss: -1.7503342628479004, Losses: L1: -2.7314155101776123, L2: 0.31654050946235657, L3: 0.05308032035827637, L4: 0.12093108892440796, L5: 0.026528893038630486
Epoch 6500, Loss: -1.7558448314666748, Losses: L1: -2.734001636505127, L2: 0.3162142038345337, L3: 0.05298250913619995, L4: 0.11973623931407928, L5: 0.026636669412255287
Epoch 7000, Loss: -1.7603744268417358, Losses: L1: -2.735762357711792, L2: 0.3158767521381378, L3: 0.052895426750183105, L4: 0.11862095445394516, L5: 0.0267486535012722
Epoch 7500, Loss: -1.7634053230285645, Losses: L1: -2.73625111579895, L2: 0.3152238130569458, L3: 0.05285137891769409, L4: 0.11792904883623123, L5: 0.026844341307878494
Epoch 8000, Loss: -1.7654248476028442, Losses: L1: -2.7381982803344727, L2: 0.31562650203704834, L3: 0.052792370319366455, L4: 0.1174427792429924, L5: 0.026921290904283524
Epoch 8500, Loss: -1.7670176029205322, Losses: L1: -2.738982677459717, L2: 0.3155808448791504, L3: 0.05276769399642944, L4: 0.11704791337251663, L5: 0.026969939470291138
Epoch 9000, Loss: -1.7680381536483765, Losses: L1: -2.739476203918457, L2: 0.31553733348846436, L3: 0.05274772644042969, L4: 0.1168035939335823, L5: 0.02700425125658512
Epoch 9500, Loss: -1.7687489986419678, Losses: L1: -2.739778518676758, L2: 0.3154900074005127, L3: 0.052733004093170166, L4: 0.11662168800830841, L5: 0.027036624029278755
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0186171531677246, Constraint losses: L1: 18.42068099975586, L2: 6.772135384380817e-05, L3: 1.0000642538070679, L4: 1.0000643730163574
Epoch 500, Loss: 0.002541088731959462, Constraint losses: L1: -1.002569556236267, L2: 0.0, L3: 0.0027706027030944824, L4: 0.0007730555953457952
Epoch 1000, Loss: 0.0013579340884462, Constraint losses: L1: -1.1176931858062744, L2: 0.0, L3: 0.0022374987602233887, L4: 0.00023812861763872206
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0064697265625, Constraint losses: L1: 7.534640789031982, L2: 0.0, L3: 0.9994674921035767, L4: 0.9994674921035767
Epoch 500, Loss: 0.002053425647318363, Constraint losses: L1: -1.0978856086730957, L2: 0.0, L3: 0.002574920654296875, L4: 0.000576390593778342
Epoch 1000, Loss: 0.0012465834151953459, Constraint losses: L1: -1.116904616355896, L2: 0.0, L3: 0.002181410789489746, L4: 0.0001820772304199636
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.26644515991211, Losses: L1: 5.4044036865234375, L2: 0.0015643644146621227, L3: 0.9970528483390808, L4: 77.46150207519531, L5: 0.26810938119888306
Epoch 500, Loss: 0.4511668384075165, Losses: L1: -1.2518492937088013, L2: 0.2312999963760376, L3: 0.09879374504089355, L4: 2.048218011856079, L5: 0.03743928670883179
Epoch 1000, Loss: -0.8545070290565491, Losses: L1: -2.0209734439849854, L2: 0.2177433967590332, L3: 0.06489479541778564, L4: 1.1874029636383057, L5: 0.014977049082517624
Epoch 1500, Loss: -1.3530030250549316, Losses: L1: -2.371565103530884, L2: 0.22697962820529938, L3: 0.05558711290359497, L4: 0.8874621391296387, L5: 0.01939500868320465
Epoch 2000, Loss: -1.7104405164718628, Losses: L1: -2.5947165489196777, L2: 0.21743632853031158, L3: 0.05246281623840332, L4: 0.6702265739440918, L5: 0.01872897893190384
Epoch 2500, Loss: -1.9049994945526123, Losses: L1: -2.7345407009124756, L2: 0.19391337037086487, L3: 0.051313936710357666, L4: 0.6593155860900879, L5: 0.018857868388295174
Epoch 3000, Loss: -1.9767706394195557, Losses: L1: -2.863969087600708, L2: 0.19922171533107758, L3: 0.050885796546936035, L4: 0.7569273114204407, L5: 0.017039477825164795
Epoch 3500, Loss: -2.1781461238861084, Losses: L1: -2.934674024581909, L2: 0.20046836137771606, L3: 0.05194622278213501, L4: 0.4836071729660034, L5: 0.019790109246969223
Epoch 4000, Loss: -2.244133234024048, Losses: L1: -3.013672113418579, L2: 0.20996728539466858, L3: 0.051960885524749756, L4: 0.4709971249103546, L5: 0.020367728546261787
Epoch 4500, Loss: -2.305229425430298, Losses: L1: -3.1109254360198975, L2: 0.23356254398822784, L3: 0.05159151554107666, L4: 0.44959524273872375, L5: 0.021180158481001854
Epoch 5000, Loss: -2.3570380210876465, Losses: L1: -3.16241192817688, L2: 0.24286845326423645, L3: 0.05088341236114502, L4: 0.41380923986434937, L5: 0.021931301802396774
Epoch 5500, Loss: -2.39048171043396, Losses: L1: -3.2025697231292725, L2: 0.2489464282989502, L3: 0.05050760507583618, L4: 0.40403518080711365, L5: 0.02232476696372032
Epoch 6000, Loss: -2.4176063537597656, Losses: L1: -3.236346960067749, L2: 0.2547268271446228, L3: 0.05040144920349121, L4: 0.39429208636283875, L5: 0.02267647534608841
Epoch 6500, Loss: -2.4389445781707764, Losses: L1: -3.261951208114624, L2: 0.2588152587413788, L3: 0.049984753131866455, L4: 0.38791847229003906, L5: 0.022894393652677536
Epoch 7000, Loss: -2.455209732055664, Losses: L1: -3.2798144817352295, L2: 0.26113927364349365, L3: 0.049423813819885254, L4: 0.38403812050819397, L5: 0.022919030860066414
Epoch 7500, Loss: -2.4667439460754395, Losses: L1: -3.292778968811035, L2: 0.2632586359977722, L3: 0.04886305332183838, L4: 0.3806530833244324, L5: 0.022930122911930084
Epoch 8000, Loss: -2.4747908115386963, Losses: L1: -3.3010852336883545, L2: 0.26443567872047424, L3: 0.04846644401550293, L4: 0.3780428171157837, L5: 0.02293793298304081
Epoch 8500, Loss: -2.4801137447357178, Losses: L1: -3.3063573837280273, L2: 0.2651260793209076, L3: 0.04820656776428223, L4: 0.37621915340423584, L5: 0.02293732762336731
Epoch 9000, Loss: -2.483588695526123, Losses: L1: -3.3098814487457275, L2: 0.26565882563591003, L3: 0.04804044961929321, L4: 0.3748537600040436, L5: 0.02293461747467518
Epoch 9500, Loss: -2.4858105182647705, Losses: L1: -3.3123178482055664, L2: 0.2660669982433319, L3: 0.047939181327819824, L4: 0.3740527033805847, L5: 0.022937117144465446
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0001490116119385, Constraint losses: L1: 5.821385860443115, L2: 0.0, L3: 0.9971640706062317, L4: 0.9971634745597839
Epoch 500, Loss: 0.002253924962133169, Constraint losses: L1: -1.1140443086624146, L2: 0.0, L3: 0.0026831626892089844, L4: 0.0006848067278042436
Epoch 1000, Loss: 0.001334208296611905, Constraint losses: L1: -1.1183242797851562, L2: 0.0, L3: 0.0022258758544921875, L4: 0.00022665677533950657
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0292279720306396, Constraint losses: L1: 18.42068099975586, L2: 0.0036021105479449034, L3: 1.003602147102356, L4: 1.0036029815673828
Epoch 500, Loss: 0.001913899788632989, Constraint losses: L1: -1.1078828573226929, L2: 0.0, L3: 0.0025101900100708008, L4: 0.0005115927197039127
Epoch 1000, Loss: 0.0012130473041906953, Constraint losses: L1: -1.1137558221817017, L2: 0.0, L3: 0.002163112163543701, L4: 0.00016369095828849822
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 47.196022033691406, Losses: L1: 6.6573662757873535, L2: 2.8515053145383717e-06, L3: 0.9973211884498596, L4: 76.56414794921875, L5: 0.2619340121746063
Epoch 500, Loss: -1.2808663845062256, Losses: L1: -2.4105916023254395, L2: 0.1640220284461975, L3: 0.05658155679702759, L4: 1.3479077816009521, L5: 0.014564244076609612
Epoch 1000, Loss: -1.9651120901107788, Losses: L1: -3.0445587635040283, L2: 0.21466876566410065, L3: 0.05131185054779053, L4: 1.0690670013427734, L5: 0.012951994314789772
Epoch 1500, Loss: -2.7031803131103516, Losses: L1: -3.3907554149627686, L2: 0.17727607488632202, L3: 0.060103416442871094, L4: 0.4114799201488495, L5: 0.007076332811266184
Epoch 2000, Loss: -2.8625967502593994, Losses: L1: -3.486344575881958, L2: 0.1472303867340088, L3: 0.00863337516784668, L4: 0.6120917201042175, L5: 0.0059745945036411285
Epoch 2500, Loss: -2.7084720134735107, Losses: L1: -3.6078717708587646, L2: 0.1861242949962616, L3: 0.029514789581298828, L4: 0.9166436195373535, L5: 0.009799785912036896
Epoch 3000, Loss: -3.323944568634033, Losses: L1: -3.655212640762329, L2: 0.10818459093570709, L3: 0.004628896713256836, L4: 0.20098060369491577, L5: 0.005150839686393738
Epoch 3500, Loss: -3.4047398567199707, Losses: L1: -3.6753859519958496, L2: 0.08605127036571503, L3: 0.0014841556549072266, L4: 0.1808609813451767, L5: 0.0051447926089167595
Epoch 4000, Loss: -3.42989444732666, Losses: L1: -3.6921753883361816, L2: 0.07958097010850906, L3: 0.005286812782287598, L4: 0.17454861104488373, L5: 0.005271012894809246
Epoch 4500, Loss: -3.4671666622161865, Losses: L1: -3.7025578022003174, L2: 0.07995323091745377, L3: 0.0014743804931640625, L4: 0.13456980884075165, L5: 0.005251232068985701
Epoch 5000, Loss: -3.4775314331054688, Losses: L1: -3.7092206478118896, L2: 0.0792449340224266, L3: 0.0010077953338623047, L4: 0.1318570375442505, L5: 0.0052551464177668095
Epoch 5500, Loss: -3.4838602542877197, Losses: L1: -3.7132492065429688, L2: 0.0788281261920929, L3: 0.0008187294006347656, L4: 0.12961386144161224, L5: 0.005288266111165285
Epoch 6000, Loss: -3.4890425205230713, Losses: L1: -3.717071056365967, L2: 0.07913732528686523, L3: 0.0003561973571777344, L4: 0.12747830152511597, L5: 0.005302373319864273
Epoch 6500, Loss: -3.4908287525177, Losses: L1: -3.7179737091064453, L2: 0.07819150388240814, L3: 0.0008636713027954102, L4: 0.12743261456489563, L5: 0.005318048410117626
Epoch 7000, Loss: -3.493492364883423, Losses: L1: -3.719600200653076, L2: 0.07848958671092987, L3: 0.0002243518829345703, L4: 0.12671685218811035, L5: 0.0053218062967062
Epoch 7500, Loss: -3.4946706295013428, Losses: L1: -3.7202086448669434, L2: 0.07841300964355469, L3: 3.36766242980957e-05, L4: 0.12663762271404266, L5: 0.005326109007000923
Epoch 8000, Loss: -3.4954183101654053, Losses: L1: -3.720393180847168, L2: 0.07799063622951508, L3: 0.0002429485321044922, L4: 0.12635262310504913, L5: 0.005331180989742279
Epoch 8500, Loss: -3.495854139328003, Losses: L1: -3.720552921295166, L2: 0.07783631980419159, L3: 0.00029277801513671875, L4: 0.12621498107910156, L5: 0.005333298351615667
Epoch 9000, Loss: -3.4963979721069336, Losses: L1: -3.7206130027770996, L2: 0.0778011679649353, L3: 0.00010609626770019531, L4: 0.12613126635551453, L5: 0.005334930494427681
Epoch 9500, Loss: -3.496702194213867, Losses: L1: -3.720820188522339, L2: 0.07782198488712311, L3: 6.16312026977539e-05, L4: 0.1260315179824829, L5: 0.005334978457540274
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0284085273742676, Constraint losses: L1: 18.42068099975586, L2: 0.003329300321638584, L3: 1.0033292770385742, L4: 1.0033293962478638
Epoch 500, Loss: 0.002430838532745838, Constraint losses: L1: -0.9983140826225281, L2: 0.0, L3: 0.002713441848754883, L4: 0.0007157109212130308
Epoch 1000, Loss: 0.0012962163891643286, Constraint losses: L1: -1.11746084690094, L2: 0.0, L3: 0.0022066235542297363, L4: 0.00020705377392005175
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9989919662475586, Constraint losses: L1: 5.68647575378418, L2: 0.0, L3: 0.9966529011726379, L4: 0.9966525435447693
Epoch 500, Loss: 0.0020370082929730415, Constraint losses: L1: -1.1105493307113647, L2: 0.0, L3: 0.002573072910308838, L4: 0.0005744847585447133
Epoch 1000, Loss: 0.0012626416282728314, Constraint losses: L1: -1.1164817810058594, L2: 0.0, L3: 0.0021892786026000977, L4: 0.00018984486814588308
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 62.592559814453125, Losses: L1: 18.42068099975586, L2: 0.0029814676381647587, L3: 1.002981424331665, L4: 83.1309814453125, L5: 0.297232061624527
Epoch 500, Loss: 5.80414342880249, Losses: L1: -0.6464923024177551, L2: 0.26559945940971375, L3: 0.08855330944061279, L4: 10.965262413024902, L5: 0.12984947860240936
Epoch 1000, Loss: -1.4117439985275269, Losses: L1: -2.897683620452881, L2: 0.326373428106308, L3: 0.01588541269302368, L4: 1.5378105640411377, L5: 0.01625826768577099
Epoch 1500, Loss: -2.091708183288574, Losses: L1: -3.13163685798645, L2: 0.2639615833759308, L3: 0.004205942153930664, L4: 0.9481210708618164, L5: 0.014766587875783443
Epoch 2000, Loss: -2.4111859798431396, Losses: L1: -3.226283073425293, L2: 0.23788273334503174, L3: 0.0032567977905273438, L4: 0.6042213439941406, L5: 0.015353686176240444
Epoch 2500, Loss: -2.6226537227630615, Losses: L1: -3.387864828109741, L2: 0.20443935692310333, L3: 0.0019196867942810059, L4: 0.6348055601119995, L5: 0.017545079812407494
Epoch 3000, Loss: -2.8181827068328857, Losses: L1: -3.5164248943328857, L2: 0.20186030864715576, L3: 0.0007520914077758789, L4: 0.5177724957466125, L5: 0.01706557348370552
Epoch 3500, Loss: -2.883220672607422, Losses: L1: -3.5651791095733643, L2: 0.1971779316663742, L3: 0.0005484819412231445, L4: 0.5031841993331909, L5: 0.01745680719614029
Epoch 4000, Loss: -2.9252817630767822, Losses: L1: -3.609812021255493, L2: 0.20345361530780792, L3: 1.8715858459472656e-05, L4: 0.4818263649940491, L5: 0.01833614520728588
Epoch 4500, Loss: -2.9544785022735596, Losses: L1: -3.6328094005584717, L2: 0.2038327157497406, L3: 0.0006234645843505859, L4: 0.4661419987678528, L5: 0.01817367598414421
Epoch 5000, Loss: -2.9735686779022217, Losses: L1: -3.644556760787964, L2: 0.20152167975902557, L3: 0.00028514862060546875, L4: 0.46400386095046997, L5: 0.0176862720400095
Epoch 5500, Loss: -2.9890623092651367, Losses: L1: -3.655942916870117, L2: 0.2011202573776245, L3: 1.8596649169921875e-05, L4: 0.4581835865974426, L5: 0.017755543813109398
Epoch 6000, Loss: -2.998791456222534, Losses: L1: -3.658280849456787, L2: 0.19776764512062073, L3: 0.00019866228103637695, L4: 0.45692944526672363, L5: 0.01754610240459442
Epoch 6500, Loss: -3.0061581134796143, Losses: L1: -3.6606974601745605, L2: 0.19648237526416779, L3: 4.315376281738281e-05, L4: 0.45338839292526245, L5: 0.017397088930010796
Epoch 7000, Loss: -3.0109703540802, Losses: L1: -3.6615729331970215, L2: 0.19516779482364655, L3: 3.36766242980957e-05, L4: 0.4511103928089142, L5: 0.01732235588133335
Epoch 7500, Loss: -3.013906955718994, Losses: L1: -3.66278076171875, L2: 0.19459468126296997, L3: 8.463859558105469e-06, L4: 0.45011696219444275, L5: 0.017304500564932823
Epoch 8000, Loss: -3.015681266784668, Losses: L1: -3.6630148887634277, L2: 0.1938721090555191, L3: 7.021427154541016e-05, L4: 0.4496040642261505, L5: 0.017323501408100128
Epoch 8500, Loss: -3.0169894695281982, Losses: L1: -3.6640021800994873, L2: 0.1938168704509735, L3: 5.8650970458984375e-05, L4: 0.4492702782154083, L5: 0.017313247546553612
Epoch 9000, Loss: -3.017808437347412, Losses: L1: -3.665105104446411, L2: 0.19402310252189636, L3: 1.71661376953125e-05, L4: 0.44908297061920166, L5: 0.017337340861558914
Epoch 9500, Loss: -3.0183346271514893, Losses: L1: -3.6654489040374756, L2: 0.19395963847637177, L3: 1.341104507446289e-05, L4: 0.4489140212535858, L5: 0.017355721443891525
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0022835731506348, Constraint losses: L1: 6.207932949066162, L2: 0.0, L3: 0.9980379343032837, L4: 0.9980378150939941
Epoch 500, Loss: 0.002187421778216958, Constraint losses: L1: -1.10593581199646, L2: 0.0, L3: 0.00264585018157959, L4: 0.0006475074915215373
Epoch 1000, Loss: 0.0013037009630352259, Constraint losses: L1: -1.1187090873718262, L2: 0.0, L3: 0.0022110342979431152, L4: 0.00021137572184670717
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0266566276550293, Constraint losses: L1: 18.42068099975586, L2: 0.002745224628597498, L3: 1.002745270729065, L4: 1.0027456283569336
Epoch 500, Loss: 0.0020914224442094564, Constraint losses: L1: -1.0458534955978394, L2: 0.0, L3: 0.0025677084922790527, L4: 0.0005695676081813872
Epoch 1000, Loss: 0.00123084697406739, Constraint losses: L1: -1.1134358644485474, L2: 0.0, L3: 0.0021718740463256836, L4: 0.00017240886518266052
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 73.3741226196289, Losses: L1: 5.848921775817871, L2: 0.0, L3: 0.9959386587142944, L4: 65.42816162109375, L5: 0.21032416820526123
Epoch 500, Loss: 1.3942499160766602, Losses: L1: -0.6228945255279541, L2: 0.11422047764062881, L3: 0.08490252494812012, L4: 1.5995527505874634, L5: 0.03869161754846573
Epoch 1000, Loss: 0.44188278913497925, Losses: L1: -1.0909255743026733, L2: 0.15416856110095978, L3: 0.07607293128967285, L4: 1.059410572052002, L5: 0.025829674676060677
Epoch 1500, Loss: -0.12639069557189941, Losses: L1: -1.2725707292556763, L2: 0.20157119631767273, L3: 0.06417113542556763, L4: 0.605252742767334, L5: 0.01888524368405342
Epoch 2000, Loss: -0.058453164994716644, Losses: L1: -1.3696141242980957, L2: 0.20005998015403748, L3: 0.06724274158477783, L4: 0.7657167911529541, L5: 0.021677449345588684
Epoch 2500, Loss: -0.509658694267273, Losses: L1: -1.4210951328277588, L2: 0.20562386512756348, L3: 0.06203502416610718, L4: 0.36599671840667725, L5: 0.02024391107261181
Epoch 3000, Loss: -0.5637235641479492, Losses: L1: -1.445695161819458, L2: 0.19914257526397705, L3: 0.06180548667907715, L4: 0.35047921538352966, L5: 0.01919241063296795
Epoch 3500, Loss: -0.6278649568557739, Losses: L1: -1.4651628732681274, L2: 0.1949082762002945, L3: 0.06055331230163574, L4: 0.31687408685684204, L5: 0.019001323729753494
Epoch 4000, Loss: -0.662871241569519, Losses: L1: -1.483649730682373, L2: 0.19317522644996643, L3: 0.05966353416442871, L4: 0.3059527575969696, L5: 0.018296455964446068
Epoch 4500, Loss: -0.7016938924789429, Losses: L1: -1.5006438493728638, L2: 0.19095510244369507, L3: 0.0593564510345459, L4: 0.2891539931297302, L5: 0.018345758318901062
Epoch 5000, Loss: -0.7251685857772827, Losses: L1: -1.515895128250122, L2: 0.190212681889534, L3: 0.0593295693397522, L4: 0.28253304958343506, L5: 0.01821799948811531
Epoch 5500, Loss: -0.743684709072113, Losses: L1: -1.524796962738037, L2: 0.18867644667625427, L3: 0.059165894985198975, L4: 0.2764902114868164, L5: 0.017874563112854958
Epoch 6000, Loss: -0.7569552063941956, Losses: L1: -1.5314053297042847, L2: 0.18778838217258453, L3: 0.05896812677383423, L4: 0.2720552086830139, L5: 0.017763841897249222
Epoch 6500, Loss: -0.7668289542198181, Losses: L1: -1.5358606576919556, L2: 0.1869654506444931, L3: 0.058922410011291504, L4: 0.2684118151664734, L5: 0.017688244581222534
Epoch 7000, Loss: -0.7732757329940796, Losses: L1: -1.5391284227371216, L2: 0.18648678064346313, L3: 0.05883389711380005, L4: 0.2663921117782593, L5: 0.017638402059674263
Epoch 7500, Loss: -0.7779728174209595, Losses: L1: -1.5413564443588257, L2: 0.1860450953245163, L3: 0.05879974365234375, L4: 0.264911949634552, L5: 0.01756393164396286
Epoch 8000, Loss: -0.7810866236686707, Losses: L1: -1.542919397354126, L2: 0.18573012948036194, L3: 0.058799028396606445, L4: 0.26402705907821655, L5: 0.01749497279524803
Epoch 8500, Loss: -0.7833319902420044, Losses: L1: -1.5440996885299683, L2: 0.18567897379398346, L3: 0.05876356363296509, L4: 0.26314592361450195, L5: 0.017473433166742325
Epoch 9000, Loss: -0.7847736477851868, Losses: L1: -1.5449203252792358, L2: 0.1856539249420166, L3: 0.05874300003051758, L4: 0.262617290019989, L5: 0.01747112348675728
Epoch 9500, Loss: -0.7856938242912292, Losses: L1: -1.5453977584838867, L2: 0.18560819327831268, L3: 0.05874145030975342, L4: 0.26227691769599915, L5: 0.01745544746518135
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.031109571456909, Constraint losses: L1: 18.42068099975586, L2: 0.004229455254971981, L3: 1.0042294263839722, L4: 1.00423002243042
Epoch 500, Loss: 0.002473750850185752, Constraint losses: L1: -1.115794062614441, L2: 0.0, L3: 0.00279390811920166, L4: 0.0007956367917358875
Epoch 1000, Loss: 0.0014169681817293167, Constraint losses: L1: -1.1176013946533203, L2: 0.0, L3: 0.0022669434547424316, L4: 0.00026762616471387446
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0009071826934814, Constraint losses: L1: 5.969275951385498, L2: 0.0, L3: 0.9974689483642578, L4: 0.9974689483642578
Epoch 500, Loss: 0.002285806927829981, Constraint losses: L1: -1.1045031547546387, L2: 0.0, L3: 0.002694249153137207, L4: 0.0006960610626265407
Epoch 1000, Loss: 0.0013333774404600263, Constraint losses: L1: -1.1149375438690186, L2: 0.0, L3: 0.0022239089012145996, L4: 0.00022440613247454166
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.50737762451172, Losses: L1: 5.992659568786621, L2: 4.4984582814322494e-07, L3: 0.9978256821632385, L4: 79.24234008789062, L5: 0.27672523260116577
Epoch 500, Loss: 3.90454363822937, Losses: L1: 0.8623706102371216, L2: 0.1502443552017212, L3: 0.13154780864715576, L4: 2.4357616901397705, L5: 0.0428268238902092
Epoch 1000, Loss: 4.794105529785156, Losses: L1: -1.5056577920913696, L2: 0.30674630403518677, L3: 0.11389422416687012, L4: 5.420295715332031, L5: 0.03818666934967041
Epoch 1500, Loss: 2.4159936904907227, Losses: L1: -1.840366244316101, L2: 0.2572784721851349, L3: 0.10122561454772949, L4: 3.515805244445801, L5: 0.023546447977423668
Epoch 2000, Loss: 0.19010965526103973, Losses: L1: -2.0643985271453857, L2: 0.25641489028930664, L3: 0.09671300649642944, L4: 1.5161076784133911, L5: 0.03214471414685249
Epoch 2500, Loss: -0.18222205340862274, Losses: L1: -2.213752031326294, L2: 0.28529611229896545, L3: 0.08705490827560425, L4: 1.254056692123413, L5: 0.03277130797505379
Epoch 3000, Loss: -0.6343254446983337, Losses: L1: -2.3566031455993652, L2: 0.335284560918808, L3: 0.08468317985534668, L4: 0.8535140156745911, L5: 0.028828151524066925
Epoch 3500, Loss: -0.758760929107666, Losses: L1: -2.376145839691162, L2: 0.3188369572162628, L3: 0.08384370803833008, L4: 0.783424973487854, L5: 0.028598692268133163
Epoch 4000, Loss: -0.7948503494262695, Losses: L1: -2.453279972076416, L2: 0.33096909523010254, L3: 0.08102697134017944, L4: 0.8080130219459534, L5: 0.02642444148659706
Epoch 4500, Loss: -0.9153140783309937, Losses: L1: -2.5460550785064697, L2: 0.347356915473938, L3: 0.07863253355026245, L4: 0.7519001960754395, L5: 0.02686193212866783
Epoch 5000, Loss: -1.032071590423584, Losses: L1: -2.5936341285705566, L2: 0.3535160720348358, L3: 0.07690155506134033, L4: 0.6728734374046326, L5: 0.027853745967149734
Epoch 5500, Loss: -1.0829906463623047, Losses: L1: -2.6190500259399414, L2: 0.3569537103176117, L3: 0.07482612133026123, L4: 0.6453204154968262, L5: 0.027179237455129623
Epoch 6000, Loss: -1.1186866760253906, Losses: L1: -2.640885829925537, L2: 0.36160901188850403, L3: 0.07310366630554199, L4: 0.6262006163597107, L5: 0.026573223993182182
Epoch 6500, Loss: -1.1435843706130981, Losses: L1: -2.655484914779663, L2: 0.3628910481929779, L3: 0.07214927673339844, L4: 0.61564701795578, L5: 0.02617272548377514
Epoch 7000, Loss: -1.1614556312561035, Losses: L1: -2.664679765701294, L2: 0.36313924193382263, L3: 0.07145202159881592, L4: 0.608163058757782, L5: 0.025878429412841797
Epoch 7500, Loss: -1.1739287376403809, Losses: L1: -2.6710214614868164, L2: 0.36285725235939026, L3: 0.07096755504608154, L4: 0.6038138270378113, L5: 0.02562934160232544
Epoch 8000, Loss: -1.1823464632034302, Losses: L1: -2.674252510070801, L2: 0.3619915544986725, L3: 0.07065176963806152, L4: 0.6011684536933899, L5: 0.025451073423027992
Epoch 8500, Loss: -1.187699794769287, Losses: L1: -2.676417350769043, L2: 0.36140552163124084, L3: 0.07043039798736572, L4: 0.5997273921966553, L5: 0.025318443775177002
Epoch 9000, Loss: -1.191486120223999, Losses: L1: -2.678013801574707, L2: 0.3610173761844635, L3: 0.07030582427978516, L4: 0.5986307263374329, L5: 0.025250710546970367
Epoch 9500, Loss: -1.1938716173171997, Losses: L1: -2.678840160369873, L2: 0.3606799840927124, L3: 0.07022607326507568, L4: 0.5979670286178589, L5: 0.025189364328980446
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0115983486175537, Constraint losses: L1: 11.639152526855469, L2: 4.1157227315125056e-06, L3: 0.9999775290489197, L4: 0.9999775886535645
Epoch 500, Loss: 0.0029308460652828217, Constraint losses: L1: -0.8958064317703247, L2: 0.0, L3: 0.002911865711212158, L4: 0.0009147870005108416
Epoch 1000, Loss: 0.0014504896244034171, Constraint losses: L1: -1.098129391670227, L2: 0.0, L3: 0.0022737979888916016, L4: 0.0002748210390564054
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0072081089019775, Constraint losses: L1: 7.988590240478516, L2: 0.0, L3: 0.999609649181366, L4: 0.9996098279953003
Epoch 500, Loss: 0.0028731212951242924, Constraint losses: L1: -1.092087984085083, L2: 0.0, L3: 0.0029813647270202637, L4: 0.000983844744041562
Epoch 1000, Loss: 0.001528930733911693, Constraint losses: L1: -1.1168748140335083, L2: 0.0, L3: 0.0023224353790283203, L4: 0.0003233702154830098
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.82763671875, Losses: L1: 18.42068099975586, L2: 0.0007601251127198339, L3: 1.0007600784301758, L4: 66.97586059570312, L5: 0.2140287607908249
Epoch 500, Loss: 1.8504998683929443, Losses: L1: -1.4658576250076294, L2: 0.3974156081676483, L3: 0.11483943462371826, L4: 2.2279365062713623, L5: 0.031955499202013016
Epoch 1000, Loss: -0.3418326675891876, Losses: L1: -2.0735607147216797, L2: 0.23757338523864746, L3: 0.07663512229919434, L4: 1.0661382675170898, L5: 0.018586385995149612
Epoch 1500, Loss: -0.7485625147819519, Losses: L1: -2.4673714637756348, L2: 0.2717683017253876, L3: 0.06455409526824951, L4: 1.0124520063400269, L5: 0.01685604453086853
Epoch 2000, Loss: -1.4650509357452393, Losses: L1: -2.626807689666748, L2: 0.205803781747818, L3: 0.06166332960128784, L4: 0.6018841862678528, L5: 0.012469262816011906
Epoch 2500, Loss: -1.6732127666473389, Losses: L1: -2.7964513301849365, L2: 0.21548905968666077, L3: 0.059407174587249756, L4: 0.5538408756256104, L5: 0.00980259571224451
Epoch 3000, Loss: -1.911555290222168, Losses: L1: -2.873037338256836, L2: 0.19691306352615356, L3: 0.05991482734680176, L4: 0.42537039518356323, L5: 0.011227971874177456
Epoch 3500, Loss: -2.1466405391693115, Losses: L1: -2.949188709259033, L2: 0.19792355597019196, L3: 0.05813801288604736, L4: 0.2678073048591614, L5: 0.011308877728879452
Epoch 4000, Loss: -2.1957738399505615, Losses: L1: -2.972062110900879, L2: 0.18937522172927856, L3: 0.05786776542663574, L4: 0.2588697671890259, L5: 0.011466378346085548
Epoch 4500, Loss: -2.2281410694122314, Losses: L1: -2.995842456817627, L2: 0.1889529526233673, L3: 0.05750066041946411, L4: 0.2513316869735718, L5: 0.011731291189789772
Epoch 5000, Loss: -2.254629373550415, Losses: L1: -3.002676486968994, L2: 0.1832878291606903, L3: 0.05729794502258301, L4: 0.24354185163974762, L5: 0.011666730977594852
Epoch 5500, Loss: -2.270909309387207, Losses: L1: -3.0240366458892822, L2: 0.18742677569389343, L3: 0.0569605827331543, L4: 0.24116332828998566, L5: 0.011594675481319427
Epoch 6000, Loss: -2.285330295562744, Losses: L1: -3.0280537605285645, L2: 0.18461818993091583, L3: 0.056843101978302, L4: 0.2371237426996231, L5: 0.011338614858686924
Epoch 6500, Loss: -2.2945642471313477, Losses: L1: -3.039476156234741, L2: 0.18681344389915466, L3: 0.056673288345336914, L4: 0.23536929488182068, L5: 0.011284596286714077
Epoch 7000, Loss: -2.3012712001800537, Losses: L1: -3.042820692062378, L2: 0.18597519397735596, L3: 0.05661529302597046, L4: 0.23394803702831268, L5: 0.011210179887712002
Epoch 7500, Loss: -2.306121587753296, Losses: L1: -3.0462052822113037, L2: 0.18623164296150208, L3: 0.05650675296783447, L4: 0.2322825938463211, L5: 0.011162164621055126
Epoch 8000, Loss: -2.3094053268432617, Losses: L1: -3.049494981765747, L2: 0.18682052195072174, L3: 0.05646771192550659, L4: 0.2312474250793457, L5: 0.011132992804050446
Epoch 8500, Loss: -2.3117334842681885, Losses: L1: -3.053056001663208, L2: 0.18790143728256226, L3: 0.0564156174659729, L4: 0.23045146465301514, L5: 0.011118589900434017
Epoch 9000, Loss: -2.3132996559143066, Losses: L1: -3.0546765327453613, L2: 0.18822960555553436, L3: 0.05637693405151367, L4: 0.2299196869134903, L5: 0.011122100055217743
Epoch 9500, Loss: -2.3143703937530518, Losses: L1: -3.0559868812561035, L2: 0.18856579065322876, L3: 0.0563502311706543, L4: 0.22955313324928284, L5: 0.011115677654743195
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9989805221557617, Constraint losses: L1: 5.672329425811768, L2: 0.0, L3: 0.9966543316841125, L4: 0.9966539740562439
Epoch 500, Loss: 0.0021489302162081003, Constraint losses: L1: -1.0114511251449585, L2: 0.0, L3: 0.002579212188720703, L4: 0.0005811691517010331
Epoch 1000, Loss: 0.0012158507015556097, Constraint losses: L1: -1.1155236959457397, L2: 0.0, L3: 0.002165496349334717, L4: 0.00016587815480306745
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019775629043579, Constraint losses: L1: 18.42068099975586, L2: 0.00045146330376155674, L3: 1.0004514455795288, L4: 1.0004520416259766
Epoch 500, Loss: 0.002254636026918888, Constraint losses: L1: -1.09647536277771, L2: 0.0, L3: 0.0026746392250061035, L4: 0.0006764723220840096
Epoch 1000, Loss: 0.0013239533873274922, Constraint losses: L1: -1.1169978380203247, L2: 0.0, L3: 0.0022202134132385254, L4: 0.0002207379147876054
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 170.83941650390625, Losses: L1: 4.751788139343262, L2: 1.0353588777434197e-06, L3: 0.9921754002571106, L4: 81.9791030883789, L5: 0.2901448607444763
Epoch 500, Loss: 10.082265853881836, Losses: L1: 1.3351892232894897, L2: 0.2220790982246399, L3: 0.0741732120513916, L4: 4.048887252807617, L5: 0.11359445750713348
Epoch 1000, Loss: 2.7471492290496826, Losses: L1: -0.23348738253116608, L2: 0.17224974930286407, L3: 0.05715036392211914, L4: 1.2457627058029175, L5: 0.060621507465839386
Epoch 1500, Loss: 1.7036559581756592, Losses: L1: -0.50014728307724, L2: 0.1581716388463974, L3: 0.04737043380737305, L4: 0.8753725290298462, L5: 0.08394818753004074
Epoch 2000, Loss: 3.065614938735962, Losses: L1: -0.43922194838523865, L2: 0.27776220440864563, L3: 0.1141735315322876, L4: 1.3455930948257446, L5: 0.059558261185884476
Epoch 2500, Loss: 1.3085486888885498, Losses: L1: -0.45416322350502014, L2: 0.25133031606674194, L3: 0.07557594776153564, L4: 0.5360131859779358, L5: 0.07374598830938339
Epoch 3000, Loss: 2.4233644008636475, Losses: L1: -1.4503074884414673, L2: 0.43254178762435913, L3: 0.14211022853851318, L4: 1.3429217338562012, L5: 0.07704900950193405
Epoch 3500, Loss: 1.4410359859466553, Losses: L1: -1.545798420906067, L2: 0.43190690875053406, L3: 0.12451517581939697, L4: 0.9195759296417236, L5: 0.06967698782682419
Epoch 4000, Loss: 1.1591529846191406, Losses: L1: -1.5678081512451172, L2: 0.42525678873062134, L3: 0.11581957340240479, L4: 0.8054282665252686, L5: 0.06790380924940109
Epoch 4500, Loss: 1.024482250213623, Losses: L1: -1.5900301933288574, L2: 0.41964974999427795, L3: 0.11189019680023193, L4: 0.7589296102523804, L5: 0.06714654713869095
Epoch 5000, Loss: 0.8973446488380432, Losses: L1: -1.6005064249038696, L2: 0.41482093930244446, L3: 0.1096617579460144, L4: 0.7080552577972412, L5: 0.06555037200450897
Epoch 5500, Loss: 0.8448954820632935, Losses: L1: -1.5960396528244019, L2: 0.4067820608615875, L3: 0.10816437005996704, L4: 0.6889795064926147, L5: 0.06616654247045517
Epoch 6000, Loss: 0.8092402815818787, Losses: L1: -1.5938897132873535, L2: 0.4017643630504608, L3: 0.10701823234558105, L4: 0.6761339902877808, L5: 0.06659366190433502
Epoch 6500, Loss: 0.7839805483818054, Losses: L1: -1.5926858186721802, L2: 0.39832377433776855, L3: 0.10611873865127563, L4: 0.6671533584594727, L5: 0.06694921106100082
Epoch 7000, Loss: 0.765927791595459, Losses: L1: -1.59220290184021, L2: 0.39601990580558777, L3: 0.10546141862869263, L4: 0.6607939600944519, L5: 0.0671602338552475
Epoch 7500, Loss: 0.7522982358932495, Losses: L1: -1.5919873714447021, L2: 0.39438000321388245, L3: 0.1050100326538086, L4: 0.6559142470359802, L5: 0.06735412031412125
Epoch 8000, Loss: 0.7424415349960327, Losses: L1: -1.5918712615966797, L2: 0.39322909712791443, L3: 0.10463613271713257, L4: 0.652416467666626, L5: 0.0674988403916359
Epoch 8500, Loss: 0.7352378368377686, Losses: L1: -1.5920205116271973, L2: 0.39246079325675964, L3: 0.10438954830169678, L4: 0.6498825550079346, L5: 0.06758515536785126
Epoch 9000, Loss: 0.729775071144104, Losses: L1: -1.5920052528381348, L2: 0.3918217122554779, L3: 0.10420787334442139, L4: 0.6479402780532837, L5: 0.06768118590116501
Epoch 9500, Loss: 0.7260338068008423, Losses: L1: -1.5920586585998535, L2: 0.3914152681827545, L3: 0.10407739877700806, L4: 0.6466155648231506, L5: 0.06775204092264175
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0230112075805664, Constraint losses: L1: 18.42068099975586, L2: 0.0015301333041861653, L3: 1.0015301704406738, L4: 1.0015300512313843
Epoch 500, Loss: 0.002819561865180731, Constraint losses: L1: -0.7905452847480774, L2: 0.0, L3: 0.002803802490234375, L4: 0.0008063046843744814
Epoch 1000, Loss: 0.0013063772348687053, Constraint losses: L1: -1.1121608018875122, L2: 0.0, L3: 0.002209007740020752, L4: 0.00020953034982085228
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022350311279297, Constraint losses: L1: 18.42068099975586, L2: 0.0013094954192638397, L3: 1.0013095140457153, L4: 1.0013104677200317
Epoch 500, Loss: 0.002238211454823613, Constraint losses: L1: -1.0544036626815796, L2: 0.0, L3: 0.002645254135131836, L4: 0.000647361041046679
Epoch 1000, Loss: 0.0012884843163192272, Constraint losses: L1: -1.1159582138061523, L2: 0.0, L3: 0.0022019147872924805, L4: 0.00020252788090147078
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 166.9557342529297, Losses: L1: 14.494223594665527, L2: 0.0011799054918810725, L3: 1.0007959604263306, L4: 75.10438537597656, L5: 0.24879957735538483
Epoch 500, Loss: 7.450326919555664, Losses: L1: 0.059181518852710724, L2: 0.2901082932949066, L3: 0.07752358913421631, L4: 3.307328462600708, L5: 0.041224461048841476
Epoch 1000, Loss: 2.0617318153381348, Losses: L1: -1.407884120941162, L2: 0.2373996526002884, L3: 0.09233599901199341, L4: 1.3955861330032349, L5: 0.018972305580973625
Epoch 1500, Loss: 1.4491630792617798, Losses: L1: -1.1901863813400269, L2: 0.15942788124084473, L3: 0.07013571262359619, L4: 1.0825905799865723, L5: 0.015041070058941841
Epoch 2000, Loss: 1.785067081451416, Losses: L1: -1.6062748432159424, L2: 0.17418000102043152, L3: 0.09314346313476562, L4: 1.4185998439788818, L5: 0.019495230168104172
Epoch 2500, Loss: -0.05944928899407387, Losses: L1: -1.683780312538147, L2: 0.17788031697273254, L3: 0.08130955696105957, L4: 0.5449840426445007, L5: 0.015983130782842636
Epoch 3000, Loss: -0.36895984411239624, Losses: L1: -1.7259480953216553, L2: 0.18252907693386078, L3: 0.07682013511657715, L4: 0.4100709557533264, L5: 0.018147891387343407
Epoch 3500, Loss: -0.3316720724105835, Losses: L1: -1.7462120056152344, L2: 0.1829548180103302, L3: 0.07591032981872559, L4: 0.4380403161048889, L5: 0.020729050040245056
Epoch 4000, Loss: -0.3739979863166809, Losses: L1: -1.7630994319915771, L2: 0.18535339832305908, L3: 0.07495558261871338, L4: 0.42363792657852173, L5: 0.02120763063430786
Epoch 4500, Loss: -0.626344621181488, Losses: L1: -1.7738755941390991, L2: 0.18829713761806488, L3: 0.07395058870315552, L4: 0.30136656761169434, L5: 0.020302370190620422
Epoch 5000, Loss: -0.6649148464202881, Losses: L1: -1.7807046175003052, L2: 0.1896744817495346, L3: 0.07328474521636963, L4: 0.2849076986312866, L5: 0.020055873319506645
Epoch 5500, Loss: -0.6862484812736511, Losses: L1: -1.7877850532531738, L2: 0.19123977422714233, L3: 0.07293784618377686, L4: 0.27660292387008667, L5: 0.019975479692220688
Epoch 6000, Loss: -0.6964676976203918, Losses: L1: -1.793412446975708, L2: 0.19228114187717438, L3: 0.07269978523254395, L4: 0.2735912799835205, L5: 0.019800378009676933
Epoch 6500, Loss: -0.7036910057067871, Losses: L1: -1.7978193759918213, L2: 0.19299755990505219, L3: 0.0725131630897522, L4: 0.2717258334159851, L5: 0.019655248150229454
Epoch 7000, Loss: -0.7088093757629395, Losses: L1: -1.8009957075119019, L2: 0.1935127079486847, L3: 0.07236635684967041, L4: 0.27043646574020386, L5: 0.0195552259683609
Epoch 7500, Loss: -0.7126446962356567, Losses: L1: -1.80339515209198, L2: 0.19399087131023407, L3: 0.07222235202789307, L4: 0.2694280445575714, L5: 0.019467920064926147
Epoch 8000, Loss: -0.7152454257011414, Losses: L1: -1.8055901527404785, L2: 0.1945086568593979, L3: 0.0721520185470581, L4: 0.2688267230987549, L5: 0.019369902089238167
Epoch 8500, Loss: -0.7172721028327942, Losses: L1: -1.8068088293075562, L2: 0.19475466012954712, L3: 0.07208716869354248, L4: 0.2682592272758484, L5: 0.019334591925144196
Epoch 9000, Loss: -0.7185558080673218, Losses: L1: -1.807734489440918, L2: 0.1949746459722519, L3: 0.07204872369766235, L4: 0.26791661977767944, L5: 0.019298702478408813
Epoch 9500, Loss: -0.7194844484329224, Losses: L1: -1.8083653450012207, L2: 0.19511796534061432, L3: 0.0720224380493164, L4: 0.26766055822372437, L5: 0.019279031082987785
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[1.76405235 1.76953488]
 [0.97873798 1.01033033]
 [1.86755799 1.85355078]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021723747253418, Constraint losses: L1: 18.42068099975586, L2: 0.0011011946480721235, L3: 1.0011011362075806, L4: 1.0011008977890015
Epoch 500, Loss: 0.0019759749993681908, Constraint losses: L1: -1.0857425928115845, L2: 0.0, L3: 0.0025299787521362305, L4: 0.0005317387403920293
Epoch 1000, Loss: 0.001212453469634056, Constraint losses: L1: -1.1183778047561646, L2: 0.0, L3: 0.0021651387214660645, L4: 0.00016569267609156668
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0261168479919434, Constraint losses: L1: 18.42068099975586, L2: 0.002565257716923952, L3: 1.0025652647018433, L4: 1.0025657415390015
Epoch 500, Loss: 0.002833129372447729, Constraint losses: L1: -1.1110972166061401, L2: 0.0, L3: 0.0029709935188293457, L4: 0.0009732331382110715
Epoch 1000, Loss: 0.001529078115709126, Constraint losses: L1: -1.116944670677185, L2: 0.0, L3: 0.0023226141929626465, L4: 0.0003234086325392127
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 166.42120361328125, Losses: L1: 18.197460174560547, L2: 0.002062832470983267, L3: 1.0020626783370972, L4: 72.86517333984375, L5: 0.24257174134254456
Epoch 500, Loss: 5.846059799194336, Losses: L1: 1.034798502922058, L2: 0.17084850370883942, L3: 0.0695500373840332, L4: 2.126858711242676, L5: 0.038373496383428574
Epoch 1000, Loss: 3.7411270141601562, Losses: L1: -0.4075396955013275, L2: 0.17774160206317902, L3: 0.04787278175354004, L4: 1.7959778308868408, L5: 0.05274117365479469
Epoch 1500, Loss: 2.285810708999634, Losses: L1: -0.6546728610992432, L2: 0.15401725471019745, L3: 0.04625129699707031, L4: 1.24058997631073, L5: 0.029383305460214615
Epoch 2000, Loss: 1.7985491752624512, Losses: L1: -1.3708014488220215, L2: 0.297316312789917, L3: 0.10604619979858398, L4: 1.1486706733703613, L5: 0.03264210745692253
Epoch 2500, Loss: 0.7310441136360168, Losses: L1: -1.425136685371399, L2: 0.22132250666618347, L3: 0.09196311235427856, L4: 0.7397101521492004, L5: 0.025094615295529366
Epoch 3000, Loss: 0.1687798798084259, Losses: L1: -1.4854110479354858, L2: 0.20070162415504456, L3: 0.08660888671875, L4: 0.516036868095398, L5: 0.02374805323779583
Epoch 3500, Loss: 0.020462509244680405, Losses: L1: -1.5057716369628906, L2: 0.19034670293331146, L3: 0.08354991674423218, L4: 0.4669751524925232, L5: 0.022245286032557487
Epoch 4000, Loss: -0.08869022876024246, Losses: L1: -1.519995927810669, L2: 0.1847286969423294, L3: 0.08176624774932861, L4: 0.4274888038635254, L5: 0.021669115871191025
Epoch 4500, Loss: -0.14291241765022278, Losses: L1: -1.5290782451629639, L2: 0.1810424029827118, L3: 0.08036631345748901, L4: 0.4110916256904602, L5: 0.020582538098096848
Epoch 5000, Loss: -0.19678691029548645, Losses: L1: -1.5385429859161377, L2: 0.180356964468956, L3: 0.07941436767578125, L4: 0.39113184809684753, L5: 0.0199748408049345
Epoch 5500, Loss: -0.23042616248130798, Losses: L1: -1.5451233386993408, L2: 0.1804797202348709, L3: 0.07843691110610962, L4: 0.3788071274757385, L5: 0.01962484046816826
Epoch 6000, Loss: -0.2532678246498108, Losses: L1: -1.5493214130401611, L2: 0.18021054565906525, L3: 0.07772493362426758, L4: 0.37094229459762573, L5: 0.019149038940668106
Epoch 6500, Loss: -0.2710653841495514, Losses: L1: -1.5526983737945557, L2: 0.18035148084163666, L3: 0.07708156108856201, L4: 0.3646518290042877, L5: 0.01873161271214485
Epoch 7000, Loss: -0.28339916467666626, Losses: L1: -1.5546694993972778, L2: 0.18023507297039032, L3: 0.07661044597625732, L4: 0.36024999618530273, L5: 0.018539633601903915
Epoch 7500, Loss: -0.2921910583972931, Losses: L1: -1.5564228296279907, L2: 0.18036861717700958, L3: 0.07630348205566406, L4: 0.3571159839630127, L5: 0.01832781545817852
Epoch 8000, Loss: -0.29791849851608276, Losses: L1: -1.557597279548645, L2: 0.18056996166706085, L3: 0.07608318328857422, L4: 0.35494714975357056, L5: 0.018239110708236694
Epoch 8500, Loss: -0.301893025636673, Losses: L1: -1.5583579540252686, L2: 0.1807301789522171, L3: 0.07593244314193726, L4: 0.3533897399902344, L5: 0.01818012073636055
Epoch 9000, Loss: -0.30456289649009705, Losses: L1: -1.5587129592895508, L2: 0.1807887852191925, L3: 0.07581847906112671, L4: 0.3523104786872864, L5: 0.018157321959733963
Epoch 9500, Loss: -0.3063324987888336, Losses: L1: -1.5589854717254639, L2: 0.18081894516944885, L3: 0.07574957609176636, L4: 0.3516237735748291, L5: 0.018134217709302902
Training done
----------------------------------------------------------------------------
######################### Running test with dataset: FrecLoWeight ###########
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.002850294113159, Constraint losses: L1: 6.30507755279541, L2: 0.0, L3: 0.9982728958129883, L4: 0.9982722997665405
Epoch 500, Loss: 0.0021953529212623835, Constraint losses: L1: -1.0886919498443604, L2: 0.0, L3: 0.002641141414642334, L4: 0.0006429035565815866
Epoch 1000, Loss: 0.001290931599214673, Constraint losses: L1: -1.1182883977890015, L2: 0.0, L3: 0.002204298973083496, L4: 0.00020492105977609754
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.996005654335022, Constraint losses: L1: 5.306856155395508, L2: 0.0, L3: 0.9953499436378479, L4: 0.9953488111495972
Epoch 500, Loss: 0.002210272941738367, Constraint losses: L1: -1.1165119409561157, L2: 0.0, L3: 0.00266265869140625, L4: 0.0006641261279582977
Epoch 1000, Loss: 0.0013187797740101814, Constraint losses: L1: -1.1188479661941528, L2: 0.0, L3: 0.0022185444831848145, L4: 0.00021908330381847918
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 38.80264663696289, Losses: L1: 5.435070514678955, L2: 0.0, L3: 0.9955669641494751, L4: 65.43917846679688, L5: 0.30040642619132996
Epoch 500, Loss: 44.004493713378906, Losses: L1: 18.419172286987305, L2: 5.5459768721899394e-11, L3: 1.0, L4: 50.00000762939453, L5: 0.17063839733600616
Epoch 1000, Loss: 38.750518798828125, Losses: L1: 12.364033699035645, L2: 0.0, L3: 0.999995231628418, L4: 51.58937072753906, L5: 0.18360859155654907
Epoch 1500, Loss: 44.03675842285156, Losses: L1: 18.42068099975586, L2: 5.7724428535743666e-12, L3: 1.0, L4: 50.0612678527832, L5: 0.17088200151920319
Epoch 2000, Loss: 44.027435302734375, Losses: L1: 18.42068099975586, L2: 3.3975801772695435e-12, L3: 1.0, L4: 50.042724609375, L5: 0.1707824170589447
Epoch 2500, Loss: 44.023189544677734, Losses: L1: 18.42068099975586, L2: 2.4340900389024922e-12, L3: 1.0, L4: 50.034278869628906, L5: 0.1707405298948288
Epoch 3000, Loss: 44.020843505859375, Losses: L1: 18.42068099975586, L2: 1.9468151049584215e-12, L3: 1.0, L4: 50.029605865478516, L5: 0.17071810364723206
Epoch 3500, Loss: 44.0193977355957, Losses: L1: 18.42068099975586, L2: 1.6664457357443152e-12, L3: 1.0, L4: 50.02672576904297, L5: 0.17070429027080536
Epoch 4000, Loss: 44.0184440612793, Losses: L1: 18.42068099975586, L2: 1.4898599931881251e-12, L3: 1.0, L4: 50.02483367919922, L5: 0.17069518566131592
Epoch 4500, Loss: 44.01778793334961, Losses: L1: 18.42068099975586, L2: 1.3737322911155925e-12, L3: 1.0, L4: 50.02352523803711, L5: 0.17068901658058167
Epoch 5000, Loss: 44.01732635498047, Losses: L1: 18.42068099975586, L2: 1.293814881619948e-12, L3: 1.0, L4: 50.02260208129883, L5: 0.17068475484848022
Epoch 5500, Loss: 44.01698684692383, Losses: L1: 18.42068099975586, L2: 1.237222347141853e-12, L3: 1.0, L4: 50.02192687988281, L5: 0.1706816554069519
Epoch 6000, Loss: 44.01673126220703, Losses: L1: 18.42068099975586, L2: 1.1961826928280628e-12, L3: 1.0, L4: 50.02142333984375, L5: 0.17067936062812805
Epoch 6500, Loss: 44.016544342041016, Losses: L1: 18.42068099975586, L2: 1.165973459275882e-12, L3: 1.0, L4: 50.02104949951172, L5: 0.17067763209342957
Epoch 7000, Loss: 44.01640701293945, Losses: L1: 18.42068099975586, L2: 1.1434266077373079e-12, L3: 1.0, L4: 50.02077102661133, L5: 0.1706763356924057
Epoch 7500, Loss: 44.016292572021484, Losses: L1: 18.42068099975586, L2: 1.126455049030306e-12, L3: 1.0, L4: 50.02054977416992, L5: 0.1706753522157669
Epoch 8000, Loss: 44.01621627807617, Losses: L1: 18.42068099975586, L2: 1.1135464295444764e-12, L3: 1.0, L4: 50.020389556884766, L5: 0.17067460715770721
Epoch 8500, Loss: 44.016151428222656, Losses: L1: 18.42068099975586, L2: 1.1036739014022579e-12, L3: 1.0, L4: 50.020263671875, L5: 0.17067402601242065
Epoch 9000, Loss: 44.0161018371582, Losses: L1: 18.42068099975586, L2: 1.096148887803905e-12, L3: 1.0, L4: 50.02016830444336, L5: 0.17067357897758484
Epoch 9500, Loss: 44.01605987548828, Losses: L1: 18.42068099975586, L2: 1.0903190243022332e-12, L3: 1.0, L4: 50.02009201049805, L5: 0.17067323625087738
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0013155937194824, Constraint losses: L1: 5.995701789855957, L2: 0.0, L3: 0.9976603388786316, L4: 0.9976596236228943
Epoch 500, Loss: 0.0021112977992743254, Constraint losses: L1: -1.1109507083892822, L2: 0.0, L3: 0.002610325813293457, L4: 0.0006119227036833763
Epoch 1000, Loss: 0.0012853160733357072, Constraint losses: L1: -1.1184821128845215, L2: 0.0, L3: 0.0022016167640686035, L4: 0.00020218155987095088
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.024152994155884, Constraint losses: L1: 18.42068099975586, L2: 0.0019275316735729575, L3: 1.0019029378890991, L4: 1.0019018650054932
Epoch 500, Loss: 0.002419255208224058, Constraint losses: L1: -1.0791040658950806, L2: 0.0, L3: 0.0027480721473693848, L4: 0.0007502872031182051
Epoch 1000, Loss: 0.0013491205172613263, Constraint losses: L1: -1.117553949356079, L2: 0.0, L3: 0.002232968807220459, L4: 0.00023370576673187315
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 41.400821685791016, Losses: L1: 6.29719352722168, L2: 3.2244377507595345e-05, L3: 0.9970500469207764, L4: 68.5719223022461, L5: 0.31912773847579956
Epoch 500, Loss: 12.411324501037598, Losses: L1: 3.8448402881622314, L2: 2.0758824348449707, L3: 0.3637869358062744, L4: 14.57365894317627, L5: 0.0598202608525753
Epoch 1000, Loss: -0.47038161754608154, Losses: L1: -2.9124255180358887, L2: 1.28467857837677, L3: 0.1926048994064331, L4: 3.3743834495544434, L5: 0.016210423782467842
Epoch 1500, Loss: -1.547288179397583, Losses: L1: -3.155946969985962, L2: 0.9564740061759949, L3: 0.08138269186019897, L4: 2.148606538772583, L5: 0.015427193604409695
Epoch 2000, Loss: -2.810208797454834, Losses: L1: -3.8210384845733643, L2: 1.236371636390686, L3: 0.08316683769226074, L4: 0.6906917691230774, L5: 0.00571443373337388
Epoch 2500, Loss: -3.101001024246216, Losses: L1: -4.0866899490356445, L2: 1.2511067390441895, L3: 0.07883340120315552, L4: 0.6315339803695679, L5: 0.004951737821102142
Epoch 3000, Loss: -3.122710704803467, Losses: L1: -4.010153770446777, L2: 1.0175433158874512, L3: 0.08418655395507812, L4: 0.6635960936546326, L5: 0.0047799767926335335
Epoch 3500, Loss: -3.209892988204956, Losses: L1: -4.072394371032715, L2: 1.1029934883117676, L3: 0.07719838619232178, L4: 0.5354709029197693, L5: 0.004669787362217903
Epoch 4000, Loss: -3.236356258392334, Losses: L1: -4.0850443840026855, L2: 1.1003295183181763, L3: 0.07467341423034668, L4: 0.5131261348724365, L5: 0.004623335786163807
Epoch 4500, Loss: -3.2561757564544678, Losses: L1: -4.0876922607421875, L2: 1.0845584869384766, L3: 0.07393240928649902, L4: 0.4954325556755066, L5: 0.004554669838398695
Epoch 5000, Loss: -3.2691116333007812, Losses: L1: -4.091253280639648, L2: 1.0761438608169556, L3: 0.07300293445587158, L4: 0.4860953092575073, L5: 0.0045207105576992035
Epoch 5500, Loss: -3.278489589691162, Losses: L1: -4.094571113586426, L2: 1.071024775505066, L3: 0.07205367088317871, L4: 0.4800884425640106, L5: 0.004497996997088194
Epoch 6000, Loss: -3.2856016159057617, Losses: L1: -4.094644546508789, L2: 1.0635062456130981, L3: 0.0716390609741211, L4: 0.4739936292171478, L5: 0.004473445005714893
Epoch 6500, Loss: -3.290789842605591, Losses: L1: -4.09415864944458, L2: 1.0570909976959229, L3: 0.071341872215271, L4: 0.4693969488143921, L5: 0.004453881643712521
Epoch 7000, Loss: -3.2947640419006348, Losses: L1: -4.093653202056885, L2: 1.0520912408828735, L3: 0.07116317749023438, L4: 0.4656345844268799, L5: 0.004444671329110861
Epoch 7500, Loss: -3.297792673110962, Losses: L1: -4.093976974487305, L2: 1.0494227409362793, L3: 0.07085657119750977, L4: 0.46321871876716614, L5: 0.004435244016349316
Epoch 8000, Loss: -3.2999954223632812, Losses: L1: -4.093888282775879, L2: 1.0469512939453125, L3: 0.07066655158996582, L4: 0.4613105058670044, L5: 0.004428831394761801
Epoch 8500, Loss: -3.301633834838867, Losses: L1: -4.094069957733154, L2: 1.0454652309417725, L3: 0.07052218914031982, L4: 0.46003636717796326, L5: 0.0044240765273571014
Epoch 9000, Loss: -3.3027994632720947, Losses: L1: -4.094199180603027, L2: 1.0443413257598877, L3: 0.07039117813110352, L4: 0.4592234194278717, L5: 0.004421968944370747
Epoch 9500, Loss: -3.30364727973938, Losses: L1: -4.094222068786621, L2: 1.0434134006500244, L3: 0.07034158706665039, L4: 0.458556205034256, L5: 0.004419348202645779
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020815849304199, Constraint losses: L1: 18.42068099975586, L2: 0.0008210241794586182, L3: 1.0007872581481934, L4: 1.0007870197296143
Epoch 500, Loss: 0.00203033909201622, Constraint losses: L1: -1.0994065999984741, L2: 0.0, L3: 0.0025640130043029785, L4: 0.0005657326546497643
Epoch 1000, Loss: 0.001245145802386105, Constraint losses: L1: -1.1181561946868896, L2: 0.0, L3: 0.0021813511848449707, L4: 0.00018195089069195092
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0258536338806152, Constraint losses: L1: 18.42068099975586, L2: 0.0024775585625320673, L3: 1.0024775266647339, L4: 1.002478003501892
Epoch 500, Loss: 0.002400042489171028, Constraint losses: L1: -1.0216741561889648, L2: 0.0, L3: 0.0027099251747131348, L4: 0.0007117916829884052
Epoch 1000, Loss: 0.001310223015025258, Constraint losses: L1: -1.118129849433899, L2: 0.0, L3: 0.0022139549255371094, L4: 0.00021439799456857145
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.19074630737305, Losses: L1: 17.04165267944336, L2: 0.0018631408456712961, L3: 1.0018491744995117, L4: 68.01057434082031, L5: 0.32097357511520386
Epoch 500, Loss: 33.3708610534668, Losses: L1: 7.297052383422852, L2: 0.03407532349228859, L3: 0.9378830194473267, L4: 50.476070404052734, L5: 0.17489591240882874
Epoch 1000, Loss: 26.62599754333496, Losses: L1: 5.462787628173828, L2: 0.15415260195732117, L3: 1.0101172924041748, L4: 40.19921875, L5: 0.24073290824890137
Epoch 1500, Loss: 1.415267825126648, Losses: L1: -1.5076414346694946, L2: 0.7307111024856567, L3: 0.16550981998443604, L4: 4.820192337036133, L5: 0.032351303845644
Epoch 2000, Loss: -0.9027753472328186, Losses: L1: -2.2964797019958496, L2: 0.5485860109329224, L3: 0.10903012752532959, L4: 2.082451105117798, L5: 0.011835377663373947
Epoch 2500, Loss: -1.8971443176269531, Losses: L1: -2.439472198486328, L2: 0.3542623817920685, L3: 0.08157479763031006, L4: 0.6255453824996948, L5: 0.0058182766661047935
Epoch 3000, Loss: -2.128757953643799, Losses: L1: -2.6017003059387207, L2: 0.34779685735702515, L3: 0.0765458345413208, L4: 0.5000449419021606, L5: 0.005374331492930651
Epoch 3500, Loss: -2.2681641578674316, Losses: L1: -2.7089405059814453, L2: 0.3481082022190094, L3: 0.07492589950561523, L4: 0.43847131729125977, L5: 0.005011805798858404
Epoch 4000, Loss: -2.3510143756866455, Losses: L1: -2.7699553966522217, L2: 0.3497354984283447, L3: 0.07377499341964722, L4: 0.3952803611755371, L5: 0.004772805608808994
Epoch 4500, Loss: -2.4054925441741943, Losses: L1: -2.8175723552703857, L2: 0.35604214668273926, L3: 0.07289612293243408, L4: 0.3764580488204956, L5: 0.004690759349614382
Epoch 5000, Loss: -2.443026304244995, Losses: L1: -2.8517961502075195, L2: 0.3602822721004486, L3: 0.07210510969161987, L4: 0.3666377663612366, L5: 0.00462863827124238
Epoch 5500, Loss: -2.4691455364227295, Losses: L1: -2.8798727989196777, L2: 0.3650744557380676, L3: 0.071586012840271, L4: 0.36630234122276306, L5: 0.0046228221617639065
Epoch 6000, Loss: -2.4901223182678223, Losses: L1: -2.8985483646392822, L2: 0.36785605549812317, L3: 0.07121920585632324, L4: 0.3593865931034088, L5: 0.004597611725330353
Epoch 6500, Loss: -2.504706382751465, Losses: L1: -2.9135313034057617, L2: 0.3709108233451843, L3: 0.0710287094116211, L4: 0.3573252260684967, L5: 0.004596332088112831
Epoch 7000, Loss: -2.5147032737731934, Losses: L1: -2.924556255340576, L2: 0.37377020716667175, L3: 0.07087928056716919, L4: 0.3566659092903137, L5: 0.004597574472427368
Epoch 7500, Loss: -2.5224549770355225, Losses: L1: -2.932213544845581, L2: 0.3756076693534851, L3: 0.07074826955795288, L4: 0.3547687232494354, L5: 0.004598162602633238
Epoch 8000, Loss: -2.527782678604126, Losses: L1: -2.9376981258392334, L2: 0.37688830494880676, L3: 0.07065534591674805, L4: 0.3538948893547058, L5: 0.004598143510520458
Epoch 8500, Loss: -2.531470775604248, Losses: L1: -2.940387725830078, L2: 0.37700408697128296, L3: 0.07057595252990723, L4: 0.3519049882888794, L5: 0.004587123170495033
Epoch 9000, Loss: -2.5340192317962646, Losses: L1: -2.942172050476074, L2: 0.3768980801105499, L3: 0.0705331563949585, L4: 0.35054659843444824, L5: 0.004581768531352282
Epoch 9500, Loss: -2.5357587337493896, Losses: L1: -2.9429168701171875, L2: 0.3764197528362274, L3: 0.0704994797706604, L4: 0.3491024971008301, L5: 0.004573649261146784
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.026620388031006, Constraint losses: L1: 18.42068099975586, L2: 0.00273310299962759, L3: 1.0027331113815308, L4: 1.0027334690093994
Epoch 500, Loss: 0.0022137355990707874, Constraint losses: L1: -0.9825596213340759, L2: 0.0, L3: 0.0025969743728637695, L4: 0.0005993209779262543
Epoch 1000, Loss: 0.0012440710561349988, Constraint losses: L1: -1.1128212213516235, L2: 0.0, L3: 0.002178013324737549, L4: 0.00017887898138724267
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0310542583465576, Constraint losses: L1: 18.42068099975586, L2: 0.004210919141769409, L3: 1.0042109489440918, L4: 1.004211664199829
Epoch 500, Loss: 0.0022000418975949287, Constraint losses: L1: -1.0901621580123901, L2: 0.0, L3: 0.0026440024375915527, L4: 0.0006462015444412827
Epoch 1000, Loss: 0.0012932834215462208, Constraint losses: L1: -1.1188582181930542, L2: 0.0, L3: 0.002205789089202881, L4: 0.00020635251712519675
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.82273864746094, Losses: L1: 11.846651077270508, L2: 0.0005740136257372797, L3: 0.9995797872543335, L4: 82.26364135742188, L5: 0.42474833130836487
Epoch 500, Loss: 69.00526428222656, Losses: L1: 18.420595169067383, L2: 2.6833012740467947e-14, L3: 1.0, L4: 50.00000762939453, L5: 0.16933000087738037
Epoch 1000, Loss: 69.00404357910156, Losses: L1: 18.41937255859375, L2: 6.233598706661958e-13, L3: 1.0, L4: 50.00000762939453, L5: 0.16933000087738037
Epoch 1500, Loss: 69.00491333007812, Losses: L1: 18.42022705078125, L2: 0.0, L3: 1.0, L4: 50.000022888183594, L5: 0.16933000087738037
Epoch 2000, Loss: 6.838614463806152, Losses: L1: -1.0251518487930298, L2: 0.4503326117992401, L3: 0.313226580619812, L4: 7.463905334472656, L5: 0.036162108182907104
Epoch 2500, Loss: 3.2843289375305176, Losses: L1: -0.5504095554351807, L2: 0.3929390013217926, L3: 0.256656289100647, L4: 3.4960505962371826, L5: 0.027780592441558838
Epoch 3000, Loss: 3.007484197616577, Losses: L1: -0.5087728500366211, L2: 0.441500186920166, L3: 0.22838836908340454, L4: 3.166008472442627, L5: 0.030608639121055603
Epoch 3500, Loss: 2.2170143127441406, Losses: L1: -0.4001355767250061, L2: 0.4115378260612488, L3: 0.21457529067993164, L4: 2.285109043121338, L5: 0.037968479096889496
Epoch 4000, Loss: 2.0126640796661377, Losses: L1: -0.3686879575252533, L2: 0.391146719455719, L3: 0.1985558271408081, L4: 2.065789222717285, L5: 0.04142317920923233
Epoch 4500, Loss: 1.6426855325698853, Losses: L1: -0.3917228579521179, L2: 0.39656776189804077, L3: 0.19161683320999146, L4: 1.7198792695999146, L5: 0.04087383300065994
Epoch 5000, Loss: 1.5244531631469727, Losses: L1: -0.38780972361564636, L2: 0.39428505301475525, L3: 0.18600094318389893, L4: 1.601305603981018, L5: 0.04162849113345146
Epoch 5500, Loss: 1.435991883277893, Losses: L1: -0.37777939438819885, L2: 0.3944094479084015, L3: 0.18152761459350586, L4: 1.5046013593673706, L5: 0.04240269213914871
Epoch 6000, Loss: 1.3916878700256348, Losses: L1: -0.3771139085292816, L2: 0.3953225016593933, L3: 0.1779438853263855, L4: 1.4608964920043945, L5: 0.04254411533474922
Epoch 6500, Loss: 1.3568981885910034, Losses: L1: -0.37178096175193787, L2: 0.39470985531806946, L3: 0.175584077835083, L4: 1.4220722913742065, L5: 0.04291985556483269
Epoch 7000, Loss: 1.3357746601104736, Losses: L1: -0.3705444633960724, L2: 0.3957366645336151, L3: 0.17396795749664307, L4: 1.3999708890914917, L5: 0.04299188032746315
Epoch 7500, Loss: 1.3231993913650513, Losses: L1: -0.3705301284790039, L2: 0.3959302008152008, L3: 0.17314380407333374, L4: 1.3876762390136719, L5: 0.043032705783843994
Epoch 8000, Loss: 1.3152730464935303, Losses: L1: -0.3703182637691498, L2: 0.3960258364677429, L3: 0.17234742641448975, L4: 1.3798757791519165, L5: 0.04305795952677727
Epoch 8500, Loss: 1.3093777894973755, Losses: L1: -0.37008553743362427, L2: 0.3960104286670685, L3: 0.17173278331756592, L4: 1.374051570892334, L5: 0.04308023303747177
Epoch 9000, Loss: 1.3052717447280884, Losses: L1: -0.37053635716438293, L2: 0.39586326479911804, L3: 0.17129355669021606, L4: 1.3706941604614258, L5: 0.04307113587856293
Epoch 9500, Loss: 1.3023515939712524, Losses: L1: -0.37075892090797424, L2: 0.39569374918937683, L3: 0.17095792293548584, L4: 1.3682492971420288, L5: 0.043070804327726364
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0207295417785645, Constraint losses: L1: 18.42068099975586, L2: 0.0007696820539422333, L3: 1.0007697343826294, L4: 1.0007694959640503
Epoch 500, Loss: 0.002612384967505932, Constraint losses: L1: -0.9673318266868591, L2: 0.0, L3: 0.002788722515106201, L4: 0.000790994381532073
Epoch 1000, Loss: 0.001353036961518228, Constraint losses: L1: -1.1167702674865723, L2: 0.0, L3: 0.00223463773727417, L4: 0.0002351695584366098
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0177228450775146, Constraint losses: L1: 16.285316467285156, L2: 0.0006157719762995839, L3: 1.0004111528396606, L4: 1.000410556793213
Epoch 500, Loss: 0.002324082423001528, Constraint losses: L1: -1.0462785959243774, L2: 0.0, L3: 0.0026839375495910645, L4: 0.000686423503793776
Epoch 1000, Loss: 0.0013058703625574708, Constraint losses: L1: -1.1177928447723389, L2: 0.0, L3: 0.0022115111351013184, L4: 0.00021215213928371668
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 93.33464050292969, Losses: L1: 17.853017807006836, L2: 0.0007309231441468, L3: 1.0006626844406128, L4: 74.6104736328125, L5: 0.3704545795917511
Epoch 500, Loss: 12.64254093170166, Losses: L1: -1.663343071937561, L2: 1.4477421045303345, L3: 0.41215837001800537, L4: 13.315224647521973, L5: 0.06070911884307861
Epoch 1000, Loss: 0.18446116149425507, Losses: L1: -2.339005470275879, L2: 0.678087055683136, L3: 0.1363753080368042, L4: 2.104410409927368, L5: 0.0118251359090209
Epoch 1500, Loss: -0.6269131302833557, Losses: L1: -2.6430118083953857, L2: 0.6616675853729248, L3: 0.12213170528411865, L4: 1.6147079467773438, L5: 0.009491163305938244
Epoch 2000, Loss: -0.5567684769630432, Losses: L1: -2.729783535003662, L2: 0.5406644940376282, L3: 0.12053430080413818, L4: 1.833891749382019, L5: 0.008523772470653057
Epoch 2500, Loss: -1.258776068687439, Losses: L1: -2.8784217834472656, L2: 0.4931822717189789, L3: 0.11231422424316406, L4: 1.3059337139129639, L5: 0.010963848792016506
Epoch 3000, Loss: -1.6040005683898926, Losses: L1: -2.875084161758423, L2: 0.43720418214797974, L3: 0.10730868577957153, L4: 0.992445170879364, L5: 0.0063817198388278484
Epoch 3500, Loss: -1.88362455368042, Losses: L1: -2.9303512573242188, L2: 0.4189755618572235, L3: 0.1030423641204834, L4: 0.7792547941207886, L5: 0.006463163532316685
Epoch 4000, Loss: -1.983544945716858, Losses: L1: -2.966900110244751, L2: 0.41688084602355957, L3: 0.10029089450836182, L4: 0.718563437461853, L5: 0.006205741781741381
Epoch 4500, Loss: -2.0627212524414062, Losses: L1: -2.9859118461608887, L2: 0.4152551591396332, L3: 0.09825140237808228, L4: 0.660534679889679, L5: 0.005902822129428387
Epoch 5000, Loss: -2.1019699573516846, Losses: L1: -3.0175094604492188, L2: 0.42394188046455383, L3: 0.09808862209320068, L4: 0.6486293077468872, L5: 0.005894810426980257
Epoch 5500, Loss: -2.137491226196289, Losses: L1: -3.043095827102661, L2: 0.43690019845962524, L3: 0.09718859195709229, L4: 0.6325972676277161, L5: 0.005963037721812725
Epoch 6000, Loss: -2.154197931289673, Losses: L1: -3.061887264251709, L2: 0.4467480480670929, L3: 0.09687173366546631, L4: 0.6300057768821716, L5: 0.005873434711247683
Epoch 6500, Loss: -2.1679351329803467, Losses: L1: -3.076606035232544, L2: 0.45452210307121277, L3: 0.0966484546661377, L4: 0.627232551574707, L5: 0.005853002890944481
Epoch 7000, Loss: -2.176934242248535, Losses: L1: -3.085904121398926, L2: 0.45995789766311646, L3: 0.09636598825454712, L4: 0.6250054836273193, L5: 0.005802452098578215
Epoch 7500, Loss: -2.1832258701324463, Losses: L1: -3.0922722816467285, L2: 0.46373480558395386, L3: 0.09614527225494385, L4: 0.62332683801651, L5: 0.005779633764177561
Epoch 8000, Loss: -2.1878113746643066, Losses: L1: -3.096949338912964, L2: 0.4664416015148163, L3: 0.09602206945419312, L4: 0.6221243143081665, L5: 0.005781727377325296
Epoch 8500, Loss: -2.1910393238067627, Losses: L1: -3.0999438762664795, L2: 0.46819862723350525, L3: 0.09589433670043945, L4: 0.6210764050483704, L5: 0.005781675688922405
Epoch 9000, Loss: -2.193312883377075, Losses: L1: -3.101879596710205, L2: 0.46938493847846985, L3: 0.09577572345733643, L4: 0.6202067136764526, L5: 0.0057795485481619835
Epoch 9500, Loss: -2.1948940753936768, Losses: L1: -3.103163480758667, L2: 0.47016215324401855, L3: 0.09568977355957031, L4: 0.619563102722168, L5: 0.005780389066785574
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0202624797821045, Constraint losses: L1: 18.42068099975586, L2: 0.0006139625911600888, L3: 1.0006139278411865, L4: 1.0006139278411865
Epoch 500, Loss: 0.0025314034428447485, Constraint losses: L1: -1.079057216644287, L2: 0.0, L3: 0.0028041601181030273, L4: 0.0008063004934228957
Epoch 1000, Loss: 0.0014032013714313507, Constraint losses: L1: -1.1173797845840454, L2: 0.0, L3: 0.0022600293159484863, L4: 0.0002605519548524171
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9990754127502441, Constraint losses: L1: 5.718447685241699, L2: 0.0, L3: 0.9966784715652466, L4: 0.9966784715652466
Epoch 500, Loss: 0.002165338722988963, Constraint losses: L1: -1.0812104940414429, L2: 0.0, L3: 0.0026223063468933105, L4: 0.0006242428789846599
Epoch 1000, Loss: 0.0012672633165493608, Constraint losses: L1: -1.11959969997406, L2: 0.0, L3: 0.0021932125091552734, L4: 0.0001936506014317274
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 92.57361602783203, Losses: L1: 18.42068099975586, L2: 0.0014478685334324837, L3: 1.0014479160308838, L4: 72.94429016113281, L5: 0.3535960018634796
Epoch 500, Loss: -2.025393009185791, Losses: L1: -3.3076882362365723, L2: 0.8595283031463623, L3: 0.08341777324676514, L4: 0.7918875813484192, L5: 0.009467226453125477
Epoch 1000, Loss: -1.7305604219436646, Losses: L1: -3.201505184173584, L2: 0.7673249840736389, L3: 0.09359568357467651, L4: 1.0241308212280273, L5: 0.008176884613931179
Epoch 1500, Loss: -1.3320361375808716, Losses: L1: -3.72129225730896, L2: 0.8878978490829468, L3: 0.07441788911819458, L4: 1.880191683769226, L5: 0.013953207060694695
Epoch 2000, Loss: -3.154670000076294, Losses: L1: -4.035699367523193, L2: 0.9248628616333008, L3: 0.025980651378631592, L4: 0.39404451847076416, L5: 0.005781562067568302
Epoch 2500, Loss: -3.227565288543701, Losses: L1: -4.03494119644165, L2: 0.592686653137207, L3: 0.02251756191253662, L4: 0.4918520748615265, L5: 0.003960907459259033
Epoch 3000, Loss: -3.430591583251953, Losses: L1: -4.0174880027771, L2: 0.6011329889297485, L3: 0.01751112937927246, L4: 0.2679554224014282, L5: 0.004809606820344925
Epoch 3500, Loss: -3.5269267559051514, Losses: L1: -4.066440105438232, L2: 0.55597984790802, L3: 0.04246699810028076, L4: 0.2309040129184723, L5: 0.0046928622759878635
Epoch 4000, Loss: -3.5639419555664062, Losses: L1: -4.0437331199646, L2: 0.5062069892883301, L3: 0.027938127517700195, L4: 0.20359890162944794, L5: 0.004559728782624006
Epoch 4500, Loss: -3.580530881881714, Losses: L1: -4.049858570098877, L2: 0.5121666789054871, L3: 0.017619609832763672, L4: 0.19543768465518951, L5: 0.004498515278100967
Epoch 5000, Loss: -3.592482089996338, Losses: L1: -4.055163383483887, L2: 0.5161223411560059, L3: 0.015083551406860352, L4: 0.1880655288696289, L5: 0.004506398923695087
Epoch 5500, Loss: -3.5990240573883057, Losses: L1: -4.057306289672852, L2: 0.513317883014679, L3: 0.0165024995803833, L4: 0.18439209461212158, L5: 0.0044900220818817616
Epoch 6000, Loss: -3.6035327911376953, Losses: L1: -4.057451248168945, L2: 0.5094162821769714, L3: 0.016860246658325195, L4: 0.18172752857208252, L5: 0.004526382312178612
Epoch 6500, Loss: -3.606102228164673, Losses: L1: -4.056546688079834, L2: 0.5063072443008423, L3: 0.016470670700073242, L4: 0.1800665259361267, L5: 0.004494598601013422
Epoch 7000, Loss: -3.6088457107543945, Losses: L1: -4.057608604431152, L2: 0.50486159324646, L3: 0.017533421516418457, L4: 0.17852269113063812, L5: 0.004521429538726807
Epoch 7500, Loss: -3.610355854034424, Losses: L1: -4.057302474975586, L2: 0.5032131671905518, L3: 0.017473936080932617, L4: 0.1775643229484558, L5: 0.004519395995885134
Epoch 8000, Loss: -3.6113314628601074, Losses: L1: -4.057250499725342, L2: 0.5021455883979797, L3: 0.017636775970458984, L4: 0.17699424922466278, L5: 0.004516742192208767
Epoch 8500, Loss: -3.6120893955230713, Losses: L1: -4.057182788848877, L2: 0.5013412237167358, L3: 0.017608642578125, L4: 0.17657677829265594, L5: 0.00452080275863409
Epoch 9000, Loss: -3.61265230178833, Losses: L1: -4.057379722595215, L2: 0.5009743571281433, L3: 0.017885923385620117, L4: 0.17625313997268677, L5: 0.004522258415818214
Epoch 9500, Loss: -3.6129982471466064, Losses: L1: -4.057302474975586, L2: 0.5005818605422974, L3: 0.017853260040283203, L4: 0.1760413944721222, L5: 0.004522728733718395
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.001131772994995, Constraint losses: L1: 5.971971035003662, L2: 0.0, L3: 0.9975801110267639, L4: 0.9975796937942505
Epoch 500, Loss: 0.002174022141844034, Constraint losses: L1: -0.9834121465682983, L2: 0.0, L3: 0.0025777220726013184, L4: 0.0005797121557407081
Epoch 1000, Loss: 0.0012311097234487534, Constraint losses: L1: -1.1123034954071045, L2: 0.0, L3: 0.0021713972091674805, L4: 0.00017201613809447736
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9911680221557617, Constraint losses: L1: 4.8731279373168945, L2: 0.0, L3: 0.993148922920227, L4: 0.9931460022926331
Epoch 500, Loss: 0.0021833395585417747, Constraint losses: L1: -1.1148210763931274, L2: 0.0, L3: 0.002648293972015381, L4: 0.0006498668808490038
Epoch 1000, Loss: 0.0013123454991728067, Constraint losses: L1: -1.1190149784088135, L2: 0.0, L3: 0.0022153854370117188, L4: 0.00021597507293336093
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 165.06039428710938, Losses: L1: 17.1618709564209, L2: 0.007985652424395084, L3: 1.0079559087753296, L4: 73.60582733154297, L5: 0.35778623819351196
Epoch 500, Loss: -1.7390631437301636, Losses: L1: -3.2550737857818604, L2: 0.4756622016429901, L3: 0.06760478019714355, L4: 0.6208823323249817, L5: 0.005225177388638258
Epoch 1000, Loss: 1.8065295219421387, Losses: L1: -2.3077051639556885, L2: 0.6511176228523254, L3: 0.13435888290405273, L4: 1.8567324876785278, L5: 0.016063008457422256
Epoch 1500, Loss: -0.36827629804611206, Losses: L1: -2.3653531074523926, L2: 0.3573002517223358, L3: 0.1143350601196289, L4: 0.8790189027786255, L5: 0.006442687939852476
Epoch 2000, Loss: -0.7082014083862305, Losses: L1: -2.523730993270874, L2: 0.25412774085998535, L3: 0.10549122095108032, L4: 0.8166525363922119, L5: 0.004829858895391226
Epoch 2500, Loss: -0.5891743302345276, Losses: L1: -2.72305965423584, L2: 0.29362866282463074, L3: 0.09551042318344116, L4: 0.9678701162338257, L5: 0.007151028141379356
Epoch 3000, Loss: -1.5784543752670288, Losses: L1: -2.803767204284668, L2: 0.26342296600341797, L3: 0.0775289535522461, L4: 0.5261921286582947, L5: 0.004905316047370434
Epoch 3500, Loss: -2.2145261764526367, Losses: L1: -2.954719305038452, L2: 0.27049705386161804, L3: 0.06738108396530151, L4: 0.28458768129348755, L5: 0.004158097319304943
Epoch 4000, Loss: -2.461615562438965, Losses: L1: -3.131157398223877, L2: 0.29754504561424255, L3: 0.062030673027038574, L4: 0.24377980828285217, L5: 0.004388879053294659
Epoch 4500, Loss: -2.6907706260681152, Losses: L1: -3.1987435817718506, L2: 0.298361599445343, L3: 0.060505032539367676, L4: 0.16324952244758606, L5: 0.004081078339368105
Epoch 5000, Loss: -2.68096923828125, Losses: L1: -3.2465786933898926, L2: 0.3101881146430969, L3: 0.06011158227920532, L4: 0.18918009102344513, L5: 0.004198330454528332
Epoch 5500, Loss: -2.761014699935913, Losses: L1: -3.272019624710083, L2: 0.3186591863632202, L3: 0.05999952554702759, L4: 0.159805566072464, L5: 0.004129054024815559
Epoch 6000, Loss: -2.7961606979370117, Losses: L1: -3.2879035472869873, L2: 0.32428476214408875, L3: 0.05976372957229614, L4: 0.14883576333522797, L5: 0.004094072617590427
Epoch 6500, Loss: -2.8062877655029297, Losses: L1: -3.2992403507232666, L2: 0.32710641622543335, L3: 0.05965888500213623, L4: 0.14876192808151245, L5: 0.004092196002602577
Epoch 7000, Loss: -2.8131167888641357, Losses: L1: -3.3062784671783447, L2: 0.32820501923561096, L3: 0.05954694747924805, L4: 0.14862164855003357, L5: 0.004084649495780468
Epoch 7500, Loss: -2.8176167011260986, Losses: L1: -3.311143636703491, L2: 0.3289962708950043, L3: 0.05947357416152954, L4: 0.14862540364265442, L5: 0.004082491155713797
Epoch 8000, Loss: -2.8207685947418213, Losses: L1: -3.314862012863159, L2: 0.32989978790283203, L3: 0.059422433376312256, L4: 0.1486956626176834, L5: 0.004081867169588804
Epoch 8500, Loss: -2.8230199813842773, Losses: L1: -3.3175206184387207, L2: 0.3306419253349304, L3: 0.059400200843811035, L4: 0.14871972799301147, L5: 0.004080833401530981
Epoch 9000, Loss: -2.824577569961548, Losses: L1: -3.3195114135742188, L2: 0.3312876224517822, L3: 0.059376299381256104, L4: 0.1487807035446167, L5: 0.004081134684383869
Epoch 9500, Loss: -2.825505018234253, Losses: L1: -3.3207805156707764, L2: 0.33167341351509094, L3: 0.059363722801208496, L4: 0.14885835349559784, L5: 0.004080114420503378
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0022668838500977, Constraint losses: L1: 6.190428256988525, L2: 0.0, L3: 0.9980384111404419, L4: 0.9980380535125732
Epoch 500, Loss: 0.0024581081233918667, Constraint losses: L1: -1.0036484003067017, L2: 0.0, L3: 0.00272977352142334, L4: 0.0007319829892367125
Epoch 1000, Loss: 0.0013374716509133577, Constraint losses: L1: -1.1165661811828613, L2: 0.0, L3: 0.002226710319519043, L4: 0.00022732754587195814
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0002083778381348, Constraint losses: L1: 5.829305648803711, L2: 0.0, L3: 0.9971898198127747, L4: 0.9971892833709717
Epoch 500, Loss: 0.0020495743956416845, Constraint losses: L1: -1.0850830078125, L2: 0.0, L3: 0.0025664567947387695, L4: 0.0005682007176801562
Epoch 1000, Loss: 0.0012394522782415152, Constraint losses: L1: -1.1198269128799438, L2: 0.0, L3: 0.0021793246269226074, L4: 0.0001799546298570931
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 147.13037109375, Losses: L1: 7.201737880706787, L2: 0.0006021926528774202, L3: 0.9976420402526855, L4: 69.5481948852539, L5: 0.3331165313720703
Epoch 500, Loss: 9.029162406921387, Losses: L1: -2.890091896057129, L2: 1.022436261177063, L3: 0.1378050446510315, L4: 5.653040409088135, L5: 0.03305327519774437
Epoch 1000, Loss: -1.4562115669250488, Losses: L1: -3.4853572845458984, L2: 0.6190445423126221, L3: 0.06851327419281006, L4: 0.8395547866821289, L5: 0.006257336121052504
Epoch 1500, Loss: -2.329158067703247, Losses: L1: -3.6937789916992188, L2: 0.6147026419639587, L3: 0.0651443600654602, L4: 0.5103313326835632, L5: 0.004034761805087328
Epoch 2000, Loss: -2.0487186908721924, Losses: L1: -3.880362033843994, L2: 0.5050347447395325, L3: 0.01967144012451172, L4: 0.7821560502052307, L5: 0.0049779233522713184
Epoch 2500, Loss: -3.1646649837493896, Losses: L1: -3.995450735092163, L2: 0.5152108669281006, L3: 0.018930792808532715, L4: 0.280027836561203, L5: 0.0036593531258404255
Epoch 3000, Loss: 11.963366508483887, Losses: L1: 2.829373598098755, L2: 3.70388126373291, L3: 0.05593752861022949, L4: 3.6123383045196533, L5: 0.0294067170470953
Epoch 3500, Loss: 5.023005962371826, Losses: L1: 0.7191545963287354, L2: 2.3244097232818604, L3: 0.002330005168914795, L4: 1.5629864931106567, L5: 0.014508948661386967
Epoch 4000, Loss: 3.768958568572998, Losses: L1: -0.1148066595196724, L2: 1.899127721786499, L3: 0.0010237693786621094, L4: 1.4599629640579224, L5: 0.013763392344117165
Epoch 4500, Loss: 2.7642123699188232, Losses: L1: -0.761012613773346, L2: 1.6371352672576904, L3: 0.0005142688751220703, L4: 1.346792459487915, L5: 0.012815320864319801
Epoch 5000, Loss: 1.9891000986099243, Losses: L1: -1.2327141761779785, L2: 1.3973219394683838, L3: 0.13361215591430664, L4: 1.2222799062728882, L5: 0.011787379160523415
Epoch 5500, Loss: 1.4749350547790527, Losses: L1: -1.5624885559082031, L2: 1.3211171627044678, L3: 0.20967447757720947, L4: 1.1305184364318848, L5: 0.010990803129971027
Epoch 6000, Loss: 1.1492902040481567, Losses: L1: -1.7875921726226807, L2: 1.3575685024261475, L3: 0.18757230043411255, L4: 1.0768979787826538, L5: 0.010516012087464333
Epoch 6500, Loss: 0.8998314142227173, Losses: L1: -1.9561336040496826, L2: 1.38994562625885, L3: 0.17244577407836914, L4: 1.0323251485824585, L5: 0.010119101032614708
Epoch 7000, Loss: 0.7138251066207886, Losses: L1: -2.0802743434906006, L2: 1.4161226749420166, L3: 0.16229289770126343, L4: 0.9975459575653076, L5: 0.009799729101359844
Epoch 7500, Loss: 0.5776689052581787, Losses: L1: -2.1701061725616455, L2: 1.4373327493667603, L3: 0.15615344047546387, L4: 0.9707375764846802, L5: 0.009556890465319157
Epoch 8000, Loss: 0.48117947578430176, Losses: L1: -2.233508825302124, L2: 1.4528989791870117, L3: 0.15109938383102417, L4: 0.9516535997390747, L5: 0.009381897747516632
Epoch 8500, Loss: 0.41469642519950867, Losses: L1: -2.2772138118743896, L2: 1.4639959335327148, L3: 0.14770019054412842, L4: 0.9384009838104248, L5: 0.009260158985853195
Epoch 9000, Loss: 0.3697971701622009, Losses: L1: -2.306561231613159, L2: 1.4711101055145264, L3: 0.14518141746520996, L4: 0.9295163154602051, L5: 0.009180017746984959
Epoch 9500, Loss: 0.33995819091796875, Losses: L1: -2.326213836669922, L2: 1.475834846496582, L3: 0.14365112781524658, L4: 0.9236510992050171, L5: 0.009126902557909489
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9968372583389282, Constraint losses: L1: 5.467857837677002, L2: 0.0, L3: 0.9956846833229065, L4: 0.9956847429275513
Epoch 500, Loss: 0.002075063530355692, Constraint losses: L1: -1.102220058441162, L2: 0.0, L3: 0.0025878548622131348, L4: 0.0005894288187846541
Epoch 1000, Loss: 0.0012586882803589106, Constraint losses: L1: -1.1182849407196045, L2: 0.0, L3: 0.002188265323638916, L4: 0.00018870789790526032
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.003342628479004, Constraint losses: L1: 6.423794269561768, L2: 0.0, L3: 0.9984596371650696, L4: 0.9984592199325562
Epoch 500, Loss: 0.0022445330396294594, Constraint losses: L1: -1.1004563570022583, L2: 0.0, L3: 0.0026715993881225586, L4: 0.0006733901100233197
Epoch 1000, Loss: 0.0013201235560700297, Constraint losses: L1: -1.119757890701294, L2: 0.0, L3: 0.0022196173667907715, L4: 0.00022026407532393932
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 157.06187438964844, Losses: L1: 8.304746627807617, L2: 0.0011756549356505275, L3: 0.9978255033493042, L4: 73.77493286132812, L5: 0.3538782000541687
Epoch 500, Loss: 51.518733978271484, Losses: L1: 4.699009895324707, L2: 6.785995006561279, L3: 0.060658395290374756, L4: 21.59028434753418, L5: 0.10791321843862534
Epoch 1000, Loss: 0.43570804595947266, Losses: L1: -3.046769380569458, L2: 0.47593432664871216, L3: 0.07041960954666138, L4: 1.5957777500152588, L5: 0.008872389793395996
Epoch 1500, Loss: -2.1090822219848633, Losses: L1: -3.4753811359405518, L2: 0.8648716807365417, L3: 0.05600041151046753, L4: 0.4483262598514557, L5: 0.0046052453108131886
Epoch 2000, Loss: -3.178190231323242, Losses: L1: -3.9090592861175537, L2: 0.3983997106552124, L3: 0.047663211822509766, L4: 0.2501920759677887, L5: 0.0037266912404447794
Epoch 2500, Loss: -2.862537384033203, Losses: L1: -3.9379847049713135, L2: 0.35222822427749634, L3: 0.09021902084350586, L4: 0.4233934283256531, L5: 0.0037183486856520176
Epoch 3000, Loss: -3.0986533164978027, Losses: L1: -3.899679660797119, L2: 0.32081300020217896, L3: 0.022122859954833984, L4: 0.3109379708766937, L5: 0.0038411826826632023
Epoch 3500, Loss: -3.374084234237671, Losses: L1: -3.9937572479248047, L2: 0.3783439099788666, L3: 0.08928656578063965, L4: 0.18931838870048523, L5: 0.003610533894971013
Epoch 4000, Loss: -3.5574042797088623, Losses: L1: -3.9565534591674805, L2: 0.3602317273616791, L3: 0.02357316017150879, L4: 0.1000778004527092, L5: 0.0035455019678920507
Epoch 4500, Loss: -3.5894479751586914, Losses: L1: -3.9755685329437256, L2: 0.37266749143600464, L3: 0.03289055824279785, L4: 0.08808665722608566, L5: 0.0035840964410454035
Epoch 5000, Loss: -3.6125733852386475, Losses: L1: -3.9832382202148438, L2: 0.38013026118278503, L3: 0.02573871612548828, L4: 0.08027713000774384, L5: 0.0035880401264876127
Epoch 5500, Loss: -3.621568441390991, Losses: L1: -3.9738495349884033, L2: 0.37690111994743347, L3: 0.0057184696197509766, L4: 0.07690371572971344, L5: 0.0035820049233734608
Epoch 6000, Loss: -3.627040386199951, Losses: L1: -3.974886417388916, L2: 0.3774009644985199, L3: 0.00200653076171875, L4: 0.07548622786998749, L5: 0.003585014259442687
Epoch 6500, Loss: -3.630491018295288, Losses: L1: -3.977980136871338, L2: 0.37892407178878784, L3: 0.003182530403137207, L4: 0.0746316909790039, L5: 0.0035863234661519527
Epoch 7000, Loss: -3.633732557296753, Losses: L1: -3.9821536540985107, L2: 0.3823462426662445, L3: 0.00440669059753418, L4: 0.07392789423465729, L5: 0.003594479290768504
Epoch 7500, Loss: -3.6355643272399902, Losses: L1: -3.983065128326416, L2: 0.3832568824291229, L3: 0.0039016008377075195, L4: 0.07336579263210297, L5: 0.0035949954763054848
Epoch 8000, Loss: -3.6373255252838135, Losses: L1: -3.9813034534454346, L2: 0.3828141987323761, L3: 9.608268737792969e-05, L4: 0.0726681500673294, L5: 0.0035931915044784546
Epoch 8500, Loss: -3.6382455825805664, Losses: L1: -3.9821267127990723, L2: 0.3830792009830475, L3: 0.0006487369537353516, L4: 0.07241503894329071, L5: 0.0035935339983552694
Epoch 9000, Loss: -3.6389784812927246, Losses: L1: -3.9835119247436523, L2: 0.38413745164871216, L3: 0.0015317201614379883, L4: 0.07225397974252701, L5: 0.003595418529585004
Epoch 9500, Loss: -3.6395413875579834, Losses: L1: -3.9825236797332764, L2: 0.38342249393463135, L3: 0.0001366138458251953, L4: 0.07200658321380615, L5: 0.0035948778968304396
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0070061683654785, Constraint losses: L1: 8.03931999206543, L2: 0.00019860683823935688, L3: 0.9993838667869568, L4: 0.9993844032287598
Epoch 500, Loss: 0.0025521107017993927, Constraint losses: L1: -1.0668725967407227, L2: 0.0, L3: 0.00280839204788208, L4: 0.0008105911547318101
Epoch 1000, Loss: 0.0013993012253195047, Constraint losses: L1: -1.1180154085159302, L2: 0.0, L3: 0.00225830078125, L4: 0.00025901588378474116
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0186500549316406, Constraint losses: L1: 18.251277923583984, L2: 0.00022269217879511416, L3: 1.0000877380371094, L4: 1.0000883340835571
Epoch 500, Loss: 0.002517353044822812, Constraint losses: L1: -1.0992252826690674, L2: 0.0, L3: 0.0028072595596313477, L4: 0.0008093189098872244
Epoch 1000, Loss: 0.0014060495886951685, Constraint losses: L1: -1.1198030710220337, L2: 0.0, L3: 0.002262592315673828, L4: 0.0002632604446262121
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 58.9901123046875, Losses: L1: 18.23734474182129, L2: 0.0011046958388760686, L3: 1.0007965564727783, L4: 79.10000610351562, L5: 0.40283191204071045
Epoch 500, Loss: 5.81513786315918, Losses: L1: -2.2078070640563965, L2: 1.4051481485366821, L3: 0.2470635175704956, L4: 14.042036056518555, L5: 0.10457901656627655
Epoch 1000, Loss: -2.3255012035369873, Losses: L1: -3.5710031986236572, L2: 0.8629361391067505, L3: 0.09784311056137085, L4: 1.4218190908432007, L5: 0.010562255047261715
Epoch 1500, Loss: -2.9420177936553955, Losses: L1: -3.8982174396514893, L2: 0.6453229188919067, L3: 0.045953989028930664, L4: 1.1684178113937378, L5: 0.0067505743354558945
Epoch 2000, Loss: -3.25809383392334, Losses: L1: -4.076205253601074, L2: 0.8352714776992798, L3: 0.03155863285064697, L4: 0.728325366973877, L5: 0.009508715011179447
Epoch 2500, Loss: -0.7140152454376221, Losses: L1: -2.1494667530059814, L2: 0.7121391296386719, L3: 0.09440761804580688, L4: 1.9580636024475098, L5: 0.011885206215083599
Epoch 3000, Loss: -2.6718480587005615, Losses: L1: -3.299276113510132, L2: 0.45833122730255127, L3: 0.09034264087677002, L4: 0.6054866313934326, L5: 0.010352443903684616
Epoch 3500, Loss: -3.095637321472168, Losses: L1: -3.7129909992218018, L2: 0.5677438378334045, L3: 0.08042484521865845, L4: 0.4951174557209015, L5: 0.01099630817770958
Epoch 4000, Loss: -3.2612271308898926, Losses: L1: -3.8838813304901123, L2: 0.6355242729187012, L3: 0.0752178430557251, L4: 0.44867846369743347, L5: 0.010670018382370472
Epoch 4500, Loss: -3.3423211574554443, Losses: L1: -3.9583137035369873, L2: 0.6597275137901306, L3: 0.0700870156288147, L4: 0.4216788709163666, L5: 0.010404710657894611
Epoch 5000, Loss: -3.390683650970459, Losses: L1: -3.9941623210906982, L2: 0.6703692078590393, L3: 0.06061887741088867, L4: 0.4052424728870392, L5: 0.010107958689332008
Epoch 5500, Loss: -3.427802085876465, Losses: L1: -4.017843246459961, L2: 0.6774122714996338, L3: 0.05057835578918457, L4: 0.39147675037384033, L5: 0.010036913678050041
Epoch 6000, Loss: -3.455946922302246, Losses: L1: -4.04242467880249, L2: 0.6925449371337891, L3: 0.041022419929504395, L4: 0.38830432295799255, L5: 0.010061956942081451
Epoch 6500, Loss: -3.475823163986206, Losses: L1: -4.058259010314941, L2: 0.7018230557441711, L3: 0.03427577018737793, L4: 0.38450801372528076, L5: 0.009988552890717983
Epoch 7000, Loss: -3.4896154403686523, Losses: L1: -4.068394660949707, L2: 0.7095106840133667, L3: 0.028429031372070312, L4: 0.3812783658504486, L5: 0.009911099448800087
Epoch 7500, Loss: -3.5000417232513428, Losses: L1: -4.075010776519775, L2: 0.7130649089813232, L3: 0.02452218532562256, L4: 0.3780173659324646, L5: 0.009811153635382652
Epoch 8000, Loss: -3.5072238445281982, Losses: L1: -4.079139232635498, L2: 0.7140913605690002, L3: 0.022294461727142334, L4: 0.3754037618637085, L5: 0.00974651612341404
Epoch 8500, Loss: -3.512284994125366, Losses: L1: -4.081809043884277, L2: 0.7150503993034363, L3: 0.020213842391967773, L4: 0.373881071805954, L5: 0.009689117781817913
Epoch 9000, Loss: -3.515890598297119, Losses: L1: -4.083515644073486, L2: 0.7153391242027283, L3: 0.018720686435699463, L4: 0.37281596660614014, L5: 0.009653501212596893
Epoch 9500, Loss: -3.518383502960205, Losses: L1: -4.084594249725342, L2: 0.7153827548027039, L3: 0.017638862133026123, L4: 0.3721340298652649, L5: 0.009626899845898151
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0256741046905518, Constraint losses: L1: 18.42068099975586, L2: 0.0024176687002182007, L3: 1.0024176836013794, L4: 1.002418041229248
Epoch 500, Loss: 0.0020689230877906084, Constraint losses: L1: -1.0573290586471558, L2: 0.0, L3: 0.002562224864959717, L4: 0.0005640273448079824
Epoch 1000, Loss: 0.001230690279044211, Constraint losses: L1: -1.1167659759521484, L2: 0.0, L3: 0.0021734237670898438, L4: 0.00017403249512426555
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.020841598510742, Constraint losses: L1: 18.42068099975586, L2: 0.0008069607429206371, L3: 1.0008069276809692, L4: 1.0008069276809692
Epoch 500, Loss: 0.0024491455405950546, Constraint losses: L1: -1.0993167161941528, L2: 0.0, L3: 0.002773284912109375, L4: 0.0007751774974167347
Epoch 1000, Loss: 0.0013851620024070144, Constraint losses: L1: -1.1196248531341553, L2: 0.0, L3: 0.002252042293548584, L4: 0.00025274461950175464
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.56903839111328, Losses: L1: 18.42068099975586, L2: 0.007258974947035313, L3: 1.0071195363998413, L4: 69.59723663330078, L5: 0.33898741006851196
Epoch 500, Loss: -0.42008933424949646, Losses: L1: -2.298306703567505, L2: 1.389858365058899, L3: 0.11605226993560791, L4: 2.112184762954712, L5: 0.011143584735691547
Epoch 1000, Loss: 4.997576713562012, Losses: L1: 0.8090673089027405, L2: 1.4495654106140137, L3: 0.13626432418823242, L4: 6.592825412750244, L5: 0.031049897894263268
Epoch 1500, Loss: -2.171586275100708, Losses: L1: -3.0825510025024414, L2: 0.5639217495918274, L3: 0.09365260601043701, L4: 1.0580214262008667, L5: 0.006340282037854195
Epoch 2000, Loss: -3.3234572410583496, Losses: L1: -4.078113555908203, L2: 0.6152092814445496, L3: 0.024984240531921387, L4: 0.8341781497001648, L5: 0.00497862184420228
Epoch 2500, Loss: -3.5595016479492188, Losses: L1: -4.087874412536621, L2: 0.5619825124740601, L3: 0.013769984245300293, L4: 0.4594871699810028, L5: 0.0038680201396346092
Epoch 3000, Loss: -3.6211395263671875, Losses: L1: -4.111525535583496, L2: 0.5634550452232361, L3: 0.006987094879150391, L4: 0.39616698026657104, L5: 0.003588075051084161
Epoch 3500, Loss: -3.685163736343384, Losses: L1: -4.080394744873047, L2: 0.5233529806137085, L3: 0.008367657661437988, L4: 0.2435123324394226, L5: 0.003430513199418783
Epoch 4000, Loss: -3.7424402236938477, Losses: L1: -4.154480934143066, L2: 0.6110610961914062, L3: 0.022217512130737305, L4: 0.16160890460014343, L5: 0.0034882384352385998
Epoch 4500, Loss: -3.7713963985443115, Losses: L1: -4.145135402679443, L2: 0.5924353003501892, L3: 0.0052220821380615234, L4: 0.13770568370819092, L5: 0.003446372225880623
Epoch 5000, Loss: -3.779430389404297, Losses: L1: -4.151407718658447, L2: 0.5981786251068115, L3: 0.0030918121337890625, L4: 0.13270333409309387, L5: 0.0034444998018443584
Epoch 5500, Loss: -3.7868716716766357, Losses: L1: -4.153041362762451, L2: 0.600151538848877, L3: 0.00044035911560058594, L4: 0.1244453564286232, L5: 0.0034307653550058603
Epoch 6000, Loss: -3.790290355682373, Losses: L1: -4.162487030029297, L2: 0.6105929613113403, L3: 0.002075672149658203, L4: 0.12277472019195557, L5: 0.0034372550435364246
Epoch 6500, Loss: -3.793626070022583, Losses: L1: -4.1653828620910645, L2: 0.6145539283752441, L3: 0.0007503032684326172, L4: 0.1205834299325943, L5: 0.003437739098444581
Epoch 7000, Loss: -3.795470714569092, Losses: L1: -4.167325496673584, L2: 0.6159752607345581, L3: 0.0006730556488037109, L4: 0.11951491236686707, L5: 0.0034365947358310223
Epoch 7500, Loss: -3.7964675426483154, Losses: L1: -4.169515609741211, L2: 0.6186044812202454, L3: 0.0010192394256591797, L4: 0.11857618391513824, L5: 0.003438408952206373
Epoch 8000, Loss: -3.7979013919830322, Losses: L1: -4.169553756713867, L2: 0.6187778115272522, L3: 1.1086463928222656e-05, L4: 0.1176319494843483, L5: 0.0034363619051873684
Epoch 8500, Loss: -3.79833984375, Losses: L1: -4.170586109161377, L2: 0.6198984384536743, L3: 0.0002040863037109375, L4: 0.11731132864952087, L5: 0.0034373756498098373
Epoch 9000, Loss: -3.798814535140991, Losses: L1: -4.170971870422363, L2: 0.6203040480613708, L3: 0.00011301040649414062, L4: 0.11691023409366608, L5: 0.0034371435176581144
Epoch 9500, Loss: -3.799144983291626, Losses: L1: -4.171170234680176, L2: 0.6204952001571655, L3: 3.0517578125e-05, L4: 0.1166204884648323, L5: 0.0034367521293461323
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0277950763702393, Constraint losses: L1: 18.42068099975586, L2: 0.0031247101724147797, L3: 1.003124713897705, L4: 1.0031249523162842
Epoch 500, Loss: 0.002104760380461812, Constraint losses: L1: -1.0939151048660278, L2: 0.0, L3: 0.002598583698272705, L4: 0.0006000918801873922
Epoch 1000, Loss: 0.0012630518758669496, Constraint losses: L1: -1.1177469491958618, L2: 0.0, L3: 0.002190113067626953, L4: 0.00019068583787884563
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9992432594299316, Constraint losses: L1: 5.742709159851074, L2: 0.0, L3: 0.9967501163482666, L4: 0.9967504143714905
Epoch 500, Loss: 0.002060956321656704, Constraint losses: L1: -1.107154369354248, L2: 0.0, L3: 0.0025832653045654297, L4: 0.0005848454311490059
Epoch 1000, Loss: 0.0012605012161657214, Constraint losses: L1: -1.1152762174606323, L2: 0.0, L3: 0.0021876096725463867, L4: 0.00018816783267538995
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.1280403137207, Losses: L1: 11.86572551727295, L2: 0.0007941891090013087, L3: 0.9996880292892456, L4: 76.98286437988281, L5: 0.38539886474609375
Epoch 500, Loss: 1.159624457359314, Losses: L1: -1.672794222831726, L2: 0.25943103432655334, L3: 0.07045149803161621, L4: 5.168862819671631, L5: 0.023910101503133774
Epoch 1000, Loss: -1.1727359294891357, Losses: L1: -3.507660150527954, L2: 0.6549306511878967, L3: 0.0517047643661499, L4: 3.8313920497894287, L5: 0.02002899907529354
Epoch 1500, Loss: -3.0295820236206055, Losses: L1: -4.017183780670166, L2: 0.6144834756851196, L3: 0.012821674346923828, L4: 1.305642008781433, L5: 0.007358717732131481
Epoch 2000, Loss: -2.6158487796783447, Losses: L1: -3.3020381927490234, L2: 0.5473787784576416, L3: 0.08239257335662842, L4: 0.6361151933670044, L5: 0.006024989299476147
Epoch 2500, Loss: -3.3946001529693604, Losses: L1: -4.130444526672363, L2: 0.7597330808639526, L3: 0.04126614332199097, L4: 0.6050125360488892, L5: 0.006102683488279581
Epoch 3000, Loss: -3.4908316135406494, Losses: L1: -4.052854537963867, L2: 0.5107540488243103, L3: 0.03377270698547363, L4: 0.5295689105987549, L5: 0.004044414963573217
Epoch 3500, Loss: -3.6095879077911377, Losses: L1: -4.073166370391846, L2: 0.5731123089790344, L3: 0.013106584548950195, L4: 0.3094851076602936, L5: 0.004586526192724705
Epoch 4000, Loss: -3.7560532093048096, Losses: L1: -4.134067535400391, L2: 0.5443313121795654, L3: 0.0015041828155517578, L4: 0.19113746285438538, L5: 0.004387912806123495
Epoch 4500, Loss: -3.7647461891174316, Losses: L1: -4.132765769958496, L2: 0.544276773929596, L3: 0.00862032175064087, L4: 0.15790396928787231, L5: 0.004154455382376909
Epoch 5000, Loss: -3.773808717727661, Losses: L1: -4.076225280761719, L2: 0.45679807662963867, L3: 0.0014162063598632812, L4: 0.1284487247467041, L5: 0.0041883825324475765
Epoch 5500, Loss: -3.7906923294067383, Losses: L1: -4.1386590003967285, L2: 0.5354628562927246, L3: 0.0003319978713989258, L4: 0.1425984799861908, L5: 0.0043019200675189495
Epoch 6000, Loss: -3.7932956218719482, Losses: L1: -4.149046421051025, L2: 0.5503582954406738, L3: 0.0010584592819213867, L4: 0.14173008501529694, L5: 0.004324033856391907
Epoch 6500, Loss: -3.7964272499084473, Losses: L1: -4.15274715423584, L2: 0.5547927021980286, L3: 0.00017523765563964844, L4: 0.1401217132806778, L5: 0.004343579523265362
Epoch 7000, Loss: -3.7972562313079834, Losses: L1: -4.154658794403076, L2: 0.5568321943283081, L3: 0.00047516822814941406, L4: 0.1396070420742035, L5: 0.004353830590844154
Epoch 7500, Loss: -3.7983477115631104, Losses: L1: -4.154730796813965, L2: 0.556825578212738, L3: 0.00020992755889892578, L4: 0.13812313973903656, L5: 0.004349416121840477
Epoch 8000, Loss: -3.798841714859009, Losses: L1: -4.154951572418213, L2: 0.5569031834602356, L3: 0.00021398067474365234, L4: 0.1374853253364563, L5: 0.004350770264863968
Epoch 8500, Loss: -3.7991905212402344, Losses: L1: -4.154960632324219, L2: 0.5568626523017883, L3: 0.00015294551849365234, L4: 0.1369798481464386, L5: 0.004347839392721653
Epoch 9000, Loss: -3.7995123863220215, Losses: L1: -4.154963970184326, L2: 0.5566713213920593, L3: 9.608268737792969e-05, L4: 0.1366444230079651, L5: 0.004348887596279383
Epoch 9500, Loss: -3.7997891902923584, Losses: L1: -4.154882907867432, L2: 0.5565464496612549, L3: 2.4557113647460938e-05, L4: 0.13620299100875854, L5: 0.004347360227257013
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020631790161133, Constraint losses: L1: 18.42068099975586, L2: 0.000736851361580193, L3: 1.0007368326187134, L4: 1.0007374286651611
Epoch 500, Loss: 0.0022368174977600574, Constraint losses: L1: -1.096643328666687, L2: 0.0, L3: 0.002665996551513672, L4: 0.0006674642208963633
Epoch 1000, Loss: 0.0013086296385154128, Constraint losses: L1: -1.1174367666244507, L2: 0.0, L3: 0.002212822437286377, L4: 0.0002132439985871315
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0238051414489746, Constraint losses: L1: 18.42068099975586, L2: 0.0017946527805179358, L3: 1.001794695854187, L4: 1.0017949342727661
Epoch 500, Loss: 0.0022434124257415533, Constraint losses: L1: -1.1107615232467651, L2: 0.0, L3: 0.002676248550415039, L4: 0.0006779254181310534
Epoch 1000, Loss: 0.001327830832451582, Constraint losses: L1: -1.1196374893188477, L2: 0.0, L3: 0.002223491668701172, L4: 0.00022397669090423733
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 80.11925506591797, Losses: L1: 8.356839179992676, L2: 2.6427176635479555e-05, L3: 0.9983677268028259, L4: 70.59458923339844, L5: 0.3388928174972534
Epoch 500, Loss: 54.286293029785156, Losses: L1: 3.5628390312194824, L2: 0.01377025991678238, L3: 0.9684818983078003, L4: 49.6629753112793, L5: 0.17022350430488586
Epoch 1000, Loss: 0.9893283247947693, Losses: L1: -2.3617146015167236, L2: 0.5850733518600464, L3: 0.1605743169784546, L4: 2.8914072513580322, L5: 0.013049212284386158
Epoch 1500, Loss: -1.0177046060562134, Losses: L1: -2.8192124366760254, L2: 0.43691927194595337, L3: 0.12809830904006958, L4: 1.4511524438858032, L5: 0.00759501988068223
Epoch 2000, Loss: -0.3572244346141815, Losses: L1: -3.0420072078704834, L2: 0.28850340843200684, L3: 0.12021833658218384, L4: 2.415851354598999, L5: 0.008923093788325787
Epoch 2500, Loss: -2.1049423217773438, Losses: L1: -3.442331314086914, L2: 0.5103322267532349, L3: 0.10304772853851318, L4: 0.9761794209480286, L5: 0.005991483107209206
Epoch 3000, Loss: -2.3916757106781006, Losses: L1: -3.742043972015381, L2: 0.7066569924354553, L3: 0.0956728458404541, L4: 0.8969252109527588, L5: 0.008883326314389706
Epoch 3500, Loss: -2.7151637077331543, Losses: L1: -3.865912675857544, L2: 0.7799869775772095, L3: 0.09102332592010498, L4: 0.6655632257461548, L5: 0.008337922394275665
Epoch 4000, Loss: -2.8149044513702393, Losses: L1: -3.9850194454193115, L2: 0.8812412023544312, L3: 0.08710479736328125, L4: 0.6378819942474365, L5: 0.00901509914547205
Epoch 4500, Loss: -2.8696601390838623, Losses: L1: -4.0521135330200195, L2: 0.9413658976554871, L3: 0.08313030004501343, L4: 0.6239300966262817, L5: 0.009420137852430344
Epoch 5000, Loss: -2.9089243412017822, Losses: L1: -4.092250347137451, L2: 0.9780303239822388, L3: 0.07960593700408936, L4: 0.6099373698234558, L5: 0.009534858167171478
Epoch 5500, Loss: -2.935971736907959, Losses: L1: -4.122199535369873, L2: 1.006921648979187, L3: 0.07673454284667969, L4: 0.6011515855789185, L5: 0.009761638939380646
Epoch 6000, Loss: -2.9537291526794434, Losses: L1: -4.141505241394043, L2: 1.0257145166397095, L3: 0.07507658004760742, L4: 0.5949456095695496, L5: 0.00979312602430582
Epoch 6500, Loss: -2.967700481414795, Losses: L1: -4.159006118774414, L2: 1.0437703132629395, L3: 0.07371699810028076, L4: 0.5907260775566101, L5: 0.009955033659934998
Epoch 7000, Loss: -2.9768457412719727, Losses: L1: -4.168786525726318, L2: 1.0537097454071045, L3: 0.07282960414886475, L4: 0.5872487425804138, L5: 0.010014353320002556
Epoch 7500, Loss: -2.9835402965545654, Losses: L1: -4.175784587860107, L2: 1.0609054565429688, L3: 0.07215380668640137, L4: 0.5846123695373535, L5: 0.010050567798316479
Epoch 8000, Loss: -2.987962484359741, Losses: L1: -4.180395126342773, L2: 1.065673589706421, L3: 0.07164740562438965, L4: 0.5829103589057922, L5: 0.010076185688376427
Epoch 8500, Loss: -2.9915006160736084, Losses: L1: -4.184181213378906, L2: 1.0698679685592651, L3: 0.07125222682952881, L4: 0.5814328193664551, L5: 0.010122997686266899
Epoch 9000, Loss: -2.9938061237335205, Losses: L1: -4.186765670776367, L2: 1.0728209018707275, L3: 0.07098817825317383, L4: 0.580485999584198, L5: 0.01015008706599474
Epoch 9500, Loss: -2.9954135417938232, Losses: L1: -4.188545227050781, L2: 1.0748752355575562, L3: 0.07080024480819702, L4: 0.579808235168457, L5: 0.0101711330935359
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0016891956329346, Constraint losses: L1: 6.112243175506592, L2: 0.0, L3: 0.9977884888648987, L4: 0.9977884888648987
Epoch 500, Loss: 0.0022416720166802406, Constraint losses: L1: -1.059875249862671, L2: 0.0, L3: 0.0026497244834899902, L4: 0.00065182289108634
Epoch 1000, Loss: 0.0012799339601770043, Constraint losses: L1: -1.1181548833847046, L2: 0.0, L3: 0.0021986961364746094, L4: 0.00019939281628467143
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0020155906677246, Constraint losses: L1: 6.201721668243408, L2: 0.0, L3: 0.9979068636894226, L4: 0.9979070425033569
Epoch 500, Loss: 0.0020537558011710644, Constraint losses: L1: -1.0895836353302002, L2: 0.0, L3: 0.0025707483291625977, L4: 0.0005725912633351982
Epoch 1000, Loss: 0.0012448988854885101, Constraint losses: L1: -1.116905927658081, L2: 0.0, L3: 0.002180635929107666, L4: 0.00018116884166374803
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 82.10277557373047, Losses: L1: 15.291851997375488, L2: 0.00340159609913826, L3: 1.0030255317687988, L4: 65.51481628417969, L5: 0.29137951135635376
Epoch 500, Loss: 15.721904754638672, Losses: L1: 4.678540229797363, L2: 2.1760241985321045, L3: 0.08405351638793945, L4: 9.806768417358398, L5: 0.06453070789575577
Epoch 1000, Loss: 7.33451509475708, Losses: L1: 2.1516709327697754, L2: 2.2082200050354004, L3: 0.05056124925613403, L4: 4.0007734298706055, L5: 0.027399728074669838
Epoch 1500, Loss: 0.1424228996038437, Losses: L1: -3.5821051597595215, L2: 0.6047741174697876, L3: 0.07263350486755371, L4: 3.32755708694458, L5: 0.02195047400891781
Epoch 2000, Loss: -2.853893518447876, Losses: L1: -3.874525547027588, L2: 0.4301564395427704, L3: 0.01277303695678711, L4: 0.7866504192352295, L5: 0.006130559835582972
Epoch 2500, Loss: -3.2565643787384033, Losses: L1: -3.9619147777557373, L2: 0.46828821301460266, L3: 0.029707908630371094, L4: 0.4339786171913147, L5: 0.007519717328250408
Epoch 3000, Loss: -3.2840301990509033, Losses: L1: -4.034780025482178, L2: 0.6256049871444702, L3: 0.037923216819763184, L4: 0.39251890778541565, L5: 0.007505278568714857
Epoch 3500, Loss: -3.546006202697754, Losses: L1: -4.130451202392578, L2: 0.6549782752990723, L3: 0.04219174385070801, L4: 0.20607206225395203, L5: 0.00869202520698309
Epoch 4000, Loss: -3.6261794567108154, Losses: L1: -4.162309646606445, L2: 0.7231519222259521, L3: 0.013527154922485352, L4: 0.15246225893497467, L5: 0.008564666844904423
Epoch 4500, Loss: -3.647982597351074, Losses: L1: -4.1662068367004395, L2: 0.7293127179145813, L3: 0.002140045166015625, L4: 0.1429262012243271, L5: 0.008501569740474224
Epoch 5000, Loss: -3.655424118041992, Losses: L1: -4.170629501342773, L2: 0.7308801412582397, L3: 0.000639796257019043, L4: 0.1405373513698578, L5: 0.008588213473558426
Epoch 5500, Loss: -3.665592908859253, Losses: L1: -4.189178466796875, L2: 0.7422152757644653, L3: 0.009001970291137695, L4: 0.13487675786018372, L5: 0.008599312976002693
Epoch 6000, Loss: -3.6719655990600586, Losses: L1: -4.191642761230469, L2: 0.7473084926605225, L3: 0.00299072265625, L4: 0.13438460230827332, L5: 0.008647436276078224
Epoch 6500, Loss: -3.6775777339935303, Losses: L1: -4.195468425750732, L2: 0.7496076226234436, L3: 0.0026090145111083984, L4: 0.1318388283252716, L5: 0.00863899476826191
Epoch 7000, Loss: -3.6818013191223145, Losses: L1: -4.19605016708374, L2: 0.7506508827209473, L3: 0.0001404285430908203, L4: 0.13017576932907104, L5: 0.008607114665210247
Epoch 7500, Loss: -3.6834144592285156, Losses: L1: -4.198841094970703, L2: 0.7512856721878052, L3: 0.0014625787734985352, L4: 0.12970148026943207, L5: 0.008620054461061954
Epoch 8000, Loss: -3.6852855682373047, Losses: L1: -4.1988115310668945, L2: 0.7506605982780457, L3: 0.000583648681640625, L4: 0.1289849877357483, L5: 0.008627248927950859
Epoch 8500, Loss: -3.6863248348236084, Losses: L1: -4.199334144592285, L2: 0.7505817413330078, L3: 0.0004088878631591797, L4: 0.1286764293909073, L5: 0.008633129298686981
Epoch 9000, Loss: -3.6871144771575928, Losses: L1: -4.199164390563965, L2: 0.7501099705696106, L3: 3.361701965332031e-05, L4: 0.12833155691623688, L5: 0.008629471063613892
Epoch 9500, Loss: -3.687635898590088, Losses: L1: -4.199564456939697, L2: 0.7501276731491089, L3: 5.984306335449219e-05, L4: 0.12817135453224182, L5: 0.008633369579911232
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.018111228942871, Constraint losses: L1: 17.474088668823242, L2: 0.00032893437310121953, L3: 1.00015389919281, L4: 1.0001541376113892
Epoch 500, Loss: 0.0019417329458519816, Constraint losses: L1: -1.0944952964782715, L2: 0.0, L3: 0.002517402172088623, L4: 0.0005188260693103075
Epoch 1000, Loss: 0.0012066959170624614, Constraint losses: L1: -1.1179412603378296, L2: 0.0, L3: 0.0021620988845825195, L4: 0.00016253840294666588
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.000203847885132, Constraint losses: L1: 5.877252578735352, L2: 0.0, L3: 0.9971633553504944, L4: 0.9971632957458496
Epoch 500, Loss: 0.002285514259710908, Constraint losses: L1: -1.0405298471450806, L2: 0.0, L3: 0.0026619434356689453, L4: 0.0006641008076258004
Epoch 1000, Loss: 0.0012885137693956494, Constraint losses: L1: -1.1189213991165161, L2: 0.0, L3: 0.0022034645080566406, L4: 0.0002039707324001938
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.03680419921875, Losses: L1: 7.527595043182373, L2: 1.543862344988156e-05, L3: 0.9964727759361267, L4: 77.72512817382812, L5: 0.3937997817993164
Epoch 500, Loss: -1.1127368211746216, Losses: L1: -3.3015079498291016, L2: 1.1518545150756836, L3: 0.08364474773406982, L4: 1.5142087936401367, L5: 0.007495084311813116
Epoch 1000, Loss: -0.5151115655899048, Losses: L1: -2.8600058555603027, L2: 0.7371838688850403, L3: 0.07216787338256836, L4: 1.887189507484436, L5: 0.008472448214888573
Epoch 1500, Loss: -2.4415905475616455, Losses: L1: -3.9130358695983887, L2: 0.3484671413898468, L3: 0.0075800418853759766, L4: 1.277531623840332, L5: 0.006049958989024162
Epoch 2000, Loss: -3.26568341255188, Losses: L1: -3.7323825359344482, L2: 0.3551226556301117, L3: 0.027149617671966553, L4: 0.2543860077857971, L5: 0.003801166545599699
Epoch 2500, Loss: -3.1701455116271973, Losses: L1: -4.018062114715576, L2: 0.8333879709243774, L3: 0.027493000030517578, L4: 0.3944542706012726, L5: 0.004637737758457661
Epoch 3000, Loss: -3.518925189971924, Losses: L1: -4.00993537902832, L2: 0.4158687889575958, L3: 0.0031048059463500977, L4: 0.27146464586257935, L5: 0.004253302700817585
Epoch 3500, Loss: -3.663308620452881, Losses: L1: -4.018085479736328, L2: 0.4279288053512573, L3: 0.012678027153015137, L4: 0.12048117071390152, L5: 0.0038264510221779346
Epoch 4000, Loss: -3.6955690383911133, Losses: L1: -4.06046199798584, L2: 0.4600307047367096, L3: 0.006940007209777832, L4: 0.12003689259290695, L5: 0.00395050086081028
Epoch 4500, Loss: -3.6442248821258545, Losses: L1: -4.0800018310546875, L2: 0.4721119999885559, L3: 0.02387988567352295, L4: 0.16750657558441162, L5: 0.004167256876826286
Epoch 5000, Loss: -3.6803009510040283, Losses: L1: -4.077260494232178, L2: 0.46371376514434814, L3: 0.020264148712158203, L4: 0.13659286499023438, L5: 0.00412289472296834
Epoch 5500, Loss: -3.739213228225708, Losses: L1: -4.080247402191162, L2: 0.48165392875671387, L3: 0.003124237060546875, L4: 0.08898497372865677, L5: 0.004048940725624561
Epoch 6000, Loss: -3.7396085262298584, Losses: L1: -4.0847649574279785, L2: 0.48473480343818665, L3: 0.007101655006408691, L4: 0.08758467435836792, L5: 0.004051243886351585
Epoch 6500, Loss: -3.7421302795410156, Losses: L1: -4.085019111633301, L2: 0.4860824644565582, L3: 0.004132986068725586, L4: 0.08759275823831558, L5: 0.004060902167111635
Epoch 7000, Loss: -3.7451391220092773, Losses: L1: -4.083569526672363, L2: 0.4847453534603119, L3: 0.002100706100463867, L4: 0.08585532754659653, L5: 0.004050903022289276
Epoch 7500, Loss: -3.746490955352783, Losses: L1: -4.083212852478027, L2: 0.4842039942741394, L3: 0.001416921615600586, L4: 0.08510874211788177, L5: 0.004047192633152008
Epoch 8000, Loss: -3.7475080490112305, Losses: L1: -4.082920551300049, L2: 0.48422059416770935, L3: 0.00038743019104003906, L4: 0.08482067286968231, L5: 0.004047065507620573
Epoch 8500, Loss: -3.747920036315918, Losses: L1: -4.082710266113281, L2: 0.48389285802841187, L3: 2.6941299438476562e-05, L4: 0.0847187265753746, L5: 0.004049041774123907
Epoch 9000, Loss: -3.7481820583343506, Losses: L1: -4.0828752517700195, L2: 0.48408520221710205, L3: 3.600120544433594e-05, L4: 0.0845198929309845, L5: 0.004047384485602379
Epoch 9500, Loss: -3.74833083152771, Losses: L1: -4.082930088043213, L2: 0.4839867055416107, L3: 4.565715789794922e-05, L4: 0.08446606248617172, L5: 0.004047033376991749
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.024322986602783, Constraint losses: L1: 18.42068099975586, L2: 0.0019674859941005707, L3: 1.001967430114746, L4: 1.001967430114746
Epoch 500, Loss: 0.0024364874698221684, Constraint losses: L1: -1.0984776020050049, L2: 0.0, L3: 0.002766549587249756, L4: 0.0007684153970330954
Epoch 1000, Loss: 0.0013868112582713366, Constraint losses: L1: -1.117782473564148, L2: 0.0, L3: 0.002252042293548584, L4: 0.0002525515155866742
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005469799041748, Constraint losses: L1: 7.083301067352295, L2: 0.0, L3: 0.9991932511329651, L4: 0.9991930723190308
Epoch 500, Loss: 0.002072317758575082, Constraint losses: L1: -1.0286390781402588, L2: 0.0, L3: 0.0025496482849121094, L4: 0.0005513085634447634
Epoch 1000, Loss: 0.0012104110792279243, Constraint losses: L1: -1.1185059547424316, L2: 0.0, L3: 0.0021642446517944336, L4: 0.00016467238310724497
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.9765167236328, Losses: L1: 14.275588035583496, L2: 0.0005751642747782171, L3: 1.0004055500030518, L4: 76.25479125976562, L5: 0.38131076097488403
Epoch 500, Loss: 2.179511070251465, Losses: L1: -2.58512544631958, L2: 0.6834276914596558, L3: 0.06947457790374756, L4: 2.1728625297546387, L5: 0.015445809811353683
Epoch 1000, Loss: -0.6778936982154846, Losses: L1: -3.5685479640960693, L2: 0.4929050803184509, L3: 0.05549943447113037, L4: 1.2918585538864136, L5: 0.009970097802579403
Epoch 1500, Loss: -0.579537034034729, Losses: L1: -3.7955706119537354, L2: 1.355518102645874, L3: 0.08534300327301025, L4: 1.224434733390808, L5: 0.008124629966914654
Epoch 2000, Loss: -2.2919533252716064, Losses: L1: -3.6815695762634277, L2: 0.3115311563014984, L3: 0.09327638149261475, L4: 0.5694013833999634, L5: 0.0035431368742138147
Epoch 2500, Loss: -3.0845065116882324, Losses: L1: -4.0009870529174805, L2: 0.42419689893722534, L3: 0.038629889488220215, L4: 0.33180689811706543, L5: 0.004277242347598076
Epoch 3000, Loss: -3.0755035877227783, Losses: L1: -4.083446979522705, L2: 0.5316974520683289, L3: 0.0514751672744751, L4: 0.3439117968082428, L5: 0.00559244817122817
Epoch 3500, Loss: -2.3912575244903564, Losses: L1: -3.5344927310943604, L2: 0.6188048124313354, L3: 0.08945685625076294, L4: 0.37057214975357056, L5: 0.006463673431426287
Epoch 4000, Loss: -3.5778026580810547, Losses: L1: -4.067855358123779, L2: 0.5137024521827698, L3: 0.002170085906982422, L4: 0.11432412266731262, L5: 0.004766599275171757
Epoch 4500, Loss: -3.5941083431243896, Losses: L1: -4.09023904800415, L2: 0.5414274334907532, L3: 0.008458614349365234, L4: 0.10728335380554199, L5: 0.004783289041370153
Epoch 5000, Loss: -3.596735954284668, Losses: L1: -4.095608234405518, L2: 0.5491744875907898, L3: 0.005822896957397461, L4: 0.10801947116851807, L5: 0.004846526309847832
Epoch 5500, Loss: -3.614532470703125, Losses: L1: -4.0969953536987305, L2: 0.554418683052063, L3: 0.000554203987121582, L4: 0.10114691406488419, L5: 0.004811394494026899
Epoch 6000, Loss: -3.6195855140686035, Losses: L1: -4.101395606994629, L2: 0.5582860112190247, L3: 0.0024476051330566406, L4: 0.09889911115169525, L5: 0.004842087626457214
Epoch 6500, Loss: -3.6232545375823975, Losses: L1: -4.10333776473999, L2: 0.5613623261451721, L3: 0.0008721351623535156, L4: 0.09804902225732803, L5: 0.004863903857767582
Epoch 7000, Loss: -3.6255123615264893, Losses: L1: -4.104621410369873, L2: 0.5629921555519104, L3: 0.00034487247467041016, L4: 0.09741644561290741, L5: 0.004870789125561714
Epoch 7500, Loss: -3.626659631729126, Losses: L1: -4.106295585632324, L2: 0.5647675395011902, L3: 0.0007698535919189453, L4: 0.09702282398939133, L5: 0.004873971920460463
Epoch 8000, Loss: -3.6271438598632812, Losses: L1: -4.107695579528809, L2: 0.5659708380699158, L3: 0.0013428926467895508, L4: 0.0968882218003273, L5: 0.004893656354397535
Epoch 8500, Loss: -3.6287877559661865, Losses: L1: -4.107017993927002, L2: 0.5658803582191467, L3: 0.0003007054328918457, L4: 0.0962715893983841, L5: 0.004892515484243631
Epoch 9000, Loss: -3.629472494125366, Losses: L1: -4.10801887512207, L2: 0.5666794180870056, L3: 0.00044417381286621094, L4: 0.09615743905305862, L5: 0.004895256832242012
Epoch 9500, Loss: -3.6299521923065186, Losses: L1: -4.1081647872924805, L2: 0.5668560266494751, L3: 0.00036907196044921875, L4: 0.09598372876644135, L5: 0.004896180704236031
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0212628841400146, Constraint losses: L1: 18.42068099975586, L2: 0.0009473697282373905, L3: 1.00094735622406, L4: 1.0009474754333496
Epoch 500, Loss: 0.002289239317178726, Constraint losses: L1: -1.078329086303711, L2: 0.0, L3: 0.002682805061340332, L4: 0.0006847634795121849
Epoch 1000, Loss: 0.0013150868471711874, Constraint losses: L1: -1.117043375968933, L2: 0.0, L3: 0.0022158026695251465, L4: 0.00021632754942402244
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0201539993286133, Constraint losses: L1: 18.42068099975586, L2: 0.0006006463663652539, L3: 1.0005662441253662, L4: 1.0005664825439453
Epoch 500, Loss: 0.0023267106153070927, Constraint losses: L1: -1.0904638767242432, L2: 0.0, L3: 0.0027076005935668945, L4: 0.0007095739711076021
Epoch 1000, Loss: 0.0013332406524568796, Constraint losses: L1: -1.1194690465927124, L2: 0.0, L3: 0.0022260546684265137, L4: 0.00022665498545393348
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 152.93963623046875, Losses: L1: 7.550405502319336, L2: 0.00012197226169519126, L3: 0.999480664730072, L4: 72.01980590820312, L5: 0.3500787913799286
Epoch 500, Loss: 0.9838784337043762, Losses: L1: -2.935938596725464, L2: 1.157628059387207, L3: 0.11090528964996338, L4: 1.609650731086731, L5: 0.010796116665005684
Epoch 1000, Loss: -1.23935067653656, Losses: L1: -3.1913092136383057, L2: 0.9838324189186096, L3: 0.06501728296279907, L4: 0.6946836709976196, L5: 0.005657736212015152
Epoch 1500, Loss: -1.7062016725540161, Losses: L1: -3.773256540298462, L2: 1.2154390811920166, L3: 0.05987119674682617, L4: 0.694195568561554, L5: 0.011072838678956032
Epoch 2000, Loss: -2.7460949420928955, Losses: L1: -4.035862922668457, L2: 1.2818386554718018, L3: 0.04807305335998535, L4: 0.2945164740085602, L5: 0.0117427883669734
Epoch 2500, Loss: -2.9964449405670166, Losses: L1: -4.1372551918029785, L2: 1.174522876739502, L3: 0.035254478454589844, L4: 0.252827525138855, L5: 0.012639237567782402
Epoch 3000, Loss: -3.2760074138641357, Losses: L1: -4.200803279876709, L2: 1.1334338188171387, L3: 0.014385342597961426, L4: 0.16594229638576508, L5: 0.011808906681835651
Epoch 3500, Loss: -3.413928747177124, Losses: L1: -4.222668170928955, L2: 1.04308021068573, L3: 2.2172927856445312e-05, L4: 0.1376183182001114, L5: 0.011940370313823223
Epoch 4000, Loss: -3.419945001602173, Losses: L1: -4.196529865264893, L2: 0.9259532690048218, L3: 0.0015201568603515625, L4: 0.15009282529354095, L5: 0.011902391910552979
Epoch 4500, Loss: -3.5278775691986084, Losses: L1: -4.169471740722656, L2: 0.8489473462104797, L3: 0.0011227130889892578, L4: 0.10235155373811722, L5: 0.011294649913907051
Epoch 5000, Loss: -3.549870014190674, Losses: L1: -4.164341449737549, L2: 0.8174530863761902, L3: 0.0014564990997314453, L4: 0.09650389850139618, L5: 0.011280781589448452
Epoch 5500, Loss: -3.5657765865325928, Losses: L1: -4.160087585449219, L2: 0.7985475659370422, L3: 0.001659393310546875, L4: 0.09109913557767868, L5: 0.011179514229297638
Epoch 6000, Loss: -3.5747368335723877, Losses: L1: -4.1620564460754395, L2: 0.7913987040519714, L3: 0.0028235912322998047, L4: 0.08883118629455566, L5: 0.011134350672364235
Epoch 6500, Loss: -3.5815250873565674, Losses: L1: -4.165359020233154, L2: 0.7888233065605164, L3: 0.003994464874267578, L4: 0.08713697642087936, L5: 0.01115393452346325
Epoch 7000, Loss: -3.586151361465454, Losses: L1: -4.166755676269531, L2: 0.7863566279411316, L3: 0.004564762115478516, L4: 0.08585498481988907, L5: 0.011151347309350967
Epoch 7500, Loss: -3.5893828868865967, Losses: L1: -4.167498588562012, L2: 0.7842279076576233, L3: 0.0049054622650146484, L4: 0.0849773958325386, L5: 0.011141540482640266
Epoch 8000, Loss: -3.5916926860809326, Losses: L1: -4.168659687042236, L2: 0.7837402820587158, L3: 0.005239725112915039, L4: 0.08435960114002228, L5: 0.011138075031340122
Epoch 8500, Loss: -3.593181610107422, Losses: L1: -4.169548988342285, L2: 0.78355473279953, L3: 0.005447864532470703, L4: 0.08400295674800873, L5: 0.011136213317513466
Epoch 9000, Loss: -3.5942306518554688, Losses: L1: -4.170068264007568, L2: 0.7833701372146606, L3: 0.005575060844421387, L4: 0.08372345566749573, L5: 0.011130542494356632
Epoch 9500, Loss: -3.5949225425720215, Losses: L1: -4.170365333557129, L2: 0.7831892371177673, L3: 0.005633950233459473, L4: 0.08354204893112183, L5: 0.011129914782941341
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.007228374481201, Constraint losses: L1: 7.9719038009643555, L2: 0.0, L3: 0.9996281862258911, L4: 0.9996282458305359
Epoch 500, Loss: 0.002424540463835001, Constraint losses: L1: -1.1067314147949219, L2: 0.0, L3: 0.0027647018432617188, L4: 0.0007665702141821384
Epoch 1000, Loss: 0.0013861970510333776, Constraint losses: L1: -1.1182737350463867, L2: 0.0, L3: 0.002251863479614258, L4: 0.00025260745314881206
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9797627925872803, Constraint losses: L1: 4.323690414428711, L2: 0.0, L3: 0.9877213835716248, L4: 0.9877176880836487
Epoch 500, Loss: 0.002093474380671978, Constraint losses: L1: -1.0890696048736572, L2: 0.0, L3: 0.0025904178619384766, L4: 0.000592126278206706
Epoch 1000, Loss: 0.0012559161987155676, Constraint losses: L1: -1.1197099685668945, L2: 0.0, L3: 0.0021875500679016113, L4: 0.00018807611195370555
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 171.41952514648438, Losses: L1: 9.348203659057617, L2: 0.00013697285612579435, L3: 0.9973025321960449, L4: 80.12470245361328, L5: 0.41227060556411743
Epoch 500, Loss: 2.070448637008667, Losses: L1: -2.3321707248687744, L2: 0.41203510761260986, L3: 0.06354057788848877, L4: 2.057762861251831, L5: 0.008767690509557724
Epoch 1000, Loss: -0.5241943001747131, Losses: L1: -3.585273027420044, L2: 0.4401395916938782, L3: 0.054051876068115234, L4: 1.3847763538360596, L5: 0.008702115155756474
Epoch 1500, Loss: -2.1598548889160156, Losses: L1: -3.6492726802825928, L2: 0.4850332736968994, L3: 0.08229565620422363, L4: 0.5788376331329346, L5: 0.0034650699235498905
Epoch 2000, Loss: 113.99614715576172, Losses: L1: 12.655817985534668, L2: 1.4304679041288182e-07, L3: 0.9999968409538269, L4: 49.99995422363281, L5: 0.17021127045154572
Epoch 2500, Loss: 103.11589813232422, Losses: L1: 2.1778600215911865, L2: 0.010788622312247753, L3: 0.9981924295425415, L4: 49.7979850769043, L5: 0.16924037039279938
Epoch 3000, Loss: 6.481348514556885, Losses: L1: -1.8024115562438965, L2: 0.879073441028595, L3: 0.22889316082000732, L4: 3.793644666671753, L5: 0.014020409435033798
Epoch 3500, Loss: 2.2224180698394775, Losses: L1: -1.7655198574066162, L2: 0.3250100910663605, L3: 0.18250542879104614, L4: 1.8126808404922485, L5: 0.008782812394201756
Epoch 4000, Loss: 0.8966159820556641, Losses: L1: -1.8851829767227173, L2: 0.22413849830627441, L3: 0.1586829423904419, L4: 1.2470775842666626, L5: 0.008445789106190205
Epoch 4500, Loss: 0.4573187530040741, Losses: L1: -1.9417005777359009, L2: 0.2223392277956009, L3: 0.1460942029953003, L4: 1.0628299713134766, L5: 0.008047808893024921
Epoch 5000, Loss: 0.22708623111248016, Losses: L1: -2.0113279819488525, L2: 0.2403312474489212, L3: 0.13840115070343018, L4: 0.982193648815155, L5: 0.00773009005934
Epoch 5500, Loss: 0.07635762542486191, Losses: L1: -2.0713984966278076, L2: 0.2538006901741028, L3: 0.13443481922149658, L4: 0.9357082843780518, L5: 0.007502208463847637
Epoch 6000, Loss: -0.024288397282361984, Losses: L1: -2.114290475845337, L2: 0.2658877670764923, L3: 0.13067162036895752, L4: 0.9059868454933167, L5: 0.007206449750810862
Epoch 6500, Loss: -0.09685636311769485, Losses: L1: -2.1436049938201904, L2: 0.2725478410720825, L3: 0.1283818483352661, L4: 0.8839275240898132, L5: 0.007118936628103256
Epoch 7000, Loss: -0.1500966101884842, Losses: L1: -2.1661298274993896, L2: 0.27892881631851196, L3: 0.12662994861602783, L4: 0.8679181337356567, L5: 0.007051313761621714
Epoch 7500, Loss: -0.18747499585151672, Losses: L1: -2.1839804649353027, L2: 0.2846391499042511, L3: 0.12537318468093872, L4: 0.857458233833313, L5: 0.0069481017999351025
Epoch 8000, Loss: -0.2140868455171585, Losses: L1: -2.195546865463257, L2: 0.28785330057144165, L3: 0.12460857629776001, L4: 0.8495840430259705, L5: 0.006878395564854145
Epoch 8500, Loss: -0.23302291333675385, Losses: L1: -2.203627109527588, L2: 0.2901546359062195, L3: 0.12401044368743896, L4: 0.8439198136329651, L5: 0.0068384506739676
Epoch 9000, Loss: -0.2464412897825241, Losses: L1: -2.2090229988098145, L2: 0.2915022373199463, L3: 0.12361288070678711, L4: 0.8397916555404663, L5: 0.006817258894443512
Epoch 9500, Loss: -0.25590530037879944, Losses: L1: -2.212480068206787, L2: 0.2920664846897125, L3: 0.12336909770965576, L4: 0.8367812633514404, L5: 0.006804925389587879
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.018409252166748, Constraint losses: L1: 17.765945434570312, L2: 0.000287068251054734, L3: 1.0001780986785889, L4: 1.0001780986785889
Epoch 500, Loss: 0.0021118163131177425, Constraint losses: L1: -1.0801024436950684, L2: 0.0, L3: 0.002595186233520508, L4: 0.0005967325414530933
Epoch 1000, Loss: 0.0012511940440163016, Constraint losses: L1: -1.1175488233566284, L2: 0.0, L3: 0.002184152603149414, L4: 0.00018459034617990255
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022270679473877, Constraint losses: L1: 18.42068099975586, L2: 0.0012832467909902334, L3: 1.0012832880020142, L4: 1.0012834072113037
Epoch 500, Loss: 0.002270369790494442, Constraint losses: L1: -1.107043981552124, L2: 0.0, L3: 0.002687811851501465, L4: 0.0006896021077409387
Epoch 1000, Loss: 0.0013293186202645302, Constraint losses: L1: -1.1186623573303223, L2: 0.0, L3: 0.0022237300872802734, L4: 0.00022425095085054636
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 52.019775390625, Losses: L1: 15.042401313781738, L2: 0.005108205135911703, L3: 1.004774570465088, L4: 69.59784698486328, L5: 0.3326932489871979
Epoch 500, Loss: -0.46568435430526733, Losses: L1: -3.0045900344848633, L2: 1.2871503829956055, L3: 0.10431313514709473, L4: 3.352752685546875, L5: 0.02065572701394558
Epoch 1000, Loss: 9.147989273071289, Losses: L1: 4.927894592285156, L2: 1.7495057582855225, L3: 0.05000424385070801, L4: 6.4564104080200195, L5: 0.03425629064440727
Epoch 1500, Loss: 2.457559585571289, Losses: L1: -3.8864755630493164, L2: 3.237495183944702, L3: 0.2605397701263428, L4: 8.368134498596191, L5: 0.04028119519352913
Epoch 2000, Loss: -2.6044909954071045, Losses: L1: -3.619147777557373, L2: 0.8769032955169678, L3: 0.08396214246749878, L4: 0.8064593076705933, L5: 0.01010200846940279
Epoch 2500, Loss: -2.683833599090576, Losses: L1: -4.039618492126465, L2: 1.0475107431411743, L3: 0.07014548778533936, L4: 1.36838960647583, L5: 0.01508775632828474
Epoch 3000, Loss: -3.2972445487976074, Losses: L1: -4.1738739013671875, L2: 1.0441083908081055, L3: 0.04725521802902222, L4: 0.5086953639984131, L5: 0.011433817446231842
Epoch 3500, Loss: -3.499838352203369, Losses: L1: -4.328300952911377, L2: 1.1796163320541382, L3: 0.001131892204284668, L4: 0.4609077572822571, L5: 0.01187338400632143
Epoch 4000, Loss: -3.502652645111084, Losses: L1: -4.344383239746094, L2: 1.1671262979507446, L3: 0.006861090660095215, L4: 0.4768206477165222, L5: 0.012070231139659882
Epoch 4500, Loss: -3.5396132469177246, Losses: L1: -4.317307472229004, L2: 1.1066588163375854, L3: 0.0021584033966064453, L4: 0.4289216697216034, L5: 0.011174434795975685
Epoch 5000, Loss: -3.5479400157928467, Losses: L1: -4.310741424560547, L2: 1.0855940580368042, L3: 0.0013775825500488281, L4: 0.4235306978225708, L5: 0.010967913083732128
Epoch 5500, Loss: -3.5500943660736084, Losses: L1: -4.304839134216309, L2: 1.0723598003387451, L3: 0.0014737248420715332, L4: 0.4204867482185364, L5: 0.010747750289738178
Epoch 6000, Loss: -3.5559771060943604, Losses: L1: -4.309251308441162, L2: 1.0740541219711304, L3: 0.0008804798126220703, L4: 0.41814160346984863, L5: 0.01083044707775116
Epoch 6500, Loss: -3.558216094970703, Losses: L1: -4.302663803100586, L2: 1.0623575448989868, L3: 0.0005453824996948242, L4: 0.4137366712093353, L5: 0.010619552806019783
Epoch 7000, Loss: -3.5612361431121826, Losses: L1: -4.30405330657959, L2: 1.0624816417694092, L3: 0.0003020763397216797, L4: 0.4113014042377472, L5: 0.010642553679645061
Epoch 7500, Loss: -3.5621962547302246, Losses: L1: -4.302879333496094, L2: 1.0595470666885376, L3: 0.0002567768096923828, L4: 0.4101868271827698, L5: 0.010605402290821075
Epoch 8000, Loss: -3.562739849090576, Losses: L1: -4.302215099334717, L2: 1.0579184293746948, L3: 0.0002808570861816406, L4: 0.409309983253479, L5: 0.010598823428153992
Epoch 8500, Loss: -3.5636093616485596, Losses: L1: -4.301513671875, L2: 1.0565769672393799, L3: 5.257129669189453e-05, L4: 0.4084434509277344, L5: 0.010578136891126633
Epoch 9000, Loss: -3.5638158321380615, Losses: L1: -4.301446914672852, L2: 1.0561810731887817, L3: 9.751319885253906e-05, L4: 0.40811672806739807, L5: 0.010574523359537125
Epoch 9500, Loss: -3.564091444015503, Losses: L1: -4.30108118057251, L2: 1.055533766746521, L3: 1.3232231140136719e-05, L4: 0.40782880783081055, L5: 0.010563944466412067
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0277485847473145, Constraint losses: L1: 18.42068099975586, L2: 0.003109247889369726, L3: 1.0031092166900635, L4: 1.0031094551086426
Epoch 500, Loss: 0.002114923670887947, Constraint losses: L1: -1.0240504741668701, L2: 0.0, L3: 0.002568662166595459, L4: 0.0005703120259568095
Epoch 1000, Loss: 0.0012142491759732366, Constraint losses: L1: -1.1166977882385254, L2: 0.0, L3: 0.0021652579307556152, L4: 0.0001656889944570139
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0206406116485596, Constraint losses: L1: 18.42068099975586, L2: 0.0007399342721328139, L3: 1.0007399320602417, L4: 1.0007400512695312
Epoch 500, Loss: 0.002265645656734705, Constraint losses: L1: -1.0614073276519775, L2: 0.0, L3: 0.0026625394821166992, L4: 0.0006645134999416769
Epoch 1000, Loss: 0.001293847570195794, Constraint losses: L1: -1.1192991733551025, L2: 0.0, L3: 0.002206265926361084, L4: 0.00020688089716713876
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 44.269935607910156, Losses: L1: 9.429791450500488, L2: 1.975659870367963e-06, L3: 0.999670147895813, L4: 65.08607482910156, L5: 0.29776880145072937
Epoch 500, Loss: 4.113564491271973, Losses: L1: -0.6624690294265747, L2: 0.5545534491539001, L3: 0.28380894660949707, L4: 7.798592567443848, L5: 0.03184274584054947
Epoch 1000, Loss: 2.9736716747283936, Losses: L1: -1.1405494213104248, L2: 0.5229788422584534, L3: 0.2424633502960205, L4: 6.664234638214111, L5: 0.035687580704689026
Epoch 1500, Loss: 3.269984006881714, Losses: L1: -0.5947763919830322, L2: 0.32167693972587585, L3: 0.2501400113105774, L4: 6.357095241546631, L5: 0.025094224140048027
Epoch 2000, Loss: 2.7758677005767822, Losses: L1: -1.111409068107605, L2: 0.4415247440338135, L3: 0.21984821557998657, L4: 6.390074253082275, L5: 0.031780898571014404
Epoch 2500, Loss: 1.4540612697601318, Losses: L1: -0.8083004951477051, L2: 0.29464423656463623, L3: 0.22865962982177734, L4: 3.283470630645752, L5: 0.015984972938895226
Epoch 3000, Loss: 1.1542514562606812, Losses: L1: -0.8125834465026855, L2: 0.27047571539878845, L3: 0.2108699083328247, L4: 2.7856287956237793, L5: 0.01704276166856289
Epoch 3500, Loss: 0.8792317509651184, Losses: L1: -0.7964928150177002, L2: 0.25307080149650574, L3: 0.19831597805023193, L4: 2.2654945850372314, L5: 0.01980992592871189
Epoch 4000, Loss: 0.9140223860740662, Losses: L1: -0.7596373558044434, L2: 0.2384873926639557, L3: 0.17918932437896729, L4: 2.3426003456115723, L5: 0.024737218394875526
Epoch 4500, Loss: 0.53975909948349, Losses: L1: -0.8147861957550049, L2: 0.23856887221336365, L3: 0.17676770687103271, L4: 1.7179824113845825, L5: 0.022734234109520912
Epoch 5000, Loss: 0.4373049736022949, Losses: L1: -0.8510251641273499, L2: 0.23866547644138336, L3: 0.17305779457092285, L4: 1.6021935939788818, L5: 0.021785015240311623
Epoch 5500, Loss: 0.3825140595436096, Losses: L1: -0.839467465877533, L2: 0.23431268334388733, L3: 0.1694953441619873, L4: 1.4848482608795166, L5: 0.023410381749272346
Epoch 6000, Loss: 0.3208765387535095, Losses: L1: -0.8542444109916687, L2: 0.23582206666469574, L3: 0.16857540607452393, L4: 1.3942917585372925, L5: 0.02291320450603962
Epoch 6500, Loss: 0.2914262115955353, Losses: L1: -0.8545167446136475, L2: 0.235436350107193, L3: 0.16680049896240234, L4: 1.3427011966705322, L5: 0.023273201659321785
Epoch 7000, Loss: 0.27318283915519714, Losses: L1: -0.8609378933906555, L2: 0.2354240119457245, L3: 0.16537880897521973, L4: 1.3248624801635742, L5: 0.023219844326376915
Epoch 7500, Loss: 0.2606981694698334, Losses: L1: -0.8661770820617676, L2: 0.23497487604618073, L3: 0.1642795205116272, L4: 1.3152707815170288, L5: 0.02319337986409664
Epoch 8000, Loss: 0.25132179260253906, Losses: L1: -0.8691517114639282, L2: 0.23459574580192566, L3: 0.16341572999954224, L4: 1.3062450885772705, L5: 0.02322162501513958
Epoch 8500, Loss: 0.24448955059051514, Losses: L1: -0.8714319467544556, L2: 0.2344885617494583, L3: 0.16272997856140137, L4: 1.2999963760375977, L5: 0.023219041526317596
Epoch 9000, Loss: 0.23944410681724548, Losses: L1: -0.8732988834381104, L2: 0.23446249961853027, L3: 0.16225433349609375, L4: 1.2956089973449707, L5: 0.023198572918772697
Epoch 9500, Loss: 0.23576034605503082, Losses: L1: -0.8745320439338684, L2: 0.234355166554451, L3: 0.16195034980773926, L4: 1.2920423746109009, L5: 0.02319289743900299
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.020738124847412, Constraint losses: L1: 18.42068099975586, L2: 0.0008226414211094379, L3: 1.0007472038269043, L4: 1.0007474422454834
Epoch 500, Loss: 0.0023490353487432003, Constraint losses: L1: -1.077554702758789, L2: 0.0, L3: 0.0027123093605041504, L4: 0.0007142807589843869
Epoch 1000, Loss: 0.0013413315173238516, Constraint losses: L1: -1.118173599243164, L2: 0.0, L3: 0.002229452133178711, L4: 0.00023005310504231602
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0061182975769043, Constraint losses: L1: 7.495005130767822, L2: 0.0, L3: 0.9993115067481995, L4: 0.9993119239807129
Epoch 500, Loss: 0.0023785624653100967, Constraint losses: L1: -1.1088801622390747, L2: 0.0, L3: 0.002742767333984375, L4: 0.0007446752861142159
Epoch 1000, Loss: 0.001368583645671606, Constraint losses: L1: -1.1186439990997314, L2: 0.0, L3: 0.002243220806121826, L4: 0.00024400692200288177
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 49.879539489746094, Losses: L1: 10.07219409942627, L2: 0.0004437000025063753, L3: 0.9987746477127075, L4: 74.17752838134766, L5: 0.36040470004081726
Epoch 500, Loss: 37.17764663696289, Losses: L1: 9.865720748901367, L2: 0.05183731019496918, L3: 0.9869760870933533, L4: 49.94252014160156, L5: 0.17039743065834045
Epoch 1000, Loss: 0.3609822690486908, Losses: L1: -1.7366427183151245, L2: 0.45308127999305725, L3: 0.09290146827697754, L4: 3.324063777923584, L5: 0.011624738574028015
Epoch 1500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.3923543429328333e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 2000, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.392134407751655e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 2500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391940895878463e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 3000, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391754378410326e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 3500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.3917248464778709e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 4000, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.3917045293965202e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 4500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 5000, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 5500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 6000, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 6500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 7000, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 7500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 8000, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 8500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 9000, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Epoch 9500, Loss: 45.761714935302734, Losses: L1: 18.42068099975586, L2: 1.391684545382077e-09, L3: 1.0, L4: 50.00001907348633, L5: 0.17051038146018982
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.000673770904541, Constraint losses: L1: 5.921000003814697, L2: 0.0, L3: 0.9973766803741455, L4: 0.9973761439323425
Epoch 500, Loss: 0.002269795397296548, Constraint losses: L1: -1.0888503789901733, L2: 0.0, L3: 0.002678394317626953, L4: 0.0006802515126764774
Epoch 1000, Loss: 0.0013181978138163686, Constraint losses: L1: -1.1180967092514038, L2: 0.0, L3: 0.0022178292274475098, L4: 0.00021846538584213704
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9933271408081055, Constraint losses: L1: 5.118445873260498, L2: 0.0, L3: 0.9941045641899109, L4: 0.9941040873527527
Epoch 500, Loss: 0.001967608230188489, Constraint losses: L1: -1.0826385021209717, L2: 0.0, L3: 0.0025243759155273438, L4: 0.0005258708260953426
Epoch 1000, Loss: 0.0012031355872750282, Constraint losses: L1: -1.1181299686431885, L2: 0.0, L3: 0.002160370349884033, L4: 0.00016089531709440053
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 87.0571060180664, Losses: L1: 5.350940227508545, L2: 0.0, L3: 0.9957455396652222, L4: 79.513916015625, L5: 0.40152329206466675
Epoch 500, Loss: 0.5605505108833313, Losses: L1: -3.901057481765747, L2: 1.5808076858520508, L3: 0.08936911821365356, L4: 3.4703075885772705, L5: 0.044316355139017105
Epoch 1000, Loss: 0.7096601128578186, Losses: L1: -2.824801206588745, L2: 0.7315691113471985, L3: 0.06900405883789062, L4: 3.020076036453247, L5: 0.02118504047393799
Epoch 1500, Loss: 2.2385098934173584, Losses: L1: -1.802335262298584, L2: 0.6531946063041687, L3: 0.18561184406280518, L4: 3.3335347175598145, L5: 0.018978582695126534
Epoch 2000, Loss: 0.3539097309112549, Losses: L1: -1.8512046337127686, L2: 0.40042445063591003, L3: 0.14368873834609985, L4: 1.7121120691299438, L5: 0.010825172066688538
Epoch 2500, Loss: -0.04914198815822601, Losses: L1: -1.9463744163513184, L2: 0.3678952753543854, L3: 0.13554787635803223, L4: 1.4375733137130737, L5: 0.00923135969787836
Epoch 3000, Loss: -0.24611611664295197, Losses: L1: -2.0054843425750732, L2: 0.355487197637558, L3: 0.1292954683303833, L4: 1.318358302116394, L5: 0.0093508530408144
Epoch 3500, Loss: -0.37217727303504944, Losses: L1: -2.0781211853027344, L2: 0.3650926351547241, L3: 0.12506389617919922, L4: 1.268608570098877, L5: 0.009322361089289188
Epoch 4000, Loss: -0.4597049951553345, Losses: L1: -2.12255859375, L2: 0.3687802255153656, L3: 0.12219589948654175, L4: 1.2293117046356201, L5: 0.00952002964913845
Epoch 4500, Loss: -0.5224213004112244, Losses: L1: -2.1579818725585938, L2: 0.37366199493408203, L3: 0.11996829509735107, L4: 1.203914999961853, L5: 0.009755987673997879
Epoch 5000, Loss: -0.5672370195388794, Losses: L1: -2.1990389823913574, L2: 0.3850898742675781, L3: 0.11835688352584839, L4: 1.1975972652435303, L5: 0.0098919328302145
Epoch 5500, Loss: -0.6040453910827637, Losses: L1: -2.2254161834716797, L2: 0.39294248819351196, L3: 0.11767709255218506, L4: 1.1844240427017212, L5: 0.010242713615298271
Epoch 6000, Loss: -0.6319630146026611, Losses: L1: -2.2530875205993652, L2: 0.4012584090232849, L3: 0.11721503734588623, L4: 1.1808794736862183, L5: 0.010371406562626362
Epoch 6500, Loss: -0.6513816714286804, Losses: L1: -2.2700626850128174, L2: 0.40628957748413086, L3: 0.1165856122970581, L4: 1.177132248878479, L5: 0.010465465486049652
Epoch 7000, Loss: -0.6672490239143372, Losses: L1: -2.283079147338867, L2: 0.4102295935153961, L3: 0.1163865327835083, L4: 1.1726279258728027, L5: 0.0106285959482193
Epoch 7500, Loss: -0.6781874299049377, Losses: L1: -2.2908103466033936, L2: 0.4127199947834015, L3: 0.11597132682800293, L4: 1.1689754724502563, L5: 0.010689334012567997
Epoch 8000, Loss: -0.6859164237976074, Losses: L1: -2.2959201335906982, L2: 0.41416066884994507, L3: 0.11568540334701538, L4: 1.166175127029419, L5: 0.01075480505824089
Epoch 8500, Loss: -0.6911576986312866, Losses: L1: -2.299637794494629, L2: 0.41512832045555115, L3: 0.1155163049697876, L4: 1.1644914150238037, L5: 0.010783964768052101
Epoch 9000, Loss: -0.6948246359825134, Losses: L1: -2.3015215396881104, L2: 0.41561904549598694, L3: 0.1153939962387085, L4: 1.1626933813095093, L5: 0.010812215507030487
Epoch 9500, Loss: -0.6971522569656372, Losses: L1: -2.3027193546295166, L2: 0.4159151613712311, L3: 0.11530590057373047, L4: 1.1615833044052124, L5: 0.010828922502696514
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0200321674346924, Constraint losses: L1: 18.42068099975586, L2: 0.000537147163413465, L3: 1.0005371570587158, L4: 1.0005371570587158
Epoch 500, Loss: 0.002573882695287466, Constraint losses: L1: -1.103219985961914, L2: 0.0, L3: 0.0028374791145324707, L4: 0.0008396236808039248
Epoch 1000, Loss: 0.0014367935946211219, Constraint losses: L1: -1.118593692779541, L2: 0.0, L3: 0.0022773146629333496, L4: 0.00027807263541035354
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0012972354888916, Constraint losses: L1: 6.023423194885254, L2: 2.9439097488648258e-05, L3: 0.9976221919059753, L4: 0.9976220726966858
Epoch 500, Loss: 0.0020657796412706375, Constraint losses: L1: -1.1032168865203857, L2: 0.0, L3: 0.0025836825370788574, L4: 0.0005853141192346811
Epoch 1000, Loss: 0.001253887778148055, Constraint losses: L1: -1.1196198463439941, L2: 0.0, L3: 0.0021865367889404297, L4: 0.00018697086488828063
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 98.06524658203125, Losses: L1: 14.792738914489746, L2: 0.0006237134803086519, L3: 1.0003118515014648, L4: 80.853759765625, L5: 0.417817085981369
Epoch 500, Loss: 52.5918083190918, Losses: L1: -1.0245821475982666, L2: 0.19944211840629578, L3: 0.9933008551597595, L4: 51.351436614990234, L5: 0.17863038182258606
Epoch 1000, Loss: 1.7380218505859375, Losses: L1: -2.306683301925659, L2: 0.7026233077049255, L3: 0.14745104312896729, L4: 3.374563455581665, L5: 0.02392795868217945
Epoch 1500, Loss: 0.16856947541236877, Losses: L1: -2.3844387531280518, L2: 0.5544043183326721, L3: 0.11377549171447754, L4: 2.0381410121917725, L5: 0.010114096105098724
Epoch 2000, Loss: 0.748282253742218, Losses: L1: -2.578155994415283, L2: 0.5466194152832031, L3: 0.10989391803741455, L4: 2.821284294128418, L5: 0.012056381441652775
Epoch 2500, Loss: -1.406809687614441, Losses: L1: -2.8747029304504395, L2: 0.501995325088501, L3: 0.0996711254119873, L4: 1.0112818479537964, L5: 0.006271614693105221
Epoch 3000, Loss: -1.9074326753616333, Losses: L1: -2.998199462890625, L2: 0.5116485953330994, L3: 0.09475290775299072, L4: 0.6400831341743469, L5: 0.005353628192096949
Epoch 3500, Loss: -1.9941695928573608, Losses: L1: -3.044593334197998, L2: 0.5046325922012329, L3: 0.0927007794380188, L4: 0.6075731515884399, L5: 0.005132722202688456
Epoch 4000, Loss: -2.0504302978515625, Losses: L1: -3.0901710987091064, L2: 0.509905993938446, L3: 0.09237957000732422, L4: 0.594942569732666, L5: 0.005086163990199566
Epoch 4500, Loss: -2.091785430908203, Losses: L1: -3.134150743484497, L2: 0.5215156078338623, L3: 0.09178978204727173, L4: 0.5929659605026245, L5: 0.005062054842710495
Epoch 5000, Loss: -2.1208083629608154, Losses: L1: -3.1569128036499023, L2: 0.5279311537742615, L3: 0.0911475419998169, L4: 0.5848392844200134, L5: 0.005004315637052059
Epoch 5500, Loss: -2.141988515853882, Losses: L1: -3.176790237426758, L2: 0.5328081846237183, L3: 0.09074258804321289, L4: 0.5819422602653503, L5: 0.004970051348209381
Epoch 6000, Loss: -2.157655954360962, Losses: L1: -3.18963885307312, L2: 0.5358395576477051, L3: 0.09034907817840576, L4: 0.5784278512001038, L5: 0.0049371239729225636
Epoch 6500, Loss: -2.1686604022979736, Losses: L1: -3.199599027633667, L2: 0.5392972230911255, L3: 0.09002476930618286, L4: 0.576309084892273, L5: 0.004931263625621796
Epoch 7000, Loss: -2.1765589714050293, Losses: L1: -3.207272529602051, L2: 0.5419919490814209, L3: 0.08982211351394653, L4: 0.575141966342926, L5: 0.0049313888885080814
Epoch 7500, Loss: -2.182539701461792, Losses: L1: -3.213439702987671, L2: 0.5441906452178955, L3: 0.08961433172225952, L4: 0.5746445655822754, L5: 0.0049310969188809395
Epoch 8000, Loss: -2.186401844024658, Losses: L1: -3.2172493934631348, L2: 0.545315682888031, L3: 0.08952641487121582, L4: 0.574207067489624, L5: 0.004929706454277039
Epoch 8500, Loss: -2.1890509128570557, Losses: L1: -3.21956205368042, L2: 0.5459839105606079, L3: 0.08944272994995117, L4: 0.573703944683075, L5: 0.0049298424273729324
Epoch 9000, Loss: -2.190812349319458, Losses: L1: -3.2209832668304443, L2: 0.5462773442268372, L3: 0.08939385414123535, L4: 0.5733155608177185, L5: 0.004928757436573505
Epoch 9500, Loss: -2.1918962001800537, Losses: L1: -3.222027063369751, L2: 0.5465646386146545, L3: 0.0893632173538208, L4: 0.5731943845748901, L5: 0.004927892237901688
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.005589246749878, Constraint losses: L1: 7.1171555519104, L2: 0.0, L3: 0.9992360472679138, L4: 0.9992359280586243
Epoch 500, Loss: 0.0022249072790145874, Constraint losses: L1: -1.1043496131896973, L2: 0.0, L3: 0.0026637911796569824, L4: 0.0006654657772742212
Epoch 1000, Loss: 0.0013173010665923357, Constraint losses: L1: -1.1183435916900635, L2: 0.0, L3: 0.002217590808868408, L4: 0.00021805395954288542
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.006988763809204, Constraint losses: L1: 7.777514457702637, L2: 3.4423272154526785e-05, L3: 0.9995883703231812, L4: 0.9995884299278259
Epoch 500, Loss: 0.0023044925183057785, Constraint losses: L1: -1.0897431373596191, L2: 0.0, L3: 0.002696216106414795, L4: 0.0006980195175856352
Epoch 1000, Loss: 0.0013166895369067788, Constraint losses: L1: -1.1184831857681274, L2: 0.0, L3: 0.0022172927856445312, L4: 0.0002178799913963303
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 93.7345199584961, Losses: L1: 7.589176177978516, L2: 1.2785729268216528e-05, L3: 0.9976097941398621, L4: 83.28731536865234, L5: 0.431400865316391
Epoch 500, Loss: 51.786441802978516, Losses: L1: -0.3170020878314972, L2: 0.4411315321922302, L3: 1.0384336709976196, L4: 49.47092819213867, L5: 0.16754227876663208
Epoch 1000, Loss: 57.01653289794922, Losses: L1: 3.975398540496826, L2: 0.001673898659646511, L3: 0.9791673421859741, L4: 50.73267364501953, L5: 0.17464371025562286
Epoch 1500, Loss: 7.772712707519531, Losses: L1: -1.5920257568359375, L2: 0.6487510204315186, L3: 0.2690192461013794, L4: 8.380014419555664, L5: 0.061155013740062714
Epoch 2000, Loss: 4.373808860778809, Losses: L1: -1.0704575777053833, L2: 0.3532273769378662, L3: 0.24687838554382324, L4: 4.728169918060303, L5: 0.02286287397146225
Epoch 2500, Loss: 3.287268877029419, Losses: L1: -0.901882529258728, L2: 0.29393285512924194, L3: 0.248602032661438, L4: 3.514336109161377, L5: 0.015322341583669186
Epoch 3000, Loss: 2.8351266384124756, Losses: L1: -0.8433614373207092, L2: 0.3051376938819885, L3: 0.23131823539733887, L4: 3.0252678394317627, L5: 0.019007498398423195
Epoch 3500, Loss: 2.6287968158721924, Losses: L1: -0.8376761674880981, L2: 0.3153977394104004, L3: 0.218269944190979, L4: 2.831791400909424, L5: 0.020221350714564323
Epoch 4000, Loss: 2.5041985511779785, Losses: L1: -0.8670727014541626, L2: 0.3167743682861328, L3: 0.21704745292663574, L4: 2.7394859790802, L5: 0.01965164765715599
Epoch 4500, Loss: 2.4144363403320312, Losses: L1: -0.846983015537262, L2: 0.3078903257846832, L3: 0.21345150470733643, L4: 2.638317108154297, L5: 0.021127013489603996
Epoch 5000, Loss: 2.3316891193389893, Losses: L1: -0.8649104237556458, L2: 0.30935877561569214, L3: 0.21314632892608643, L4: 2.5743706226348877, L5: 0.020628415048122406
Epoch 5500, Loss: 2.2911720275878906, Losses: L1: -0.8648868799209595, L2: 0.30714282393455505, L3: 0.2117997407913208, L4: 2.537174940109253, L5: 0.02085648477077484
Epoch 6000, Loss: 2.282759666442871, Losses: L1: -0.8772742748260498, L2: 0.309249609708786, L3: 0.21143102645874023, L4: 2.541799783706665, L5: 0.020373590290546417
Epoch 6500, Loss: 2.2483317852020264, Losses: L1: -0.8719556331634521, L2: 0.30715829133987427, L3: 0.21053624153137207, L4: 2.504171848297119, L5: 0.020732028409838676
Epoch 7000, Loss: 2.2365150451660156, Losses: L1: -0.8726167678833008, L2: 0.3069808781147003, L3: 0.209955096244812, L4: 2.4941890239715576, L5: 0.02077099308371544
Epoch 7500, Loss: 2.2283318042755127, Losses: L1: -0.8738232254981995, L2: 0.30689987540245056, L3: 0.2096063494682312, L4: 2.4879767894744873, L5: 0.02075774408876896
Epoch 8000, Loss: 2.2228081226348877, Losses: L1: -0.8754947781562805, L2: 0.3071170449256897, L3: 0.20932424068450928, L4: 2.4846856594085693, L5: 0.02070515602827072
Epoch 8500, Loss: 2.217888116836548, Losses: L1: -0.8757612109184265, L2: 0.306906521320343, L3: 0.20913362503051758, L4: 2.4804959297180176, L5: 0.020716482773423195
Epoch 9000, Loss: 2.215001106262207, Losses: L1: -0.8760144710540771, L2: 0.30673885345458984, L3: 0.20899814367294312, L4: 2.478205442428589, L5: 0.020722094923257828
Epoch 9500, Loss: 2.2128467559814453, Losses: L1: -0.8765498995780945, L2: 0.3067167401313782, L3: 0.20890522003173828, L4: 2.4768075942993164, L5: 0.02071017026901245
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.004380226135254, Constraint losses: L1: 6.675299167633057, L2: 0.0, L3: 0.9988527894020081, L4: 0.9988522529602051
Epoch 500, Loss: 0.0022991655860096216, Constraint losses: L1: -1.0951225757598877, L2: 0.0, L3: 0.0026961565017700195, L4: 0.0006981317419558764
Epoch 1000, Loss: 0.0013380212476477027, Constraint losses: L1: -1.1185158491134644, L2: 0.0, L3: 0.002227962017059326, L4: 0.00022857505246065557
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022857189178467, Constraint losses: L1: 18.42068099975586, L2: 0.0014790489803999662, L3: 1.0014790296554565, L4: 1.0014784336090088
Epoch 500, Loss: 0.002265032147988677, Constraint losses: L1: -1.002307415008545, L2: 0.0, L3: 0.002632617950439453, L4: 0.0006347217131406069
Epoch 1000, Loss: 0.0012661910150200129, Constraint losses: L1: -1.1179343461990356, L2: 0.0, L3: 0.0021918416023254395, L4: 0.0001922837836900726
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 159.727783203125, Losses: L1: 10.722344398498535, L2: 0.0006832050275988877, L3: 0.9987163543701172, L4: 73.41505432128906, L5: 0.35510653257369995
Epoch 500, Loss: -1.296380877494812, Losses: L1: -3.399623155593872, L2: 0.6220461130142212, L3: 0.07222241163253784, L4: 0.8215126991271973, L5: 0.00949791818857193
Epoch 1000, Loss: -0.473861962556839, Losses: L1: -3.385422468185425, L2: 0.5054651498794556, L3: 0.05853849649429321, L4: 1.2681927680969238, L5: 0.010731140151619911
Epoch 1500, Loss: -2.9026331901550293, Losses: L1: -3.974714994430542, L2: 0.49900203943252563, L3: 0.04049164056777954, L4: 0.3688424229621887, L5: 0.007826043292880058
Epoch 2000, Loss: -2.860776424407959, Losses: L1: -3.9068262577056885, L2: 0.381639301776886, L3: 0.019715189933776855, L4: 0.40594226121902466, L5: 0.007830818183720112
Epoch 2500, Loss: -2.43221378326416, Losses: L1: -4.007566928863525, L2: 0.49695780873298645, L3: 0.020415067672729492, L4: 0.64065021276474, L5: 0.009487070143222809
Epoch 3000, Loss: -3.5207090377807617, Losses: L1: -4.039316654205322, L2: 0.47653552889823914, L3: 0.010185599327087402, L4: 0.12812256813049316, L5: 0.007447338663041592
Epoch 3500, Loss: -3.501042366027832, Losses: L1: -4.055111885070801, L2: 0.4911004900932312, L3: 0.008729338645935059, L4: 0.14375019073486328, L5: 0.007120747119188309
Epoch 4000, Loss: 5.798200607299805, Losses: L1: 2.1635499000549316, L2: 0.9632514119148254, L3: 0.11046767234802246, L4: 1.4636101722717285, L5: 0.009738481603562832
Epoch 4500, Loss: 1.138519048690796, Losses: L1: -0.89652419090271, L2: 2.0159661769866943, L3: 0.08983111381530762, L4: 0.42169520258903503, L5: 0.008015096187591553
Epoch 5000, Loss: 0.1829613745212555, Losses: L1: -1.6531260013580322, L2: 2.088353157043457, L3: 0.014987945556640625, L4: 0.3790876567363739, L5: 0.00751918600872159
Epoch 5500, Loss: 0.013081222772598267, Losses: L1: -1.829075574874878, L2: 2.122860908508301, L3: 0.005951523780822754, L4: 0.3825274705886841, L5: 0.007536710239946842
Epoch 6000, Loss: -0.09496743232011795, Losses: L1: -1.925180435180664, L2: 2.118985891342163, L3: 0.0005371570587158203, L4: 0.3829779624938965, L5: 0.007379637099802494
Epoch 6500, Loss: -0.17098213732242584, Losses: L1: -1.994624376296997, L2: 2.11336350440979, L3: 0.0006803274154663086, L4: 0.3809574246406555, L5: 0.007369950879365206
Epoch 7000, Loss: -0.21578754484653473, Losses: L1: -2.0404999256134033, L2: 2.1123971939086914, L3: 0.0002338886260986328, L4: 0.3821873068809509, L5: 0.007342800032347441
Epoch 7500, Loss: -0.24656033515930176, Losses: L1: -2.0715835094451904, L2: 2.113335609436035, L3: 0.0001016855239868164, L4: 0.38224875926971436, L5: 0.0073089599609375
Epoch 8000, Loss: -0.26686006784439087, Losses: L1: -2.0923666954040527, L2: 2.1133124828338623, L3: 0.00027364492416381836, L4: 0.38232776522636414, L5: 0.007295101881027222
Epoch 8500, Loss: -0.28129956126213074, Losses: L1: -2.106966972351074, L2: 2.1141157150268555, L3: 0.00010836124420166016, L4: 0.3823768198490143, L5: 0.007278380449861288
Epoch 9000, Loss: -0.2913561165332794, Losses: L1: -2.1170461177825928, L2: 2.1144509315490723, L3: 5.7697296142578125e-05, L4: 0.3823569715023041, L5: 0.007270416710525751
Epoch 9500, Loss: -0.2983953356742859, Losses: L1: -2.1240572929382324, L2: 2.11458420753479, L3: 6.210803985595703e-05, L4: 0.38230690360069275, L5: 0.007263642735779285
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.996344804763794, Constraint losses: L1: 5.352352619171143, L2: 0.0, L3: 0.9954966306686401, L4: 0.9954958558082581
Epoch 500, Loss: 0.0024075740948319435, Constraint losses: L1: -1.1111377477645874, L2: 0.0, L3: 0.002758502960205078, L4: 0.0007602089317515492
Epoch 1000, Loss: 0.0013856703881174326, Constraint losses: L1: -1.116852879524231, L2: 0.0, L3: 0.0022509098052978516, L4: 0.0002516136155463755
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0188584327697754, Constraint losses: L1: 18.42068099975586, L2: 0.00014597902190871537, L3: 1.0001460313796997, L4: 1.0001459121704102
Epoch 500, Loss: 0.002097896533086896, Constraint losses: L1: -1.0758157968521118, L2: 0.0, L3: 0.002585887908935547, L4: 0.0005878244992345572
Epoch 1000, Loss: 0.0012471543159335852, Constraint losses: L1: -1.1192413568496704, L2: 0.0, L3: 0.0021829605102539062, L4: 0.00018343524425290525
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 150.19895935058594, Losses: L1: 18.42068099975586, L2: 0.004160285461694002, L3: 1.0041602849960327, L4: 64.73936462402344, L5: 0.28916066884994507
Epoch 500, Loss: -0.12765811383724213, Losses: L1: -2.9134998321533203, L2: 0.6299210786819458, L3: 0.07348597049713135, L4: 1.1579749584197998, L5: 0.00795938353985548
Epoch 1000, Loss: -0.4467709958553314, Losses: L1: -3.78879451751709, L2: 1.320151925086975, L3: 0.07390916347503662, L4: 1.2626010179519653, L5: 0.008927262388169765
Epoch 1500, Loss: -2.596277952194214, Losses: L1: -3.947505235671997, L2: 0.666576623916626, L3: 0.006166338920593262, L4: 0.5002284646034241, L5: 0.005149217322468758
Epoch 2000, Loss: -3.2804248332977295, Losses: L1: -4.040251731872559, L2: 0.5374672412872314, L3: 0.011861801147460938, L4: 0.23165278136730194, L5: 0.0040643601678311825
Epoch 2500, Loss: -0.5461143851280212, Losses: L1: -3.3961124420166016, L2: 2.7878024578094482, L3: 0.009817719459533691, L4: 0.7154415845870972, L5: 0.005578110925853252
Epoch 3000, Loss: -2.6299595832824707, Losses: L1: -3.987949848175049, L2: 1.3830465078353882, L3: 0.001687765121459961, L4: 0.3294226825237274, L5: 0.004246102645993233
Epoch 3500, Loss: -3.1357855796813965, Losses: L1: -3.9682979583740234, L2: 0.7871658205986023, L3: 0.00226593017578125, L4: 0.21528120338916779, L5: 0.003835291601717472
Epoch 4000, Loss: 1.4063936471939087, Losses: L1: 0.27164167165756226, L2: 0.8261797428131104, L3: 0.0015285015106201172, L4: 0.35701078176498413, L5: 0.004583502653986216
Epoch 4500, Loss: -0.661409318447113, Losses: L1: -1.8616869449615479, L2: 1.1430028676986694, L3: 0.06816732883453369, L4: 0.24425384402275085, L5: 0.003933812491595745
Epoch 5000, Loss: -0.9860184192657471, Losses: L1: -2.0779199600219727, L2: 1.1675059795379639, L3: 0.0018949508666992188, L4: 0.250190794467926, L5: 0.003977031446993351
Epoch 5500, Loss: -1.402098536491394, Losses: L1: -2.7668840885162354, L2: 1.1215380430221558, L3: 0.10428965091705322, L4: 0.2956308126449585, L5: 0.00417558616027236
Epoch 6000, Loss: -2.5573151111602783, Losses: L1: -3.661484956741333, L2: 0.7804332971572876, L3: 0.11236673593521118, L4: 0.24255461990833282, L5: 0.004110521636903286
Epoch 6500, Loss: -2.8345072269439697, Losses: L1: -3.78928279876709, L2: 0.7238548398017883, L3: 0.07328319549560547, L4: 0.22113294899463654, L5: 0.004015712067484856
Epoch 7000, Loss: -2.9700613021850586, Losses: L1: -3.785234212875366, L2: 0.5969784259796143, L3: 0.05730050802230835, L4: 0.19908076524734497, L5: 0.003921004943549633
Epoch 7500, Loss: -3.0431840419769287, Losses: L1: -3.7822530269622803, L2: 0.5305031538009644, L3: 0.04903435707092285, L4: 0.18593919277191162, L5: 0.0038703433237969875
Epoch 8000, Loss: -3.089796781539917, Losses: L1: -3.793989419937134, L2: 0.5049543976783752, L3: 0.041914403438568115, L4: 0.18201112747192383, L5: 0.003864638041704893
Epoch 8500, Loss: -3.121811866760254, Losses: L1: -3.8046631813049316, L2: 0.4991084337234497, L3: 0.03599822521209717, L4: 0.17872115969657898, L5: 0.003858323208987713
Epoch 9000, Loss: -3.1451950073242188, Losses: L1: -3.8172733783721924, L2: 0.5033645629882812, L3: 0.030636191368103027, L4: 0.17763131856918335, L5: 0.0038609905168414116
Epoch 9500, Loss: -3.1625001430511475, Losses: L1: -3.8284265995025635, L2: 0.5091962218284607, L3: 0.026436448097229004, L4: 0.17729483544826508, L5: 0.0038656233809888363
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 0.5, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.001180648803711, Constraint losses: L1: 6.012264251708984, L2: 0.0, L3: 0.9975842237472534, L4: 0.9975841045379639
Epoch 500, Loss: 0.002328400034457445, Constraint losses: L1: -1.0961309671401978, L2: 0.0, L3: 0.0027112364768981934, L4: 0.0007132944883778691
Epoch 1000, Loss: 0.0013466228265315294, Constraint losses: L1: -1.1181259155273438, L2: 0.0, L3: 0.0022320151329040527, L4: 0.0002327336260350421
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9997602701187134, Constraint losses: L1: 5.802642822265625, L2: 0.0, L3: 0.9969788789749146, L4: 0.996978759765625
Epoch 500, Loss: 0.002252929611131549, Constraint losses: L1: -1.1133098602294922, L2: 0.0, L3: 0.0026822686195373535, L4: 0.0006839708657935262
Epoch 1000, Loss: 0.0013308223569765687, Constraint losses: L1: -1.1199307441711426, L2: 0.0, L3: 0.002225041389465332, L4: 0.0002257117594126612
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 158.702392578125, Losses: L1: 18.42068099975586, L2: 0.0018818657845258713, L3: 1.0018818378448486, L4: 68.81474304199219, L5: 0.32375913858413696
Epoch 500, Loss: 0.5341393351554871, Losses: L1: -3.4957242012023926, L2: 1.004282832145691, L3: 0.05282098054885864, L4: 1.7015101909637451, L5: 0.009529928676784039
Epoch 1000, Loss: 0.11834825575351715, Losses: L1: -3.656121253967285, L2: 0.7660633325576782, L3: 0.07198846340179443, L4: 1.6165263652801514, L5: 0.007204124238342047
Epoch 1500, Loss: -0.8278236389160156, Losses: L1: -3.7937088012695312, L2: 0.530935525894165, L3: 0.06635868549346924, L4: 1.2780039310455322, L5: 0.005846151616424322
Epoch 2000, Loss: -2.327152967453003, Losses: L1: -3.769648551940918, L2: 0.3271286189556122, L3: 0.010328292846679688, L4: 0.625029981136322, L5: 0.00410732114687562
Epoch 2500, Loss: -2.3449196815490723, Losses: L1: -3.8007936477661133, L2: 0.2630692422389984, L3: 0.016449928283691406, L4: 0.6417925357818604, L5: 0.003927228040993214
Epoch 3000, Loss: -2.865628957748413, Losses: L1: -3.78045916557312, L2: 0.23543284833431244, L3: 0.02759164571762085, L4: 0.36738237738609314, L5: 0.003582937875762582
Epoch 3500, Loss: -3.290846824645996, Losses: L1: -3.8662726879119873, L2: 0.3024400770664215, L3: 0.003657102584838867, L4: 0.2050548493862152, L5: 0.0033908840268850327
Epoch 4000, Loss: -3.272282600402832, Losses: L1: -3.878969430923462, L2: 0.3143877685070038, L3: 0.009669721126556396, L4: 0.21172377467155457, L5: 0.0033528944477438927
Epoch 4500, Loss: -3.3073079586029053, Losses: L1: -3.90903377532959, L2: 0.3599308729171753, L3: 0.018507003784179688, L4: 0.18900159001350403, L5: 0.0033715490717440844
Epoch 5000, Loss: -3.3592405319213867, Losses: L1: -3.9426021575927734, L2: 0.38744261860847473, L3: 0.004963278770446777, L4: 0.18650338053703308, L5: 0.0033535307738929987
Epoch 5500, Loss: -3.3832805156707764, Losses: L1: -3.950331926345825, L2: 0.3980911076068878, L3: 0.002598404884338379, L4: 0.17804399132728577, L5: 0.003360492642968893
Epoch 6000, Loss: -3.3881618976593018, Losses: L1: -3.9575541019439697, L2: 0.40857818722724915, L3: 0.0015828609466552734, L4: 0.17761462926864624, L5: 0.0033540106378495693
Epoch 6500, Loss: -3.38793683052063, Losses: L1: -3.964765787124634, L2: 0.4154021441936493, L3: 0.005806088447570801, L4: 0.17540036141872406, L5: 0.0033575748093426228
Epoch 7000, Loss: -3.398545742034912, Losses: L1: -3.9642913341522217, L2: 0.41728392243385315, L3: 0.0014576911926269531, L4: 0.17373865842819214, L5: 0.0033554481342434883
Epoch 7500, Loss: -3.4005916118621826, Losses: L1: -3.9649083614349365, L2: 0.42023465037345886, L3: 0.0010116100311279297, L4: 0.17272977530956268, L5: 0.003358362941071391
Epoch 8000, Loss: -3.401639461517334, Losses: L1: -3.9666357040405273, L2: 0.42273640632629395, L3: 0.0011183619499206543, L4: 0.17233747243881226, L5: 0.0033581305760890245
Epoch 8500, Loss: -3.403317451477051, Losses: L1: -3.9679112434387207, L2: 0.42431601881980896, L3: 0.0009201765060424805, L4: 0.17194028198719025, L5: 0.0033574600238353014
Epoch 9000, Loss: -3.405823230743408, Losses: L1: -3.969104051589966, L2: 0.42540815472602844, L3: 0.00028401613235473633, L4: 0.17164763808250427, L5: 0.003356519155204296
Epoch 9500, Loss: -3.4066548347473145, Losses: L1: -3.970092535018921, L2: 0.42638298869132996, L3: 0.00024890899658203125, L4: 0.17151778936386108, L5: 0.003356462111696601
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0038580894470215, Constraint losses: L1: 6.517037391662598, L2: 8.941456997035857e-08, L3: 0.9986708760261536, L4: 0.9986701011657715
Epoch 500, Loss: 0.0020179040729999542, Constraint losses: L1: -1.1116225719451904, L2: 0.0, L3: 0.0025640130043029785, L4: 0.0005655138520523906
Epoch 1000, Loss: 0.0012537778820842505, Constraint losses: L1: -1.1181799173355103, L2: 0.0, L3: 0.0021857023239135742, L4: 0.00018625558004714549
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0085537433624268, Constraint losses: L1: 8.830653190612793, L2: 2.842123876689584e-06, L3: 0.9998601078987122, L4: 0.9998601078987122
Epoch 500, Loss: 0.0025702437851577997, Constraint losses: L1: -1.0403738021850586, L2: 0.0, L3: 0.0028041601181030273, L4: 0.0008064574794843793
Epoch 1000, Loss: 0.0013716667890548706, Constraint losses: L1: -1.1188069581985474, L2: 0.0, L3: 0.0022449493408203125, L4: 0.00024552439572289586
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.15544128417969, Losses: L1: 5.11635684967041, L2: 0.0, L3: 0.9931026697158813, L4: 80.67686462402344, L5: 0.4082055687904358
Epoch 500, Loss: -1.7108370065689087, Losses: L1: -3.089334726333618, L2: 0.3143559396266937, L3: 0.08969473838806152, L4: 2.0264923572540283, L5: 0.012096903286874294
Epoch 1000, Loss: -2.8632211685180664, Losses: L1: -3.7621965408325195, L2: 0.3635641932487488, L3: 0.05906069278717041, L4: 1.0032535791397095, L5: 0.008508075028657913
Epoch 1500, Loss: 3.3649230003356934, Losses: L1: -0.6151875257492065, L2: 0.43099236488342285, L3: 0.28139805793762207, L4: 6.791253089904785, L5: 0.025585012510418892
Epoch 2000, Loss: 2.169213056564331, Losses: L1: -0.912358820438385, L2: 0.1959170252084732, L3: 0.2222355604171753, L4: 5.532665729522705, L5: 0.01640826091170311
Epoch 2500, Loss: 0.43665483593940735, Losses: L1: -1.4316422939300537, L2: 0.13030697405338287, L3: 0.18843400478363037, L4: 3.2750136852264404, L5: 0.012532511726021767
Epoch 3000, Loss: 0.17122460901737213, Losses: L1: -1.8835984468460083, L2: 0.29880887269973755, L3: 0.17088139057159424, L4: 3.3127572536468506, L5: 0.028389709070324898
Epoch 3500, Loss: -0.6352688670158386, Losses: L1: -1.9194179773330688, L2: 0.3348459005355835, L3: 0.16315698623657227, L4: 1.716181993484497, L5: 0.019267480820417404
Epoch 4000, Loss: -0.8146926164627075, Losses: L1: -1.9762033224105835, L2: 0.3760071396827698, L3: 0.15583586692810059, L4: 1.3976744413375854, L5: 0.017496736720204353
Epoch 4500, Loss: -0.854274332523346, Losses: L1: -2.0150699615478516, L2: 0.4002322852611542, L3: 0.1520296335220337, L4: 1.3514024019241333, L5: 0.017694717273116112
Epoch 5000, Loss: -0.9721249341964722, Losses: L1: -2.126737117767334, L2: 0.42269012331962585, L3: 0.14673233032226562, L4: 1.3008195161819458, L5: 0.016292238608002663
Epoch 5500, Loss: -1.0021207332611084, Losses: L1: -2.1527583599090576, L2: 0.42662957310676575, L3: 0.14627110958099365, L4: 1.2855037450790405, L5: 0.01624104008078575
Epoch 6000, Loss: -1.0156115293502808, Losses: L1: -2.166425943374634, L2: 0.43220508098602295, L3: 0.14580309391021729, L4: 1.27516770362854, L5: 0.01624765805900097
Epoch 6500, Loss: -1.0234942436218262, Losses: L1: -2.172544002532959, L2: 0.43457645177841187, L3: 0.14521169662475586, L4: 1.2675716876983643, L5: 0.016163136810064316
Epoch 7000, Loss: -1.0283557176589966, Losses: L1: -2.176084041595459, L2: 0.436164528131485, L3: 0.14481347799301147, L4: 1.2622700929641724, L5: 0.016043851152062416
Epoch 7500, Loss: -1.031423568725586, Losses: L1: -2.180716037750244, L2: 0.43848928809165955, L3: 0.14459019899368286, L4: 1.260872721672058, L5: 0.016143223270773888
Epoch 8000, Loss: -1.0338823795318604, Losses: L1: -2.1822433471679688, L2: 0.4389653205871582, L3: 0.14445602893829346, L4: 1.2582471370697021, L5: 0.016088150441646576
Epoch 8500, Loss: -1.0354336500167847, Losses: L1: -2.183349609375, L2: 0.43929803371429443, L3: 0.1443692445755005, L4: 1.2568086385726929, L5: 0.01605766825377941
Epoch 9000, Loss: -1.0364603996276855, Losses: L1: -2.1845943927764893, L2: 0.43980544805526733, L3: 0.14432215690612793, L4: 1.256258249282837, L5: 0.016076665371656418
Epoch 9500, Loss: -1.0371980667114258, Losses: L1: -2.1852471828460693, L2: 0.44003114104270935, L3: 0.14429330825805664, L4: 1.2556700706481934, L5: 0.016072453930974007
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023784637451172, Constraint losses: L1: 18.42068099975586, L2: 0.001787905697710812, L3: 1.0017879009246826, L4: 1.0017881393432617
Epoch 500, Loss: 0.0026672303210943937, Constraint losses: L1: -1.1077749729156494, L2: 0.0, L3: 0.002886474132537842, L4: 0.000888531212694943
Epoch 1000, Loss: 0.001467543886974454, Constraint losses: L1: -1.1171324253082275, L2: 0.0, L3: 0.0022919178009033203, L4: 0.00029275863198563457
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0196151733398438, Constraint losses: L1: 18.42068099975586, L2: 0.00040631493902765214, L3: 1.0003941059112549, L4: 1.0003939867019653
Epoch 500, Loss: 0.0021850918419659138, Constraint losses: L1: -1.1009472608566284, L2: 0.0, L3: 0.0026421546936035156, L4: 0.0006438842974603176
Epoch 1000, Loss: 0.001293687499128282, Constraint losses: L1: -1.119088888168335, L2: 0.0, L3: 0.002206087112426758, L4: 0.00020668937941081822
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 46.58171081542969, Losses: L1: 5.506597995758057, L2: 5.095138178035086e-08, L3: 0.9938330054283142, L4: 80.33680725097656, L5: 0.40979281067848206
Epoch 500, Loss: -1.8576585054397583, Losses: L1: -3.1807548999786377, L2: 0.30775144696235657, L3: 0.11010140180587769, L4: 1.9084463119506836, L5: 0.006071232259273529
Epoch 1000, Loss: 3.6225318908691406, Losses: L1: -2.6059012413024902, L2: 0.665776789188385, L3: 0.1853501796722412, L4: 10.834351539611816, L5: 0.052805345505476
Epoch 1500, Loss: -1.0527147054672241, Losses: L1: -3.006559133529663, L2: 0.5253391861915588, L3: 0.12829554080963135, L4: 2.7063047885894775, L5: 0.011205137707293034
Epoch 2000, Loss: -2.2278900146484375, Losses: L1: -3.1579039096832275, L2: 0.4344606399536133, L3: 0.10728943347930908, L4: 0.8734702467918396, L5: 0.005173450335860252
Epoch 2500, Loss: -2.424203872680664, Losses: L1: -3.321606159210205, L2: 0.4590406119823456, L3: 0.10161983966827393, L4: 0.7648923397064209, L5: 0.005105410702526569
Epoch 3000, Loss: -2.776954174041748, Losses: L1: -3.673924446105957, L2: 0.4577968716621399, L3: 0.07166808843612671, L4: 0.7974517941474915, L5: 0.004613358061760664
Epoch 3500, Loss: -3.165320634841919, Losses: L1: -3.7688376903533936, L2: 0.39211800694465637, L3: 0.06315088272094727, L4: 0.3505212068557739, L5: 0.00456314766779542
Epoch 4000, Loss: -3.2634353637695312, Losses: L1: -3.7923502922058105, L2: 0.33769696950912476, L3: 0.0553739070892334, L4: 0.3184702396392822, L5: 0.0042957523837685585
Epoch 4500, Loss: -3.3157222270965576, Losses: L1: -3.8044912815093994, L2: 0.30273813009262085, L3: 0.05048692226409912, L4: 0.31300896406173706, L5: 0.004282998386770487
Epoch 5000, Loss: -3.345108985900879, Losses: L1: -3.815765142440796, L2: 0.28898435831069946, L3: 0.04749774932861328, L4: 0.30744174122810364, L5: 0.004202230367809534
Epoch 5500, Loss: -3.3627734184265137, Losses: L1: -3.818760871887207, L2: 0.27758949995040894, L3: 0.04518091678619385, L4: 0.3032654821872711, L5: 0.0041746534407138824
Epoch 6000, Loss: -3.3754546642303467, Losses: L1: -3.821899175643921, L2: 0.27022987604141235, L3: 0.04299211502075195, L4: 0.3011320233345032, L5: 0.004152648616582155
Epoch 6500, Loss: -3.38555645942688, Losses: L1: -3.8233113288879395, L2: 0.26416245102882385, L3: 0.041777074337005615, L4: 0.2970612347126007, L5: 0.004172937478870153
Epoch 7000, Loss: -3.3923532962799072, Losses: L1: -3.824674606323242, L2: 0.2601280212402344, L3: 0.04076904058456421, L4: 0.29529839754104614, L5: 0.00415934668853879
Epoch 7500, Loss: -3.3974249362945557, Losses: L1: -3.8257853984832764, L2: 0.2575010061264038, L3: 0.03986012935638428, L4: 0.29353633522987366, L5: 0.004161326214671135
Epoch 8000, Loss: -3.4010770320892334, Losses: L1: -3.8269882202148438, L2: 0.2557438910007477, L3: 0.039137840270996094, L4: 0.29288819432258606, L5: 0.004154139664024115
Epoch 8500, Loss: -3.4036943912506104, Losses: L1: -3.827887773513794, L2: 0.25443577766418457, L3: 0.03863954544067383, L4: 0.2925790846347809, L5: 0.004148243460804224
Epoch 9000, Loss: -3.4055991172790527, Losses: L1: -3.828315019607544, L2: 0.253314733505249, L3: 0.038280367851257324, L4: 0.2922293543815613, L5: 0.004146248567849398
Epoch 9500, Loss: -3.406966209411621, Losses: L1: -3.8285484313964844, L2: 0.25241994857788086, L3: 0.0380169153213501, L4: 0.29201728105545044, L5: 0.004145145416259766
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.009204864501953, Constraint losses: L1: 9.538615226745605, L2: 4.764805271406658e-05, L3: 0.9998092651367188, L4: 0.9998095035552979
Epoch 500, Loss: 0.0023428108543157578, Constraint losses: L1: -1.076633095741272, L2: 0.0, L3: 0.0027087926864624023, L4: 0.0007106513367034495
Epoch 1000, Loss: 0.0013187151635065675, Constraint losses: L1: -1.1159977912902832, L2: 0.0, L3: 0.002217113971710205, L4: 0.00021759900846518576
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9830272197723389, Constraint losses: L1: 4.4622416496276855, L2: 0.0, L3: 0.9892840385437012, L4: 0.9892809987068176
Epoch 500, Loss: 0.002261945977807045, Constraint losses: L1: -1.0360063314437866, L2: 0.0, L3: 0.0026479363441467285, L4: 0.0006500158924609423
Epoch 1000, Loss: 0.0012810988118872046, Constraint losses: L1: -1.1181704998016357, L2: 0.0, L3: 0.0021992921829223633, L4: 0.00019997719209641218
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.737186431884766, Losses: L1: 18.42068099975586, L2: 0.0011749998666346073, L3: 1.001141905784607, L4: 70.27528381347656, L5: 0.33856067061424255
Epoch 500, Loss: 44.27373504638672, Losses: L1: 18.42068099975586, L2: 9.982369419958559e-08, L3: 1.0000001192092896, L4: 50.0235710144043, L5: 0.17063464224338531
Epoch 1000, Loss: 44.26869201660156, Losses: L1: 18.42068099975586, L2: 5.3872550864753066e-08, L3: 1.0, L4: 50.01358413696289, L5: 0.170608788728714
Epoch 1500, Loss: 44.266788482666016, Losses: L1: 18.42068099975586, L2: 3.7945724784549384e-08, L3: 1.0, L4: 50.009803771972656, L5: 0.170603409409523
Epoch 2000, Loss: 44.26585388183594, Losses: L1: 18.42068099975586, L2: 3.028723583042847e-08, L3: 1.0, L4: 50.0079460144043, L5: 0.17060160636901855
Epoch 2500, Loss: 44.26532745361328, Losses: L1: 18.42068099975586, L2: 2.5987068497101973e-08, L3: 1.0, L4: 50.006893157958984, L5: 0.17060138285160065
Epoch 3000, Loss: 44.26499938964844, Losses: L1: 18.42068099975586, L2: 2.3321971909240347e-08, L3: 1.0, L4: 50.00623321533203, L5: 0.1706012487411499
Epoch 3500, Loss: 44.2647819519043, Losses: L1: 18.42068099975586, L2: 2.1567219121720882e-08, L3: 1.0, L4: 50.00579833984375, L5: 0.17060117423534393
Epoch 4000, Loss: 44.26463317871094, Losses: L1: 18.42068099975586, L2: 2.0355605201416438e-08, L3: 1.0, L4: 50.005496978759766, L5: 0.17060111463069916
Epoch 4500, Loss: 44.2645263671875, Losses: L1: 18.42068099975586, L2: 1.9494795111540952e-08, L3: 1.0, L4: 50.00528335571289, L5: 0.17060106992721558
Epoch 5000, Loss: 44.264442443847656, Losses: L1: 18.42068099975586, L2: 1.887080358642379e-08, L3: 1.0, L4: 50.005123138427734, L5: 0.170601025223732
Epoch 5500, Loss: 44.26438903808594, Losses: L1: 18.42068099975586, L2: 1.8407288138178046e-08, L3: 1.0, L4: 50.005008697509766, L5: 0.1706010103225708
Epoch 6000, Loss: 44.26434326171875, Losses: L1: 18.42068099975586, L2: 1.805863902859528e-08, L3: 1.0, L4: 50.004920959472656, L5: 0.1706009954214096
Epoch 6500, Loss: 44.26430892944336, Losses: L1: 18.42068099975586, L2: 1.7795935391973217e-08, L3: 1.0, L4: 50.004852294921875, L5: 0.1706009805202484
Epoch 7000, Loss: 44.264286041259766, Losses: L1: 18.42068099975586, L2: 1.759650380961375e-08, L3: 1.0, L4: 50.00480651855469, L5: 0.17060096561908722
Epoch 7500, Loss: 44.26426696777344, Losses: L1: 18.42068099975586, L2: 1.7443538169459316e-08, L3: 1.0, L4: 50.00476837158203, L5: 0.17060096561908722
Epoch 8000, Loss: 44.264251708984375, Losses: L1: 18.42068099975586, L2: 1.7325834988923816e-08, L3: 1.0, L4: 50.00474166870117, L5: 0.17060095071792603
Epoch 8500, Loss: 44.26424026489258, Losses: L1: 18.42068099975586, L2: 1.7234990323800048e-08, L3: 1.0, L4: 50.00471496582031, L5: 0.17060095071792603
Epoch 9000, Loss: 44.26422882080078, Losses: L1: 18.42068099975586, L2: 1.7164687449167104e-08, L3: 1.0, L4: 50.004695892333984, L5: 0.17060095071792603
Epoch 9500, Loss: 44.264225006103516, Losses: L1: 18.42068099975586, L2: 1.7110897587713225e-08, L3: 1.0, L4: 50.00468444824219, L5: 0.17060095071792603
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.011482000350952, Constraint losses: L1: 11.486006736755371, L2: 0.0003583540965337306, L3: 0.9998186826705933, L4: 0.9998189210891724
Epoch 500, Loss: 0.002186006400734186, Constraint losses: L1: -0.9642318487167358, L2: 0.0, L3: 0.002574026584625244, L4: 0.0005762118380516768
Epoch 1000, Loss: 0.0012151835253462195, Constraint losses: L1: -1.1143062114715576, L2: 0.0, L3: 0.0021644234657287598, L4: 0.00016506630345247686
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0199193954467773, Constraint losses: L1: 18.42068099975586, L2: 0.0004996635252609849, L3: 1.0004996061325073, L4: 1.0004994869232178
Epoch 500, Loss: 0.0023190064821392298, Constraint losses: L1: -1.0902879238128662, L2: 0.0, L3: 0.0027036070823669434, L4: 0.0007056873291730881
Epoch 1000, Loss: 0.0013327072374522686, Constraint losses: L1: -1.1183124780654907, L2: 0.0, L3: 0.002225160598754883, L4: 0.00022585908300243318
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 93.06532287597656, Losses: L1: 6.2141265869140625, L2: 0.0, L3: 0.9965271353721619, L4: 86.12492370605469, L5: 0.4560307562351227
Epoch 500, Loss: 62.005882263183594, Losses: L1: 11.421026229858398, L2: 0.0, L3: 0.9999733567237854, L4: 49.99991989135742, L5: 0.1699020266532898
Epoch 1000, Loss: 69.02812194824219, Losses: L1: 18.42068099975586, L2: 1.7314442857241374e-07, L3: 1.0000001192092896, L4: 50.0224723815918, L5: 0.1699356883764267
Epoch 1500, Loss: 69.01873016357422, Losses: L1: 18.42068099975586, L2: 9.435397885226848e-08, L3: 1.0, L4: 50.013099670410156, L5: 0.16990900039672852
Epoch 2000, Loss: 69.01534271240234, Losses: L1: 18.42068099975586, L2: 6.745782599182348e-08, L3: 1.0, L4: 50.00970458984375, L5: 0.16990311443805695
Epoch 2500, Loss: 69.01365661621094, Losses: L1: 18.42068099975586, L2: 5.452728757404657e-08, L3: 1.0, L4: 50.00802230834961, L5: 0.16990044713020325
Epoch 3000, Loss: 69.01268768310547, Losses: L1: 18.42068099975586, L2: 4.72039438648153e-08, L3: 1.0, L4: 50.007049560546875, L5: 0.16990002989768982
Epoch 3500, Loss: 69.0120620727539, Losses: L1: 18.42068099975586, L2: 4.263331021547856e-08, L3: 1.0, L4: 50.006431579589844, L5: 0.16989979147911072
Epoch 4000, Loss: 69.01165008544922, Losses: L1: 18.42068099975586, L2: 3.959858574376085e-08, L3: 1.0, L4: 50.00601577758789, L5: 0.1698996126651764
Epoch 4500, Loss: 69.01136779785156, Losses: L1: 18.42068099975586, L2: 3.7510304196075595e-08, L3: 1.0, L4: 50.005733489990234, L5: 0.16989950835704803
Epoch 5000, Loss: 69.01116180419922, Losses: L1: 18.42068099975586, L2: 3.60207756955333e-08, L3: 1.0, L4: 50.00552749633789, L5: 0.16989940404891968
Epoch 5500, Loss: 69.0110092163086, Losses: L1: 18.42068099975586, L2: 3.493541811394607e-08, L3: 1.0, L4: 50.005374908447266, L5: 0.1698993593454361
Epoch 6000, Loss: 69.01090240478516, Losses: L1: 18.42068099975586, L2: 3.4134085780124224e-08, L3: 1.0, L4: 50.00526428222656, L5: 0.16989931464195251
Epoch 6500, Loss: 69.01081085205078, Losses: L1: 18.42068099975586, L2: 3.3532892018683924e-08, L3: 1.0, L4: 50.00517654418945, L5: 0.16989926993846893
Epoch 7000, Loss: 69.01074981689453, Losses: L1: 18.42068099975586, L2: 3.3079111005918094e-08, L3: 1.0, L4: 50.0051155090332, L5: 0.16989925503730774
Epoch 7500, Loss: 69.01070404052734, Losses: L1: 18.42068099975586, L2: 3.2735592014887516e-08, L3: 1.0, L4: 50.005069732666016, L5: 0.16989924013614655
Epoch 8000, Loss: 69.01065826416016, Losses: L1: 18.42068099975586, L2: 3.247203750333938e-08, L3: 1.0, L4: 50.005027770996094, L5: 0.16989921033382416
Epoch 8500, Loss: 69.01063537597656, Losses: L1: 18.42068099975586, L2: 3.2267241323324924e-08, L3: 1.0, L4: 50.005001068115234, L5: 0.16989921033382416
Epoch 9000, Loss: 69.01061248779297, Losses: L1: 18.42068099975586, L2: 3.211000532132857e-08, L3: 1.0, L4: 50.004981994628906, L5: 0.16989921033382416
Epoch 9500, Loss: 69.0105972290039, Losses: L1: 18.42068099975586, L2: 3.1991376658879744e-08, L3: 1.0, L4: 50.00495910644531, L5: 0.16989919543266296
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0028562545776367, Constraint losses: L1: 6.348750114440918, L2: 0.0, L3: 0.9982536435127258, L4: 0.9982537031173706
Epoch 500, Loss: 0.0022105220705270767, Constraint losses: L1: -1.1058642864227295, L2: 0.0, L3: 0.0026573538780212402, L4: 0.0006590323755517602
Epoch 1000, Loss: 0.0013110064901411533, Constraint losses: L1: -1.1182676553726196, L2: 0.0, L3: 0.002214372158050537, L4: 0.0002149019856005907
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0020265579223633, Constraint losses: L1: 6.178708076477051, L2: 0.0, L3: 0.9979239106178284, L4: 0.9979239702224731
Epoch 500, Loss: 0.0020925444550812244, Constraint losses: L1: -1.0452866554260254, L2: 0.0, L3: 0.002567887306213379, L4: 0.0005699438042938709
Epoch 1000, Loss: 0.0012270798906683922, Constraint losses: L1: -1.1183152198791504, L2: 0.0, L3: 0.0021724700927734375, L4: 0.00017292509437538683
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 90.4749526977539, Losses: L1: 14.807418823242188, L2: 0.00031566491816192865, L3: 1.0001064538955688, L4: 74.79794311523438, L5: 0.36922192573547363
Epoch 500, Loss: 0.374008446931839, Losses: L1: -1.9515362977981567, L2: 0.17316217720508575, L3: 0.10118651390075684, L4: 2.091679096221924, L5: 0.010110157541930676
Epoch 1000, Loss: 10.899186134338379, Losses: L1: -1.0648584365844727, L2: 1.0620291233062744, L3: 0.3388787508010864, L4: 10.687970161437988, L5: 0.04460617154836655
Epoch 1500, Loss: 5.375248432159424, Losses: L1: -0.7154801487922668, L2: 0.15200988948345184, L3: 0.22309839725494385, L4: 5.805471420288086, L5: 0.02169807441532612
Epoch 2000, Loss: 0.5055872201919556, Losses: L1: -1.8028863668441772, L2: 0.40170958638191223, L3: 0.14840471744537354, L4: 1.8186988830566406, L5: 0.013862749561667442
Epoch 2500, Loss: -0.16398537158966064, Losses: L1: -1.7048323154449463, L2: 0.2691999077796936, L3: 0.13854116201400757, L4: 1.1947381496429443, L5: 0.007638340350240469
Epoch 3000, Loss: -0.3078927993774414, Losses: L1: -1.7406750917434692, L2: 0.24652841687202454, L3: 0.13609236478805542, L4: 1.1106295585632324, L5: 0.007578134536743164
Epoch 3500, Loss: -0.3919289708137512, Losses: L1: -1.7608433961868286, L2: 0.23571264743804932, L3: 0.13379955291748047, L4: 1.0594830513000488, L5: 0.006818954832851887
Epoch 4000, Loss: -0.44548049569129944, Losses: L1: -1.795365571975708, L2: 0.2379656732082367, L3: 0.13218903541564941, L4: 1.0389541387557983, L5: 0.00687071681022644
Epoch 4500, Loss: -0.48082780838012695, Losses: L1: -1.8182141780853271, L2: 0.2387036383152008, L3: 0.13133597373962402, L4: 1.0262157917022705, L5: 0.006798980757594109
Epoch 5000, Loss: -0.5062190890312195, Losses: L1: -1.8351572751998901, L2: 0.23950643837451935, L3: 0.13058942556381226, L4: 1.0173983573913574, L5: 0.006738625932484865
Epoch 5500, Loss: -0.5254071950912476, Losses: L1: -1.8513284921646118, L2: 0.24213320016860962, L3: 0.12974607944488525, L4: 1.012183427810669, L5: 0.006731645204126835
Epoch 6000, Loss: -0.5398693084716797, Losses: L1: -1.8603533506393433, L2: 0.24130302667617798, L3: 0.12969791889190674, L4: 1.0076165199279785, L5: 0.0067155552096664906
Epoch 6500, Loss: -0.5504962205886841, Losses: L1: -1.8657329082489014, L2: 0.23980320990085602, L3: 0.1296025514602661, L4: 1.003891110420227, L5: 0.006741062738001347
Epoch 7000, Loss: -0.5578439831733704, Losses: L1: -1.8690615892410278, L2: 0.23885971307754517, L3: 0.12947773933410645, L4: 1.0008962154388428, L5: 0.00672276271507144
Epoch 7500, Loss: -0.5625354647636414, Losses: L1: -1.871304988861084, L2: 0.238450825214386, L3: 0.12941312789916992, L4: 0.9988983869552612, L5: 0.006713809911161661
Epoch 8000, Loss: -0.5652020573616028, Losses: L1: -1.872314691543579, L2: 0.23807096481323242, L3: 0.12933123111724854, L4: 0.9976842403411865, L5: 0.006691888440400362
Epoch 8500, Loss: -0.5674269199371338, Losses: L1: -1.8735430240631104, L2: 0.2381889522075653, L3: 0.12921267747879028, L4: 0.9966249465942383, L5: 0.006695882882922888
Epoch 9000, Loss: -0.5687174797058105, Losses: L1: -1.8745135068893433, L2: 0.23831278085708618, L3: 0.12916243076324463, L4: 0.9962024092674255, L5: 0.006699593737721443
Epoch 9500, Loss: -0.569564700126648, Losses: L1: -1.8749600648880005, L2: 0.23833392560482025, L3: 0.12911105155944824, L4: 0.995816171169281, L5: 0.006689711473882198
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0035433769226074, Constraint losses: L1: 6.544500350952148, L2: 0.0, L3: 0.9984992742538452, L4: 0.9984995722770691
Epoch 500, Loss: 0.0019783354364335537, Constraint losses: L1: -1.0921177864074707, L2: 0.0, L3: 0.0025344491004943848, L4: 0.0005360041977837682
Epoch 1000, Loss: 0.0012219367781654, Constraint losses: L1: -1.116546392440796, L2: 0.0, L3: 0.002169013023376465, L4: 0.0001694702368695289
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.016798973083496, Constraint losses: L1: 16.630111694335938, L2: 0.00014919406385160983, L3: 1.0000097751617432, L4: 1.0000098943710327
Epoch 500, Loss: 0.0021780007518827915, Constraint losses: L1: -1.0992034673690796, L2: 0.0, L3: 0.002637803554534912, L4: 0.0006394007941707969
Epoch 1000, Loss: 0.0012952025281265378, Constraint losses: L1: -1.1197502613067627, L2: 0.0, L3: 0.0022072196006774902, L4: 0.0002077332464978099
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 80.99154663085938, Losses: L1: 8.906418800354004, L2: 2.4366732759517618e-05, L3: 0.9989526867866516, L4: 70.91363525390625, L5: 0.33599328994750977
Epoch 500, Loss: 1.6122705936431885, Losses: L1: -3.0882203578948975, L2: 0.5719481110572815, L3: 0.09549462795257568, L4: 4.027161598205566, L5: 0.02681697905063629
Epoch 1000, Loss: -2.403456211090088, Losses: L1: -3.397041082382202, L2: 0.20692753791809082, L3: 0.05409538745880127, L4: 0.7472390532493591, L5: 0.006185330916196108
Epoch 1500, Loss: -1.8692214488983154, Losses: L1: -3.7864112854003906, L2: 0.2278144210577011, L3: 0.0036699771881103516, L4: 1.6656221151351929, L5: 0.010959072038531303
Epoch 2000, Loss: -2.0912744998931885, Losses: L1: -3.53619647026062, L2: 0.14839191734790802, L3: 0.003613710403442383, L4: 1.276804804801941, L5: 0.00895912665873766
Epoch 2500, Loss: -2.9126336574554443, Losses: L1: -3.9039547443389893, L2: 0.18831786513328552, L3: 0.08541977405548096, L4: 0.7469292879104614, L5: 0.006681991275399923
Epoch 3000, Loss: -3.4968526363372803, Losses: L1: -3.9062764644622803, L2: 0.15411481261253357, L3: 0.08559310436248779, L4: 0.20357389748096466, L5: 0.004469295032322407
Epoch 3500, Loss: -3.5262327194213867, Losses: L1: -3.896263837814331, L2: 0.14002639055252075, L3: 0.07580018043518066, L4: 0.18466442823410034, L5: 0.0037201899103820324
Epoch 4000, Loss: -3.6275222301483154, Losses: L1: -3.9078707695007324, L2: 0.14117291569709778, L3: 0.08248090744018555, L4: 0.09001532196998596, L5: 0.003959888592362404
Epoch 4500, Loss: -3.6463897228240967, Losses: L1: -3.9044811725616455, L2: 0.1354905068874359, L3: 0.08008599281311035, L4: 0.07493092119693756, L5: 0.0038135398644953966
Epoch 5000, Loss: -3.657581329345703, Losses: L1: -3.9055635929107666, L2: 0.1339036226272583, L3: 0.08133983612060547, L4: 0.06579451262950897, L5: 0.003807127010077238
Epoch 5500, Loss: -3.658402442932129, Losses: L1: -3.9070651531219482, L2: 0.1336393654346466, L3: 0.08216977119445801, L4: 0.0663452222943306, L5: 0.003796534612774849
Epoch 6000, Loss: -3.6640467643737793, Losses: L1: -3.9086408615112305, L2: 0.1337171494960785, L3: 0.08279931545257568, L4: 0.0618627704679966, L5: 0.0038073023315519094
Epoch 6500, Loss: -3.666306972503662, Losses: L1: -3.90925931930542, L2: 0.133339524269104, L3: 0.08308696746826172, L4: 0.060442905873060226, L5: 0.0038132434710860252
Epoch 7000, Loss: -3.6673507690429688, Losses: L1: -3.9099888801574707, L2: 0.13333141803741455, L3: 0.08324384689331055, L4: 0.06005884334445, L5: 0.0038130690809339285
Epoch 7500, Loss: -3.6683411598205566, Losses: L1: -3.9106147289276123, L2: 0.1334764063358307, L3: 0.0833207368850708, L4: 0.05951744318008423, L5: 0.003809672547504306
Epoch 8000, Loss: -3.6689584255218506, Losses: L1: -3.9110264778137207, L2: 0.1335151046514511, L3: 0.08332717418670654, L4: 0.05927104875445366, L5: 0.0038091461174190044
Epoch 8500, Loss: -3.6694061756134033, Losses: L1: -3.9113762378692627, L2: 0.13358430564403534, L3: 0.08333683013916016, L4: 0.059100449085235596, L5: 0.0038085265550762415
Epoch 9000, Loss: -3.6697256565093994, Losses: L1: -3.911447525024414, L2: 0.1335042268037796, L3: 0.08327364921569824, L4: 0.05896604806184769, L5: 0.0038074750918895006
Epoch 9500, Loss: -3.6699609756469727, Losses: L1: -3.9115846157073975, L2: 0.1335243135690689, L3: 0.08325421810150146, L4: 0.0588572658598423, L5: 0.003807463450357318
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0020201206207275, Constraint losses: L1: 6.166713714599609, L2: 0.0, L3: 0.9979267120361328, L4: 0.997926652431488
Epoch 500, Loss: 0.002645357046276331, Constraint losses: L1: -1.0761003494262695, L2: 0.0, L3: 0.0028595924377441406, L4: 0.0008618651190772653
Epoch 1000, Loss: 0.001434514531865716, Constraint losses: L1: -1.118270993232727, L2: 0.0, L3: 0.0022760629653930664, L4: 0.0002767225378192961
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.018296480178833, Constraint losses: L1: 17.875699996948242, L2: 0.00017812468286138028, L3: 1.0001213550567627, L4: 1.0001213550567627
Epoch 500, Loss: 0.002009589923545718, Constraint losses: L1: -1.0260214805603027, L2: 0.0, L3: 0.002516806125640869, L4: 0.0005188054055906832
Epoch 1000, Loss: 0.001191239571198821, Constraint losses: L1: -1.1172091960906982, L2: 0.0, L3: 0.0021538734436035156, L4: 0.00015457527479156852
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 147.84768676757812, Losses: L1: 5.175158500671387, L2: 0.0, L3: 0.9938668012619019, L4: 71.00346374511719, L5: 0.3373401165008545
Epoch 500, Loss: 5.253588676452637, Losses: L1: -2.460892677307129, L2: 0.4144357442855835, L3: 0.06558966636657715, L4: 3.628328323364258, L5: 0.021188244223594666
Epoch 1000, Loss: 6.892096519470215, Losses: L1: -2.4123873710632324, L2: 0.49789515137672424, L3: 0.08457720279693604, L4: 4.378207683563232, L5: 0.015769580379128456
Epoch 1500, Loss: -0.6115856170654297, Losses: L1: -3.644791603088379, L2: 0.462408185005188, L3: 0.05380350351333618, L4: 1.2696048021316528, L5: 0.00937314797192812
Epoch 2000, Loss: -2.6251442432403564, Losses: L1: -3.7338199615478516, L2: 0.21476413309574127, L3: 0.014185905456542969, L4: 0.44223153591156006, L5: 0.004711216781288385
Epoch 2500, Loss: -2.6685638427734375, Losses: L1: -3.817247152328491, L2: 0.17965713143348694, L3: 0.06598317623138428, L4: 0.46678417921066284, L5: 0.004932174924761057
Epoch 3000, Loss: -3.063359498977661, Losses: L1: -3.752634048461914, L2: 0.14628103375434875, L3: 0.010274171829223633, L4: 0.26808878779411316, L5: 0.0033573557157069445
Epoch 3500, Loss: -3.285313606262207, Losses: L1: -3.814063310623169, L2: 0.15097711980342865, L3: 0.04714536666870117, L4: 0.17623382806777954, L5: 0.003464810084551573
Epoch 4000, Loss: -3.4519495964050293, Losses: L1: -3.8271279335021973, L2: 0.14645805954933167, L3: 0.06327271461486816, L4: 0.0976443737745285, L5: 0.003590364009141922
Epoch 4500, Loss: -3.482532262802124, Losses: L1: -3.833087205886841, L2: 0.14636744558811188, L3: 0.0693511962890625, L4: 0.08384693413972855, L5: 0.0036357007920742035
Epoch 5000, Loss: -3.4925625324249268, Losses: L1: -3.840296983718872, L2: 0.1472751498222351, L3: 0.07564103603363037, L4: 0.08040474355220795, L5: 0.0036583105102181435
Epoch 5500, Loss: -3.498558282852173, Losses: L1: -3.8420095443725586, L2: 0.14640922844409943, L3: 0.07684540748596191, L4: 0.0783955454826355, L5: 0.0036557912826538086
Epoch 6000, Loss: -3.502624273300171, Losses: L1: -3.844087600708008, L2: 0.14565230906009674, L3: 0.07986843585968018, L4: 0.07702413946390152, L5: 0.0036571624223142862
Epoch 6500, Loss: -3.5062832832336426, Losses: L1: -3.8436431884765625, L2: 0.14398132264614105, L3: 0.08056831359863281, L4: 0.07563651353120804, L5: 0.0036430670879781246
Epoch 7000, Loss: -3.509039878845215, Losses: L1: -3.8447585105895996, L2: 0.1434699445962906, L3: 0.08209776878356934, L4: 0.07468810677528381, L5: 0.0036474906373769045
Epoch 7500, Loss: -3.510643243789673, Losses: L1: -3.8454227447509766, L2: 0.142991304397583, L3: 0.08328497409820557, L4: 0.07416094839572906, L5: 0.003647920908406377
Epoch 8000, Loss: -3.5116770267486572, Losses: L1: -3.8464159965515137, L2: 0.14298319816589355, L3: 0.08438992500305176, L4: 0.07386770844459534, L5: 0.00365055026486516
Epoch 8500, Loss: -3.512746810913086, Losses: L1: -3.8465447425842285, L2: 0.14276760816574097, L3: 0.08452677726745605, L4: 0.07347151637077332, L5: 0.0036479735281318426
Epoch 9000, Loss: -3.513338327407837, Losses: L1: -3.846806526184082, L2: 0.14257806539535522, L3: 0.08496081829071045, L4: 0.07329270243644714, L5: 0.0036483542062342167
Epoch 9500, Loss: -3.5138020515441895, Losses: L1: -3.846991777420044, L2: 0.14252637326717377, L3: 0.08513796329498291, L4: 0.07313534617424011, L5: 0.003647478297352791
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0062079429626465, Constraint losses: L1: 7.410594940185547, L2: 0.0, L3: 0.9993987083435059, L4: 0.9993986487388611
Epoch 500, Loss: 0.002071522641927004, Constraint losses: L1: -1.099306583404541, L2: 0.0, L3: 0.0025845766067504883, L4: 0.000586252543143928
Epoch 1000, Loss: 0.0012613129802048206, Constraint losses: L1: -1.1180813312530518, L2: 0.0, L3: 0.0021893978118896484, L4: 0.00018999655731022358
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.018078327178955, Constraint losses: L1: 17.279953002929688, L2: 0.00040659907972440124, L3: 1.0001957416534424, L4: 1.0001959800720215
Epoch 500, Loss: 0.0024348911829292774, Constraint losses: L1: -1.0078403949737549, L2: 0.0, L3: 0.002720177173614502, L4: 0.000722554512321949
Epoch 1000, Loss: 0.0013084840029478073, Constraint losses: L1: -1.1189948320388794, L2: 0.0, L3: 0.0022134780883789062, L4: 0.00021400087280198932
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 152.41983032226562, Losses: L1: 11.128521919250488, L2: 0.00023048654838930815, L3: 0.999798595905304, L4: 70.22901153564453, L5: 0.33316662907600403
Epoch 500, Loss: 0.4347423315048218, Losses: L1: -2.895418882369995, L2: 0.3881289064884186, L3: 0.0763387680053711, L4: 1.4483033418655396, L5: 0.007256165146827698
Epoch 1000, Loss: -1.2108768224716187, Losses: L1: -3.7031192779541016, L2: 0.3047758936882019, L3: 0.015191793441772461, L4: 1.0858548879623413, L5: 0.008160931058228016
Epoch 1500, Loss: -2.5945675373077393, Losses: L1: -3.915128469467163, L2: 0.3604791760444641, L3: 0.07801663875579834, L4: 0.45776987075805664, L5: 0.005533718504011631
Epoch 2000, Loss: -3.3367719650268555, Losses: L1: -3.8582003116607666, L2: 0.1507667750120163, L3: 0.14827513694763184, L4: 0.14643093943595886, L5: 0.0036621165927499533
Epoch 2500, Loss: -2.7811858654022217, Losses: L1: -3.8645694255828857, L2: 0.1309959590435028, L3: 0.19461750984191895, L4: 0.42550551891326904, L5: 0.004067951813340187
Epoch 3000, Loss: -3.0402159690856934, Losses: L1: -3.8292765617370605, L2: 0.10179877281188965, L3: 0.1412949562072754, L4: 0.30662575364112854, L5: 0.0033629306126385927
Epoch 3500, Loss: -3.4183521270751953, Losses: L1: -3.869852304458618, L2: 0.10484042763710022, L3: 0.1786060333251953, L4: 0.12693166732788086, L5: 0.003493364667519927
Epoch 4000, Loss: -3.3983302116394043, Losses: L1: -3.879641056060791, L2: 0.11044175922870636, L3: 0.18279612064361572, L4: 0.1380326896905899, L5: 0.0034057307057082653
Epoch 4500, Loss: -3.4768617153167725, Losses: L1: -3.875671148300171, L2: 0.10286896675825119, L3: 0.17896604537963867, L4: 0.10153563320636749, L5: 0.0033859298564493656
Epoch 5000, Loss: -3.491140127182007, Losses: L1: -3.88217830657959, L2: 0.10801196098327637, L3: 0.17775416374206543, L4: 0.09534190595149994, L5: 0.00346552487462759
Epoch 5500, Loss: -3.5405428409576416, Losses: L1: -3.8795430660247803, L2: 0.10456214100122452, L3: 0.1740131378173828, L4: 0.07200274616479874, L5: 0.0034261427354067564
Epoch 6000, Loss: -3.546501398086548, Losses: L1: -3.880199670791626, L2: 0.10524950921535492, L3: 0.17135190963745117, L4: 0.06967438012361526, L5: 0.0034242370165884495
Epoch 6500, Loss: -3.5494556427001953, Losses: L1: -3.880012273788452, L2: 0.10473610460758209, L3: 0.16951394081115723, L4: 0.06882299482822418, L5: 0.0034176413901150227
Epoch 7000, Loss: -3.552288293838501, Losses: L1: -3.880977153778076, L2: 0.10565981268882751, L3: 0.16824007034301758, L4: 0.06774409115314484, L5: 0.003420928493142128
Epoch 7500, Loss: -3.554015874862671, Losses: L1: -3.880819082260132, L2: 0.10551847517490387, L3: 0.16685163974761963, L4: 0.06722013652324677, L5: 0.003418729407712817
Epoch 8000, Loss: -3.555044651031494, Losses: L1: -3.880932331085205, L2: 0.10566122829914093, L3: 0.1658005714416504, L4: 0.06695354729890823, L5: 0.0034191657323390245
Epoch 8500, Loss: -3.5561280250549316, Losses: L1: -3.881009578704834, L2: 0.10573700815439224, L3: 0.16509079933166504, L4: 0.06659063696861267, L5: 0.0034176807384938
Epoch 9000, Loss: -3.5567588806152344, Losses: L1: -3.8810479640960693, L2: 0.1057971641421318, L3: 0.16452550888061523, L4: 0.06640611588954926, L5: 0.0034171247389167547
Epoch 9500, Loss: -3.557199239730835, Losses: L1: -3.8810813426971436, L2: 0.10585968941450119, L3: 0.16409599781036377, L4: 0.06627866625785828, L5: 0.0034170488361269236
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.034168243408203, Constraint losses: L1: 18.42068099975586, L2: 0.005248961504548788, L3: 1.0052489042282104, L4: 1.0052497386932373
Epoch 500, Loss: 0.001962656155228615, Constraint losses: L1: -1.1061162948608398, L2: 0.0, L3: 0.00253373384475708, L4: 0.0005350386491045356
Epoch 1000, Loss: 0.0012325096176937222, Constraint losses: L1: -1.118330478668213, L2: 0.0, L3: 0.0021752119064331055, L4: 0.0001756282290443778
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022164821624756, Constraint losses: L1: 18.42068099975586, L2: 0.0012479763245210052, L3: 1.0012480020523071, L4: 1.0012480020523071
Epoch 500, Loss: 0.0023144246079027653, Constraint losses: L1: -1.0932410955429077, L2: 0.0, L3: 0.002702772617340088, L4: 0.0007048931438475847
Epoch 1000, Loss: 0.001334670465439558, Constraint losses: L1: -1.1198140382766724, L2: 0.0, L3: 0.002226889133453369, L4: 0.00022759549028705806
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 165.7435302734375, Losses: L1: 8.804651260375977, L2: 0.0007471952121704817, L3: 0.9938958287239075, L4: 77.82737731933594, L5: 0.3932128846645355
Epoch 500, Loss: 26.380247116088867, Losses: L1: 1.7707725763320923, L2: 1.6945871114730835, L3: 0.38063329458236694, L4: 11.316483497619629, L5: 0.045802462846040726
Epoch 1000, Loss: 12.123360633850098, Losses: L1: -0.4249992370605469, L2: 0.5935866832733154, L3: 0.30992960929870605, L4: 5.871340751647949, L5: 0.02856353670358658
Epoch 1500, Loss: 22.778730392456055, Losses: L1: 0.0390927754342556, L2: 0.3200410008430481, L3: 0.2833585739135742, L4: 11.081768035888672, L5: 0.05719108134508133
Epoch 2000, Loss: 5.8497314453125, Losses: L1: -1.080923318862915, L2: 0.28821131587028503, L3: 0.24903583526611328, L4: 3.2392756938934326, L5: 0.019687198102474213
Epoch 2500, Loss: 3.465008497238159, Losses: L1: -1.3590787649154663, L2: 0.29186421632766724, L3: 0.1917736530303955, L4: 2.205427646636963, L5: 0.012740540318191051
Epoch 3000, Loss: 2.2096216678619385, Losses: L1: -1.5451743602752686, L2: 0.3290628492832184, L3: 0.1704195737838745, L4: 1.662007212638855, L5: 0.008254490792751312
Epoch 3500, Loss: 1.7683252096176147, Losses: L1: -1.6217273473739624, L2: 0.3045117259025574, L3: 0.1598602533340454, L4: 1.4955981969833374, L5: 0.007207189686596394
Epoch 4000, Loss: 1.5080208778381348, Losses: L1: -1.675544023513794, L2: 0.2790778875350952, L3: 0.1541464924812317, L4: 1.4068505764007568, L5: 0.00685631250962615
Epoch 4500, Loss: 1.3364601135253906, Losses: L1: -1.6974236965179443, L2: 0.2626016438007355, L3: 0.14893203973770142, L4: 1.3416825532913208, L5: 0.006725532468408346
Epoch 5000, Loss: 1.215995192527771, Losses: L1: -1.7299830913543701, L2: 0.25533974170684814, L3: 0.14484000205993652, L4: 1.3022178411483765, L5: 0.006891421973705292
Epoch 5500, Loss: 1.12551748752594, Losses: L1: -1.7501243352890015, L2: 0.24976341426372528, L3: 0.14200818538665771, L4: 1.2704143524169922, L5: 0.007022794336080551
Epoch 6000, Loss: 1.062752604484558, Losses: L1: -1.7640807628631592, L2: 0.24533173441886902, L3: 0.13961708545684814, L4: 1.2487491369247437, L5: 0.007097424939274788
Epoch 6500, Loss: 1.023863434791565, Losses: L1: -1.7757210731506348, L2: 0.2417810559272766, L3: 0.1385936737060547, L4: 1.236965537071228, L5: 0.0072878277860581875
Epoch 7000, Loss: 0.9965511560440063, Losses: L1: -1.7803679704666138, L2: 0.2386312186717987, L3: 0.13785964250564575, L4: 1.227344036102295, L5: 0.007335015572607517
Epoch 7500, Loss: 0.9780439138412476, Losses: L1: -1.7840436697006226, L2: 0.2363862246274948, L3: 0.13741910457611084, L4: 1.2210869789123535, L5: 0.007408903446048498
Epoch 8000, Loss: 0.9652732014656067, Losses: L1: -1.786303997039795, L2: 0.23483839631080627, L3: 0.13706272840499878, L4: 1.2166415452957153, L5: 0.00746216019615531
Epoch 8500, Loss: 0.9567693471908569, Losses: L1: -1.7874287366867065, L2: 0.2336495965719223, L3: 0.13683408498764038, L4: 1.2135765552520752, L5: 0.007489156909286976
Epoch 9000, Loss: 0.9510992765426636, Losses: L1: -1.788273572921753, L2: 0.23281550407409668, L3: 0.13671886920928955, L4: 1.2115795612335205, L5: 0.007519411854445934
Epoch 9500, Loss: 0.947180986404419, Losses: L1: -1.7886276245117188, L2: 0.23224788904190063, L3: 0.13660907745361328, L4: 1.210098385810852, L5: 0.007529723923653364
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.01985502243042, Constraint losses: L1: 18.42068099975586, L2: 0.00047799674212001264, L3: 1.0004780292510986, L4: 1.0004781484603882
Epoch 500, Loss: 0.0022548844572156668, Constraint losses: L1: -1.0483254194259644, L2: 0.0, L3: 0.002650737762451172, L4: 0.0006524721975438297
Epoch 1000, Loss: 0.0012889759382233024, Constraint losses: L1: -1.1172471046447754, L2: 0.0, L3: 0.0022028088569641113, L4: 0.0002034142380580306
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.019991397857666, Constraint losses: L1: 18.42068099975586, L2: 0.0005235954304225743, L3: 1.000523567199707, L4: 1.0005234479904175
Epoch 500, Loss: 0.002208980266004801, Constraint losses: L1: -1.0347559452056885, L2: 0.0, L3: 0.002620995044708252, L4: 0.0006227411795407534
Epoch 1000, Loss: 0.0012631445424631238, Constraint losses: L1: -1.1174677610397339, L2: 0.0, L3: 0.002190113067626953, L4: 0.00019049920956604183
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 50.35398483276367, Losses: L1: 5.4800567626953125, L2: 0.0, L3: 0.9949406981468201, L4: 87.29730224609375, L5: 0.46066898107528687
Epoch 500, Loss: -1.0116511583328247, Losses: L1: -3.033771514892578, L2: 0.507321298122406, L3: 0.09443974494934082, L4: 2.826876163482666, L5: 0.013842440210282803
Epoch 1000, Loss: 1.836520791053772, Losses: L1: -1.6704565286636353, L2: 0.4341009557247162, L3: 0.20857882499694824, L4: 5.700845241546631, L5: 0.027749663218855858
Epoch 1500, Loss: -2.55399489402771, Losses: L1: -3.540168046951294, L2: 0.5472296476364136, L3: 0.0916440486907959, L4: 0.6857755184173584, L5: 0.008823701180517673
Epoch 2000, Loss: -2.947354316711426, Losses: L1: -3.820366144180298, L2: 0.5281291604042053, L3: 0.06607913970947266, L4: 0.5519838929176331, L5: 0.005623223725706339
Epoch 2500, Loss: -2.883491277694702, Losses: L1: -4.012356281280518, L2: 0.5824925303459167, L3: 0.036454856395721436, L4: 1.0120869874954224, L5: 0.0077482848428189754
Epoch 3000, Loss: -3.2525556087493896, Losses: L1: -3.9397037029266357, L2: 0.47295233607292175, L3: 0.0222092866897583, L4: 0.3794832229614258, L5: 0.004489357583224773
Epoch 3500, Loss: -3.308681011199951, Losses: L1: -3.9332618713378906, L2: 0.4439028203487396, L3: 0.01487886905670166, L4: 0.327799916267395, L5: 0.0037986007519066334
Epoch 4000, Loss: -3.3725745677948, Losses: L1: -3.964282989501953, L2: 0.4650939702987671, L3: 0.0017209053039550781, L4: 0.24575161933898926, L5: 0.004035328980535269
Epoch 4500, Loss: -3.3859498500823975, Losses: L1: -3.9472625255584717, L2: 0.4364793002605438, L3: 0.002714395523071289, L4: 0.2404109239578247, L5: 0.003827085718512535
Epoch 5000, Loss: -3.404327630996704, Losses: L1: -3.9443211555480957, L2: 0.42575857043266296, L3: 0.0006572604179382324, L4: 0.2232854813337326, L5: 0.003869445761665702
Epoch 5500, Loss: -3.409595012664795, Losses: L1: -3.941148519515991, L2: 0.4187852442264557, L3: 0.0008646249771118164, L4: 0.21998241543769836, L5: 0.003824553918093443
Epoch 6000, Loss: -3.4151430130004883, Losses: L1: -3.9352970123291016, L2: 0.40938419103622437, L3: 0.002076268196105957, L4: 0.21356597542762756, L5: 0.003821144113317132
Epoch 6500, Loss: -3.4192593097686768, Losses: L1: -3.9352400302886963, L2: 0.4074113070964813, L3: 0.000764310359954834, L4: 0.21178902685642242, L5: 0.003820860991254449
Epoch 7000, Loss: -3.4217851161956787, Losses: L1: -3.933845043182373, L2: 0.4045610725879669, L3: 0.00020968914031982422, L4: 0.21076761186122894, L5: 0.003810320282354951
Epoch 7500, Loss: -3.423128843307495, Losses: L1: -3.934305429458618, L2: 0.4036986827850342, L3: 8.881092071533203e-05, L4: 0.2109493613243103, L5: 0.0038291136734187603
Epoch 8000, Loss: -3.424602508544922, Losses: L1: -3.932873249053955, L2: 0.4016968011856079, L3: 8.89897346496582e-05, L4: 0.20915867388248444, L5: 0.003811424830928445
Epoch 8500, Loss: -3.4252655506134033, Losses: L1: -3.932892084121704, L2: 0.4011293351650238, L3: 8.7738037109375e-05, L4: 0.20900386571884155, L5: 0.003815018804743886
Epoch 9000, Loss: -3.42585825920105, Losses: L1: -3.9322476387023926, L2: 0.40027719736099243, L3: 2.4437904357910156e-05, L4: 0.20836782455444336, L5: 0.0038079649675637484
Epoch 9500, Loss: -3.4262027740478516, Losses: L1: -3.932020425796509, L2: 0.3997998535633087, L3: 5.0067901611328125e-05, L4: 0.20812785625457764, L5: 0.003807708155363798
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0231175422668457, Constraint losses: L1: 18.42068099975586, L2: 0.0015655695460736752, L3: 1.0015655755996704, L4: 1.0015658140182495
Epoch 500, Loss: 0.002314161043614149, Constraint losses: L1: -1.0860090255737305, L2: 0.0, L3: 0.002699136734008789, L4: 0.0007010332774370909
Epoch 1000, Loss: 0.0013295592507347465, Constraint losses: L1: -1.118284821510315, L2: 0.0, L3: 0.0022236108779907227, L4: 0.00022423329937737435
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022650718688965, Constraint losses: L1: 18.42068099975586, L2: 0.0014100964181125164, L3: 1.0014101266860962, L4: 1.0014097690582275
Epoch 500, Loss: 0.002378772245720029, Constraint losses: L1: -1.031943678855896, L2: 0.0, L3: 0.0027042627334594727, L4: 0.0007064532255753875
Epoch 1000, Loss: 0.0013065863167867064, Constraint losses: L1: -1.119019865989685, L2: 0.0, L3: 0.0022125244140625, L4: 0.00021308183204382658
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 60.124412536621094, Losses: L1: 18.42068099975586, L2: 0.0019785126205533743, L3: 1.0019681453704834, L4: 80.5728759765625, L5: 0.41334715485572815
Epoch 500, Loss: 3.3919286727905273, Losses: L1: -2.4719176292419434, L2: 1.028891921043396, L3: 0.2261928915977478, L4: 9.101643562316895, L5: 0.0579398050904274
Epoch 1000, Loss: -0.3777690827846527, Losses: L1: -2.292952060699463, L2: 0.41405731439590454, L3: 0.15257155895233154, L4: 2.675842046737671, L5: 0.01063314639031887
Epoch 1500, Loss: -0.5250199437141418, Losses: L1: -2.6600558757781982, L2: 0.4309556484222412, L3: 0.08956396579742432, L4: 3.210592746734619, L5: 0.009220078587532043
Epoch 2000, Loss: -2.1027557849884033, Losses: L1: -3.0557525157928467, L2: 0.5287918448448181, L3: 0.08658874034881592, L4: 0.642999529838562, L5: 0.01611630618572235
Epoch 2500, Loss: -2.274991750717163, Losses: L1: -3.155912160873413, L2: 0.5307371020317078, L3: 0.08285719156265259, L4: 0.5075339674949646, L5: 0.013559150509536266
Epoch 3000, Loss: -2.3941943645477295, Losses: L1: -3.249253511428833, L2: 0.5352751612663269, L3: 0.07648426294326782, L4: 0.4603922367095947, L5: 0.013103674165904522
Epoch 3500, Loss: -2.510622978210449, Losses: L1: -3.303133487701416, L2: 0.5193379521369934, L3: 0.07380819320678711, L4: 0.3739640414714813, L5: 0.012382423505187035
Epoch 4000, Loss: -2.589301347732544, Losses: L1: -3.3329622745513916, L2: 0.5021821856498718, L3: 0.07232558727264404, L4: 0.3165437579154968, L5: 0.010881180875003338
Epoch 4500, Loss: -2.6324961185455322, Losses: L1: -3.346040964126587, L2: 0.4887717664241791, L3: 0.07115823030471802, L4: 0.2865479588508606, L5: 0.010340987704694271
Epoch 5000, Loss: -2.6597042083740234, Losses: L1: -3.3629674911499023, L2: 0.4908795654773712, L3: 0.07067203521728516, L4: 0.2637670934200287, L5: 0.009828147478401661
Epoch 5500, Loss: -2.6740195751190186, Losses: L1: -3.3653271198272705, L2: 0.4822136163711548, L3: 0.07039272785186768, L4: 0.2586331367492676, L5: 0.00938463769853115
Epoch 6000, Loss: -2.6835341453552246, Losses: L1: -3.3734519481658936, L2: 0.48167380690574646, L3: 0.07025980949401855, L4: 0.2578049302101135, L5: 0.009081839583814144
Epoch 6500, Loss: -2.6906795501708984, Losses: L1: -3.3831024169921875, L2: 0.4846893548965454, L3: 0.07015252113342285, L4: 0.25717297196388245, L5: 0.00899449735879898
Epoch 7000, Loss: -2.695462703704834, Losses: L1: -3.3891384601593018, L2: 0.48616188764572144, L3: 0.07004624605178833, L4: 0.2571990489959717, L5: 0.008868193253874779
Epoch 7500, Loss: -2.699003219604492, Losses: L1: -3.3933310508728027, L2: 0.48714131116867065, L3: 0.06995636224746704, L4: 0.25682759284973145, L5: 0.008816355839371681
Epoch 8000, Loss: -2.7014994621276855, Losses: L1: -3.396259307861328, L2: 0.4876931607723236, L3: 0.06991928815841675, L4: 0.2567739188671112, L5: 0.008760571479797363
Epoch 8500, Loss: -2.7033004760742188, Losses: L1: -3.3983802795410156, L2: 0.4880794882774353, L3: 0.06987929344177246, L4: 0.25681284070014954, L5: 0.008714509196579456
Epoch 9000, Loss: -2.704573631286621, Losses: L1: -3.399902105331421, L2: 0.48830515146255493, L3: 0.06985676288604736, L4: 0.2569613754749298, L5: 0.008685912936925888
Epoch 9500, Loss: -2.7054762840270996, Losses: L1: -3.400801181793213, L2: 0.48835378885269165, L3: 0.06983649730682373, L4: 0.2569422125816345, L5: 0.008663385175168514
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0200557708740234, Constraint losses: L1: 18.42068099975586, L2: 0.0005448885494843125, L3: 1.0005449056625366, L4: 1.0005452632904053
Epoch 500, Loss: 0.002125371713191271, Constraint losses: L1: -1.1095237731933594, L2: 0.0, L3: 0.0026167631149291992, L4: 0.000618132296949625
Epoch 1000, Loss: 0.0012851980281993747, Constraint losses: L1: -1.1174606084823608, L2: 0.0, L3: 0.002201080322265625, L4: 0.0002015783975366503
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002279281616211, Constraint losses: L1: 6.2172698974609375, L2: 0.0, L3: 0.9980311393737793, L4: 0.9980310201644897
Epoch 500, Loss: 0.002360924379900098, Constraint losses: L1: -1.0615843534469604, L2: 0.0, L3: 0.0027102231979370117, L4: 0.0007122856331989169
Epoch 1000, Loss: 0.0013220359105616808, Constraint losses: L1: -1.119592547416687, L2: 0.0, L3: 0.0022205114364624023, L4: 0.00022111702128313482
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.4177131652832, Losses: L1: 18.42068099975586, L2: 0.000989927793852985, L3: 1.0009899139404297, L4: 72.57991790771484, L5: 0.35254696011543274
Epoch 500, Loss: 0.5574225187301636, Losses: L1: -2.279433250427246, L2: 0.5586583018302917, L3: 0.15756535530090332, L4: 4.156517505645752, L5: 0.021186642348766327
Epoch 1000, Loss: -1.8903943300247192, Losses: L1: -3.230666399002075, L2: 0.2596045732498169, L3: 0.06480967998504639, L4: 1.995591163635254, L5: 0.009031005203723907
Epoch 1500, Loss: -3.272617816925049, Losses: L1: -3.774103879928589, L2: 0.2018076628446579, L3: 0.01667630672454834, L4: 0.5501545071601868, L5: 0.003962219227105379
Epoch 2000, Loss: -3.0695576667785645, Losses: L1: -3.982274055480957, L2: 0.530026912689209, L3: 0.0033372044563293457, L4: 0.7384363412857056, L5: 0.005067088175565004
Epoch 2500, Loss: -3.2375612258911133, Losses: L1: -3.8435516357421875, L2: 0.28630128502845764, L3: 0.0018924474716186523, L4: 0.6191235184669495, L5: 0.0041174557991325855
Epoch 3000, Loss: -3.4532415866851807, Losses: L1: -3.888766288757324, L2: 0.2727707326412201, L3: 0.01035618782043457, L4: 0.29001736640930176, L5: 0.003694709623232484
Epoch 3500, Loss: -3.5124289989471436, Losses: L1: -3.910541296005249, L2: 0.2700616121292114, L3: 0.019606471061706543, L4: 0.20254290103912354, L5: 0.003586344886571169
Epoch 4000, Loss: -3.549311637878418, Losses: L1: -3.903123140335083, L2: 0.2547851502895355, L3: 0.015501618385314941, L4: 0.1529722511768341, L5: 0.0035193145740777254
Epoch 4500, Loss: -3.5515763759613037, Losses: L1: -3.9061286449432373, L2: 0.25149279832839966, L3: 0.005452752113342285, L4: 0.1810007095336914, L5: 0.003553330199792981
Epoch 5000, Loss: -3.5846164226531982, Losses: L1: -3.905702829360962, L2: 0.24245736002922058, L3: 0.00019240379333496094, L4: 0.14275728166103363, L5: 0.003528977045789361
Epoch 5500, Loss: -3.5900325775146484, Losses: L1: -3.8919177055358887, L2: 0.22471974790096283, L3: 0.0012761354446411133, L4: 0.13771025836467743, L5: 0.0035170859191566706
Epoch 6000, Loss: -3.596733808517456, Losses: L1: -3.8972129821777344, L2: 0.22653810679912567, L3: 0.00014084577560424805, L4: 0.13350442051887512, L5: 0.0035238901618868113
Epoch 6500, Loss: -3.6006197929382324, Losses: L1: -3.897550582885742, L2: 0.22455067932605743, L3: 0.0005004405975341797, L4: 0.12965062260627747, L5: 0.0035272003151476383
Epoch 7000, Loss: -3.6014392375946045, Losses: L1: -3.900251626968384, L2: 0.22463388741016388, L3: 0.003049492835998535, L4: 0.12813183665275574, L5: 0.003531554713845253
Epoch 7500, Loss: -3.603595018386841, Losses: L1: -3.896113634109497, L2: 0.22172895073890686, L3: 0.0005180835723876953, L4: 0.12642592191696167, L5: 0.003529340960085392
Epoch 8000, Loss: -3.6047003269195557, Losses: L1: -3.8964521884918213, L2: 0.22178535163402557, L3: 2.3603439331054688e-05, L4: 0.12575677037239075, L5: 0.0035323232877999544
Epoch 8500, Loss: -3.605337142944336, Losses: L1: -3.8976974487304688, L2: 0.2220233827829361, L3: 0.0005792379379272461, L4: 0.1253870278596878, L5: 0.003531885100528598
Epoch 9000, Loss: -3.6057801246643066, Losses: L1: -3.8978521823883057, L2: 0.22196727991104126, L3: 0.0004856586456298828, L4: 0.12510226666927338, L5: 0.003534133778885007
Epoch 9500, Loss: -3.606121778488159, Losses: L1: -3.8976807594299316, L2: 0.22180043160915375, L3: 0.00031638145446777344, L4: 0.12474901974201202, L5: 0.003533849259838462
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.026254653930664, Constraint losses: L1: 18.42068099975586, L2: 0.002611171454191208, L3: 1.0026111602783203, L4: 1.0026116371154785
Epoch 500, Loss: 0.0022235866636037827, Constraint losses: L1: -1.07794189453125, L2: 0.0, L3: 0.002649962902069092, L4: 0.0006515658460557461
Epoch 1000, Loss: 0.0012906091287732124, Constraint losses: L1: -1.1167585849761963, L2: 0.0, L3: 0.00220334529876709, L4: 0.00020402252266649157
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9902901649475098, Constraint losses: L1: 4.841958999633789, L2: 0.0, L3: 0.9927253127098083, L4: 0.9927228689193726
Epoch 500, Loss: 0.0020078031811863184, Constraint losses: L1: -1.116391658782959, L2: 0.0, L3: 0.0025613903999328613, L4: 0.0005628044600598514
Epoch 1000, Loss: 0.0012538217706605792, Constraint losses: L1: -1.1193755865097046, L2: 0.0, L3: 0.0021863579750061035, L4: 0.0001868395193014294
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 101.09064483642578, Losses: L1: 18.42068099975586, L2: 0.0056143212132155895, L3: 1.0049819946289062, L4: 81.44577026367188, L5: 0.4271996021270752
Epoch 500, Loss: 3.49289608001709, Losses: L1: -0.4563365578651428, L2: 1.2269117832183838, L3: 0.06600117683410645, L4: 2.648480176925659, L5: 0.01567867211997509
Epoch 1000, Loss: -0.6841080188751221, Losses: L1: -3.463538885116577, L2: 0.46102258563041687, L3: 0.05325043201446533, L4: 2.26027512550354, L5: 0.00976557843387127
Epoch 1500, Loss: 37.49909210205078, Losses: L1: -2.7612106800079346, L2: 0.8837820887565613, L3: 0.8796796798706055, L4: 38.43682098388672, L5: 0.12003806978464127
Epoch 2000, Loss: -1.3151851892471313, Losses: L1: -3.2567949295043945, L2: 0.3731714189052582, L3: 0.08612948656082153, L4: 1.4792560338974, L5: 0.00610584020614624
Epoch 2500, Loss: -2.7632558345794678, Losses: L1: -3.747870683670044, L2: 0.3987219035625458, L3: 0.06600695848464966, L4: 0.5176807045936584, L5: 0.004410946741700172
Epoch 3000, Loss: -3.0616934299468994, Losses: L1: -3.748286247253418, L2: 0.34692132472991943, L3: 0.05869591236114502, L4: 0.2791350185871124, L5: 0.003681013360619545
Epoch 3500, Loss: -3.153752326965332, Losses: L1: -3.796217441558838, L2: 0.35033032298088074, L3: 0.034153759479522705, L4: 0.2561292350292206, L5: 0.0037034412380307913
Epoch 4000, Loss: -3.21875, Losses: L1: -3.8350186347961426, L2: 0.3522735834121704, L3: 0.01763594150543213, L4: 0.2445303499698639, L5: 0.003658055095002055
Epoch 4500, Loss: -3.2533681392669678, Losses: L1: -3.8604581356048584, L2: 0.3526676893234253, L3: 0.015136778354644775, L4: 0.23749956488609314, L5: 0.0035725608468055725
Epoch 5000, Loss: -3.2777457237243652, Losses: L1: -3.8706727027893066, L2: 0.3514685332775116, L3: 0.003475666046142578, L4: 0.2361636459827423, L5: 0.0036382311955094337
Epoch 5500, Loss: -3.3030972480773926, Losses: L1: -3.8678927421569824, L2: 0.3365219235420227, L3: 0.0007662773132324219, L4: 0.2257200926542282, L5: 0.00357425375841558
Epoch 6000, Loss: -3.308623790740967, Losses: L1: -3.869249105453491, L2: 0.33159688115119934, L3: 0.002269268035888672, L4: 0.22496555745601654, L5: 0.003587363287806511
Epoch 6500, Loss: -3.319342851638794, Losses: L1: -3.866304636001587, L2: 0.32369741797447205, L3: 0.0007768869400024414, L4: 0.22070953249931335, L5: 0.0035561728291213512
Epoch 7000, Loss: -3.3238189220428467, Losses: L1: -3.865532636642456, L2: 0.32021263241767883, L3: 0.00027889013290405273, L4: 0.21944880485534668, L5: 0.003546770429238677
Epoch 7500, Loss: -3.3267762660980225, Losses: L1: -3.86527156829834, L2: 0.31778550148010254, L3: 0.0005325675010681152, L4: 0.21840469539165497, L5: 0.0035448179114609957
Epoch 8000, Loss: -3.3289363384246826, Losses: L1: -3.8648269176483154, L2: 0.3160233199596405, L3: 0.0004417896270751953, L4: 0.21765390038490295, L5: 0.0035428565461188555
Epoch 8500, Loss: -3.3302080631256104, Losses: L1: -3.864990472793579, L2: 0.3153596818447113, L3: 0.0002770423889160156, L4: 0.21737319231033325, L5: 0.0035452304873615503
Epoch 9000, Loss: -3.331616163253784, Losses: L1: -3.864379644393921, L2: 0.3141859769821167, L3: 7.033348083496094e-06, L4: 0.21679989993572235, L5: 0.003540865145623684
Epoch 9500, Loss: -3.3320415019989014, Losses: L1: -3.8641648292541504, L2: 0.31355908513069153, L3: 0.00016582012176513672, L4: 0.21662850677967072, L5: 0.0035393566358834505
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.002612590789795, Constraint losses: L1: 6.301543235778809, L2: 0.0, L3: 0.9981555342674255, L4: 0.9981555938720703
Epoch 500, Loss: 0.0023460085503757, Constraint losses: L1: -0.981204628944397, L2: 0.0, L3: 0.0026625394821166992, L4: 0.0006646738620474935
Epoch 1000, Loss: 0.0012690435396507382, Constraint losses: L1: -1.11606764793396, L2: 0.0, L3: 0.002192258834838867, L4: 0.0001928524870891124
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.003289222717285, Constraint losses: L1: 6.42950963973999, L2: 0.0, L3: 0.9984299540519714, L4: 0.9984298348426819
Epoch 500, Loss: 0.002138112671673298, Constraint losses: L1: -1.073003888130188, L2: 0.0, L3: 0.0026046037673950195, L4: 0.0006065130000934005
Epoch 1000, Loss: 0.0012540423776954412, Constraint losses: L1: -1.1198484897613525, L2: 0.0, L3: 0.0021866559982299805, L4: 0.00018723492394201458
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 92.97785186767578, Losses: L1: 5.381070613861084, L2: 0.00017932670016307384, L3: 0.9963387846946716, L4: 86.15184020996094, L5: 0.44842180609703064
Epoch 500, Loss: 0.3390210270881653, Losses: L1: -2.8796114921569824, L2: 0.5901997685432434, L3: 0.06637799739837646, L4: 2.5518245697021484, L5: 0.010230360552668571
Epoch 1000, Loss: -2.1015236377716064, Losses: L1: -3.4180755615234375, L2: 0.5635401010513306, L3: 0.07119786739349365, L4: 0.6725918054580688, L5: 0.009222173132002354
Epoch 1500, Loss: -1.451483130455017, Losses: L1: -3.394876480102539, L2: 0.5657856464385986, L3: 0.07852822542190552, L4: 1.2939646244049072, L5: 0.005114882718771696
Epoch 2000, Loss: -2.1267073154449463, Losses: L1: -3.7613461017608643, L2: 0.48741620779037476, L3: 0.05771291255950928, L4: 1.084834337234497, L5: 0.004675394389778376
Epoch 2500, Loss: -2.860875368118286, Losses: L1: -3.9116885662078857, L2: 0.47929394245147705, L3: 0.003692626953125, L4: 0.5628252625465393, L5: 0.0050013004802167416
Epoch 3000, Loss: -3.242501735687256, Losses: L1: -3.8940861225128174, L2: 0.39420774579048157, L3: 0.005776882171630859, L4: 0.2461617887020111, L5: 0.005438037682324648
Epoch 3500, Loss: -3.3047850131988525, Losses: L1: -3.9018235206604004, L2: 0.38002443313598633, L3: 0.002049088478088379, L4: 0.20952092111110687, L5: 0.005444284528493881
Epoch 4000, Loss: -3.321593761444092, Losses: L1: -3.8982183933258057, L2: 0.36362046003341675, L3: 0.0019249916076660156, L4: 0.2057691514492035, L5: 0.005309976637363434
Epoch 4500, Loss: -3.3378164768218994, Losses: L1: -3.9019222259521484, L2: 0.3528476357460022, L3: 0.0024406909942626953, L4: 0.20333042740821838, L5: 0.005486990790814161
Epoch 5000, Loss: -3.354142427444458, Losses: L1: -3.8987858295440674, L2: 0.34273141622543335, L3: 0.001741170883178711, L4: 0.19473913311958313, L5: 0.005431545898318291
Epoch 5500, Loss: -3.361992597579956, Losses: L1: -3.8966691493988037, L2: 0.33641722798347473, L3: 0.0008280277252197266, L4: 0.19202381372451782, L5: 0.005407583899796009
Epoch 6000, Loss: -3.3679556846618652, Losses: L1: -3.89785099029541, L2: 0.33306658267974854, L3: 0.0011851787567138672, L4: 0.19016756117343903, L5: 0.005475978367030621
Epoch 6500, Loss: -3.3723461627960205, Losses: L1: -3.897428512573242, L2: 0.33002474904060364, L3: 0.000827789306640625, L4: 0.1887299120426178, L5: 0.005499820224940777
Epoch 7000, Loss: -3.3754122257232666, Losses: L1: -3.8971168994903564, L2: 0.3280509412288666, L3: 6.151199340820312e-05, L4: 0.18804901838302612, L5: 0.005543207284063101
Epoch 7500, Loss: -3.377223491668701, Losses: L1: -3.8961281776428223, L2: 0.3258393704891205, L3: 0.00011229515075683594, L4: 0.18739265203475952, L5: 0.005560419987887144
Epoch 8000, Loss: -3.378483772277832, Losses: L1: -3.898012638092041, L2: 0.3258950114250183, L3: 0.000813603401184082, L4: 0.18723013997077942, L5: 0.005589877255260944
Epoch 8500, Loss: -3.3798582553863525, Losses: L1: -3.8972668647766113, L2: 0.32508501410484314, L3: 1.2993812561035156e-05, L4: 0.18671754002571106, L5: 0.0055931038223207
Epoch 9000, Loss: -3.3804526329040527, Losses: L1: -3.8974266052246094, L2: 0.32468098402023315, L3: 9.441375732421875e-05, L4: 0.18659614026546478, L5: 0.00560246454551816
Epoch 9500, Loss: -3.3809406757354736, Losses: L1: -3.8972933292388916, L2: 0.32428112626075745, L3: 4.9948692321777344e-05, L4: 0.1864146739244461, L5: 0.00560677470639348
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9991544485092163, Constraint losses: L1: 5.703617572784424, L2: 0.0, L3: 0.9967254996299744, L4: 0.99672532081604
Epoch 500, Loss: 0.002094883704558015, Constraint losses: L1: -1.108346700668335, L2: 0.0, L3: 0.0026009082794189453, L4: 0.0006023221649229527
Epoch 1000, Loss: 0.0012760742101818323, Constraint losses: L1: -1.115720272064209, L2: 0.0, L3: 0.0021956562995910645, L4: 0.00019613832409959286
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.024056911468506, Constraint losses: L1: 18.42068099975586, L2: 0.001878769020549953, L3: 1.0018787384033203, L4: 1.0018786191940308
Epoch 500, Loss: 0.001985217910259962, Constraint losses: L1: -1.0485565662384033, L2: 0.0, L3: 0.0025159120559692383, L4: 0.000517862499691546
Epoch 1000, Loss: 0.0011951189953833818, Constraint losses: L1: -1.117147445678711, L2: 0.0, L3: 0.0021558403968811035, L4: 0.00015642604557797313
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 91.37246704101562, Losses: L1: 14.102882385253906, L2: 0.0025038488674908876, L3: 1.0014805793762207, L4: 75.50297546386719, L5: 0.38131365180015564
Epoch 500, Loss: -0.6000092625617981, Losses: L1: -2.6133580207824707, L2: 0.4350431561470032, L3: 0.06989842653274536, L4: 1.4873549938201904, L5: 0.010526148602366447
Epoch 1000, Loss: -0.23747220635414124, Losses: L1: -3.419027090072632, L2: 0.4528452157974243, L3: 0.06488597393035889, L4: 2.639002799987793, L5: 0.012410324066877365
Epoch 1500, Loss: -2.728360891342163, Losses: L1: -3.7279069423675537, L2: 0.21908512711524963, L3: 0.003313779830932617, L4: 0.7686884999275208, L5: 0.004229310434311628
Epoch 2000, Loss: -2.989161252975464, Losses: L1: -3.581932783126831, L2: 0.2033901959657669, L3: 0.013008832931518555, L4: 0.3686372637748718, L5: 0.0038675994146615267
Epoch 2500, Loss: -3.1277949810028076, Losses: L1: -3.7540369033813477, L2: 0.2372715026140213, L3: 0.011033296585083008, L4: 0.3689481019973755, L5: 0.004494515713304281
Epoch 3000, Loss: -3.1915831565856934, Losses: L1: -3.7598321437835693, L2: 0.21198803186416626, L3: 0.0016770362854003906, L4: 0.3455544114112854, L5: 0.004514757543802261
Epoch 3500, Loss: -3.451892137527466, Losses: L1: -3.7891900539398193, L2: 0.21416698396205902, L3: 0.00830543041229248, L4: 0.10705217719078064, L5: 0.0038866724353283644
Epoch 4000, Loss: -3.4701685905456543, Losses: L1: -3.791329860687256, L2: 0.20508535206317902, L3: 0.009008646011352539, L4: 0.09944447875022888, L5: 0.0038114646449685097
Epoch 4500, Loss: -3.4821789264678955, Losses: L1: -3.7910146713256836, L2: 0.19944684207439423, L3: 0.008555412292480469, L4: 0.09330160170793533, L5: 0.003765948349609971
Epoch 5000, Loss: -3.490448474884033, Losses: L1: -3.789381742477417, L2: 0.195352241396904, L3: 0.007010698318481445, L4: 0.0890788808465004, L5: 0.0037457046564668417
Epoch 5500, Loss: -3.4932773113250732, Losses: L1: -3.7893505096435547, L2: 0.19363005459308624, L3: 0.0062062740325927734, L4: 0.0887894406914711, L5: 0.0037237463984638453
Epoch 6000, Loss: -3.498713493347168, Losses: L1: -3.788361072540283, L2: 0.19184835255146027, L3: 0.004908204078674316, L4: 0.08545753359794617, L5: 0.0037168448325246572
Epoch 6500, Loss: -3.5007853507995605, Losses: L1: -3.787108898162842, L2: 0.19017264246940613, L3: 0.003945827484130859, L4: 0.0847923681139946, L5: 0.0037062768824398518
Epoch 7000, Loss: -3.5024502277374268, Losses: L1: -3.7870781421661377, L2: 0.1894952803850174, L3: 0.003592967987060547, L4: 0.08413653075695038, L5: 0.0037015401758253574
Epoch 7500, Loss: -3.5035669803619385, Losses: L1: -3.786372184753418, L2: 0.1887844204902649, L3: 0.0028486251831054688, L4: 0.08378288149833679, L5: 0.003694704733788967
Epoch 8000, Loss: -3.504415512084961, Losses: L1: -3.785952091217041, L2: 0.18838147819042206, L3: 0.002302408218383789, L4: 0.08347418159246445, L5: 0.0036892478819936514
Epoch 8500, Loss: -3.5050201416015625, Losses: L1: -3.785365104675293, L2: 0.18801508843898773, L3: 0.0017018318176269531, L4: 0.08325710892677307, L5: 0.00368545763194561
Epoch 9000, Loss: -3.505446672439575, Losses: L1: -3.785222291946411, L2: 0.18806472420692444, L3: 0.0012443065643310547, L4: 0.08309995383024216, L5: 0.0036833633203059435
Epoch 9500, Loss: -3.505706548690796, Losses: L1: -3.7849624156951904, L2: 0.18795464932918549, L3: 0.0008893013000488281, L4: 0.08304981142282486, L5: 0.0036811132449656725
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.023862361907959, Constraint losses: L1: 18.42068099975586, L2: 0.0018137727165594697, L3: 1.0018137693405151, L4: 1.0018141269683838
Epoch 500, Loss: 0.0023841317743062973, Constraint losses: L1: -1.1098871231079102, L2: 0.0, L3: 0.002746105194091797, L4: 0.0007479137275367975
Epoch 1000, Loss: 0.0013745817122980952, Constraint losses: L1: -1.1170774698257446, L2: 0.0, L3: 0.0022455453872680664, L4: 0.0002461138356011361
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.003082275390625, Constraint losses: L1: 6.399618148803711, L2: 0.0, L3: 0.9983413219451904, L4: 0.9983412623405457
Epoch 500, Loss: 0.002136159222573042, Constraint losses: L1: -1.1059372425079346, L2: 0.0, L3: 0.0026203393936157227, L4: 0.0006217570044100285
Epoch 1000, Loss: 0.0012880489230155945, Constraint losses: L1: -1.1200262308120728, L2: 0.0, L3: 0.002203822135925293, L4: 0.00020425309776328504
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 176.20858764648438, Losses: L1: 10.031959533691406, L2: 0.00035830517299473286, L3: 0.9981804490089417, L4: 82.48380279541016, L5: 0.4209478497505188
Epoch 500, Loss: 110.13389587402344, Losses: L1: 9.044078826904297, L2: 0.0, L3: 0.9998998045921326, L4: 50.002376556396484, L5: 0.17032909393310547
Epoch 1000, Loss: 105.2264175415039, Losses: L1: 3.2378029823303223, L2: 0.005131135229021311, L3: 0.9814953207969666, L4: 50.457862854003906, L5: 0.17252781987190247
Epoch 1500, Loss: 104.30867004394531, Losses: L1: 2.518603563308716, L2: 0.003540384117513895, L3: 0.9535624980926514, L4: 50.37284851074219, L5: 0.1745246797800064
Epoch 2000, Loss: 13.344193458557129, Losses: L1: -0.9393371939659119, L2: 0.4420406222343445, L3: 0.29725146293640137, L4: 6.765294551849365, L5: 0.027299324050545692
Epoch 2500, Loss: 14.517422676086426, Losses: L1: -0.4272124767303467, L2: 0.32484936714172363, L3: 0.2625826597213745, L4: 7.169505596160889, L5: 0.0363839715719223
Epoch 3000, Loss: 7.72604513168335, Losses: L1: -0.44560569524765015, L2: 0.42703327536582947, L3: 0.23987650871276855, L4: 3.7437915802001953, L5: 0.034315794706344604
Epoch 3500, Loss: 7.227473735809326, Losses: L1: -0.38021567463874817, L2: 0.4429592788219452, L3: 0.2355138063430786, L4: 3.4553189277648926, L5: 0.037156980484724045
Epoch 4000, Loss: 6.99951696395874, Losses: L1: -0.39990168809890747, L2: 0.43837475776672363, L3: 0.2343427538871765, L4: 3.3542397022247314, L5: 0.03644363582134247
Epoch 4500, Loss: 6.816322326660156, Losses: L1: -0.3985903263092041, L2: 0.4262889623641968, L3: 0.23263752460479736, L4: 3.2687788009643555, L5: 0.03685728833079338
Epoch 5000, Loss: 6.7043137550354, Losses: L1: -0.42776498198509216, L2: 0.4278417229652405, L3: 0.23150396347045898, L4: 3.2274844646453857, L5: 0.035528410226106644
Epoch 5500, Loss: 6.599157810211182, Losses: L1: -0.43036267161369324, L2: 0.422322541475296, L3: 0.23119354248046875, L4: 3.179079055786133, L5: 0.035692114382982254
Epoch 6000, Loss: 6.52341890335083, Losses: L1: -0.4326381981372833, L2: 0.4176444709300995, L3: 0.2310727834701538, L4: 3.144705295562744, L5: 0.035857800394296646
Epoch 6500, Loss: 6.468777179718018, Losses: L1: -0.4368067979812622, L2: 0.4149602949619293, L3: 0.2310999631881714, L4: 3.120795726776123, L5: 0.035864487290382385
Epoch 7000, Loss: 6.4274210929870605, Losses: L1: -0.43854355812072754, L2: 0.4124408960342407, L3: 0.2309880256652832, L4: 3.1022799015045166, L5: 0.035951513797044754
Epoch 7500, Loss: 6.398314476013184, Losses: L1: -0.4414224922657013, L2: 0.4118911921977997, L3: 0.2310103178024292, L4: 3.0894393920898438, L5: 0.03591352328658104
Epoch 8000, Loss: 6.378024578094482, Losses: L1: -0.4414447247982025, L2: 0.4103297293186188, L3: 0.23074156045913696, L4: 3.080199718475342, L5: 0.03599710389971733
Epoch 8500, Loss: 6.36287260055542, Losses: L1: -0.44381576776504517, L2: 0.4103025794029236, L3: 0.23075568675994873, L4: 3.073833465576172, L5: 0.03592580929398537
Epoch 9000, Loss: 6.353890895843506, Losses: L1: -0.44499140977859497, L2: 0.4102538824081421, L3: 0.23070669174194336, L4: 3.0699875354766846, L5: 0.03589341416954994
Epoch 9500, Loss: 6.347776412963867, Losses: L1: -0.4454692602157593, L2: 0.4100531041622162, L3: 0.23067080974578857, L4: 3.0672881603240967, L5: 0.03589017689228058
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0001773834228516, Constraint losses: L1: 5.806655406951904, L2: 0.0, L3: 0.9971858263015747, L4: 0.9971849918365479
Epoch 500, Loss: 0.0022093872539699078, Constraint losses: L1: -1.0708199739456177, L2: 0.0, L3: 0.0026391148567199707, L4: 0.0006410925416275859
Epoch 1000, Loss: 0.0012844586744904518, Constraint losses: L1: -1.1182078123092651, L2: 0.0, L3: 0.0022011399269104004, L4: 0.00020152650540694594
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9963619709014893, Constraint losses: L1: 5.367025852203369, L2: 0.0, L3: 0.9954977035522461, L4: 0.9954971671104431
Epoch 500, Loss: 0.002483135322108865, Constraint losses: L1: -1.1006863117218018, L2: 0.0, L3: 0.0027909278869628906, L4: 0.0007928937557153404
Epoch 1000, Loss: 0.0013970719883218408, Constraint losses: L1: -1.1193315982818604, L2: 0.0, L3: 0.0022578835487365723, L4: 0.00025852012913674116
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 172.75717163085938, Losses: L1: 10.155447959899902, L2: 0.0010833472479134798, L3: 0.9987053871154785, L4: 80.59857940673828, L5: 0.4047745168209076
Epoch 500, Loss: 7.608555793762207, Losses: L1: -3.04008150100708, L2: 0.6770965456962585, L3: 0.09773141145706177, L4: 4.923693656921387, L5: 0.026422252878546715
Epoch 1000, Loss: 1.8825013637542725, Losses: L1: -2.780592918395996, L2: 0.6551963686943054, L3: 0.10879874229431152, L4: 1.9391319751739502, L5: 0.02083512209355831
Epoch 1500, Loss: -1.312840223312378, Losses: L1: -3.184267044067383, L2: 0.3501228392124176, L3: 0.05873394012451172, L4: 0.7277371883392334, L5: 0.007095630280673504
Epoch 2000, Loss: -2.4745590686798096, Losses: L1: -3.5985562801361084, L2: 0.2619984745979309, L3: 0.08123505115509033, L4: 0.38817381858825684, L5: 0.004416206385940313
Epoch 2500, Loss: 6.711230754852295, Losses: L1: -1.4061620235443115, L2: 4.174628257751465, L3: 0.038405537605285645, L4: 1.945662498474121, L5: 0.013033968396484852
Epoch 3000, Loss: -0.4600333869457245, Losses: L1: -2.8935887813568115, L2: 1.1613150835037231, L3: 0.0815199613571167, L4: 0.5921430587768555, L5: 0.006434236187487841
Epoch 3500, Loss: -1.5702210664749146, Losses: L1: -2.918853282928467, L2: 0.6304562091827393, L3: 0.053183794021606445, L4: 0.330289751291275, L5: 0.004412769805639982
Epoch 4000, Loss: -1.9251803159713745, Losses: L1: -2.9895153045654297, L2: 0.5246761441230774, L3: 0.058296144008636475, L4: 0.23859357833862305, L5: 0.0041755628772079945
Epoch 4500, Loss: -2.07556414604187, Losses: L1: -3.0432095527648926, L2: 0.4953519403934479, L3: 0.05159813165664673, L4: 0.2082982361316681, L5: 0.004098942037671804
Epoch 5000, Loss: -2.179273843765259, Losses: L1: -3.079220771789551, L2: 0.4602251350879669, L3: 0.05486142635345459, L4: 0.1904039829969406, L5: 0.004052314441651106
Epoch 5500, Loss: -2.2402870655059814, Losses: L1: -3.1059253215789795, L2: 0.45014676451683044, L3: 0.05308425426483154, L4: 0.179194837808609, L5: 0.0040177833288908005
Epoch 6000, Loss: -2.2823405265808105, Losses: L1: -3.1185998916625977, L2: 0.43426644802093506, L3: 0.05624490976333618, L4: 0.1708766520023346, L5: 0.003994730766862631
Epoch 6500, Loss: -2.321614980697632, Losses: L1: -3.1308717727661133, L2: 0.41489169001579285, L3: 0.062265098094940186, L4: 0.1640554666519165, L5: 0.003988889046013355
Epoch 7000, Loss: -2.387009859085083, Losses: L1: -3.152705192565918, L2: 0.38601234555244446, L3: 0.05618053674697876, L4: 0.1597558856010437, L5: 0.003990887198597193
Epoch 7500, Loss: -2.446042776107788, Losses: L1: -3.168501138687134, L2: 0.35722771286964417, L3: 0.05434149503707886, L4: 0.15345090627670288, L5: 0.0039869691245257854
Epoch 8000, Loss: -2.484116792678833, Losses: L1: -3.1810319423675537, L2: 0.35433581471443176, L3: 0.045369088649749756, L4: 0.1466233730316162, L5: 0.0039635226130485535
Epoch 8500, Loss: -2.5021791458129883, Losses: L1: -3.193225383758545, L2: 0.35760781168937683, L3: 0.04294472932815552, L4: 0.14326782524585724, L5: 0.0039580147713422775
Epoch 9000, Loss: -2.509122848510742, Losses: L1: -3.2029166221618652, L2: 0.3625774681568146, L3: 0.04333662986755371, L4: 0.14196136593818665, L5: 0.0039570946246385574
Epoch 9500, Loss: -2.5133602619171143, Losses: L1: -3.2099533081054688, L2: 0.36625537276268005, L3: 0.04381537437438965, L4: 0.14128132164478302, L5: 0.003959729336202145
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0015106201171875, Constraint losses: L1: 6.025609016418457, L2: 0.0, L3: 0.9977427124977112, L4: 0.9977421760559082
Epoch 500, Loss: 0.002129910048097372, Constraint losses: L1: -1.0937814712524414, L2: 0.0, L3: 0.0026110410690307617, L4: 0.0006126505322754383
Epoch 1000, Loss: 0.0012790556065738201, Constraint losses: L1: -1.1181089878082275, L2: 0.0, L3: 0.002198338508605957, L4: 0.00019882623746525496
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0066168308258057, Constraint losses: L1: 7.623281478881836, L2: 0.0, L3: 0.9994967579841614, L4: 0.9994968175888062
Epoch 500, Loss: 0.0018922485178336501, Constraint losses: L1: -1.0732927322387695, L2: 0.0, L3: 0.002482116222381592, L4: 0.0004834251303691417
Epoch 1000, Loss: 0.0012061219895258546, Constraint losses: L1: -1.103847861289978, L2: 0.0, L3: 0.0021547675132751465, L4: 0.00015520230226684362
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 161.7462615966797, Losses: L1: 14.124954223632812, L2: 0.0012797001982107759, L3: 1.0008548498153687, L4: 72.95259094238281, L5: 0.35699695348739624
Epoch 500, Loss: 5.227557182312012, Losses: L1: -2.0927529335021973, L2: 0.652557373046875, L3: 0.08494234085083008, L4: 3.2790064811706543, L5: 0.012398707680404186
Epoch 1000, Loss: -1.194488763809204, Losses: L1: -3.044724225997925, L2: 0.3614678680896759, L3: 0.061942338943481445, L4: 0.7051646709442139, L5: 0.008247995749115944
Epoch 1500, Loss: -1.2747386693954468, Losses: L1: -3.255829334259033, L2: 0.3021826446056366, L3: 0.05049705505371094, L4: 0.807070791721344, L5: 0.007134667132049799
Epoch 2000, Loss: -1.3296194076538086, Losses: L1: -3.4734127521514893, L2: 0.33522558212280273, L3: 0.05106163024902344, L4: 0.8703299760818481, L5: 0.008423090912401676
Epoch 2500, Loss: -1.9488060474395752, Losses: L1: -3.5907740592956543, L2: 0.33653464913368225, L3: 0.048985958099365234, L4: 0.6204354166984558, L5: 0.007788269780576229
Epoch 3000, Loss: -3.012740135192871, Losses: L1: -3.673518419265747, L2: 0.30911964178085327, L3: 0.034942626953125, L4: 0.15299156308174133, L5: 0.0053664082661271095
Epoch 3500, Loss: -2.946446418762207, Losses: L1: -3.735145330429077, L2: 0.3209720849990845, L3: 0.024899840354919434, L4: 0.21524178981781006, L5: 0.006171619053930044
Epoch 4000, Loss: -3.0777955055236816, Losses: L1: -3.750600814819336, L2: 0.30581626296043396, L3: 0.017861485481262207, L4: 0.16918130218982697, L5: 0.005382519215345383
Epoch 4500, Loss: -3.2695281505584717, Losses: L1: -3.7722718715667725, L2: 0.30395475029945374, L3: 0.011676788330078125, L4: 0.08787938207387924, L5: 0.00567663973197341
Epoch 5000, Loss: -3.2827303409576416, Losses: L1: -3.7799384593963623, L2: 0.2982289493083954, L3: 0.007786393165588379, L4: 0.09009526669979095, L5: 0.005501104053109884
Epoch 5500, Loss: -3.3332037925720215, Losses: L1: -3.7874960899353027, L2: 0.29553911089897156, L3: 0.004550755023956299, L4: 0.07156326621770859, L5: 0.00553794763982296
Epoch 6000, Loss: -3.344682455062866, Losses: L1: -3.7942702770233154, L2: 0.2963242828845978, L3: 0.001967191696166992, L4: 0.07011166960000992, L5: 0.00553657952696085
Epoch 6500, Loss: -3.351059675216675, Losses: L1: -3.7971749305725098, L2: 0.2960798144340515, L3: 0.00022280216217041016, L4: 0.0693860799074173, L5: 0.005520096980035305
Epoch 7000, Loss: -3.354705333709717, Losses: L1: -3.796015739440918, L2: 0.2928544282913208, L3: 2.86102294921875e-06, L4: 0.06872053444385529, L5: 0.005505986511707306
Epoch 7500, Loss: -3.356219530105591, Losses: L1: -3.794926404953003, L2: 0.2903822660446167, L3: 0.00010669231414794922, L4: 0.06861110031604767, L5: 0.0054977876134216785
Epoch 8000, Loss: -3.3578696250915527, Losses: L1: -3.7937216758728027, L2: 0.28836411237716675, L3: 2.0503997802734375e-05, L4: 0.06825446337461472, L5: 0.005479168146848679
Epoch 8500, Loss: -3.358787775039673, Losses: L1: -3.793165683746338, L2: 0.28699159622192383, L3: 1.4543533325195312e-05, L4: 0.06821385771036148, L5: 0.005472100805491209
Epoch 9000, Loss: -3.3594493865966797, Losses: L1: -3.7925987243652344, L2: 0.28604403138160706, L3: 3.6954879760742188e-06, L4: 0.06808273494243622, L5: 0.005467960145324469
Epoch 9500, Loss: -3.359877109527588, Losses: L1: -3.7923667430877686, L2: 0.28550830483436584, L3: 6.67572021484375e-06, L4: 0.06802420318126678, L5: 0.00546311168000102
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0062825679779053, Constraint losses: L1: 7.454397678375244, L2: 0.0, L3: 0.9994141459465027, L4: 0.9994140267372131
Epoch 500, Loss: 0.002288504969328642, Constraint losses: L1: -1.0666145086288452, L2: 0.0, L3: 0.002676725387573242, L4: 0.0006783940480090678
Epoch 1000, Loss: 0.0013045805972069502, Constraint losses: L1: -1.1179654598236084, L2: 0.0, L3: 0.0022109150886535645, L4: 0.00021163106430321932
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9980251789093018, Constraint losses: L1: 5.576473712921143, L2: 0.0, L3: 0.9962245225906372, L4: 0.9962241649627686
Epoch 500, Loss: 0.0022260453552007675, Constraint losses: L1: -1.112504005432129, L2: 0.0, L3: 0.0026683807373046875, L4: 0.0006701686652377248
Epoch 1000, Loss: 0.001325280056335032, Constraint losses: L1: -1.1195428371429443, L2: 0.0, L3: 0.002222120761871338, L4: 0.00022270216140896082
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 43.01209259033203, Losses: L1: 6.139349460601807, L2: 0.0, L3: 0.9971135258674622, L4: 69.42887115478516, L5: 0.32816246151924133
Epoch 500, Loss: -0.30396780371665955, Losses: L1: -2.9300997257232666, L2: 0.8951271176338196, L3: 0.10618066787719727, L4: 3.010350465774536, L5: 0.026936562731862068
Epoch 1000, Loss: -0.15655213594436646, Losses: L1: -2.7981739044189453, L2: 0.6958086490631104, L3: 0.06785821914672852, L4: 3.6050050258636475, L5: 0.015188340097665787
Epoch 1500, Loss: -2.3037679195404053, Losses: L1: -3.715308666229248, L2: 0.4893105924129486, L3: 0.06558889150619507, L4: 1.5699784755706787, L5: 0.012126650661230087
Epoch 2000, Loss: -2.5288100242614746, Losses: L1: -3.729083776473999, L2: 0.6558328866958618, L3: 0.06626856327056885, L4: 0.815178632736206, L5: 0.00862866174429655
Epoch 2500, Loss: -3.298802375793457, Losses: L1: -3.8268637657165527, L2: 0.35178884863853455, L3: 0.0031664371490478516, L4: 0.3354499042034149, L5: 0.004429625812917948
Epoch 3000, Loss: -3.4314768314361572, Losses: L1: -3.838580369949341, L2: 0.2596699595451355, L3: 0.0010031461715698242, L4: 0.28675001859664917, L5: 0.004104462452232838
Epoch 3500, Loss: -3.456037998199463, Losses: L1: -3.845689535140991, L2: 0.2511317729949951, L3: 0.005213260650634766, L4: 0.2524121403694153, L5: 0.0037741356063634157
Epoch 4000, Loss: -3.4925334453582764, Losses: L1: -3.850243091583252, L2: 0.24489986896514893, L3: 0.0048912763595581055, L4: 0.2020975947380066, L5: 0.003957331646233797
Epoch 4500, Loss: -3.497069835662842, Losses: L1: -3.861724853515625, L2: 0.24691671133041382, L3: 0.0037745237350463867, L4: 0.21657532453536987, L5: 0.0038031202275305986
Epoch 5000, Loss: -3.5183959007263184, Losses: L1: -3.868467092514038, L2: 0.24783632159233093, L3: 0.002778291702270508, L4: 0.18937145173549652, L5: 0.003985071554780006
Epoch 5500, Loss: -3.520117998123169, Losses: L1: -3.8703248500823975, L2: 0.24699169397354126, L3: 0.004334807395935059, L4: 0.18521779775619507, L5: 0.0038733291439712048
Epoch 6000, Loss: -3.5299415588378906, Losses: L1: -3.8695969581604004, L2: 0.2454388439655304, L3: 0.0002728700637817383, L4: 0.18336617946624756, L5: 0.003975619561970234
Epoch 6500, Loss: -3.5343017578125, Losses: L1: -3.869302272796631, L2: 0.24441073834896088, L3: 3.796815872192383e-05, L4: 0.17711184918880463, L5: 0.003915607929229736
Epoch 7000, Loss: -3.535656452178955, Losses: L1: -3.8696045875549316, L2: 0.24387258291244507, L3: 0.00021445751190185547, L4: 0.1753937155008316, L5: 0.003899339586496353
Epoch 7500, Loss: -3.535068988800049, Losses: L1: -3.871317148208618, L2: 0.24419769644737244, L3: 0.0012161731719970703, L4: 0.17530035972595215, L5: 0.003935930319130421
Epoch 8000, Loss: -3.5366125106811523, Losses: L1: -3.8693363666534424, L2: 0.2429417222738266, L3: 0.0004432201385498047, L4: 0.17389725148677826, L5: 0.0038943029940128326
Epoch 8500, Loss: -3.5383658409118652, Losses: L1: -3.8698463439941406, L2: 0.24289828538894653, L3: 7.355213165283203e-05, L4: 0.1729585826396942, L5: 0.003912071231752634
Epoch 9000, Loss: -3.538823366165161, Losses: L1: -3.869770050048828, L2: 0.24264580011367798, L3: 2.6464462280273438e-05, L4: 0.1725916564464569, L5: 0.0039042234420776367
Epoch 9500, Loss: -3.539031744003296, Losses: L1: -3.869856595993042, L2: 0.24253995716571808, L3: 9.608268737792969e-05, L4: 0.1722770631313324, L5: 0.003908840008080006
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0202701091766357, Constraint losses: L1: 18.42068099975586, L2: 0.0006384718581102788, L3: 1.0006053447723389, L4: 1.000605583190918
Epoch 500, Loss: 0.002243157709017396, Constraint losses: L1: -1.103732705116272, L2: 0.0, L3: 0.0026724934577941895, L4: 0.00067439692793414
Epoch 1000, Loss: 0.0013233094941824675, Constraint losses: L1: -1.1185013055801392, L2: 0.0, L3: 0.002220630645751953, L4: 0.00022118023480288684
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0027222633361816, Constraint losses: L1: 6.228484630584717, L2: 0.0, L3: 0.9982472658157349, L4: 0.998246431350708
Epoch 500, Loss: 0.0021058067213743925, Constraint losses: L1: -1.0629138946533203, L2: 0.0, L3: 0.002583444118499756, L4: 0.0005852765752933919
Epoch 1000, Loss: 0.0012424704618752003, Constraint losses: L1: -1.119031310081482, L2: 0.0, L3: 0.0021805167198181152, L4: 0.00018098505097441375
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 43.76993179321289, Losses: L1: 6.330350875854492, L2: 0.00010281553841196, L3: 0.9876712560653687, L4: 70.25882720947266, L5: 0.3347201943397522
Epoch 500, Loss: 26.246049880981445, Losses: L1: 2.5195465087890625, L2: 0.005844560917466879, L3: 0.9363694190979004, L4: 43.388526916503906, L5: 0.153656005859375
Epoch 1000, Loss: -0.3018464744091034, Losses: L1: -2.3297955989837646, L2: 0.33131399750709534, L3: 0.1803727149963379, L4: 2.643627882003784, L5: 0.014075789600610733
Epoch 1500, Loss: -0.5370675325393677, Losses: L1: -2.6797125339508057, L2: 0.3312819302082062, L3: 0.12281298637390137, L4: 3.0934197902679443, L5: 0.01902722381055355
Epoch 2000, Loss: -2.0001914501190186, Losses: L1: -2.971858263015747, L2: 0.2541305720806122, L3: 0.10417622327804565, L4: 1.0098506212234497, L5: 0.004258376080542803
Epoch 2500, Loss: -2.219261884689331, Losses: L1: -3.3267581462860107, L2: 0.3527856767177582, L3: 0.09669959545135498, L4: 1.1043277978897095, L5: 0.009147603996098042
Epoch 3000, Loss: -2.4367895126342773, Losses: L1: -3.47891902923584, L2: 0.37787187099456787, L3: 0.08604979515075684, L4: 0.9670727849006653, L5: 0.008621462620794773
Epoch 3500, Loss: -2.8644087314605713, Losses: L1: -3.6389858722686768, L2: 0.37468916177749634, L3: 0.08310085535049438, L4: 0.45572954416275024, L5: 0.005821541417390108
Epoch 4000, Loss: -2.990821361541748, Losses: L1: -3.7221388816833496, L2: 0.359271377325058, L3: 0.07703888416290283, L4: 0.4259272515773773, L5: 0.005004832521080971
Epoch 4500, Loss: -3.0915939807891846, Losses: L1: -3.76883864402771, L2: 0.33363452553749084, L3: 0.06888949871063232, L4: 0.4028829336166382, L5: 0.004389497917145491
Epoch 5000, Loss: -3.1650748252868652, Losses: L1: -3.806425094604492, L2: 0.32397693395614624, L3: 0.061173200607299805, L4: 0.3819476068019867, L5: 0.004053186159580946
Epoch 5500, Loss: -3.206813097000122, Losses: L1: -3.847580671310425, L2: 0.33893126249313354, L3: 0.05439072847366333, L4: 0.3781701326370239, L5: 0.003969965502619743
Epoch 6000, Loss: -3.235016107559204, Losses: L1: -3.8678791522979736, L2: 0.34373152256011963, L3: 0.04942452907562256, L4: 0.3727155923843384, L5: 0.003924536984413862
Epoch 6500, Loss: -3.2541754245758057, Losses: L1: -3.872924566268921, L2: 0.3419937491416931, L3: 0.04518002271652222, L4: 0.3650386929512024, L5: 0.0038759273011237383
Epoch 7000, Loss: -3.2678282260894775, Losses: L1: -3.8756442070007324, L2: 0.34186410903930664, L3: 0.04100048542022705, L4: 0.360221803188324, L5: 0.0038400678895413876
Epoch 7500, Loss: -3.2778451442718506, Losses: L1: -3.8772528171539307, L2: 0.3400580585002899, L3: 0.03877151012420654, L4: 0.35598820447921753, L5: 0.0038124448619782925
Epoch 8000, Loss: -3.2848739624023438, Losses: L1: -3.8772494792938232, L2: 0.3384723961353302, L3: 0.03692960739135742, L4: 0.35249996185302734, L5: 0.00379397114738822
Epoch 8500, Loss: -3.2898924350738525, Losses: L1: -3.8777379989624023, L2: 0.3381153643131256, L3: 0.035313963890075684, L4: 0.3506344258785248, L5: 0.003784865140914917
Epoch 9000, Loss: -3.2934653759002686, Losses: L1: -3.8783228397369385, L2: 0.3381563425064087, L3: 0.03406113386154175, L4: 0.3495994806289673, L5: 0.00377902970649302
Epoch 9500, Loss: -3.2959511280059814, Losses: L1: -3.8789429664611816, L2: 0.33815574645996094, L3: 0.033287107944488525, L4: 0.3489742577075958, L5: 0.0037748152390122414
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0010900497436523, Constraint losses: L1: 5.995340347290039, L2: 0.0, L3: 0.9975473284721375, L4: 0.9975472688674927
Epoch 500, Loss: 0.002313274424523115, Constraint losses: L1: -1.1042850017547607, L2: 0.0, L3: 0.002707839012145996, L4: 0.0007097204215824604
Epoch 1000, Loss: 0.001346080913208425, Constraint losses: L1: -1.1185357570648193, L2: 0.0, L3: 0.0022320151329040527, L4: 0.00023260156740434468
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0186939239501953, Constraint losses: L1: 17.710357666015625, L2: 0.0004394646384753287, L3: 1.0002721548080444, L4: 1.0002720355987549
Epoch 500, Loss: 0.0022639892995357513, Constraint losses: L1: -1.064789056777954, L2: 0.0, L3: 0.0026631951332092285, L4: 0.0006655833567492664
Epoch 1000, Loss: 0.001300255418755114, Constraint losses: L1: -1.119400143623352, L2: 0.0, L3: 0.0022095441818237305, L4: 0.0002101114223478362
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 58.431678771972656, Losses: L1: 15.038544654846191, L2: 0.0009923826437443495, L3: 1.000842571258545, L4: 81.12339782714844, L5: 0.41437894105911255
Epoch 500, Loss: -1.0973896980285645, Losses: L1: -2.6995372772216797, L2: 0.4367789924144745, L3: 0.06623327732086182, L4: 2.029726266860962, L5: 0.00901944749057293
Epoch 1000, Loss: -1.9335025548934937, Losses: L1: -3.5008766651153564, L2: 0.36498990654945374, L3: 0.05777943134307861, L4: 2.1149609088897705, L5: 0.014672399498522282
Epoch 1500, Loss: -2.991055488586426, Losses: L1: -3.6989049911499023, L2: 0.23440136015415192, L3: 0.019190192222595215, L4: 0.8456419110298157, L5: 0.0061233448795974255
Epoch 2000, Loss: -3.330263376235962, Losses: L1: -3.7086455821990967, L2: 0.15940900146961212, L3: 0.0032165050506591797, L4: 0.40804827213287354, L5: 0.004257990047335625
Epoch 2500, Loss: -3.4669947624206543, Losses: L1: -3.865795373916626, L2: 0.16795937716960907, L3: 0.029545068740844727, L4: 0.3264898359775543, L5: 0.0042530447244644165
Epoch 3000, Loss: -3.5624196529388428, Losses: L1: -3.7924234867095947, L2: 0.10422111302614212, L3: 0.00267714262008667, L4: 0.2275407910346985, L5: 0.003328937804326415
Epoch 3500, Loss: -3.535231113433838, Losses: L1: -3.785731554031372, L2: 0.10581684112548828, L3: 0.019002318382263184, L4: 0.200219064950943, L5: 0.0032846732065081596
Epoch 4000, Loss: -3.6013293266296387, Losses: L1: -3.812941551208496, L2: 0.10878002643585205, L3: 4.673004150390625e-05, L4: 0.19209836423397064, L5: 0.00334489275701344
Epoch 4500, Loss: -3.648613452911377, Losses: L1: -3.8114590644836426, L2: 0.10787167400121689, L3: 0.0041727423667907715, L4: 0.07962654531002045, L5: 0.003407574724406004
Epoch 5000, Loss: -3.639286994934082, Losses: L1: -3.818525552749634, L2: 0.11179633438587189, L3: 0.0030624866485595703, L4: 0.1092640832066536, L5: 0.0033425947185605764
Epoch 5500, Loss: -3.6644046306610107, Losses: L1: -3.8176043033599854, L2: 0.10867594927549362, L3: 0.002648591995239258, L4: 0.06495612114667892, L5: 0.0033742201048880816
Epoch 6000, Loss: -3.665151596069336, Losses: L1: -3.8195908069610596, L2: 0.10942533612251282, L3: 0.00215303897857666, L4: 0.06799081712961197, L5: 0.0033562404569238424
Epoch 6500, Loss: -3.673999071121216, Losses: L1: -3.8246548175811768, L2: 0.11177657544612885, L3: 0.001075148582458496, L4: 0.0599493607878685, L5: 0.003377111628651619
Epoch 7000, Loss: -3.6751177310943604, Losses: L1: -3.8229377269744873, L2: 0.11083759367465973, L3: 0.00030553340911865234, L4: 0.05928467959165573, L5: 0.0033644153736531734
Epoch 7500, Loss: -3.6752820014953613, Losses: L1: -3.8246266841888428, L2: 0.11160743981599808, L3: 0.0006737709045410156, L4: 0.059282973408699036, L5: 0.0033740957733243704
Epoch 8000, Loss: -3.6771769523620605, Losses: L1: -3.823791027069092, L2: 0.1111912801861763, L3: 2.9802322387695312e-05, L4: 0.057252489030361176, L5: 0.0033684768714010715
Epoch 8500, Loss: -3.6769392490386963, Losses: L1: -3.824070453643799, L2: 0.11124661564826965, L3: 0.00021338462829589844, L4: 0.057452425360679626, L5: 0.0033658237662166357
Epoch 9000, Loss: -3.677522897720337, Losses: L1: -3.8239901065826416, L2: 0.11124233156442642, L3: 9.894371032714844e-06, L4: 0.05693946033716202, L5: 0.0033676489256322384
Epoch 9500, Loss: -3.6775848865509033, Losses: L1: -3.8240807056427, L2: 0.1112961396574974, L3: 1.2636184692382812e-05, L4: 0.05687965452671051, L5: 0.0033673483412712812
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.004727840423584, Constraint losses: L1: 6.881087303161621, L2: 0.0001699892891338095, L3: 0.9988380670547485, L4: 0.9988386631011963
Epoch 500, Loss: 0.002354471944272518, Constraint losses: L1: -1.1031084060668945, L2: 0.0, L3: 0.002727985382080078, L4: 0.0007295950781553984
Epoch 1000, Loss: 0.0013587013818323612, Constraint losses: L1: -1.1180669069290161, L2: 0.0, L3: 0.0022380948066711426, L4: 0.0002386734850006178
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0170912742614746, Constraint losses: L1: 16.739160537719727, L2: 0.00019968891865573823, L3: 1.0000762939453125, L4: 1.000076174736023
Epoch 500, Loss: 0.0022167651914060116, Constraint losses: L1: -1.0727508068084717, L2: 0.0, L3: 0.002643883228302002, L4: 0.0006456327391788363
Epoch 1000, Loss: 0.0012817285023629665, Constraint losses: L1: -1.1184114217758179, L2: 0.0, L3: 0.0021997690200805664, L4: 0.00020037093781866133
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 86.1969223022461, Losses: L1: 10.899162292480469, L2: 0.00021899768034927547, L3: 0.9987707138061523, L4: 73.11992645263672, L5: 0.360148161649704
Epoch 500, Loss: 57.857601165771484, Losses: L1: 6.452622413635254, L2: 0.0243978388607502, L3: 0.9390718936920166, L4: 49.41666793823242, L5: 0.17154079675674438
Epoch 1000, Loss: 2.2587337493896484, Losses: L1: -1.9432374238967896, L2: 0.7036247253417969, L3: 0.16016924381256104, L4: 3.163667917251587, L5: 0.028680071234703064
Epoch 1500, Loss: 0.6670919060707092, Losses: L1: -1.8306726217269897, L2: 0.39979279041290283, L3: 0.14661026000976562, L4: 1.7992664575576782, L5: 0.010969548486173153
Epoch 2000, Loss: 0.13708901405334473, Losses: L1: -1.9085164070129395, L2: 0.34431973099708557, L3: 0.11786651611328125, L4: 1.4603146314620972, L5: 0.0104761254042387
Epoch 2500, Loss: -0.39267802238464355, Losses: L1: -1.9400430917739868, L2: 0.26451680064201355, L3: 0.11375796794891357, L4: 1.0515607595443726, L5: 0.00754307396709919
Epoch 3000, Loss: -0.542137622833252, Losses: L1: -1.9374407529830933, L2: 0.22080014646053314, L3: 0.11353683471679688, L4: 0.9441505670547485, L5: 0.0065574063919484615
Epoch 3500, Loss: -0.6468664407730103, Losses: L1: -1.9827736616134644, L2: 0.2169950157403946, L3: 0.11084866523742676, L4: 0.8941118717193604, L5: 0.00620607752352953
Epoch 4000, Loss: -0.7444582581520081, Losses: L1: -2.023057460784912, L2: 0.21235236525535583, L3: 0.10820382833480835, L4: 0.8468979597091675, L5: 0.005882327910512686
Epoch 4500, Loss: -0.862440824508667, Losses: L1: -2.0674996376037598, L2: 0.20599304139614105, L3: 0.10469722747802734, L4: 0.786858320236206, L5: 0.005626010708510876
Epoch 5000, Loss: -1.0716454982757568, Losses: L1: -2.103738307952881, L2: 0.18158335983753204, L3: 0.09941816329956055, L4: 0.6490663290023804, L5: 0.005213492084294558
Epoch 5500, Loss: -1.3305456638336182, Losses: L1: -2.1408584117889404, L2: 0.1649772971868515, L3: 0.09440600872039795, L4: 0.454092800617218, L5: 0.00486135296523571
Epoch 6000, Loss: -1.3634881973266602, Losses: L1: -2.1759426593780518, L2: 0.18166247010231018, L3: 0.09258842468261719, L4: 0.4432012736797333, L5: 0.004827666562050581
Epoch 6500, Loss: -1.3793562650680542, Losses: L1: -2.200382947921753, L2: 0.1936534345149994, L3: 0.09169459342956543, L4: 0.44155097007751465, L5: 0.0048663001507520676
Epoch 7000, Loss: -1.3892842531204224, Losses: L1: -2.2088377475738525, L2: 0.19695457816123962, L3: 0.09121882915496826, L4: 0.43774473667144775, L5: 0.00483329314738512
Epoch 7500, Loss: -1.3961328268051147, Losses: L1: -2.215214967727661, L2: 0.19933299720287323, L3: 0.09097015857696533, L4: 0.43539705872535706, L5: 0.004823744297027588
Epoch 8000, Loss: -1.4008640050888062, Losses: L1: -2.219836711883545, L2: 0.20088407397270203, L3: 0.09065830707550049, L4: 0.43437284231185913, L5: 0.0047982060350477695
Epoch 8500, Loss: -1.4040549993515015, Losses: L1: -2.222975015640259, L2: 0.2018822282552719, L3: 0.090484619140625, L4: 0.4336759150028229, L5: 0.0047854348085820675
Epoch 9000, Loss: -1.406348705291748, Losses: L1: -2.2249536514282227, L2: 0.2024286687374115, L3: 0.09037482738494873, L4: 0.43304041028022766, L5: 0.004772680811583996
Epoch 9500, Loss: -1.407875418663025, Losses: L1: -2.2260820865631104, L2: 0.20264503359794617, L3: 0.09031170606613159, L4: 0.43255603313446045, L5: 0.004764228593558073
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9975194931030273, Constraint losses: L1: 5.424842834472656, L2: 0.0, L3: 0.9960482120513916, L4: 0.9960463643074036
Epoch 500, Loss: 0.0025133262388408184, Constraint losses: L1: -1.1066081523895264, L2: 0.0, L3: 0.0028090476989746094, L4: 0.0008108867332339287
Epoch 1000, Loss: 0.0014193401439115405, Constraint losses: L1: -1.1185749769210815, L2: 0.0, L3: 0.0022686123847961426, L4: 0.0002693027490749955
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.017754077911377, Constraint losses: L1: 17.685150146484375, L2: 4.301366789150052e-05, L3: 1.000012993812561, L4: 1.000012993812561
Epoch 500, Loss: 0.002216753549873829, Constraint losses: L1: -1.1094905138015747, L2: 0.0, L3: 0.0026623010635375977, L4: 0.0006639431230723858
Epoch 1000, Loss: 0.0013170498423278332, Constraint losses: L1: -1.1186084747314453, L2: 0.0, L3: 0.002217590808868408, L4: 0.00021806758013553917
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 100.60088348388672, Losses: L1: 14.306437492370605, L2: 0.002668678294867277, L3: 1.0022603273391724, L4: 83.85322570800781, L5: 0.4340306520462036
Epoch 500, Loss: -1.9898186922073364, Losses: L1: -3.014639139175415, L2: 0.3905765116214752, L3: 0.0686141848564148, L4: 0.48861661553382874, L5: 0.008398784324526787
Epoch 1000, Loss: -2.0361406803131104, Losses: L1: -3.723630905151367, L2: 0.32054832577705383, L3: 0.04971355199813843, L4: 1.2618787288665771, L5: 0.005636123009026051
Epoch 1500, Loss: -3.0651676654815674, Losses: L1: -3.909921407699585, L2: 0.2737419009208679, L3: 0.019860029220581055, L4: 0.524063229560852, L5: 0.007228722795844078
Epoch 2000, Loss: -3.0978710651397705, Losses: L1: -3.892801523208618, L2: 0.2637445628643036, L3: 0.017487764358520508, L4: 0.4880184233188629, L5: 0.00819186121225357
Epoch 2500, Loss: -3.0177881717681885, Losses: L1: -3.8315677642822266, L2: 0.20935775339603424, L3: 0.021167278289794922, L4: 0.5578408241271973, L5: 0.00424655107781291
Epoch 3000, Loss: -3.38830304145813, Losses: L1: -3.8865811824798584, L2: 0.2004077136516571, L3: 0.008433222770690918, L4: 0.2762804329395294, L5: 0.004723612684756517
Epoch 3500, Loss: -3.540677070617676, Losses: L1: -3.920149803161621, L2: 0.20602849125862122, L3: 0.0033178329467773438, L4: 0.16176444292068481, L5: 0.005044190213084221
Epoch 4000, Loss: -3.6086196899414062, Losses: L1: -3.9274275302886963, L2: 0.20781362056732178, L3: 0.0035883188247680664, L4: 0.09896549582481384, L5: 0.00485224137082696
Epoch 4500, Loss: -3.6307241916656494, Losses: L1: -3.909362554550171, L2: 0.19112180173397064, L3: 0.003994464874267578, L4: 0.07496193796396255, L5: 0.0045656850561499596
Epoch 5000, Loss: -3.6513302326202393, Losses: L1: -3.915510416030884, L2: 0.19070473313331604, L3: 0.0005185604095458984, L4: 0.06791612505912781, L5: 0.00452203257009387
Epoch 5500, Loss: -3.655975580215454, Losses: L1: -3.913381338119507, L2: 0.18733438849449158, L3: 0.00021326541900634766, L4: 0.0651441365480423, L5: 0.004500970244407654
Epoch 6000, Loss: -3.6581571102142334, Losses: L1: -3.9126522541046143, L2: 0.18532009422779083, L3: 0.00039964914321899414, L4: 0.06387535482645035, L5: 0.004500292707234621
Epoch 6500, Loss: -3.6598799228668213, Losses: L1: -3.9140024185180664, L2: 0.18538305163383484, L3: 0.0005877017974853516, L4: 0.0630854144692421, L5: 0.00447873817756772
Epoch 7000, Loss: -3.661001205444336, Losses: L1: -3.9136290550231934, L2: 0.1844566911458969, L3: 0.00035572052001953125, L4: 0.06298945099115372, L5: 0.004470289219170809
Epoch 7500, Loss: -3.6624085903167725, Losses: L1: -3.912829875946045, L2: 0.1834365576505661, L3: 0.0001919269561767578, L4: 0.06215442344546318, L5: 0.004446224309504032
Epoch 8000, Loss: -3.663113832473755, Losses: L1: -3.9122111797332764, L2: 0.18261827528476715, L3: 6.198883056640625e-06, L4: 0.06202615052461624, L5: 0.004440277814865112
Epoch 8500, Loss: -3.6634302139282227, Losses: L1: -3.9119198322296143, L2: 0.1821381002664566, L3: 1.8477439880371094e-05, L4: 0.061880066990852356, L5: 0.004434384871274233
Epoch 9000, Loss: -3.663644790649414, Losses: L1: -3.9118378162384033, L2: 0.18192258477210999, L3: 1.5974044799804688e-05, L4: 0.061807215213775635, L5: 0.004431169014424086
Epoch 9500, Loss: -3.6637041568756104, Losses: L1: -3.9119200706481934, L2: 0.181857168674469, L3: 7.605552673339844e-05, L4: 0.0617762953042984, L5: 0.004430234432220459
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0196356773376465, Constraint losses: L1: 18.347652435302734, L2: 0.0004809032252524048, L3: 1.0004035234451294, L4: 1.0004035234451294
Epoch 500, Loss: 0.0020210284274071455, Constraint losses: L1: -1.1148179769515991, L2: 0.0, L3: 0.0025672316551208496, L4: 0.0005686148651875556
Epoch 1000, Loss: 0.0012539582094177604, Constraint losses: L1: -1.1187444925308228, L2: 0.0, L3: 0.002186119556427002, L4: 0.00018658314365893602
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.982255458831787, Constraint losses: L1: 4.45487642288208, L2: 0.0, L3: 0.9889014363288879, L4: 0.9888991117477417
Epoch 500, Loss: 0.0020488621667027473, Constraint losses: L1: -1.091463327407837, L2: 0.0, L3: 0.002569437026977539, L4: 0.0005708884564228356
Epoch 1000, Loss: 0.0012395146768540144, Constraint losses: L1: -1.1196438074111938, L2: 0.0, L3: 0.002179384231567383, L4: 0.00017977430252358317
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 93.81733703613281, Losses: L1: 5.799713611602783, L2: 0.0, L3: 0.9967973828315735, L4: 85.13858795166016, L5: 0.44271907210350037
Epoch 500, Loss: 56.23138427734375, Losses: L1: 3.0361902713775635, L2: 0.006727154366672039, L3: 0.9522621631622314, L4: 50.93380355834961, L5: 0.17507056891918182
Epoch 1000, Loss: 6.966985702514648, Losses: L1: -1.897418737411499, L2: 0.7573051452636719, L3: 0.11386466026306152, L4: 7.796003818511963, L5: 0.04168318957090378
Epoch 1500, Loss: 0.12443839013576508, Losses: L1: -2.405543088912964, L2: 0.38084495067596436, L3: 0.1330050230026245, L4: 1.8554928302764893, L5: 0.01381688378751278
Epoch 2000, Loss: 0.15877051651477814, Losses: L1: -2.800865411758423, L2: 0.2992127239704132, L3: 0.10570728778839111, L4: 2.4182369709014893, L5: 0.015385842882096767
Epoch 2500, Loss: -1.5557790994644165, Losses: L1: -2.8558475971221924, L2: 0.25989919900894165, L3: 0.10352158546447754, L4: 0.8232441544532776, L5: 0.00494104390963912
Epoch 3000, Loss: -1.840491771697998, Losses: L1: -2.9645049571990967, L2: 0.2672088146209717, L3: 0.1007223129272461, L4: 0.6449849009513855, L5: 0.0051873717457056046
Epoch 3500, Loss: -1.9583791494369507, Losses: L1: -3.0087668895721436, L2: 0.2674234211444855, L3: 0.09776777029037476, L4: 0.578052282333374, L5: 0.004688176326453686
Epoch 4000, Loss: -2.018159866333008, Losses: L1: -3.036480665206909, L2: 0.2687869668006897, L3: 0.09608900547027588, L4: 0.5485131740570068, L5: 0.004421369172632694
Epoch 4500, Loss: -2.071524143218994, Losses: L1: -3.0633580684661865, L2: 0.2726159989833832, L3: 0.09491002559661865, L4: 0.5204424262046814, L5: 0.004477682523429394
Epoch 5000, Loss: -2.1020729541778564, Losses: L1: -3.0789780616760254, L2: 0.27293115854263306, L3: 0.09426474571228027, L4: 0.5065217614173889, L5: 0.004461388103663921
Epoch 5500, Loss: -2.123666286468506, Losses: L1: -3.0895040035247803, L2: 0.2729353904724121, L3: 0.09380048513412476, L4: 0.4964733123779297, L5: 0.004414119757711887
Epoch 6000, Loss: -2.139502763748169, Losses: L1: -3.0979225635528564, L2: 0.2728598713874817, L3: 0.09331178665161133, L4: 0.4901276230812073, L5: 0.004404481966048479
Epoch 6500, Loss: -2.1513171195983887, Losses: L1: -3.1041665077209473, L2: 0.27303850650787354, L3: 0.09295403957366943, L4: 0.48509687185287476, L5: 0.004403047263622284
Epoch 7000, Loss: -2.1599910259246826, Losses: L1: -3.1065030097961426, L2: 0.2718573212623596, L3: 0.09273862838745117, L4: 0.4804428815841675, L5: 0.004367232322692871
Epoch 7500, Loss: -2.166569948196411, Losses: L1: -3.1096134185791016, L2: 0.27147889137268066, L3: 0.09257340431213379, L4: 0.4776649475097656, L5: 0.004376421216875315
Epoch 8000, Loss: -2.171308994293213, Losses: L1: -3.1111011505126953, L2: 0.270833820104599, L3: 0.092434823513031, L4: 0.475355863571167, L5: 0.004366529174149036
Epoch 8500, Loss: -2.174675941467285, Losses: L1: -3.1119425296783447, L2: 0.27020782232284546, L3: 0.09233391284942627, L4: 0.47366300225257874, L5: 0.004363951738923788
Epoch 9000, Loss: -2.1770267486572266, Losses: L1: -3.112471580505371, L2: 0.2696634829044342, L3: 0.09228616952896118, L4: 0.47248542308807373, L5: 0.0043616462498903275
Epoch 9500, Loss: -2.1785776615142822, Losses: L1: -3.112823009490967, L2: 0.26925554871559143, L3: 0.09223377704620361, L4: 0.47179698944091797, L5: 0.004362632520496845
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0301175117492676, Constraint losses: L1: 18.42068099975586, L2: 0.0038985777646303177, L3: 1.0038986206054688, L4: 1.0038994550704956
Epoch 500, Loss: 0.002835182473063469, Constraint losses: L1: -0.9756943583488464, L2: 0.0, L3: 0.0029039978981018066, L4: 0.0009068790241144598
Epoch 1000, Loss: 0.0014271873515099287, Constraint losses: L1: -1.11612868309021, L2: 0.0, L3: 0.0022712349891662598, L4: 0.00027208111714571714
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0196900367736816, Constraint losses: L1: 18.42068099975586, L2: 0.0004256413085386157, L3: 1.0004217624664307, L4: 1.0004221200942993
Epoch 500, Loss: 0.0022251252084970474, Constraint losses: L1: -1.0156489610671997, L2: 0.0, L3: 0.002619326114654541, L4: 0.0006214481545612216
Epoch 1000, Loss: 0.0012558214366436005, Constraint losses: L1: -1.117843508720398, L2: 0.0, L3: 0.0021865367889404297, L4: 0.00018712820019572973
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 162.4644317626953, Losses: L1: 17.33126449584961, L2: 0.0025487495586276054, L3: 1.0024710893630981, L4: 71.47639465332031, L5: 0.34577420353889465
Epoch 500, Loss: 2.2352828979492188, Losses: L1: -2.2714085578918457, L2: 0.39704951643943787, L3: 0.06135368347167969, L4: 1.991781234741211, L5: 0.006744622718542814
Epoch 1000, Loss: 1.220623254776001, Losses: L1: -3.069140672683716, L2: 0.4551088213920593, L3: 0.07210516929626465, L4: 1.8414686918258667, L5: 0.015014654025435448
Epoch 1500, Loss: 0.7674496173858643, Losses: L1: -3.1735453605651855, L2: 0.2955186367034912, L3: 0.06652915477752686, L4: 1.754844069480896, L5: 0.00545981340110302
Epoch 2000, Loss: -2.692002296447754, Losses: L1: -3.8212697505950928, L2: 0.26484552025794983, L3: 0.01921379566192627, L4: 0.41173064708709717, L5: 0.005065992008894682
Epoch 2500, Loss: -2.1197166442871094, Losses: L1: -3.819999933242798, L2: 0.2058018445968628, L3: 0.006185770034790039, L4: 0.7400461435317993, L5: 0.004035635851323605
Epoch 3000, Loss: -3.2569360733032227, Losses: L1: -3.852281332015991, L2: 0.19925372302532196, L3: 0.007909893989562988, L4: 0.18893811106681824, L5: 0.0047906311228871346
Epoch 3500, Loss: -3.346182107925415, Losses: L1: -3.862442970275879, L2: 0.18941830098628998, L3: 0.015132308006286621, L4: 0.14703842997550964, L5: 0.005001879762858152
Epoch 4000, Loss: -3.3274497985839844, Losses: L1: -3.8651022911071777, L2: 0.18794581294059753, L3: 0.0015036463737487793, L4: 0.17226633429527283, L5: 0.004333137068897486
Epoch 4500, Loss: -3.483506679534912, Losses: L1: -3.881660223007202, L2: 0.1932699829339981, L3: 0.0007085800170898438, L4: 0.10061796009540558, L5: 0.004460692405700684
Epoch 5000, Loss: -3.516247034072876, Losses: L1: -3.8864619731903076, L2: 0.19240126013755798, L3: 0.0018699169158935547, L4: 0.08592769503593445, L5: 0.004436773713678122
Epoch 5500, Loss: -3.526975631713867, Losses: L1: -3.884638786315918, L2: 0.19005341827869415, L3: 0.0022972822189331055, L4: 0.08040539920330048, L5: 0.004408982582390308
Epoch 6000, Loss: -3.538525342941284, Losses: L1: -3.889631986618042, L2: 0.19062760472297668, L3: 0.00028693675994873047, L4: 0.07885202020406723, L5: 0.004402190446853638
Epoch 6500, Loss: -3.541301965713501, Losses: L1: -3.8903565406799316, L2: 0.18934521079063416, L3: 0.0007519721984863281, L4: 0.07800320535898209, L5: 0.00439820159226656
Epoch 7000, Loss: -3.5429489612579346, Losses: L1: -3.89041805267334, L2: 0.18805821239948273, L3: 0.001012563705444336, L4: 0.07759460806846619, L5: 0.0043929326348006725
Epoch 7500, Loss: -3.544973611831665, Losses: L1: -3.8885865211486816, L2: 0.18644395470619202, L3: 0.00033038854598999023, L4: 0.07716065645217896, L5: 0.004374139942228794
Epoch 8000, Loss: -3.547313690185547, Losses: L1: -3.8889827728271484, L2: 0.1859690546989441, L3: 3.7789344787597656e-05, L4: 0.07671745866537094, L5: 0.004378784913569689
Epoch 8500, Loss: -3.547783136367798, Losses: L1: -3.8890161514282227, L2: 0.18550746142864227, L3: 0.0001583099365234375, L4: 0.07660975307226181, L5: 0.004378611221909523
Epoch 9000, Loss: -3.548621654510498, Losses: L1: -3.8886682987213135, L2: 0.18506388366222382, L3: 1.5974044799804688e-05, L4: 0.07638198137283325, L5: 0.004373585339635611
Epoch 9500, Loss: -3.548945426940918, Losses: L1: -3.8886687755584717, L2: 0.1848348081111908, L3: 2.6106834411621094e-05, L4: 0.07632452994585037, L5: 0.004374377895146608
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0034849643707275, Constraint losses: L1: 6.467379093170166, L2: 0.0, L3: 0.9985089302062988, L4: 0.998508632183075
Epoch 500, Loss: 0.002493482083082199, Constraint losses: L1: -1.101186752319336, L2: 0.0, L3: 0.002796351909637451, L4: 0.0007983171381056309
Epoch 1000, Loss: 0.001400919514708221, Constraint losses: L1: -1.1177279949188232, L2: 0.0, L3: 0.0022589564323425293, L4: 0.0002596911508589983
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.001823902130127, Constraint losses: L1: 6.136307716369629, L2: 0.0, L3: 0.9978439211845398, L4: 0.9978437423706055
Epoch 500, Loss: 0.0022657853551208973, Constraint losses: L1: -1.006870985031128, L2: 0.0, L3: 0.0026353001594543457, L4: 0.0006373560754582286
Epoch 1000, Loss: 0.0012546350480988622, Constraint losses: L1: -1.1193313598632812, L2: 0.0, L3: 0.0021867752075195312, L4: 0.00018719134095590562
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 167.2974853515625, Losses: L1: 6.410841464996338, L2: 0.00047115972847677767, L3: 0.9984528422355652, L4: 79.24490356445312, L5: 0.39945486187934875
Epoch 500, Loss: -0.21358594298362732, Losses: L1: -3.183037757873535, L2: 0.7342106699943542, L3: 0.07156562805175781, L4: 1.0394335985183716, L5: 0.013242634013295174
Epoch 1000, Loss: -0.0036042015999555588, Losses: L1: -3.7856855392456055, L2: 0.4545333981513977, L3: 0.008191287517547607, L4: 1.6474921703338623, L5: 0.016181202605366707
Epoch 1500, Loss: -2.118387460708618, Losses: L1: -3.7680768966674805, L2: 0.22050189971923828, L3: 9.691715240478516e-05, L4: 0.7118074297904968, L5: 0.005378860980272293
Epoch 2000, Loss: -2.671882390975952, Losses: L1: -3.9093165397644043, L2: 0.2379426509141922, L3: 0.0022504329681396484, L4: 0.4937794804573059, L5: 0.0074317967519164085
Epoch 2500, Loss: -3.0349490642547607, Losses: L1: -3.9539220333099365, L2: 0.2573210895061493, L3: 0.0036059021949768066, L4: 0.3246321380138397, L5: 0.005175756756216288
Epoch 3000, Loss: -3.251816511154175, Losses: L1: -3.9881999492645264, L2: 0.26130208373069763, L3: 0.0055446624755859375, L4: 0.22920817136764526, L5: 0.005575814750045538
Epoch 3500, Loss: -3.574138879776001, Losses: L1: -3.981759548187256, L2: 0.24101395905017853, L3: 0.0020911693572998047, L4: 0.07844693958759308, L5: 0.0055304705165326595
Epoch 4000, Loss: -3.4973275661468506, Losses: L1: -3.9909651279449463, L2: 0.24472489953041077, L3: 0.0018210411071777344, L4: 0.11971668899059296, L5: 0.0058372835628688335
Epoch 4500, Loss: -3.636075735092163, Losses: L1: -3.9951069355010986, L2: 0.24083077907562256, L3: 0.0031386613845825195, L4: 0.05321058630943298, L5: 0.005502067971974611
Epoch 5000, Loss: -3.647523880004883, Losses: L1: -3.9990880489349365, L2: 0.24089227616786957, L3: 0.0011435747146606445, L4: 0.05144836753606796, L5: 0.005488120950758457
Epoch 5500, Loss: -3.653022050857544, Losses: L1: -3.9984614849090576, L2: 0.2369207888841629, L3: 0.0006661415100097656, L4: 0.05086423456668854, L5: 0.005457975436002016
Epoch 6000, Loss: -3.6604881286621094, Losses: L1: -4.000062465667725, L2: 0.2366676926612854, L3: 0.0001226663589477539, L4: 0.048598382622003555, L5: 0.00546461483463645
Epoch 6500, Loss: -3.663433790206909, Losses: L1: -4.000237941741943, L2: 0.23488833010196686, L3: 8.821487426757812e-05, L4: 0.04814760386943817, L5: 0.005444270092993975
Epoch 7000, Loss: -3.664881944656372, Losses: L1: -4.001581192016602, L2: 0.23459632694721222, L3: 0.0004978179931640625, L4: 0.04782742261886597, L5: 0.005452295765280724
Epoch 7500, Loss: -3.6669392585754395, Losses: L1: -4.001366138458252, L2: 0.2340420037508011, L3: 0.00037419795989990234, L4: 0.047098930925130844, L5: 0.005438724532723427
Epoch 8000, Loss: -3.6683475971221924, Losses: L1: -4.001750469207764, L2: 0.23359112441539764, L3: 7.2479248046875e-05, L4: 0.04711991548538208, L5: 0.005427217110991478
Epoch 8500, Loss: -3.6695351600646973, Losses: L1: -4.002055644989014, L2: 0.23350214958190918, L3: 4.76837158203125e-05, L4: 0.046744123101234436, L5: 0.005434785038232803
Epoch 9000, Loss: -3.670006513595581, Losses: L1: -4.002098560333252, L2: 0.23330892622470856, L3: 3.0517578125e-05, L4: 0.0466461256146431, L5: 0.005429775919765234
Epoch 9500, Loss: -3.6702659130096436, Losses: L1: -4.002080917358398, L2: 0.23310062289237976, L3: 4.51207160949707e-05, L4: 0.04659683257341385, L5: 0.005430339835584164
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 1, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0293827056884766, Constraint losses: L1: 18.42068099975586, L2: 0.003653894178569317, L3: 1.003653883934021, L4: 1.0036543607711792
Epoch 500, Loss: 0.0021726489067077637, Constraint losses: L1: -1.0820962190628052, L2: 0.0, L3: 0.0026265382766723633, L4: 0.0006282067624852061
Epoch 1000, Loss: 0.0012790668988600373, Constraint losses: L1: -1.118348479270935, L2: 0.0, L3: 0.002198457717895508, L4: 0.0001989577867789194
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0289466381073, Constraint losses: L1: 18.42068099975586, L2: 0.0035084690898656845, L3: 1.003508448600769, L4: 1.0035090446472168
Epoch 500, Loss: 0.0024549406953155994, Constraint losses: L1: -1.0401606559753418, L2: 0.0, L3: 0.002746284008026123, L4: 0.0007488172268494964
Epoch 1000, Loss: 0.00134426006115973, Constraint losses: L1: -1.1189347505569458, L2: 0.0, L3: 0.002231299877166748, L4: 0.00023189495550468564
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 171.26513671875, Losses: L1: 16.129547119140625, L2: 0.005987280048429966, L3: 1.0058808326721191, L4: 76.17398071289062, L5: 0.3849416971206665
Epoch 500, Loss: 3.5245327949523926, Losses: L1: -2.0806009769439697, L2: 0.6211987137794495, L3: 0.08042681217193604, L4: 2.4031875133514404, L5: 0.00835329107940197
Epoch 1000, Loss: -1.27086341381073, Losses: L1: -3.376577377319336, L2: 0.5583134889602661, L3: 0.07240909337997437, L4: 0.696161150932312, L5: 0.0051300195045769215
Epoch 1500, Loss: -1.5538051128387451, Losses: L1: -3.727694034576416, L2: 0.3655354976654053, L3: 0.03594410419464111, L4: 0.8624467253684998, L5: 0.005785885266959667
Epoch 2000, Loss: -2.2450215816497803, Losses: L1: -3.8583438396453857, L2: 0.3790310323238373, L3: 0.0036360621452331543, L4: 0.6069177389144897, L5: 0.0065918234176933765
Epoch 2500, Loss: -2.659313678741455, Losses: L1: -3.764068365097046, L2: 0.23499491810798645, L3: 0.025624871253967285, L4: 0.4048113524913788, L5: 0.004443625453859568
Epoch 3000, Loss: -3.0630807876586914, Losses: L1: -3.7569351196289062, L2: 0.20538932085037231, L3: 0.01238107681274414, L4: 0.22807104885578156, L5: 0.0037803668528795242
Epoch 3500, Loss: -2.971271514892578, Losses: L1: -3.7824106216430664, L2: 0.21091723442077637, L3: 0.01139688491821289, L4: 0.2842365801334381, L5: 0.004477491602301598
Epoch 4000, Loss: -3.2943315505981445, Losses: L1: -3.771040678024292, L2: 0.18991929292678833, L3: 0.012431144714355469, L4: 0.1269068419933319, L5: 0.004056931007653475
Epoch 4500, Loss: -3.3145558834075928, Losses: L1: -3.771427869796753, L2: 0.18255750834941864, L3: 0.012415647506713867, L4: 0.12069495022296906, L5: 0.004046587273478508
Epoch 5000, Loss: -3.3379833698272705, Losses: L1: -3.763864278793335, L2: 0.1787819266319275, L3: 0.0031136274337768555, L4: 0.11639193445444107, L5: 0.0040439460426568985
Epoch 5500, Loss: -3.3427340984344482, Losses: L1: -3.762535333633423, L2: 0.17806364595890045, L3: 0.001193404197692871, L4: 0.11560871452093124, L5: 0.004066672641783953
Epoch 6000, Loss: -3.348404884338379, Losses: L1: -3.771319627761841, L2: 0.17873646318912506, L3: 0.004152059555053711, L4: 0.11387047171592712, L5: 0.004066613502800465
Epoch 6500, Loss: -3.3555264472961426, Losses: L1: -3.768169641494751, L2: 0.1773994117975235, L3: 0.000962376594543457, L4: 0.11259692162275314, L5: 0.004062627907842398
Epoch 7000, Loss: -3.3583502769470215, Losses: L1: -3.768519163131714, L2: 0.17717623710632324, L3: 0.0003445148468017578, L4: 0.11209137737751007, L5: 0.004060342907905579
Epoch 7500, Loss: -3.3604671955108643, Losses: L1: -3.7681808471679688, L2: 0.17651322484016418, L3: 6.42538070678711e-05, L4: 0.11147075891494751, L5: 0.004065102897584438
Epoch 8000, Loss: -3.3609838485717773, Losses: L1: -3.7692525386810303, L2: 0.1763412058353424, L3: 0.0007853507995605469, L4: 0.11111123859882355, L5: 0.004067071247845888
Epoch 8500, Loss: -3.362490177154541, Losses: L1: -3.768291473388672, L2: 0.1759396642446518, L3: 6.669759750366211e-05, L4: 0.11079975217580795, L5: 0.0040643541142344475
Epoch 9000, Loss: -3.362785816192627, Losses: L1: -3.768559217453003, L2: 0.17600196599960327, L3: 0.00014966726303100586, L4: 0.11066757142543793, L5: 0.004068512469530106
Epoch 9500, Loss: -3.3636035919189453, Losses: L1: -3.7687320709228516, L2: 0.1757698655128479, L3: 0.00016045570373535156, L4: 0.11045177280902863, L5: 0.004067109432071447
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0262770652770996, Constraint losses: L1: 18.42068099975586, L2: 0.002618603641167283, L3: 1.0026185512542725, L4: 1.0026191473007202
Epoch 500, Loss: 0.0023414294701069593, Constraint losses: L1: -1.0716568231582642, L2: 0.0, L3: 0.002705514430999756, L4: 0.0007075718604028225
Epoch 1000, Loss: 0.0013342497404664755, Constraint losses: L1: -1.1179412603378296, L2: 0.0, L3: 0.0022257566452026367, L4: 0.00022643448028247803
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.02923583984375, Constraint losses: L1: 18.42068099975586, L2: 0.0036051832139492035, L3: 1.0036051273345947, L4: 1.0036050081253052
Epoch 500, Loss: 0.002439687727019191, Constraint losses: L1: -1.0021283626556396, L2: 0.0, L3: 0.002719700336456299, L4: 0.0007221157429739833
Epoch 1000, Loss: 0.0013136111665517092, Constraint losses: L1: -1.1160844564437866, L2: 0.0, L3: 0.0022145509719848633, L4: 0.0002151446824427694
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 54.721614837646484, Losses: L1: 18.42068099975586, L2: 0.005979633890092373, L3: 1.0059788227081299, L4: 71.22493743896484, L5: 0.34704092144966125
Epoch 500, Loss: -2.4588446617126465, Losses: L1: -3.1515769958496094, L2: 0.16618075966835022, L3: 0.08603465557098389, L4: 0.6294710040092468, L5: 0.0052359458059072495
Epoch 1000, Loss: 25.79368019104004, Losses: L1: -0.9259815216064453, L2: 0.14679303765296936, L3: 0.9874889254570007, L4: 51.686405181884766, L5: 0.17825543880462646
Epoch 1500, Loss: 44.014732360839844, Losses: L1: 18.42068099975586, L2: 5.390043224906549e-05, L3: 1.0000356435775757, L4: 50.01763153076172, L5: 0.17022262513637543
Epoch 2000, Loss: 44.01271057128906, Losses: L1: 18.42068099975586, L2: 2.886454421968665e-05, L3: 1.0000174045562744, L4: 50.01371383666992, L5: 0.17021511495113373
Epoch 2500, Loss: 44.0117073059082, Losses: L1: 18.42068099975586, L2: 2.110039167746436e-05, L3: 1.0000121593475342, L4: 50.01174545288086, L5: 0.1702122688293457
Epoch 3000, Loss: 44.0111083984375, Losses: L1: 18.42068099975586, L2: 1.7304899301961996e-05, L3: 1.0000097751617432, L4: 50.01055908203125, L5: 0.17021101713180542
Epoch 3500, Loss: 44.010719299316406, Losses: L1: 18.42068099975586, L2: 1.5121369870030321e-05, L3: 1.000008463859558, L4: 50.00979232788086, L5: 0.17021024227142334
Epoch 4000, Loss: 44.01044845581055, Losses: L1: 18.42068099975586, L2: 1.3744274838245474e-05, L3: 1.0000076293945312, L4: 50.00926208496094, L5: 0.17020970582962036
Epoch 4500, Loss: 44.01026153564453, Losses: L1: 18.42068099975586, L2: 1.2822815733670723e-05, L3: 1.0000070333480835, L4: 50.00889205932617, L5: 0.17020933330059052
Epoch 5000, Loss: 44.01012420654297, Losses: L1: 18.42068099975586, L2: 1.218008401338011e-05, L3: 1.0000066757202148, L4: 50.00861358642578, L5: 0.17020906507968903
Epoch 5500, Loss: 44.01002502441406, Losses: L1: 18.42068099975586, L2: 1.1720653674274217e-05, L3: 1.0000063180923462, L4: 50.008419036865234, L5: 0.1702088713645935
Epoch 6000, Loss: 44.00994873046875, Losses: L1: 18.42068099975586, L2: 1.1384265235392377e-05, L3: 1.0000061988830566, L4: 50.008270263671875, L5: 0.17020876705646515
Epoch 6500, Loss: 44.00989532470703, Losses: L1: 18.42068099975586, L2: 1.1133811312902253e-05, L3: 1.000006079673767, L4: 50.00815963745117, L5: 0.17020875215530396
Epoch 7000, Loss: 44.009849548339844, Losses: L1: 18.42068099975586, L2: 1.0946905604214408e-05, L3: 1.0000059604644775, L4: 50.00807189941406, L5: 0.17020873725414276
Epoch 7500, Loss: 44.00981521606445, Losses: L1: 18.42068099975586, L2: 1.0805840247485321e-05, L3: 1.000005841255188, L4: 50.00800704956055, L5: 0.17020872235298157
Epoch 8000, Loss: 44.009788513183594, Losses: L1: 18.42068099975586, L2: 1.0697862308006734e-05, L3: 1.0000057220458984, L4: 50.00796127319336, L5: 0.17020870745182037
Epoch 8500, Loss: 44.009769439697266, Losses: L1: 18.42068099975586, L2: 1.0615870451147202e-05, L3: 1.0000057220458984, L4: 50.00791931152344, L5: 0.17020869255065918
Epoch 9000, Loss: 44.0097541809082, Losses: L1: 18.42068099975586, L2: 1.0552989806456026e-05, L3: 1.0000057220458984, L4: 50.00788879394531, L5: 0.17020869255065918
Epoch 9500, Loss: 44.009742736816406, Losses: L1: 18.42068099975586, L2: 1.0504038073122501e-05, L3: 1.0000057220458984, L4: 50.00786590576172, L5: 0.17020869255065918
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.019115447998047, Constraint losses: L1: 18.42068099975586, L2: 0.00024036818649619818, L3: 1.0002270936965942, L4: 1.0002272129058838
Epoch 500, Loss: 0.002190651837736368, Constraint losses: L1: -1.111331582069397, L2: 0.0, L3: 0.002650141716003418, L4: 0.000651841692160815
Epoch 1000, Loss: 0.0013055710587650537, Constraint losses: L1: -1.116139531135559, L2: 0.0, L3: 0.0022104978561401367, L4: 0.00021121278405189514
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.021604061126709, Constraint losses: L1: 18.42068099975586, L2: 0.001060929149389267, L3: 1.001060962677002, L4: 1.0010613203048706
Epoch 500, Loss: 0.0022970098070800304, Constraint losses: L1: -1.0909184217453003, L2: 0.0, L3: 0.002692878246307373, L4: 0.0006950499955564737
Epoch 1000, Loss: 0.0013218300882726908, Constraint losses: L1: -1.1193267107009888, L2: 0.0, L3: 0.002220332622528076, L4: 0.000220824294956401
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 51.313270568847656, Losses: L1: 11.418570518493652, L2: 0.0005577574484050274, L3: 0.999942421913147, L4: 77.99515533447266, L5: 0.3960351347923279
Epoch 500, Loss: -1.1500635147094727, Losses: L1: -3.1088175773620605, L2: 0.18619710206985474, L3: 0.07733428478240967, L4: 3.058048725128174, L5: 0.018668366596102715
Epoch 1000, Loss: -2.963646650314331, Losses: L1: -3.657174587249756, L2: 0.0950436145067215, L3: 0.03380018472671509, L4: 0.964860737323761, L5: 0.004110099747776985
Epoch 1500, Loss: 0.5259528756141663, Losses: L1: -2.636077404022217, L2: 0.27828332781791687, L3: 0.09642410278320312, L4: 5.0659356117248535, L5: 0.024283695966005325
Epoch 2000, Loss: -3.3099842071533203, Losses: L1: -3.717215061187744, L2: 0.09893383830785751, L3: 0.04473543167114258, L4: 0.3652490973472595, L5: 0.004370919894427061
Epoch 2500, Loss: -3.068624973297119, Losses: L1: -3.6710925102233887, L2: 0.05118580162525177, L3: 0.054788947105407715, L4: 0.9368210434913635, L5: 0.0042908675968647
Epoch 3000, Loss: -3.476693868637085, Losses: L1: -3.7967770099639893, L2: 0.04926679655909538, L3: 0.021625638008117676, L4: 0.41488197445869446, L5: 0.0032956080976873636
Epoch 3500, Loss: -3.5598437786102295, Losses: L1: -3.815864324569702, L2: 0.04939083755016327, L3: 0.038777828216552734, L4: 0.26922547817230225, L5: 0.00323717063292861
Epoch 4000, Loss: -3.6517539024353027, Losses: L1: -3.833991527557373, L2: 0.05197841674089432, L3: 0.05171084403991699, L4: 0.0983046218752861, L5: 0.003273113863542676
Epoch 4500, Loss: -3.659954309463501, Losses: L1: -3.8339006900787354, L2: 0.04973522946238518, L3: 0.05335402488708496, L4: 0.08908333629369736, L5: 0.003257201984524727
Epoch 5000, Loss: -3.664745807647705, Losses: L1: -3.8400802612304688, L2: 0.04982830956578255, L3: 0.05875873565673828, L4: 0.0860435962677002, L5: 0.0032768019009381533
Epoch 5500, Loss: -3.6731064319610596, Losses: L1: -3.843458652496338, L2: 0.04955185949802399, L3: 0.0624234676361084, L4: 0.07354149967432022, L5: 0.003266002517193556
Epoch 6000, Loss: -3.675755023956299, Losses: L1: -3.844644784927368, L2: 0.04906187579035759, L3: 0.06271648406982422, L4: 0.07228641211986542, L5: 0.0032645445317029953
Epoch 6500, Loss: -3.677487373352051, Losses: L1: -3.846625804901123, L2: 0.04908578842878342, L3: 0.06387734413146973, L4: 0.07152660191059113, L5: 0.003264984115958214
Epoch 7000, Loss: -3.6790637969970703, Losses: L1: -3.847676992416382, L2: 0.04884893074631691, L3: 0.06463217735290527, L4: 0.0706724300980568, L5: 0.003262712387368083
Epoch 7500, Loss: -3.68005108833313, Losses: L1: -3.8484854698181152, L2: 0.04864843189716339, L3: 0.0653073787689209, L4: 0.07044178992509842, L5: 0.0032629799097776413
Epoch 8000, Loss: -3.6808035373687744, Losses: L1: -3.849170207977295, L2: 0.048462335020303726, L3: 0.06601786613464355, L4: 0.07034112513065338, L5: 0.0032622909639030695
Epoch 8500, Loss: -3.6813862323760986, Losses: L1: -3.8495450019836426, L2: 0.04827312380075455, L3: 0.06643915176391602, L4: 0.07026289403438568, L5: 0.0032616674434393644
Epoch 9000, Loss: -3.6818366050720215, Losses: L1: -3.8499059677124023, L2: 0.048163220286369324, L3: 0.06679177284240723, L4: 0.07017093896865845, L5: 0.003261834615841508
Epoch 9500, Loss: -3.6821651458740234, Losses: L1: -3.8501687049865723, L2: 0.04805898666381836, L3: 0.06710171699523926, L4: 0.07014637440443039, L5: 0.003261504229158163
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.022862434387207, Constraint losses: L1: 18.42068099975586, L2: 0.0014804657548666, L3: 1.0014804601669312, L4: 1.0014806985855103
Epoch 500, Loss: 0.0020866310223937035, Constraint losses: L1: -1.0766900777816772, L2: 0.0, L3: 0.0025806427001953125, L4: 0.0005826783599331975
Epoch 1000, Loss: 0.0012471515219658613, Constraint losses: L1: -1.1179783344268799, L2: 0.0, L3: 0.002182304859161377, L4: 0.00018282505334354937
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.023752212524414, Constraint losses: L1: 18.42068099975586, L2: 0.0017771058483049273, L3: 1.0017770528793335, L4: 1.0017775297164917
Epoch 500, Loss: 0.0027470930945128202, Constraint losses: L1: -1.11643385887146, L2: 0.0, L3: 0.0029307007789611816, L4: 0.0009328261949121952
Epoch 1000, Loss: 0.0015019032871350646, Constraint losses: L1: -1.1187973022460938, L2: 0.0, L3: 0.0023099184036254883, L4: 0.00031078222673386335
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 48.766845703125, Losses: L1: 13.106369972229004, L2: 0.0010090850992128253, L3: 1.0003712177276611, L4: 69.00352478027344, L5: 0.32825496792793274
Epoch 500, Loss: -1.0150588750839233, Losses: L1: -3.2877814769744873, L2: 0.2847340404987335, L3: 0.07352864742279053, L4: 3.262341260910034, L5: 0.01765977032482624
Epoch 1000, Loss: -2.9979677200317383, Losses: L1: -3.680567502975464, L2: 0.17653436958789825, L3: 0.010155439376831055, L4: 0.6332892775535583, L5: 0.0039043393917381763
Epoch 1500, Loss: -2.8716959953308105, Losses: L1: -3.7508649826049805, L2: 0.1042318344116211, L3: 0.0329899787902832, L4: 1.280760407447815, L5: 0.006915110629051924
Epoch 2000, Loss: -3.492481231689453, Losses: L1: -3.86418080329895, L2: 0.051790256053209305, L3: 0.10229825973510742, L4: 0.4203590452671051, L5: 0.003395144594833255
Epoch 2500, Loss: -3.5290799140930176, Losses: L1: -3.888079881668091, L2: 0.053915318101644516, L3: 0.09662413597106934, L4: 0.39243826270103455, L5: 0.003319178707897663
Epoch 3000, Loss: -3.6705870628356934, Losses: L1: -3.9110054969787598, L2: 0.04832186549901962, L3: 0.12602615356445312, L4: 0.14905130863189697, L5: 0.0031180139631032944
Epoch 3500, Loss: -3.670498847961426, Losses: L1: -3.9159889221191406, L2: 0.05126718804240227, L3: 0.1111687421798706, L4: 0.16210973262786865, L5: 0.003158219624310732
Epoch 4000, Loss: -3.7137091159820557, Losses: L1: -3.923504114151001, L2: 0.04828203469514847, L3: 0.11740565299987793, L4: 0.09654462337493896, L5: 0.0031277798116207123
Epoch 4500, Loss: -3.706296443939209, Losses: L1: -3.9186744689941406, L2: 0.046122003346681595, L3: 0.10883712768554688, L4: 0.11885888129472733, L5: 0.0031430860981345177
Epoch 5000, Loss: -3.724945545196533, Losses: L1: -3.9272356033325195, L2: 0.04799285903573036, L3: 0.11176955699920654, L4: 0.08833324909210205, L5: 0.003126464318484068
Epoch 5500, Loss: -3.729686737060547, Losses: L1: -3.9282846450805664, L2: 0.04814921319484711, L3: 0.10913753509521484, L4: 0.08296653628349304, L5: 0.0031238077208399773
Epoch 6000, Loss: -3.7332427501678467, Losses: L1: -3.927229881286621, L2: 0.0475565604865551, L3: 0.10489296913146973, L4: 0.08036068081855774, L5: 0.0031235809437930584
Epoch 6500, Loss: -3.7351691722869873, Losses: L1: -3.9277892112731934, L2: 0.04763808101415634, L3: 0.10270857810974121, L4: 0.07948221266269684, L5: 0.0031243099365383387
Epoch 7000, Loss: -3.736760377883911, Losses: L1: -3.9284894466400146, L2: 0.04777773469686508, L3: 0.10133099555969238, L4: 0.07852009683847427, L5: 0.0031240214593708515
Epoch 7500, Loss: -3.7377777099609375, Losses: L1: -3.9288015365600586, L2: 0.04781302437186241, L3: 0.10003137588500977, L4: 0.07826686650514603, L5: 0.0031242044642567635
Epoch 8000, Loss: -3.738506555557251, Losses: L1: -3.928921699523926, L2: 0.047790177166461945, L3: 0.09897685050964355, L4: 0.07819633930921555, L5: 0.0031241229735314846
Epoch 8500, Loss: -3.739044427871704, Losses: L1: -3.929058790206909, L2: 0.047801993787288666, L3: 0.09821474552154541, L4: 0.07810933142900467, L5: 0.0031242878176271915
Epoch 9000, Loss: -3.7394299507141113, Losses: L1: -3.9291226863861084, L2: 0.04779265448451042, L3: 0.09768176078796387, L4: 0.0780358761548996, L5: 0.003124317154288292
Epoch 9500, Loss: -3.7396910190582275, Losses: L1: -3.929072618484497, L2: 0.04775426909327507, L3: 0.09723186492919922, L4: 0.0780167281627655, L5: 0.003124296898022294
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.040297031402588, Constraint losses: L1: 18.42068099975586, L2: 0.0072918543592095375, L3: 1.0072919130325317, L4: 1.0072925090789795
Epoch 500, Loss: 0.00208451459184289, Constraint losses: L1: -1.1076018810272217, L2: 0.0, L3: 0.0025953054428100586, L4: 0.0005968109471723437
Epoch 1000, Loss: 0.001271288376301527, Constraint losses: L1: -1.1184449195861816, L2: 0.0, L3: 0.002194643020629883, L4: 0.00019509033882059157
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.002286672592163, Constraint losses: L1: 6.1786651611328125, L2: 0.0, L3: 0.9980542659759521, L4: 0.9980537295341492
Epoch 500, Loss: 0.0018877133261412382, Constraint losses: L1: -1.1017537117004395, L2: 0.0, L3: 0.00249403715133667, L4: 0.0004954299656674266
Epoch 1000, Loss: 0.0011946104932576418, Constraint losses: L1: -1.1197373867034912, L2: 0.0, L3: 0.002156972885131836, L4: 0.0001573750050738454
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 85.45178985595703, Losses: L1: 5.263014793395996, L2: 0.0, L3: 0.9954833388328552, L4: 79.48881530761719, L5: 0.40444085001945496
Epoch 500, Loss: 57.52425003051758, Losses: L1: 6.689520835876465, L2: 0.0, L3: 0.9905577301979065, L4: 50.25385665893555, L5: 0.17118456959724426
Epoch 1000, Loss: 11.190882682800293, Losses: L1: -0.43437477946281433, L2: 0.3145509660243988, L3: 0.31432169675827026, L4: 10.82449722290039, L5: 0.028995024040341377
Epoch 1500, Loss: 6.044462203979492, Losses: L1: -0.7633363008499146, L2: 0.3657347559928894, L3: 0.25739651918411255, L4: 5.937282085418701, L5: 0.020697301253676414
Epoch 2000, Loss: 4.8873820304870605, Losses: L1: -0.8076604604721069, L2: 0.3142392039299011, L3: 0.275846004486084, L4: 4.919309616088867, L5: 0.018662327900528908
Epoch 2500, Loss: 4.4955339431762695, Losses: L1: -0.8276348114013672, L2: 0.34303778409957886, L3: 0.2762494683265686, L4: 4.489953994750977, L5: 0.01802944578230381
Epoch 3000, Loss: 4.253602027893066, Losses: L1: -0.733005166053772, L2: 0.3663538992404938, L3: 0.28185510635375977, L4: 4.103396415710449, L5: 0.019150828942656517
Epoch 3500, Loss: 4.138120651245117, Losses: L1: -0.7003787159919739, L2: 0.3917277157306671, L3: 0.28310173749923706, L4: 3.903096914291382, L5: 0.020791539922356606
Epoch 4000, Loss: 4.112965106964111, Losses: L1: -0.6939890384674072, L2: 0.4060627818107605, L3: 0.2826905846595764, L4: 3.8427648544311523, L5: 0.021436309441924095
Epoch 4500, Loss: 4.031654357910156, Losses: L1: -0.6287490725517273, L2: 0.3929029703140259, L3: 0.2811746597290039, L4: 3.7221126556396484, L5: 0.023795433342456818
Epoch 5000, Loss: 4.000370979309082, Losses: L1: -0.6237502694129944, L2: 0.39478322863578796, L3: 0.28115248680114746, L4: 3.681874990463257, L5: 0.024207327514886856
Epoch 5500, Loss: 3.9682462215423584, Losses: L1: -0.6292451620101929, L2: 0.3990667164325714, L3: 0.28148412704467773, L4: 3.6465554237365723, L5: 0.024120919406414032
Epoch 6000, Loss: 3.9529969692230225, Losses: L1: -0.624313235282898, L2: 0.39933791756629944, L3: 0.28105562925338745, L4: 3.62589168548584, L5: 0.02442999742925167
Epoch 6500, Loss: 3.940103530883789, Losses: L1: -0.6266114115715027, L2: 0.40151146054267883, L3: 0.28087878227233887, L4: 3.6110570430755615, L5: 0.02439105696976185
Epoch 7000, Loss: 3.931506872177124, Losses: L1: -0.6230519413948059, L2: 0.40102413296699524, L3: 0.2805684208869934, L4: 3.5999276638031006, L5: 0.024597330018877983
Epoch 7500, Loss: 3.9251246452331543, Losses: L1: -0.623505175113678, L2: 0.401571124792099, L3: 0.2805073857307434, L4: 3.5929245948791504, L5: 0.02461862750351429
Epoch 8000, Loss: 3.9211113452911377, Losses: L1: -0.6244218945503235, L2: 0.40202730894088745, L3: 0.2805072069168091, L4: 3.588921070098877, L5: 0.024608341977000237
Epoch 8500, Loss: 3.9180610179901123, Losses: L1: -0.6222376823425293, L2: 0.4014275074005127, L3: 0.2804269790649414, L4: 3.5848660469055176, L5: 0.02472815476357937
Epoch 9000, Loss: 3.9158222675323486, Losses: L1: -0.6227027773857117, L2: 0.4016740620136261, L3: 0.2804252505302429, L4: 3.5826034545898438, L5: 0.024721398949623108
Epoch 9500, Loss: 3.9144396781921387, Losses: L1: -0.6231505274772644, L2: 0.40190380811691284, L3: 0.28041988611221313, L4: 3.5812175273895264, L5: 0.02471013367176056
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0680415630340576, Constraint losses: L1: 18.42068099975586, L2: 0.016539106145501137, L3: 1.0165390968322754, L4: 1.016542673110962
Epoch 500, Loss: 0.002432700479403138, Constraint losses: L1: -1.1057331562042236, L2: 0.0, L3: 0.0027683377265930176, L4: 0.000770095968618989
Epoch 1000, Loss: 0.0013926916290074587, Constraint losses: L1: -1.1154847145080566, L2: 0.0, L3: 0.002253711223602295, L4: 0.0002544652088545263
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.018828868865967, Constraint losses: L1: 18.42068099975586, L2: 0.00013604604464489967, L3: 1.0001360177993774, L4: 1.000136137008667
Epoch 500, Loss: 0.0020916638895869255, Constraint losses: L1: -1.088971734046936, L2: 0.0, L3: 0.002589404582977295, L4: 0.0005912309279665351
Epoch 1000, Loss: 0.001263149082660675, Constraint losses: L1: -1.1185238361358643, L2: 0.0, L3: 0.002190530300140381, L4: 0.00019114266615360975
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 72.8322982788086, Losses: L1: 5.70579719543457, L2: 0.0, L3: 0.9965394139289856, L4: 66.32783508300781, L5: 0.3004016578197479
Epoch 500, Loss: -0.31882205605506897, Losses: L1: -2.8352255821228027, L2: 0.26497456431388855, L3: 0.07598876953125, L4: 1.9399069547653198, L5: 0.008552994579076767
Epoch 1000, Loss: 1.513700246810913, Losses: L1: -2.8272805213928223, L2: 0.3301638960838318, L3: 0.07935976982116699, L4: 3.621284246444702, L5: 0.019688552245497704
Epoch 1500, Loss: -1.6368565559387207, Losses: L1: -3.4500186443328857, L2: 0.2110208421945572, L3: 0.026910483837127686, L4: 1.3702378273010254, L5: 0.007427460979670286
Epoch 2000, Loss: -2.3887882232666016, Losses: L1: -2.9075896739959717, L2: 0.10229980200529099, L3: 0.04785454273223877, L4: 0.2861616015434265, L5: 0.004112905822694302
Epoch 2500, Loss: -2.8553688526153564, Losses: L1: -3.450909376144409, L2: 0.1674174964427948, L3: 0.0398373007774353, L4: 0.23697036504745483, L5: 0.0038163699209690094
Epoch 3000, Loss: -2.6790411472320557, Losses: L1: -3.5527000427246094, L2: 0.14415951073169708, L3: 0.024190783500671387, L4: 0.5688692927360535, L5: 0.004374867305159569
Epoch 3500, Loss: -3.1331377029418945, Losses: L1: -3.556993246078491, L2: 0.11037609726190567, L3: 0.006475687026977539, L4: 0.19615544378757477, L5: 0.0037096755113452673
Epoch 4000, Loss: -3.2385003566741943, Losses: L1: -3.5694425106048584, L2: 0.09300070255994797, L3: 0.0009316205978393555, L4: 0.1408705711364746, L5: 0.003604382509365678
Epoch 4500, Loss: -3.2845377922058105, Losses: L1: -3.5794429779052734, L2: 0.08695082366466522, L3: 9.894371032714844e-05, L4: 0.11734981089830399, L5: 0.003604264697059989
Epoch 5000, Loss: -3.3021352291107178, Losses: L1: -3.5892159938812256, L2: 0.08507802337408066, L3: 0.000110626220703125, L4: 0.11326573044061661, L5: 0.003603703109547496
Epoch 5500, Loss: -3.3130133152008057, Losses: L1: -3.595729351043701, L2: 0.08358723670244217, L3: 0.00023186206817626953, L4: 0.11182300746440887, L5: 0.003602525917813182
Epoch 6000, Loss: -3.320924758911133, Losses: L1: -3.6010453701019287, L2: 0.0828007310628891, L3: 1.633167266845703e-05, L4: 0.11091278493404388, L5: 0.003598299343138933
Epoch 6500, Loss: -3.326784610748291, Losses: L1: -3.6051547527313232, L2: 0.08251283317804337, L3: 4.506111145019531e-05, L4: 0.10972228646278381, L5: 0.0035995086655020714
Epoch 7000, Loss: -3.330364227294922, Losses: L1: -3.607940673828125, L2: 0.08226267248392105, L3: 0.00013840198516845703, L4: 0.10938412696123123, L5: 0.003598031820729375
Epoch 7500, Loss: -3.3329110145568848, Losses: L1: -3.6091978549957275, L2: 0.08174208551645279, L3: 3.218650817871094e-05, L4: 0.10918980836868286, L5: 0.0035970481112599373
Epoch 8000, Loss: -3.3345999717712402, Losses: L1: -3.609511375427246, L2: 0.08113591372966766, L3: 0.0001251697540283203, L4: 0.10898030549287796, L5: 0.003596609691157937
Epoch 8500, Loss: -3.335865020751953, Losses: L1: -3.6098716259002686, L2: 0.08081348985433578, L3: 6.318092346191406e-06, L4: 0.10878049582242966, L5: 0.00359615171328187
Epoch 9000, Loss: -3.336657762527466, Losses: L1: -3.6104981899261475, L2: 0.08078265935182571, L3: 9.179115295410156e-06, L4: 0.10867410153150558, L5: 0.0035964809358119965
Epoch 9500, Loss: -3.337259292602539, Losses: L1: -3.611037254333496, L2: 0.0808127149939537, L3: 3.349781036376953e-05, L4: 0.10853982716798782, L5: 0.0035960059612989426
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0008902549743652, Constraint losses: L1: 5.95309591293335, L2: 0.0, L3: 0.9974686503410339, L4: 0.9974683523178101
Epoch 500, Loss: 0.002171187661588192, Constraint losses: L1: -1.112729787826538, L2: 0.0, L3: 0.0026412010192871094, L4: 0.0006427164189517498
Epoch 1000, Loss: 0.001307775964960456, Constraint losses: L1: -1.1157463788986206, L2: 0.0, L3: 0.0022115111351013184, L4: 0.0002120112330885604
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9940955638885498, Constraint losses: L1: 5.1390557289123535, L2: 0.0, L3: 0.9944788813591003, L4: 0.9944776296615601
Epoch 500, Loss: 0.002286061644554138, Constraint losses: L1: -0.9474443197250366, L2: 0.0, L3: 0.002615630626678467, L4: 0.0006178752519190311
Epoch 1000, Loss: 0.001242325408384204, Constraint losses: L1: -1.1153113842010498, L2: 0.0, L3: 0.0021785497665405273, L4: 0.0001790870155673474
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 105.32969665527344, Losses: L1: 18.42068099975586, L2: 0.004484621342271566, L3: 1.0044368505477905, L4: 85.50159454345703, L5: 0.44811591506004333
Epoch 500, Loss: 4.491667747497559, Losses: L1: -1.5465930700302124, L2: 0.2808736562728882, L3: 0.08819764852523804, L4: 5.376548767089844, L5: 0.027932943776249886
Epoch 1000, Loss: -0.6429564952850342, Losses: L1: -3.1338415145874023, L2: 0.16509152948856354, L3: 0.07892537117004395, L4: 2.106692314147949, L5: 0.007273553404957056
Epoch 1500, Loss: -2.27150297164917, Losses: L1: -3.6028003692626953, L2: 0.15578648447990417, L3: 0.026638507843017578, L4: 0.9923964142799377, L5: 0.0070043602026999
Epoch 2000, Loss: -2.740901470184326, Losses: L1: -3.8119122982025146, L2: 0.11365991085767746, L3: 0.018715858459472656, L4: 0.821478545665741, L5: 0.006427338812500238
Epoch 2500, Loss: -2.9977738857269287, Losses: L1: -3.6939234733581543, L2: 0.09887277334928513, L3: 0.0579448938369751, L4: 0.45977768301963806, L5: 0.004826963879168034
Epoch 3000, Loss: -3.4908030033111572, Losses: L1: -3.9227757453918457, L2: 0.08539263159036636, L3: 0.00815129280090332, L4: 0.24931834638118744, L5: 0.00389667646959424
Epoch 3500, Loss: -3.643383264541626, Losses: L1: -3.952380657196045, L2: 0.08786752820014954, L3: 0.008571386337280273, L4: 0.12169943749904633, L5: 0.0036386693827807903
Epoch 4000, Loss: -3.6762990951538086, Losses: L1: -3.9698269367218018, L2: 0.08525484055280685, L3: 0.0024030208587646484, L4: 0.11456886678934097, L5: 0.0036238341126590967
Epoch 4500, Loss: -3.666980028152466, Losses: L1: -3.9799892902374268, L2: 0.08331265300512314, L3: 0.009681940078735352, L4: 0.13429276645183563, L5: 0.003625103272497654
Epoch 5000, Loss: -3.722363233566284, Losses: L1: -3.9850313663482666, L2: 0.08142418414354324, L3: 0.0011496543884277344, L4: 0.09219120442867279, L5: 0.0035268384963274
Epoch 5500, Loss: -3.7269835472106934, Losses: L1: -3.98813796043396, L2: 0.0803728699684143, L3: 0.003962039947509766, L4: 0.09143618494272232, L5: 0.0034956771414726973
Epoch 6000, Loss: -3.7353646755218506, Losses: L1: -3.9899988174438477, L2: 0.07923740893602371, L3: 0.0015690326690673828, L4: 0.08836694061756134, L5: 0.0035039305221289396
Epoch 6500, Loss: -3.7403671741485596, Losses: L1: -3.9910173416137695, L2: 0.0782802626490593, L3: 0.00039076805114746094, L4: 0.08691179752349854, L5: 0.0034912435803562403
Epoch 7000, Loss: -3.7429258823394775, Losses: L1: -3.992121934890747, L2: 0.07786137610673904, L3: 8.851289749145508e-05, L4: 0.08645746111869812, L5: 0.0034856421407312155
Epoch 7500, Loss: -3.744537830352783, Losses: L1: -3.9928689002990723, L2: 0.07757581770420074, L3: 0.00028955936431884766, L4: 0.08607406169176102, L5: 0.0034803173039108515
Epoch 8000, Loss: -3.7458455562591553, Losses: L1: -3.9934325218200684, L2: 0.07740689814090729, L3: 5.733966827392578e-05, L4: 0.08578867465257645, L5: 0.0034778716508299112
Epoch 8500, Loss: -3.7466917037963867, Losses: L1: -3.9937222003936768, L2: 0.07723944634199142, L3: 5.555152893066406e-05, L4: 0.08557292819023132, L5: 0.0034755184315145016
Epoch 9000, Loss: -3.7472827434539795, Losses: L1: -3.9939534664154053, L2: 0.07712520658969879, L3: 6.973743438720703e-05, L4: 0.08543744683265686, L5: 0.0034740539267659187
Epoch 9500, Loss: -3.747655153274536, Losses: L1: -3.994067430496216, L2: 0.07703720033168793, L3: 9.489059448242188e-05, L4: 0.08534363657236099, L5: 0.0034733538050204515
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0203893184661865, Constraint losses: L1: 18.42068099975586, L2: 0.0006562317721545696, L3: 1.000656247138977, L4: 1.0006561279296875
Epoch 500, Loss: 0.0024004923179745674, Constraint losses: L1: -1.050524353981018, L2: 0.0, L3: 0.002724587917327881, L4: 0.0007264286978170276
Epoch 1000, Loss: 0.0013277435209602118, Constraint losses: L1: -1.116702914237976, L2: 0.0, L3: 0.0022218823432922363, L4: 0.000222564151044935
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.005608320236206, Constraint losses: L1: 7.119908332824707, L2: 0.0, L3: 0.9992443323135376, L4: 0.9992441534996033
Epoch 500, Loss: 0.0020315099973231554, Constraint losses: L1: -1.0921409130096436, L2: 0.0, L3: 0.0025610923767089844, L4: 0.000562558532692492
Epoch 1000, Loss: 0.0012377242092043161, Constraint losses: L1: -1.1197720766067505, L2: 0.0, L3: 0.0021785497665405273, L4: 0.00017894658958539367
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 171.30149841308594, Losses: L1: 18.42068099975586, L2: 0.004863203503191471, L3: 1.0048612356185913, L4: 76.08885192871094, L5: 0.3819339871406555
Epoch 500, Loss: 12.837226867675781, Losses: L1: -1.8903067111968994, L2: 0.42694970965385437, L3: 0.1894817352294922, L4: 6.882252216339111, L5: 0.028778575360774994
Epoch 1000, Loss: 4.244755268096924, Losses: L1: -2.5551466941833496, L2: 0.18590866029262543, L3: 0.0951957106590271, L4: 3.1878626346588135, L5: 0.00952206365764141
Epoch 1500, Loss: -1.8263258934020996, Losses: L1: -3.3618814945220947, L2: 0.17907634377479553, L3: 0.0693250298500061, L4: 0.5701130628585815, L5: 0.005028619430959225
Epoch 2000, Loss: 0.008869173936545849, Losses: L1: -3.6180002689361572, L2: 0.20208312571048737, L3: 0.03230476379394531, L4: 1.6005367040634155, L5: 0.010954862460494041
Epoch 2500, Loss: -2.140873670578003, Losses: L1: -3.6082136631011963, L2: 0.09228774160146713, L3: 0.05514484643936157, L4: 0.6267197132110596, L5: 0.003505114698782563
Epoch 3000, Loss: -2.569988250732422, Losses: L1: -3.730181932449341, L2: 0.12144464999437332, L3: 0.012712955474853516, L4: 0.4542352557182312, L5: 0.00495410431176424
Epoch 3500, Loss: -3.168966293334961, Losses: L1: -3.7255823612213135, L2: 0.10223715752363205, L3: 0.009638071060180664, L4: 0.17265398800373077, L5: 0.00402991846203804
Epoch 4000, Loss: -3.046288013458252, Losses: L1: -3.732295513153076, L2: 0.09825208783149719, L3: 0.008984804153442383, L4: 0.24145624041557312, L5: 0.004197032656520605
Epoch 4500, Loss: -3.2601897716522217, Losses: L1: -3.724773645401001, L2: 0.08864101767539978, L3: 0.0032733678817749023, L4: 0.1418580710887909, L5: 0.00389776099473238
Epoch 5000, Loss: -3.320241689682007, Losses: L1: -3.7177839279174805, L2: 0.08214497566223145, L3: 0.0002015233039855957, L4: 0.11563046276569366, L5: 0.003780914703384042
Epoch 5500, Loss: -3.3290462493896484, Losses: L1: -3.7195560932159424, L2: 0.08177220821380615, L3: 7.975101470947266e-05, L4: 0.1125141978263855, L5: 0.0037945944350212812
Epoch 6000, Loss: -3.3370537757873535, Losses: L1: -3.7216415405273438, L2: 0.08189551532268524, L3: 0.0001323223114013672, L4: 0.10941934585571289, L5: 0.003784300060942769
Epoch 6500, Loss: -3.340698480606079, Losses: L1: -3.722594976425171, L2: 0.08146185427904129, L3: 0.0010197162628173828, L4: 0.10828609764575958, L5: 0.003780876751989126
Epoch 7000, Loss: -3.3432300090789795, Losses: L1: -3.722508430480957, L2: 0.08127989619970322, L3: 0.0002576112747192383, L4: 0.1073504090309143, L5: 0.003778014564886689
Epoch 7500, Loss: -3.344900608062744, Losses: L1: -3.7225232124328613, L2: 0.0809558629989624, L3: 0.00034236907958984375, L4: 0.1068270206451416, L5: 0.00377154303714633
Epoch 8000, Loss: -3.34627628326416, Losses: L1: -3.7227399349212646, L2: 0.08098731189966202, L3: 0.00013339519500732422, L4: 0.10626854002475739, L5: 0.0037701621185988188
Epoch 8500, Loss: -3.3472166061401367, Losses: L1: -3.7226579189300537, L2: 0.0808219313621521, L3: 9.131431579589844e-05, L4: 0.10593361407518387, L5: 0.0037687041331082582
Epoch 9000, Loss: -3.3478610515594482, Losses: L1: -3.7231225967407227, L2: 0.08094529807567596, L3: 0.00028395652770996094, L4: 0.10567232966423035, L5: 0.003768252907320857
Epoch 9500, Loss: -3.3483550548553467, Losses: L1: -3.7229957580566406, L2: 0.080860435962677, L3: 0.00010251998901367188, L4: 0.10549253225326538, L5: 0.0037676948122680187
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0081064701080322, Constraint losses: L1: 8.602484703063965, L2: 0.0, L3: 0.9997519254684448, L4: 0.9997521042823792
Epoch 500, Loss: 0.0021941782906651497, Constraint losses: L1: -1.1017202138900757, L2: 0.0, L3: 0.002647101879119873, L4: 0.0006487966747954488
Epoch 1000, Loss: 0.0013032836141064763, Constraint losses: L1: -1.11809504032135, L2: 0.0, L3: 0.0022103190422058105, L4: 0.00021105966879986227
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 1.9738006591796875, Constraint losses: L1: 4.174129009246826, L2: 0.0, L3: 0.9848141074180603, L4: 0.9848124384880066
Epoch 500, Loss: 0.0021206168457865715, Constraint losses: L1: -1.0711687803268433, L2: 0.0, L3: 0.0025950074195861816, L4: 0.0005967782344669104
Epoch 1000, Loss: 0.0012569022364914417, Constraint losses: L1: -1.1196500062942505, L2: 0.0, L3: 0.00218808650970459, L4: 0.0001884658558992669
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 169.73480224609375, Losses: L1: 18.42068099975586, L2: 0.000895181146916002, L3: 1.0007472038269043, L4: 75.21778106689453, L5: 0.37639033794403076
Epoch 500, Loss: 3.4882242679595947, Losses: L1: -2.4090776443481445, L2: 0.1909659057855606, L3: 0.08849447965621948, L4: 2.730743885040283, L5: 0.009635231457650661
Epoch 1000, Loss: -0.34024202823638916, Losses: L1: -3.013136386871338, L2: 0.19235168397426605, L3: 0.05831938982009888, L4: 1.1269872188568115, L5: 0.005056725349277258
Epoch 1500, Loss: -1.4545384645462036, Losses: L1: -3.2077314853668213, L2: 0.1765500158071518, L3: 0.05898094177246094, L4: 0.6830887198448181, L5: 0.004425012972205877
Epoch 2000, Loss: -2.322056770324707, Losses: L1: -3.3653008937835693, L2: 0.17627041041851044, L3: 0.055377304553985596, L4: 0.3296237587928772, L5: 0.003767108079046011
Epoch 2500, Loss: -2.504903554916382, Losses: L1: -3.400405168533325, L2: 0.13394738733768463, L3: 0.0501023530960083, L4: 0.2995854616165161, L5: 0.003384905168786645
Epoch 3000, Loss: -2.4067225456237793, Losses: L1: -3.648681879043579, L2: 0.14310263097286224, L3: 0.03674721717834473, L4: 0.4667244851589203, L5: 0.00393128814175725
Epoch 3500, Loss: -3.286180257797241, Losses: L1: -3.684351682662964, L2: 0.08346446603536606, L3: 0.021285295486450195, L4: 0.10865828394889832, L5: 0.0032832054421305656
Epoch 4000, Loss: -3.3898873329162598, Losses: L1: -3.728105306625366, L2: 0.08643586188554764, L3: 0.015487611293792725, L4: 0.07716222107410431, L5: 0.003277897834777832
Epoch 4500, Loss: -3.3948330879211426, Losses: L1: -3.7407584190368652, L2: 0.08625558763742447, L3: 0.011957943439483643, L4: 0.08207590878009796, L5: 0.0032831786666065454
Epoch 5000, Loss: -3.433136463165283, Losses: L1: -3.7395105361938477, L2: 0.08085822314023972, L3: 0.012355923652648926, L4: 0.06760664284229279, L5: 0.0032663135789334774
Epoch 5500, Loss: -3.4430580139160156, Losses: L1: -3.7429771423339844, L2: 0.08032553642988205, L3: 0.011227428913116455, L4: 0.06519436836242676, L5: 0.003265690989792347
Epoch 6000, Loss: -3.449434280395508, Losses: L1: -3.7438454627990723, L2: 0.07873661071062088, L3: 0.010744810104370117, L4: 0.06415082514286041, L5: 0.0032639384735375643
Epoch 6500, Loss: -3.455197811126709, Losses: L1: -3.744011640548706, L2: 0.07759033143520355, L3: 0.010326623916625977, L4: 0.06260377913713455, L5: 0.0032623049337416887
Epoch 7000, Loss: -3.458216667175293, Losses: L1: -3.744595766067505, L2: 0.0769331231713295, L3: 0.009829282760620117, L4: 0.06216835230588913, L5: 0.0032615598756819963
Epoch 7500, Loss: -3.4608585834503174, Losses: L1: -3.744544506072998, L2: 0.07619914412498474, L3: 0.00965505838394165, L4: 0.06159966066479683, L5: 0.003260897472500801
Epoch 8000, Loss: -3.4622678756713867, Losses: L1: -3.7451887130737305, L2: 0.07610466331243515, L3: 0.009457767009735107, L4: 0.06136097386479378, L5: 0.0032607687171548605
Epoch 8500, Loss: -3.463489294052124, Losses: L1: -3.745426893234253, L2: 0.07586857676506042, L3: 0.009297728538513184, L4: 0.06114557385444641, L5: 0.0032604578882455826
Epoch 9000, Loss: -3.464271068572998, Losses: L1: -3.7454981803894043, L2: 0.07562804967164993, L3: 0.009159564971923828, L4: 0.06106540188193321, L5: 0.0032603065483272076
Epoch 9500, Loss: -3.4647586345672607, Losses: L1: -3.745723247528076, L2: 0.07557188719511032, L3: 0.009075760841369629, L4: 0.06101148575544357, L5: 0.003260223660618067
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 0.5, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.004157543182373, Constraint losses: L1: 6.645760536193848, L2: 0.0, L3: 0.998755931854248, L4: 0.998755693435669
Epoch 500, Loss: 0.0022079378832131624, Constraint losses: L1: -1.0967376232147217, L2: 0.0, L3: 0.002651393413543701, L4: 0.0006532821571454406
Epoch 1000, Loss: 0.001298538874834776, Constraint losses: L1: -1.1184580326080322, L2: 0.0, L3: 0.002208232879638672, L4: 0.00020876404596492648
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.020071268081665, Constraint losses: L1: 18.42068099975586, L2: 0.0005658911541104317, L3: 1.000542402267456, L4: 1.0005422830581665
Epoch 500, Loss: 0.0020695612765848637, Constraint losses: L1: -1.0990244150161743, L2: 0.0, L3: 0.0025835037231445312, L4: 0.0005850819870829582
Epoch 1000, Loss: 0.0012561260955408216, Constraint losses: L1: -1.1196149587631226, L2: 0.0, L3: 0.0021875500679016113, L4: 0.00018819102842826396
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 177.1963653564453, Losses: L1: 15.32461929321289, L2: 0.0038530942983925343, L3: 1.0035653114318848, L4: 80.2765884399414, L5: 0.4045412838459015
Epoch 500, Loss: 11.04757022857666, Losses: L1: -1.253306269645691, L2: 0.37918221950531006, L3: 0.07956993579864502, L4: 5.727311611175537, L5: 0.0240519717335701
Epoch 1000, Loss: 2.5814995765686035, Losses: L1: -2.6316940784454346, L2: 0.5527597665786743, L3: 0.05873739719390869, L4: 2.0290963649749756, L5: 0.010056382045149803
Epoch 1500, Loss: -1.3477566242218018, Losses: L1: -3.4281654357910156, L2: 0.20248472690582275, L3: 0.05822288990020752, L4: 0.8180347681045532, L5: 0.0051292069256305695
Epoch 2000, Loss: -0.6827654838562012, Losses: L1: -3.4224929809570312, L2: 0.14288491010665894, L3: 0.06216311454772949, L4: 1.205329179763794, L5: 0.006108758971095085
Epoch 2500, Loss: -2.946728229522705, Losses: L1: -3.614525079727173, L2: 0.12041670829057693, L3: 0.03552514314651489, L4: 0.2011587917804718, L5: 0.00344160501845181
Epoch 3000, Loss: -2.669581890106201, Losses: L1: -3.6694939136505127, L2: 0.11548150330781937, L3: 0.011271297931671143, L4: 0.37812933325767517, L5: 0.003527281805872917
Epoch 3500, Loss: -3.20805287361145, Losses: L1: -3.6698014736175537, L2: 0.09162703156471252, L3: 0.012213587760925293, L4: 0.13277433812618256, L5: 0.0034195163752883673
Epoch 4000, Loss: -3.195215940475464, Losses: L1: -3.685473918914795, L2: 0.08726009726524353, L3: 0.00595933198928833, L4: 0.1529979705810547, L5: 0.0033810390159487724
Epoch 4500, Loss: -3.2999610900878906, Losses: L1: -3.6869146823883057, L2: 0.08062107861042023, L3: 0.003601968288421631, L4: 0.10856102406978607, L5: 0.003394091734662652
Epoch 5000, Loss: -3.3069114685058594, Losses: L1: -3.6916327476501465, L2: 0.07699556648731232, L3: 0.0011812448501586914, L4: 0.11168637871742249, L5: 0.0033833892084658146
Epoch 5500, Loss: -3.329888343811035, Losses: L1: -3.6934239864349365, L2: 0.07417171448469162, L3: 0.0003166794776916504, L4: 0.10413211584091187, L5: 0.003384792245924473
Epoch 6000, Loss: -3.3371918201446533, Losses: L1: -3.6952507495880127, L2: 0.07227132469415665, L3: 4.982948303222656e-05, L4: 0.10336445271968842, L5: 0.003381116781383753
Epoch 6500, Loss: -3.345857620239258, Losses: L1: -3.695162296295166, L2: 0.07062177360057831, L3: 0.00020372867584228516, L4: 0.10059806704521179, L5: 0.003381630638614297
Epoch 7000, Loss: -3.349625587463379, Losses: L1: -3.695955991744995, L2: 0.06981632858514786, L3: 2.9206275939941406e-05, L4: 0.09996035695075989, L5: 0.0033812017645686865
Epoch 7500, Loss: -3.352405071258545, Losses: L1: -3.696303367614746, L2: 0.06916122138500214, L3: 2.8848648071289062e-05, L4: 0.09940093755722046, L5: 0.0033798690419644117
Epoch 8000, Loss: -3.3543684482574463, Losses: L1: -3.6963863372802734, L2: 0.06868889927864075, L3: 1.7642974853515625e-05, L4: 0.09893587231636047, L5: 0.0033797752112150192
Epoch 8500, Loss: -3.3557209968566895, Losses: L1: -3.696526050567627, L2: 0.06840039044618607, L3: 1.9788742065429688e-05, L4: 0.09861784428358078, L5: 0.0033793861512094736
Epoch 9000, Loss: -3.356597900390625, Losses: L1: -3.6964805126190186, L2: 0.06812915205955505, L3: 2.205371856689453e-05, L4: 0.09842747449874878, L5: 0.0033790571615099907
Epoch 9500, Loss: -3.3572838306427, Losses: L1: -3.696585178375244, L2: 0.06798452138900757, L3: 7.152557373046875e-07, L4: 0.09828680753707886, L5: 0.0033789717126637697
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.005359649658203, Constraint losses: L1: 7.040940284729004, L2: 0.0, L3: 0.9991594552993774, L4: 0.9991592764854431
Epoch 500, Loss: 0.0022410424426198006, Constraint losses: L1: -1.0633131265640259, L2: 0.0, L3: 0.0026511549949645996, L4: 0.0006532006082125008
Epoch 1000, Loss: 0.0012935036793351173, Constraint losses: L1: -1.117146372795105, L2: 0.0, L3: 0.002205073833465576, L4: 0.00020557636162266135
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.040914535522461, Constraint losses: L1: 18.42068099975586, L2: 0.007497668266296387, L3: 1.0074976682662964, L4: 1.0074985027313232
Epoch 500, Loss: 0.001969479024410248, Constraint losses: L1: -1.113402009010315, L2: 0.0, L3: 0.0025407075881958008, L4: 0.0005421733949333429
Epoch 1000, Loss: 0.0012392255011945963, Constraint losses: L1: -1.1200242042541504, L2: 0.0, L3: 0.002179384231567383, L4: 0.00017986554303206503
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 53.6408576965332, Losses: L1: 7.11588716506958, L2: 1.3788193200525711e-06, L3: 0.9976983666419983, L4: 90.57252502441406, L5: 0.48201677203178406
Epoch 500, Loss: -1.5063925981521606, Losses: L1: -2.894106388092041, L2: 0.30196312069892883, L3: 0.08278393745422363, L4: 1.3936209678649902, L5: 0.008386372588574886
Epoch 1000, Loss: -1.5773118734359741, Losses: L1: -3.1160683631896973, L2: 0.12776176631450653, L3: 0.07706034183502197, L4: 2.4040145874023438, L5: 0.008330559358000755
Epoch 1500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 7.975986981989536e-09, L3: 1.0, L4: 50.00014114379883, L5: 0.17030654847621918
Epoch 2000, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0929032123740967e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 2500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0919806170406332e-09, L3: 1.0, L4: 50.00014877319336, L5: 0.17030653357505798
Epoch 3000, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.091285395382613e-09, L3: 1.0, L4: 50.00014877319336, L5: 0.17030653357505798
Epoch 3500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.090758261490521e-09, L3: 1.0, L4: 50.00014877319336, L5: 0.17030653357505798
Epoch 4000, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.090292855998598e-09, L3: 1.0, L4: 50.00014877319336, L5: 0.17030653357505798
Epoch 4500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0898690838700986e-09, L3: 1.0, L4: 50.00014877319336, L5: 0.17030653357505798
Epoch 5000, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.089714096735861e-09, L3: 1.0, L4: 50.00014877319336, L5: 0.17030653357505798
Epoch 5500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0896160640427865e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 6000, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0895415680778342e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 6500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0894791735438503e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 7000, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0894275481732052e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 7500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0893875801443187e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 8000, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0893649315946163e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 8500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0893460578031977e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 9000, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0893307367254579e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Epoch 9500, Loss: 44.50590515136719, Losses: L1: 18.42068099975586, L2: 1.0893239643650077e-09, L3: 1.0, L4: 50.000144958496094, L5: 0.17030653357505798
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0202014446258545, Constraint losses: L1: 18.42068099975586, L2: 0.0005934016080573201, L3: 1.0005934238433838, L4: 1.000593900680542
Epoch 500, Loss: 0.0019056107848882675, Constraint losses: L1: -1.1110252141952515, L2: 0.0, L3: 0.002507627010345459, L4: 0.0005090089980512857
Epoch 1000, Loss: 0.0012186262756586075, Constraint losses: L1: -1.118558645248413, L2: 0.0, L3: 0.00216829776763916, L4: 0.0001688871707301587
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.018573760986328, Constraint losses: L1: 18.092016220092773, L2: 0.00022160513617563993, L3: 1.0001299381256104, L4: 1.0001300573349
Epoch 500, Loss: 0.0021786920260638, Constraint losses: L1: -1.1137131452560425, L2: 0.0, L3: 0.0026453733444213867, L4: 0.0006470319349318743
Epoch 1000, Loss: 0.001309140003286302, Constraint losses: L1: -1.1191396713256836, L2: 0.0, L3: 0.0022138357162475586, L4: 0.00021444400772452354
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 56.33401870727539, Losses: L1: 16.900949478149414, L2: 0.009808201342821121, L3: 1.0097284317016602, L4: 76.05108642578125, L5: 0.3781821131706238
Epoch 500, Loss: -2.178292989730835, Losses: L1: -3.28908109664917, L2: 0.25933194160461426, L3: 0.07791727781295776, L4: 1.0133142471313477, L5: 0.007549874484539032
Epoch 1000, Loss: 3.578676462173462, Losses: L1: -1.053989052772522, L2: 0.4662182629108429, L3: 0.27984941005706787, L4: 6.7299017906188965, L5: 0.05542872101068497
Epoch 1500, Loss: -1.5186117887496948, Losses: L1: -2.5283048152923584, L2: 0.20446106791496277, L3: 0.08613985776901245, L4: 1.01468825340271, L5: 0.00728681031614542
Epoch 2000, Loss: -1.6464905738830566, Losses: L1: -2.829862356185913, L2: 0.19656142592430115, L3: 0.08442163467407227, L4: 1.398037075996399, L5: 0.006808724254369736
Epoch 2500, Loss: -2.2453479766845703, Losses: L1: -2.9633493423461914, L2: 0.17929799854755402, L3: 0.09071725606918335, L4: 0.5293744802474976, L5: 0.004000776447355747
Epoch 3000, Loss: -2.3406941890716553, Losses: L1: -3.0491251945495605, L2: 0.16799496114253998, L3: 0.08700418472290039, L4: 0.563056230545044, L5: 0.003908928018063307
Epoch 3500, Loss: -2.47001051902771, Losses: L1: -3.0957624912261963, L2: 0.1613268107175827, L3: 0.08855628967285156, L4: 0.42197006940841675, L5: 0.003557192627340555
Epoch 4000, Loss: -2.501649856567383, Losses: L1: -3.1152896881103516, L2: 0.15593457221984863, L3: 0.0887189507484436, L4: 0.4189111590385437, L5: 0.003596233669668436
Epoch 4500, Loss: -2.521707534790039, Losses: L1: -3.1332716941833496, L2: 0.1549988090991974, L3: 0.08844202756881714, L4: 0.41913124918937683, L5: 0.0035587786696851254
Epoch 5000, Loss: -2.5364391803741455, Losses: L1: -3.1426045894622803, L2: 0.15319716930389404, L3: 0.08805811405181885, L4: 0.4163045287132263, L5: 0.0035608785692602396
Epoch 5500, Loss: -2.5466246604919434, Losses: L1: -3.150999069213867, L2: 0.15264907479286194, L3: 0.0877954363822937, L4: 0.4154302179813385, L5: 0.0035658779088407755
Epoch 6000, Loss: -2.5540897846221924, Losses: L1: -3.15771746635437, L2: 0.1525130569934845, L3: 0.0875478982925415, L4: 0.4149661660194397, L5: 0.0035704607143998146
Epoch 6500, Loss: -2.559904098510742, Losses: L1: -3.1626501083374023, L2: 0.15229322016239166, L3: 0.0873374342918396, L4: 0.414522260427475, L5: 0.0035609686747193336
Epoch 7000, Loss: -2.564246416091919, Losses: L1: -3.167093515396118, L2: 0.15249250829219818, L3: 0.08711862564086914, L4: 0.4143639802932739, L5: 0.0035614699590951204
Epoch 7500, Loss: -2.5676052570343018, Losses: L1: -3.170778274536133, L2: 0.15279410779476166, L3: 0.08693867921829224, L4: 0.4141755998134613, L5: 0.003558284603059292
Epoch 8000, Loss: -2.5700740814208984, Losses: L1: -3.1736299991607666, L2: 0.15305209159851074, L3: 0.08681434392929077, L4: 0.41415834426879883, L5: 0.0035581428091973066
Epoch 8500, Loss: -2.571845293045044, Losses: L1: -3.175083637237549, L2: 0.15295615792274475, L3: 0.08670711517333984, L4: 0.41412052512168884, L5: 0.003558750031515956
Epoch 9000, Loss: -2.573103904724121, Losses: L1: -3.176201581954956, L2: 0.152917742729187, L3: 0.08667862415313721, L4: 0.414050817489624, L5: 0.0035580622497946024
Epoch 9500, Loss: -2.5739283561706543, Losses: L1: -3.1767003536224365, L2: 0.15277092158794403, L3: 0.08666062355041504, L4: 0.4140227437019348, L5: 0.003558174706995487
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9970711469650269, Constraint losses: L1: 5.439779758453369, L2: 0.0, L3: 0.9958161115646362, L4: 0.9958152770996094
Epoch 500, Loss: 0.0020579160191118717, Constraint losses: L1: -1.104669451713562, L2: 0.0, L3: 0.0025805234909057617, L4: 0.0005820620572194457
Epoch 1000, Loss: 0.0012632552534341812, Constraint losses: L1: -1.1181366443634033, L2: 0.0, L3: 0.0021904706954956055, L4: 0.00019092127331532538
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.004791021347046, Constraint losses: L1: 7.07061767578125, L2: 6.384229345712811e-05, L3: 0.9988278746604919, L4: 0.998828649520874
Epoch 500, Loss: 0.002434867899864912, Constraint losses: L1: -1.1105495691299438, L2: 0.0, L3: 0.0027717947959899902, L4: 0.000773622770793736
Epoch 1000, Loss: 0.0013919484335929155, Constraint losses: L1: -1.1196720600128174, L2: 0.0, L3: 0.0022554397583007812, L4: 0.0002561807632446289
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 47.397727966308594, Losses: L1: 8.270819664001465, L2: 6.391661008819938e-05, L3: 0.9972757697105408, L4: 74.7865219116211, L5: 0.36812275648117065
Epoch 500, Loss: -0.20390929281711578, Losses: L1: -2.409660577774048, L2: 0.31514912843704224, L3: 0.09314942359924316, L4: 2.870659351348877, L5: 0.023486966267228127
Epoch 1000, Loss: -2.293386220932007, Losses: L1: -2.9190986156463623, L2: 0.13649170100688934, L3: 0.054699063301086426, L4: 0.5813224911689758, L5: 0.0036844091955572367
Epoch 1500, Loss: -2.2057230472564697, Losses: L1: -3.2359488010406494, L2: 0.0891379863023758, L3: 0.05083686113357544, L4: 1.573907732963562, L5: 0.007079462055116892
Epoch 2000, Loss: -2.755382776260376, Losses: L1: -3.53987717628479, L2: 0.1407948136329651, L3: 0.052208900451660156, L4: 0.8770261406898499, L5: 0.006091320887207985
Epoch 2500, Loss: -3.41170072555542, Losses: L1: -3.7330739498138428, L2: 0.11271972209215164, L3: 0.006596863269805908, L4: 0.1654200553894043, L5: 0.003313446417450905
Epoch 3000, Loss: -3.3439536094665527, Losses: L1: -3.7448742389678955, L2: 0.0914241224527359, L3: 0.003138899803161621, L4: 0.414788156747818, L5: 0.0037696021609008312
Epoch 3500, Loss: -3.5095715522766113, Losses: L1: -3.7212698459625244, L2: 0.06826388090848923, L3: 0.004999518394470215, L4: 0.12748482823371887, L5: 0.0032141990959644318
Epoch 4000, Loss: -3.5587782859802246, Losses: L1: -3.726702928543091, L2: 0.061360958963632584, L3: 0.009572029113769531, L4: 0.05848202109336853, L5: 0.0031947812531143427
Epoch 4500, Loss: -3.547086000442505, Losses: L1: -3.732051372528076, L2: 0.05823288857936859, L3: 0.014284372329711914, L4: 0.09558484703302383, L5: 0.0032113997731357813
Epoch 5000, Loss: -3.5625133514404297, Losses: L1: -3.7301602363586426, L2: 0.05271776020526886, L3: 0.017266511917114258, L4: 0.07714562118053436, L5: 0.0031859739683568478
Epoch 5500, Loss: -3.5765902996063232, Losses: L1: -3.7302403450012207, L2: 0.05216003954410553, L3: 0.01761150360107422, L4: 0.050719570368528366, L5: 0.003179370891302824
Epoch 6000, Loss: -3.579176902770996, Losses: L1: -3.7305431365966797, L2: 0.05087273567914963, L3: 0.018773436546325684, L4: 0.0489770770072937, L5: 0.003179495455697179
Epoch 6500, Loss: -3.580998659133911, Losses: L1: -3.7325615882873535, L2: 0.05026606470346451, L3: 0.02036118507385254, L4: 0.048625390976667404, L5: 0.003178477054461837
Epoch 7000, Loss: -3.5822060108184814, Losses: L1: -3.7354423999786377, L2: 0.05034727230668068, L3: 0.022023677825927734, L4: 0.04832758754491806, L5: 0.0031771650537848473
Epoch 7500, Loss: -3.5831336975097656, Losses: L1: -3.7377357482910156, L2: 0.05048620328307152, L3: 0.023278355598449707, L4: 0.0479959174990654, L5: 0.0031765613239258528
Epoch 8000, Loss: -3.5838208198547363, Losses: L1: -3.7394025325775146, L2: 0.050581082701683044, L3: 0.024200081825256348, L4: 0.04773397743701935, L5: 0.0031763282604515553
Epoch 8500, Loss: -3.584261417388916, Losses: L1: -3.7405357360839844, L2: 0.05065121501684189, L3: 0.0248262882232666, L4: 0.04758574813604355, L5: 0.003176274709403515
Epoch 9000, Loss: -3.5846171379089355, Losses: L1: -3.741152048110962, L2: 0.05057455971837044, L3: 0.025246858596801758, L4: 0.047575097531080246, L5: 0.0031757038086652756
Epoch 9500, Loss: -3.5848724842071533, Losses: L1: -3.7418506145477295, L2: 0.050630636513233185, L3: 0.02562689781188965, L4: 0.04747747257351875, L5: 0.003175654448568821
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0184531211853027, Constraint losses: L1: 17.929275512695312, L2: 0.00023013344616629183, L3: 1.0001468658447266, L4: 1.0001468658447266
Epoch 500, Loss: 0.0024401205591857433, Constraint losses: L1: -0.9968414902687073, L2: 0.0, L3: 0.0027173757553100586, L4: 0.0007195865036919713
Epoch 1000, Loss: 0.0013160964008420706, Constraint losses: L1: -1.1135568618774414, L2: 0.0, L3: 0.0022144317626953125, L4: 0.00021522148745134473
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0223515033721924, Constraint losses: L1: 18.42068099975586, L2: 0.001310234423726797, L3: 1.0013102293014526, L4: 1.0013103485107422
Epoch 500, Loss: 0.0023867362178862095, Constraint losses: L1: -1.1001828908920288, L2: 0.0, L3: 0.0027425289154052734, L4: 0.0007443903014063835
Epoch 1000, Loss: 0.0013682255521416664, Constraint losses: L1: -1.118392825126648, L2: 0.0, L3: 0.0022430419921875, L4: 0.00024357641814276576
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 89.23348999023438, Losses: L1: 16.103254318237305, L2: 0.006915321107953787, L3: 1.0067291259765625, L4: 71.93293762207031, L5: 0.3534875512123108
Epoch 500, Loss: 0.07872176170349121, Losses: L1: -2.9064781665802, L2: 0.23912499845027924, L3: 0.079520583152771, L4: 2.418179988861084, L5: 0.018498890101909637
Epoch 1000, Loss: -0.02108265645802021, Losses: L1: -3.1132400035858154, L2: 0.3028854429721832, L3: 0.08911919593811035, L4: 2.3936009407043457, L5: 0.007332768756896257
Epoch 1500, Loss: -0.5421727895736694, Losses: L1: -3.313457489013672, L2: 0.1475105732679367, L3: 0.07952678203582764, L4: 2.3938448429107666, L5: 0.005783813539892435
Epoch 2000, Loss: -2.41549015045166, Losses: L1: -3.692729949951172, L2: 0.17159946262836456, L3: 0.05450361967086792, L4: 0.875073254108429, L5: 0.00892781000584364
Epoch 2500, Loss: -2.6990554332733154, Losses: L1: -3.7327659130096436, L2: 0.16689762473106384, L3: 0.0241241455078125, L4: 0.67359858751297, L5: 0.004384798463433981
Epoch 3000, Loss: -3.1157870292663574, Losses: L1: -3.8734190464019775, L2: 0.14988818764686584, L3: 0.03892624378204346, L4: 0.41586819291114807, L5: 0.006122637074440718
Epoch 3500, Loss: -3.150947093963623, Losses: L1: -3.8911221027374268, L2: 0.14071595668792725, L3: 0.012508869171142578, L4: 0.4432758390903473, L5: 0.005916793830692768
Epoch 4000, Loss: -3.421905994415283, Losses: L1: -3.9205944538116455, L2: 0.13502518832683563, L3: 0.003918647766113281, L4: 0.22237618267536163, L5: 0.004686892032623291
Epoch 4500, Loss: -3.4590396881103516, Losses: L1: -3.9304473400115967, L2: 0.13021419942378998, L3: 0.0010766983032226562, L4: 0.20749671757221222, L5: 0.004811994265764952
Epoch 5000, Loss: -3.497293472290039, Losses: L1: -3.9310953617095947, L2: 0.12393927574157715, L3: 0.004544615745544434, L4: 0.17911453545093536, L5: 0.004528649616986513
Epoch 5500, Loss: -3.510504961013794, Losses: L1: -3.934011936187744, L2: 0.12175043672323227, L3: 0.0002211928367614746, L4: 0.17757229506969452, L5: 0.00442506093531847
Epoch 6000, Loss: -3.516983985900879, Losses: L1: -3.935605525970459, L2: 0.11979229748249054, L3: 8.225440979003906e-05, L4: 0.17677392065525055, L5: 0.004361154977232218
Epoch 6500, Loss: -3.523075819015503, Losses: L1: -3.9368505477905273, L2: 0.11861483752727509, L3: 1.817941665649414e-05, L4: 0.1743471473455429, L5: 0.004359513055533171
Epoch 7000, Loss: -3.5266098976135254, Losses: L1: -3.937453031539917, L2: 0.11773144453763962, L3: 4.76837158203125e-06, L4: 0.1732090562582016, L5: 0.004333160817623138
Epoch 7500, Loss: -3.5286309719085693, Losses: L1: -3.937293529510498, L2: 0.11674448102712631, L3: 0.0006864070892333984, L4: 0.17233440279960632, L5: 0.004305545706301928
Epoch 8000, Loss: -3.5304248332977295, Losses: L1: -3.937744140625, L2: 0.11649428308010101, L3: 0.00042176246643066406, L4: 0.17175953090190887, L5: 0.004298779182136059
Epoch 8500, Loss: -3.5317952632904053, Losses: L1: -3.938117265701294, L2: 0.11639691889286041, L3: 2.5928020477294922e-05, L4: 0.17135877907276154, L5: 0.004286689218133688
Epoch 9000, Loss: -3.532428741455078, Losses: L1: -3.9381730556488037, L2: 0.11619807034730911, L3: 0.00014835596084594727, L4: 0.1710585206747055, L5: 0.004282892681658268
Epoch 9500, Loss: -3.533017635345459, Losses: L1: -3.938232660293579, L2: 0.11611916124820709, L3: 2.7000904083251953e-05, L4: 0.17080935835838318, L5: 0.004280871246010065
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0170416831970215, Constraint losses: L1: 16.037809371948242, L2: 0.0005657828878611326, L3: 1.0002189874649048, L4: 1.0002191066741943
Epoch 500, Loss: 0.002353742253035307, Constraint losses: L1: -1.0813409090042114, L2: 0.0, L3: 0.002716541290283203, L4: 0.0007185417925938964
Epoch 1000, Loss: 0.0013399117160588503, Constraint losses: L1: -1.1140398979187012, L2: 0.0, L3: 0.0022266507148742676, L4: 0.00022730088676325977
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0031728744506836, Constraint losses: L1: 6.457596778869629, L2: 0.0, L3: 0.9983575940132141, L4: 0.9983577728271484
Epoch 500, Loss: 0.002448397921398282, Constraint losses: L1: -0.9476317763328552, L2: 0.0, L3: 0.0026968717575073242, L4: 0.0006991580594331026
Epoch 1000, Loss: 0.0012918191496282816, Constraint losses: L1: -1.1149492263793945, L2: 0.0, L3: 0.0022031664848327637, L4: 0.00020360195776447654
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 101.00884246826172, Losses: L1: 17.72719955444336, L2: 0.006128291133791208, L3: 1.0061242580413818, L4: 81.84497833251953, L5: 0.4182822108268738
Epoch 500, Loss: 2.4105520248413086, Losses: L1: -2.225099563598633, L2: 0.2295263558626175, L3: 0.12284624576568604, L4: 4.04231071472168, L5: 0.011441836133599281
Epoch 1000, Loss: -1.1864875555038452, Losses: L1: -2.9246137142181396, L2: 0.2045120745897293, L3: 0.07301294803619385, L4: 1.2477134466171265, L5: 0.008375358767807484
Epoch 1500, Loss: -1.2574349641799927, Losses: L1: -3.181454658508301, L2: 0.22443124651908875, L3: 0.07369375228881836, L4: 1.3917876482009888, L5: 0.009675764478743076
Epoch 2000, Loss: -1.595272183418274, Losses: L1: -3.4671471118927, L2: 0.2253650277853012, L3: 0.06350481510162354, L4: 1.3496161699295044, L5: 0.008024031296372414
Epoch 2500, Loss: -2.1999170780181885, Losses: L1: -3.5738937854766846, L2: 0.2088475078344345, L3: 0.05750769376754761, L4: 0.893318772315979, L5: 0.005455140955746174
Epoch 3000, Loss: -2.8263795375823975, Losses: L1: -3.6203384399414062, L2: 0.18100978434085846, L3: 0.047337889671325684, L4: 0.38079240918159485, L5: 0.003808915615081787
Epoch 3500, Loss: -3.059098958969116, Losses: L1: -3.6450612545013428, L2: 0.17474035918712616, L3: 0.03616601228713989, L4: 0.19678963720798492, L5: 0.0035259861033409834
Epoch 4000, Loss: -3.1193971633911133, Losses: L1: -3.660623073577881, L2: 0.16953669488430023, L3: 0.031073808670043945, L4: 0.1675916165113449, L5: 0.0034871406387537718
Epoch 4500, Loss: -3.144606351852417, Losses: L1: -3.670553684234619, L2: 0.16583740711212158, L3: 0.026778340339660645, L4: 0.16402924060821533, L5: 0.0034648238215595484
Epoch 5000, Loss: -3.162208080291748, Losses: L1: -3.6783039569854736, L2: 0.16379156708717346, L3: 0.02260446548461914, L4: 0.16243769228458405, L5: 0.003470670199021697
Epoch 5500, Loss: -3.174241304397583, Losses: L1: -3.6849873065948486, L2: 0.1628323793411255, L3: 0.020105063915252686, L4: 0.16150778532028198, L5: 0.00346821965649724
Epoch 6000, Loss: -3.1834897994995117, Losses: L1: -3.6871633529663086, L2: 0.16087126731872559, L3: 0.018589258193969727, L4: 0.15988513827323914, L5: 0.003456538775935769
Epoch 6500, Loss: -3.1904664039611816, Losses: L1: -3.6901514530181885, L2: 0.1601523905992508, L3: 0.01718926429748535, L4: 0.15873456001281738, L5: 0.003456269856542349
Epoch 7000, Loss: -3.1955926418304443, Losses: L1: -3.692854642868042, L2: 0.16005687415599823, L3: 0.01568615436553955, L4: 0.15800544619560242, L5: 0.0034566668327897787
Epoch 7500, Loss: -3.1993045806884766, Losses: L1: -3.6953227519989014, L2: 0.16025252640247345, L3: 0.014593124389648438, L4: 0.15746411681175232, L5: 0.0034557939507067204
Epoch 8000, Loss: -3.2021610736846924, Losses: L1: -3.697465181350708, L2: 0.16043831408023834, L3: 0.01381385326385498, L4: 0.15715910494327545, L5: 0.0034546377137303352
Epoch 8500, Loss: -3.2042572498321533, Losses: L1: -3.6988930702209473, L2: 0.16056032478809357, L3: 0.013207554817199707, L4: 0.15685325860977173, L5: 0.0034543860238045454
Epoch 9000, Loss: -3.2057700157165527, Losses: L1: -3.7000062465667725, L2: 0.16063745319843292, L3: 0.01284325122833252, L4: 0.15666405856609344, L5: 0.0034539576154202223
Epoch 9500, Loss: -3.206852436065674, Losses: L1: -3.700746536254883, L2: 0.16064511239528656, L3: 0.012631773948669434, L4: 0.1565188765525818, L5: 0.0034533545840531588
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.021822929382324, Constraint losses: L1: 18.42068099975586, L2: 0.001135853584855795, L3: 1.0011335611343384, L4: 1.0011329650878906
Epoch 500, Loss: 0.0025457493029534817, Constraint losses: L1: -1.1161413192749023, L2: 0.0, L3: 0.002830028533935547, L4: 0.0008318622130900621
Epoch 1000, Loss: 0.0014408230781555176, Constraint losses: L1: -1.1182630062103271, L2: 0.0, L3: 0.002279222011566162, L4: 0.0002798641799017787
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0233142375946045, Constraint losses: L1: 18.42068099975586, L2: 0.001631049788556993, L3: 1.0016310214996338, L4: 1.001631498336792
Epoch 500, Loss: 0.002087241504341364, Constraint losses: L1: -1.1112571954727173, L2: 0.0, L3: 0.0025984644889831543, L4: 0.000600034196395427
Epoch 1000, Loss: 0.001276983879506588, Constraint losses: L1: -1.1190805435180664, L2: 0.0, L3: 0.0021976828575134277, L4: 0.00019838158914353698
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 102.60038757324219, Losses: L1: 11.891969680786133, L2: 4.6166329411789775e-05, L3: 0.9994692802429199, L4: 88.76771545410156, L5: 0.4705688953399658
Epoch 500, Loss: 0.42302972078323364, Losses: L1: -2.812894105911255, L2: 0.23660673201084137, L3: 0.07608485221862793, L4: 2.6627755165100098, L5: 0.01192501001060009
Epoch 1000, Loss: -2.0894272327423096, Losses: L1: -3.095898151397705, L2: 0.10769177228212357, L3: 0.06680291891098022, L4: 0.7154282331466675, L5: 0.004428057000041008
Epoch 1500, Loss: -3.168762683868408, Losses: L1: -3.753774404525757, L2: 0.0775635838508606, L3: 0.06510257720947266, L4: 0.3578018844127655, L5: 0.003490011440590024
Epoch 2000, Loss: -3.377458095550537, Losses: L1: -3.8024373054504395, L2: 0.06969687342643738, L3: 0.07454586029052734, L4: 0.20431865751743317, L5: 0.0033604023046791553
Epoch 2500, Loss: -3.1797046661376953, Losses: L1: -3.816539764404297, L2: 0.09201198816299438, L3: 0.07266974449157715, L4: 0.3729577958583832, L5: 0.0035919032525271177
Epoch 3000, Loss: -3.4578938484191895, Losses: L1: -3.769164800643921, L2: 0.04497995972633362, L3: 0.05570793151855469, L4: 0.15886324644088745, L5: 0.0033699064515531063
Epoch 3500, Loss: -3.492750406265259, Losses: L1: -3.7603466510772705, L2: 0.05977125093340874, L3: 0.019613981246948242, L4: 0.1217818558216095, L5: 0.0033289664424955845
Epoch 4000, Loss: -3.4733726978302, Losses: L1: -3.753882646560669, L2: 0.05100319907069206, L3: 0.01544642448425293, L4: 0.1564134955406189, L5: 0.003321767784655094
Epoch 4500, Loss: -3.50050950050354, Losses: L1: -3.759899139404297, L2: 0.05127720907330513, L3: 0.013938426971435547, L4: 0.1362553834915161, L5: 0.0033208101522177458
Epoch 5000, Loss: -3.570777654647827, Losses: L1: -3.7412967681884766, L2: 0.042231615632772446, L3: 0.00025707483291625977, L4: 0.07913510501384735, L5: 0.003331863321363926
Epoch 5500, Loss: -3.5769782066345215, Losses: L1: -3.74375057220459, L2: 0.04264610633254051, L3: 0.00020122528076171875, L4: 0.07462406158447266, L5: 0.003327540121972561
Epoch 6000, Loss: -3.57783842086792, Losses: L1: -3.749074697494507, L2: 0.043955713510513306, L3: 0.0020074844360351562, L4: 0.07466579973697662, L5: 0.0033258048351854086
Epoch 6500, Loss: -3.587937593460083, Losses: L1: -3.7477009296417236, L2: 0.04346092417836189, L3: 0.0002218484878540039, L4: 0.06596319377422333, L5: 0.003328166203573346
Epoch 7000, Loss: -3.5884320735931396, Losses: L1: -3.749669075012207, L2: 0.04371055215597153, L3: 0.0005142688751220703, L4: 0.06664866209030151, L5: 0.003326475154608488
Epoch 7500, Loss: -3.5912117958068848, Losses: L1: -3.749484062194824, L2: 0.043329864740371704, L3: 0.000232696533203125, L4: 0.06472380459308624, L5: 0.0033280665520578623
Epoch 8000, Loss: -3.591843605041504, Losses: L1: -3.749774217605591, L2: 0.043298982083797455, L3: 0.00010514259338378906, L4: 0.06457128375768661, L5: 0.0033281203359365463
Epoch 8500, Loss: -3.592670202255249, Losses: L1: -3.7500295639038086, L2: 0.04326903447508812, L3: 5.0067901611328125e-05, L4: 0.06411564350128174, L5: 0.0033277610782533884
Epoch 9000, Loss: -3.593019723892212, Losses: L1: -3.7502803802490234, L2: 0.043271150439977646, L3: 7.510185241699219e-05, L4: 0.06398773193359375, L5: 0.003327694721519947
Epoch 9500, Loss: -3.5933053493499756, Losses: L1: -3.7503371238708496, L2: 0.043212890625, L3: 2.4437904357910156e-05, L4: 0.06392620503902435, L5: 0.003327732440084219
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.004950523376465, Constraint losses: L1: 6.9146728515625, L2: 0.0, L3: 0.9990179538726807, L4: 0.9990179538726807
Epoch 500, Loss: 0.0020935917273163795, Constraint losses: L1: -1.0974200963974, L2: 0.0, L3: 0.0025946497917175293, L4: 0.0005963621661067009
Epoch 1000, Loss: 0.0012608596589416265, Constraint losses: L1: -1.1178232431411743, L2: 0.0, L3: 0.0021890997886657715, L4: 0.0001895831519505009
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.02103590965271, Constraint losses: L1: 18.42068099975586, L2: 0.0008717508753761649, L3: 1.0008717775344849, L4: 1.0008716583251953
Epoch 500, Loss: 0.0023100466933101416, Constraint losses: L1: -1.0936404466629028, L2: 0.0, L3: 0.0027008652687072754, L4: 0.0007028218824416399
Epoch 1000, Loss: 0.0013262140564620495, Constraint losses: L1: -1.1196188926696777, L2: 0.0, L3: 0.0022226572036743164, L4: 0.0002231758990092203
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 187.65773010253906, Losses: L1: 14.543113708496094, L2: 0.003377756103873253, L3: 1.002854347229004, L4: 85.93855285644531, L5: 0.4558198153972626
Epoch 500, Loss: 1.5701422691345215, Losses: L1: -2.5713400840759277, L2: 0.1942824125289917, L3: 0.0866665244102478, L4: 1.8289316892623901, L5: 0.016775133088231087
Epoch 1000, Loss: -0.6277183294296265, Losses: L1: -3.225375175476074, L2: 0.19271859526634216, L3: 0.05547422170639038, L4: 1.0760992765426636, L5: 0.009093470871448517
Epoch 1500, Loss: -2.199659585952759, Losses: L1: -3.5958971977233887, L2: 0.19791503250598907, L3: 0.03110504150390625, L4: 0.48275917768478394, L5: 0.0075678350403904915
Epoch 2000, Loss: -1.604729175567627, Losses: L1: -3.5995922088623047, L2: 0.15553563833236694, L3: 0.021938741207122803, L4: 0.8284604549407959, L5: 0.009863754734396935
Epoch 2500, Loss: -2.633697271347046, Losses: L1: -3.759394645690918, L2: 0.1243920847773552, L3: 0.033150672912597656, L4: 0.4203350245952606, L5: 0.006185237783938646
Epoch 3000, Loss: -3.0655274391174316, Losses: L1: -3.774015426635742, L2: 0.11541125178337097, L3: 0.03598141670227051, L4: 0.21963432431221008, L5: 0.004830825608223677
Epoch 3500, Loss: -3.0870134830474854, Losses: L1: -3.7687554359436035, L2: 0.10530036687850952, L3: 0.02723526954650879, L4: 0.22084163129329681, L5: 0.004445243161171675
Epoch 4000, Loss: -3.282057762145996, Losses: L1: -3.754196882247925, L2: 0.09843160212039948, L3: 0.009380817413330078, L4: 0.13193342089653015, L5: 0.00405639735981822
Epoch 4500, Loss: -3.3438639640808105, Losses: L1: -3.7534725666046143, L2: 0.0947141945362091, L3: 0.010400533676147461, L4: 0.10392738878726959, L5: 0.003849816508591175
Epoch 5000, Loss: -3.357511281967163, Losses: L1: -3.743375778198242, L2: 0.09042918682098389, L3: 0.002301335334777832, L4: 0.10040926933288574, L5: 0.003772149095311761
Epoch 5500, Loss: -3.3830549716949463, Losses: L1: -3.7434542179107666, L2: 0.08848373591899872, L3: 0.004323720932006836, L4: 0.08863484114408493, L5: 0.003676952328532934
Epoch 6000, Loss: -3.3858330249786377, Losses: L1: -3.740161895751953, L2: 0.08738914877176285, L3: 0.0011074542999267578, L4: 0.0883045643568039, L5: 0.0036681098863482475
Epoch 6500, Loss: -3.389382839202881, Losses: L1: -3.7398157119750977, L2: 0.08680064231157303, L3: 0.0009162425994873047, L4: 0.08704560250043869, L5: 0.0036481365095824003
Epoch 7000, Loss: -3.3929214477539062, Losses: L1: -3.7384445667266846, L2: 0.08587275445461273, L3: 0.0003948211669921875, L4: 0.08578337728977203, L5: 0.003632202511653304
Epoch 7500, Loss: -3.3945133686065674, Losses: L1: -3.7384040355682373, L2: 0.08541559427976608, L3: 0.0007995367050170898, L4: 0.08522471785545349, L5: 0.003621090669184923
Epoch 8000, Loss: -3.395721912384033, Losses: L1: -3.737868309020996, L2: 0.08519475907087326, L3: 0.00021886825561523438, L4: 0.08486489206552505, L5: 0.0036170377861708403
Epoch 8500, Loss: -3.3961422443389893, Losses: L1: -3.7380127906799316, L2: 0.08506853133440018, L3: 0.00048100948333740234, L4: 0.08472229540348053, L5: 0.0036157637368887663
Epoch 9000, Loss: -3.3968758583068848, Losses: L1: -3.7374236583709717, L2: 0.08479204773902893, L3: 8.738040924072266e-05, L4: 0.08453530073165894, L5: 0.003611466148868203
Epoch 9500, Loss: -3.3972136974334717, Losses: L1: -3.7373340129852295, L2: 0.08469374477863312, L3: 7.855892181396484e-05, L4: 0.08442426472902298, L5: 0.0036109420470893383
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.022109270095825, Constraint losses: L1: 18.42068099975586, L2: 0.0012295711785554886, L3: 1.0012295246124268, L4: 1.0012295246124268
Epoch 500, Loss: 0.0022627997677773237, Constraint losses: L1: -1.0933072566986084, L2: 0.0, L3: 0.00267714262008667, L4: 0.0006789644248783588
Epoch 1000, Loss: 0.001318264752626419, Constraint losses: L1: -1.1184349060058594, L2: 0.0, L3: 0.0022180676460266113, L4: 0.00021863204892724752
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0023763179779053, Constraint losses: L1: 6.223809242248535, L2: 0.0, L3: 0.9980763792991638, L4: 0.9980761408805847
Epoch 500, Loss: 0.0025618160143494606, Constraint losses: L1: -0.8829077482223511, L2: 0.0, L3: 0.0027213692665100098, L4: 0.0007233544019982219
Epoch 1000, Loss: 0.0012926579220220447, Constraint losses: L1: -1.1125767230987549, L2: 0.0, L3: 0.002202272415161133, L4: 0.00020296227012295276
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 166.1654815673828, Losses: L1: 18.42068099975586, L2: 0.007472617086023092, L3: 1.0074726343154907, L4: 73.17922973632812, L5: 0.3639209568500519
Epoch 500, Loss: 3.5360188484191895, Losses: L1: -2.3309454917907715, L2: 0.16549265384674072, L3: 0.056375205516815186, L4: 2.733919858932495, L5: 0.01176401972770691
Epoch 1000, Loss: 8.389140129089355, Losses: L1: -2.1078577041625977, L2: 0.5992621183395386, L3: 0.12212693691253662, L4: 4.572665214538574, L5: 0.031016740947961807
Epoch 1500, Loss: 1.751380443572998, Losses: L1: -2.4012999534606934, L2: 0.47353699803352356, L3: 0.0905105471611023, L4: 1.5540927648544312, L5: 0.006910282652825117
Epoch 2000, Loss: 0.3397073447704315, Losses: L1: -2.6335649490356445, L2: 0.24651239812374115, L3: 0.07692337036132812, L4: 1.1990633010864258, L5: 0.005197484511882067
Epoch 2500, Loss: -1.4833836555480957, Losses: L1: -2.8986713886260986, L2: 0.2549872398376465, L3: 0.07477807998657227, L4: 0.41255539655685425, L5: 0.005424428731203079
Epoch 3000, Loss: -1.115158200263977, Losses: L1: -2.9796290397644043, L2: 0.24016883969306946, L3: 0.07317250967025757, L4: 0.6522853374481201, L5: 0.006389977876096964
Epoch 3500, Loss: -1.888464093208313, Losses: L1: -2.9958765506744385, L2: 0.21527284383773804, L3: 0.07301199436187744, L4: 0.2997131943702698, L5: 0.004428667016327381
Epoch 4000, Loss: -1.9652396440505981, Losses: L1: -3.015648603439331, L2: 0.204136461019516, L3: 0.07315576076507568, L4: 0.2823787331581116, L5: 0.00422259233891964
Epoch 4500, Loss: -2.0236120223999023, Losses: L1: -3.029052972793579, L2: 0.19618241488933563, L3: 0.07325094938278198, L4: 0.2678462862968445, L5: 0.004132802132517099
Epoch 5000, Loss: -2.061617851257324, Losses: L1: -3.038065195083618, L2: 0.19036217033863068, L3: 0.07327556610107422, L4: 0.25917595624923706, L5: 0.004095601849257946
Epoch 5500, Loss: -2.086245536804199, Losses: L1: -3.044221878051758, L2: 0.18603019416332245, L3: 0.07347732782363892, L4: 0.2541919946670532, L5: 0.004054844845086336
Epoch 6000, Loss: -2.1016483306884766, Losses: L1: -3.0484540462493896, L2: 0.18315036594867706, L3: 0.07344520092010498, L4: 0.2515230178833008, L5: 0.004013473633676767
Epoch 6500, Loss: -2.11391019821167, Losses: L1: -3.052119731903076, L2: 0.18143309652805328, L3: 0.07340419292449951, L4: 0.24896851181983948, L5: 0.004002224653959274
Epoch 7000, Loss: -2.122138261795044, Losses: L1: -3.0548887252807617, L2: 0.18029406666755676, L3: 0.07332897186279297, L4: 0.24742379784584045, L5: 0.003985981922596693
Epoch 7500, Loss: -2.1281607151031494, Losses: L1: -3.057112455368042, L2: 0.17956224083900452, L3: 0.07326287031173706, L4: 0.24629375338554382, L5: 0.003976800478994846
Epoch 8000, Loss: -2.132417917251587, Losses: L1: -3.0588583946228027, L2: 0.17909598350524902, L3: 0.07322567701339722, L4: 0.24552583694458008, L5: 0.003971140831708908
Epoch 8500, Loss: -2.13547945022583, Losses: L1: -3.060035228729248, L2: 0.1787213534116745, L3: 0.07319134473800659, L4: 0.24497783184051514, L5: 0.003966017160564661
Epoch 9000, Loss: -2.1376261711120605, Losses: L1: -3.060868740081787, L2: 0.17844851315021515, L3: 0.07317817211151123, L4: 0.24460090696811676, L5: 0.003965727053582668
Epoch 9500, Loss: -2.1391894817352295, Losses: L1: -3.061279535293579, L2: 0.17818786203861237, L3: 0.07316416501998901, L4: 0.2442937195301056, L5: 0.0039628478698432446
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 1, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.009812355041504, Constraint losses: L1: 9.825916290283203, L2: 3.0879018595442176e-05, L3: 0.9999778270721436, L4: 0.9999776482582092
Epoch 500, Loss: 0.002186818514019251, Constraint losses: L1: -1.1046295166015625, L2: 0.0, L3: 0.002644956111907959, L4: 0.0006464918842539191
Epoch 1000, Loss: 0.0013013744028285146, Constraint losses: L1: -1.1182646751403809, L2: 0.0, L3: 0.0022095441818237305, L4: 0.00021009497868362814
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022939682006836, Constraint losses: L1: 18.42068099975586, L2: 0.0015062986640259624, L3: 1.0015063285827637, L4: 1.0015062093734741
Epoch 500, Loss: 0.002440138952806592, Constraint losses: L1: -1.0276418924331665, L2: 0.0, L3: 0.0027326345443725586, L4: 0.0007351463427767158
Epoch 1000, Loss: 0.0013283782172948122, Constraint losses: L1: -1.118981957435608, L2: 0.0, L3: 0.0022233128547668457, L4: 0.00022404734045267105
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 159.91696166992188, Losses: L1: 14.814383506774902, L2: 0.0014749655965715647, L3: 1.0013784170150757, L4: 71.70372009277344, L5: 0.3454081416130066
Epoch 500, Loss: 3.233847141265869, Losses: L1: -2.134014368057251, L2: 0.28233593702316284, L3: 0.07480490207672119, L4: 2.354158401489258, L5: 0.01003397349268198
Epoch 1000, Loss: 0.6736345887184143, Losses: L1: -3.5819091796875, L2: 0.4547082781791687, L3: 0.05845212936401367, L4: 1.6300801038742065, L5: 0.013757383450865746
Epoch 1500, Loss: -1.9940229654312134, Losses: L1: -3.5936713218688965, L2: 0.13745057582855225, L3: 0.03792846202850342, L4: 0.6379084587097168, L5: 0.005500976461917162
Epoch 2000, Loss: -2.928640842437744, Losses: L1: -3.7725510597229004, L2: 0.12298915535211563, L3: 0.04033017158508301, L4: 0.27284181118011475, L5: 0.005959092639386654
Epoch 2500, Loss: -3.0547988414764404, Losses: L1: -3.7887799739837646, L2: 0.10034406185150146, L3: 0.03363144397735596, L4: 0.24483439326286316, L5: 0.004996476694941521
Epoch 3000, Loss: -3.146641254425049, Losses: L1: -3.8129234313964844, L2: 0.10323972254991531, L3: 0.040579795837402344, L4: 0.20516684651374817, L5: 0.004444638267159462
Epoch 3500, Loss: -3.2900712490081787, Losses: L1: -3.7642006874084473, L2: 0.08018498122692108, L3: 0.004402637481689453, L4: 0.15090417861938477, L5: 0.0037742278072983027
Epoch 4000, Loss: -3.2564570903778076, Losses: L1: -3.755777597427368, L2: 0.07883834093809128, L3: 0.003630995750427246, L4: 0.16531845927238464, L5: 0.0036879852414131165
Epoch 4500, Loss: -3.4356589317321777, Losses: L1: -3.775787353515625, L2: 0.07808741182088852, L3: 0.0023626089096069336, L4: 0.08704067021608353, L5: 0.0037548004183918238
Epoch 5000, Loss: -3.451303243637085, Losses: L1: -3.774441719055176, L2: 0.07487674057483673, L3: 0.0031815767288208008, L4: 0.08139828592538834, L5: 0.0037034766282886267
Epoch 5500, Loss: -3.466064453125, Losses: L1: -3.7744274139404297, L2: 0.07445427775382996, L3: 2.1696090698242188e-05, L4: 0.0760202407836914, L5: 0.0036960660945624113
Epoch 6000, Loss: -3.470107316970825, Losses: L1: -3.775221824645996, L2: 0.07348737865686417, L3: 0.00039649009704589844, L4: 0.07519234716892242, L5: 0.003679294604808092
Epoch 6500, Loss: -3.4732561111450195, Losses: L1: -3.7756459712982178, L2: 0.0725913941860199, L3: 0.0008111000061035156, L4: 0.07453100383281708, L5: 0.003667043522000313
Epoch 7000, Loss: -3.474961757659912, Losses: L1: -3.7750680446624756, L2: 0.07183539867401123, L3: 0.0002855062484741211, L4: 0.07441585510969162, L5: 0.00365918455645442
Epoch 7500, Loss: -3.4772140979766846, Losses: L1: -3.774977684020996, L2: 0.07135067880153656, L3: 0.0001277923583984375, L4: 0.07382194697856903, L5: 0.0036452629137784243
Epoch 8000, Loss: -3.4786317348480225, Losses: L1: -3.7749152183532715, L2: 0.0710010752081871, L3: 6.794929504394531e-06, L4: 0.07349628210067749, L5: 0.0036410109605640173
Epoch 8500, Loss: -3.4793922901153564, Losses: L1: -3.7751593589782715, L2: 0.07084202766418457, L3: 0.0001366138458251953, L4: 0.07333613932132721, L5: 0.0036370891612023115
Epoch 9000, Loss: -3.47995662689209, Losses: L1: -3.775115489959717, L2: 0.07065519690513611, L3: 9.167194366455078e-05, L4: 0.07324390858411789, L5: 0.003634497057646513
Epoch 9500, Loss: -3.4802591800689697, Losses: L1: -3.775218963623047, L2: 0.0705784261226654, L3: 0.0002027750015258789, L4: 0.07316648960113525, L5: 0.0036334432661533356
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0240273475646973, Constraint losses: L1: 18.42068099975586, L2: 0.0018689028220251203, L3: 1.0018688440322876, L4: 1.0018689632415771
Epoch 500, Loss: 0.0022189151495695114, Constraint losses: L1: -1.1121071577072144, L2: 0.0, L3: 0.002664804458618164, L4: 0.000666217936668545
Epoch 1000, Loss: 0.0013193481136113405, Constraint losses: L1: -1.1178539991378784, L2: 0.0, L3: 0.0022183656692504883, L4: 0.0002188364596804604
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0064101219177246, Constraint losses: L1: 7.49519681930542, L2: 0.0, L3: 0.9994574785232544, L4: 0.9994574785232544
Epoch 500, Loss: 0.0020013940520584583, Constraint losses: L1: -1.113974690437317, L2: 0.0, L3: 0.0025569796562194824, L4: 0.0005583891179412603
Epoch 1000, Loss: 0.0012485329061746597, Constraint losses: L1: -1.1196640729904175, L2: 0.0, L3: 0.0021839141845703125, L4: 0.00018428295152261853
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 55.891441345214844, Losses: L1: 15.410334587097168, L2: 0.001991154393181205, L3: 1.0018482208251953, L4: 76.56573486328125, L5: 0.38111716508865356
Epoch 500, Loss: 1.0311994552612305, Losses: L1: -2.0733182430267334, L2: 0.1091865599155426, L3: 0.10185933113098145, L4: 5.345010280609131, L5: 0.01984168402850628
Epoch 1000, Loss: 32.897132873535156, Losses: L1: 5.652711391448975, L2: 0.013647469691932201, L3: 0.9962307810783386, L4: 50.27762222290039, L5: 0.1717049479484558
Epoch 1500, Loss: 25.839387893676758, Losses: L1: -2.2760562896728516, L2: 0.251922070980072, L3: 0.9918754696846008, L4: 51.0797233581543, L5: 0.17597423493862152
Epoch 2000, Loss: 25.745655059814453, Losses: L1: -2.381056785583496, L2: 0.28465816378593445, L3: 0.9923725724220276, L4: 50.969886779785156, L5: 0.17541660368442535
Epoch 2500, Loss: 26.421247482299805, Losses: L1: -1.3735029697418213, L2: 0.22645588219165802, L3: 0.8867765665054321, L4: 50.96116256713867, L5: 0.1754089742898941
Epoch 3000, Loss: 25.594202041625977, Losses: L1: -2.4720993041992188, L2: 0.35546427965164185, L3: 0.9101533889770508, L4: 50.89504623413086, L5: 0.17508813738822937
Epoch 3500, Loss: 29.89240264892578, Losses: L1: 3.1355907917022705, L2: 0.2731097936630249, L3: 0.28793013095855713, L4: 51.093509674072266, L5: 0.17595656216144562
Epoch 4000, Loss: 28.1341609954834, Losses: L1: 0.9125897884368896, L2: 0.4936709702014923, L3: 0.018727362155914307, L4: 52.212188720703125, L5: 0.18136261403560638
Epoch 4500, Loss: 27.808208465576172, Losses: L1: 0.5874091982841492, L2: 0.46389108896255493, L3: 0.04367673397064209, L4: 52.22987365722656, L5: 0.18145450949668884
Epoch 5000, Loss: 27.664255142211914, Losses: L1: 0.453807532787323, L2: 0.4326924681663513, L3: 0.06455409526824951, L4: 52.25035095214844, L5: 0.18155670166015625
Epoch 5500, Loss: 27.57459831237793, Losses: L1: 0.3837185800075531, L2: 0.42037761211395264, L3: 0.05648607015609741, L4: 52.29254150390625, L5: 0.18176166713237762
Epoch 6000, Loss: 27.49675941467285, Losses: L1: 0.3653753697872162, L2: 0.42222532629966736, L3: 0.02168172597885132, L4: 52.30531692504883, L5: 0.18182240426540375
Epoch 6500, Loss: 27.458650588989258, Losses: L1: 0.3540148437023163, L2: 0.4247695803642273, L3: 0.0025970935821533203, L4: 52.31792449951172, L5: 0.18188278377056122
Epoch 7000, Loss: 27.437973022460938, Losses: L1: 0.3419523537158966, L2: 0.42016521096229553, L3: 0.0024489760398864746, L4: 52.3196907043457, L5: 0.18189172446727753
Epoch 7500, Loss: 27.428863525390625, Losses: L1: 0.3370594084262848, L2: 0.4194321632385254, L3: 0.0006489753723144531, L4: 52.32138442993164, L5: 0.18189984560012817
Epoch 8000, Loss: 27.423860549926758, Losses: L1: 0.33113303780555725, L2: 0.41828036308288574, L3: 0.0007622241973876953, L4: 52.327354431152344, L5: 0.18192893266677856
Epoch 8500, Loss: 27.41947364807129, Losses: L1: 0.32748204469680786, L2: 0.4169955551624298, L3: 0.001142263412475586, L4: 52.32949447631836, L5: 0.18193945288658142
Epoch 9000, Loss: 27.417461395263672, Losses: L1: 0.3257368206977844, L2: 0.41661307215690613, L3: 0.001019120216369629, L4: 52.33097457885742, L5: 0.18194663524627686
Epoch 9500, Loss: 27.416208267211914, Losses: L1: 0.3247663974761963, L2: 0.41639775037765503, L3: 0.0009053945541381836, L4: 52.331722259521484, L5: 0.18195027112960815
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.010603904724121, Constraint losses: L1: 10.575063705444336, L2: 6.590710836462677e-05, L3: 0.9999815225601196, L4: 0.9999812841415405
Epoch 500, Loss: 0.0020476619247347116, Constraint losses: L1: -1.1027847528457642, L2: 0.0, L3: 0.002574443817138672, L4: 0.0005760028725489974
Epoch 1000, Loss: 0.0012533578556030989, Constraint losses: L1: -1.1181836128234863, L2: 0.0, L3: 0.002185523509979248, L4: 0.00018601804913487285
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0216495990753174, Constraint losses: L1: 18.42068099975586, L2: 0.001076188636943698, L3: 1.0010762214660645, L4: 1.0010764598846436
Epoch 500, Loss: 0.002180091105401516, Constraint losses: L1: -1.1140393018722534, L2: 0.0, L3: 0.002646327018737793, L4: 0.0006478034192696214
Epoch 1000, Loss: 0.0013092233566567302, Constraint losses: L1: -1.118221640586853, L2: 0.0, L3: 0.0022134780883789062, L4: 0.00021396696683950722
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 60.447898864746094, Losses: L1: 18.42068099975586, L2: 0.001497195684351027, L3: 1.0012710094451904, L4: 79.24349212646484, L5: 0.39993199706077576
Epoch 500, Loss: -0.622183084487915, Losses: L1: -2.6428110599517822, L2: 0.09121165424585342, L3: 0.08139604330062866, L4: 3.3218588829040527, L5: 0.014482976868748665
Epoch 1000, Loss: -1.3830602169036865, Losses: L1: -3.137197494506836, L2: 0.11975044757127762, L3: 0.0904269814491272, L4: 2.642648696899414, L5: 0.012458139099180698
Epoch 1500, Loss: -2.060983657836914, Losses: L1: -3.3469841480255127, L2: 0.12435558438301086, L3: 0.09583091735839844, L4: 1.6780158281326294, L5: 0.006619770545512438
Epoch 2000, Loss: -3.261235475540161, Losses: L1: -3.6728250980377197, L2: 0.06320800632238388, L3: 0.0004309415817260742, L4: 0.5613271594047546, L5: 0.0036482138093560934
Epoch 2500, Loss: -3.160017251968384, Losses: L1: -3.61702299118042, L2: 0.05381009355187416, L3: 0.011368513107299805, L4: 0.6444690227508545, L5: 0.004413871094584465
Epoch 3000, Loss: -3.543088436126709, Losses: L1: -3.719843864440918, L2: 0.05320807918906212, L3: 0.0016939640045166016, L4: 0.12701445817947388, L5: 0.0034438972361385822
Epoch 3500, Loss: -3.5551645755767822, Losses: L1: -3.7141668796539307, L2: 0.04007541760802269, L3: 0.00225222110748291, L4: 0.14179664850234985, L5: 0.0034487040247768164
Epoch 4000, Loss: -3.524754524230957, Losses: L1: -3.713498592376709, L2: 0.03896310180425644, L3: 0.0009349584579467773, L4: 0.21083267033100128, L5: 0.0035317298024892807
Epoch 4500, Loss: -3.5907657146453857, Losses: L1: -3.7419040203094482, L2: 0.04324192926287651, L3: 0.00020760297775268555, L4: 0.12180851399898529, L5: 0.003335057059302926
Epoch 5000, Loss: -3.6264703273773193, Losses: L1: -3.740931510925293, L2: 0.03831120952963829, L3: 0.0003641843795776367, L4: 0.06751282513141632, L5: 0.003353741718456149
Epoch 5500, Loss: -3.6361279487609863, Losses: L1: -3.7407989501953125, L2: 0.03616093099117279, L3: 0.0005917549133300781, L4: 0.055609092116355896, L5: 0.0033610567916184664
Epoch 6000, Loss: -3.6371636390686035, Losses: L1: -3.7418711185455322, L2: 0.035953063517808914, L3: 0.0006598234176635742, L4: 0.05623853951692581, L5: 0.003362396964803338
Epoch 6500, Loss: -3.640056848526001, Losses: L1: -3.742058277130127, L2: 0.03574759140610695, L3: 0.00019049644470214844, L4: 0.05353071540594101, L5: 0.003359857015311718
Epoch 7000, Loss: -3.6409451961517334, Losses: L1: -3.7426366806030273, L2: 0.03570587560534477, L3: 0.00030231475830078125, L4: 0.052632711827754974, L5: 0.0033584898337721825
Epoch 7500, Loss: -3.642416000366211, Losses: L1: -3.743293046951294, L2: 0.035636723041534424, L3: 2.396106719970703e-05, L4: 0.05239642411470413, L5: 0.0033573873806744814
Epoch 8000, Loss: -3.642752170562744, Losses: L1: -3.7435543537139893, L2: 0.035601772367954254, L3: 7.49826431274414e-05, L4: 0.05218273401260376, L5: 0.003357331734150648
Epoch 8500, Loss: -3.6430931091308594, Losses: L1: -3.7436540126800537, L2: 0.03554869815707207, L3: 4.172325134277344e-05, L4: 0.052045367658138275, L5: 0.003357342444360256
Epoch 9000, Loss: -3.64328932762146, Losses: L1: -3.7438220977783203, L2: 0.03555135801434517, L3: 3.898143768310547e-05, L4: 0.05199022963643074, L5: 0.003357246983796358
Epoch 9500, Loss: -3.6434340476989746, Losses: L1: -3.7439253330230713, L2: 0.035560037940740585, L3: 1.1920928955078125e-05, L4: 0.051980748772621155, L5: 0.003356885863468051
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 0.5, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0225300788879395, Constraint losses: L1: 18.42068099975586, L2: 0.0013695554807782173, L3: 1.001369595527649, L4: 1.0013701915740967
Epoch 500, Loss: 0.002356104552745819, Constraint losses: L1: -1.0984423160552979, L2: 0.0, L3: 0.002726316452026367, L4: 0.0007282303413376212
Epoch 1000, Loss: 0.0013559580547735095, Constraint losses: L1: -1.118638038635254, L2: 0.0, L3: 0.00223696231842041, L4: 0.0002376338525209576
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.00637149810791, Constraint losses: L1: 7.634030818939209, L2: 0.0, L3: 0.9993684887886047, L4: 0.9993691444396973
Epoch 500, Loss: 0.0023385738022625446, Constraint losses: L1: -0.9737988114356995, L2: 0.0, L3: 0.002655029296875, L4: 0.0006573431892320514
Epoch 1000, Loss: 0.001261252211406827, Constraint losses: L1: -1.1175100803375244, L2: 0.0, L3: 0.002189040184020996, L4: 0.00018972210818901658
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 41.70758819580078, Losses: L1: 4.669309616088867, L2: 0.0, L3: 0.9898926019668579, L4: 68.81562805175781, L5: 0.32533958554267883
Epoch 500, Loss: 2.4267663955688477, Losses: L1: -2.151618480682373, L2: 0.3563797175884247, L3: 0.10273295640945435, L4: 7.136584758758545, L5: 0.04593350738286972
Epoch 1000, Loss: -0.8481122255325317, Losses: L1: -2.9234039783477783, L2: 0.13188791275024414, L3: 0.05766487121582031, L4: 3.3288004398345947, L5: 0.01589297689497471
Epoch 1500, Loss: -2.9569382667541504, Losses: L1: -3.6439266204833984, L2: 0.06035799905657768, L3: 0.028279125690460205, L4: 1.000270962715149, L5: 0.004789333324879408
Epoch 2000, Loss: -3.4216959476470947, Losses: L1: -3.6849308013916016, L2: 0.05785571038722992, L3: 0.004966914653778076, L4: 0.2615598738193512, L5: 0.003404830116778612
Epoch 2500, Loss: -3.382232427597046, Losses: L1: -3.679084300994873, L2: 0.04116404056549072, L3: 0.004462718963623047, L4: 0.3973994851112366, L5: 0.003449355950579047
Epoch 3000, Loss: -3.533033847808838, Losses: L1: -3.7228410243988037, L2: 0.03812941908836365, L3: 0.011890172958374023, L4: 0.16646666824817657, L5: 0.003267318243160844
Epoch 3500, Loss: -3.559440851211548, Losses: L1: -3.7185933589935303, L2: 0.036102838814258575, L3: 0.009036540985107422, L4: 0.12447915971279144, L5: 0.00331694888882339
Epoch 4000, Loss: -3.5644314289093018, Losses: L1: -3.7343971729278564, L2: 0.038634587079286575, L3: 0.012777924537658691, L4: 0.12096726149320602, L5: 0.003328548278659582
Epoch 4500, Loss: -3.5887134075164795, Losses: L1: -3.7286009788513184, L2: 0.040040891617536545, L3: 0.0010880231857299805, L4: 0.10210943222045898, L5: 0.003287604544311762
Epoch 5000, Loss: -3.614248037338257, Losses: L1: -3.7416622638702393, L2: 0.04096405953168869, L3: 0.004910826683044434, L4: 0.05809219181537628, L5: 0.00330928573384881
Epoch 5500, Loss: -3.617310047149658, Losses: L1: -3.743175983428955, L2: 0.041464947164058685, L3: 0.004101395606994629, L4: 0.05622783675789833, L5: 0.003309691557660699
Epoch 6000, Loss: -3.620971441268921, Losses: L1: -3.7384021282196045, L2: 0.04030488058924675, L3: 0.0009751319885253906, L4: 0.056485772132873535, L5: 0.003313858760520816
Epoch 6500, Loss: -3.6246349811553955, Losses: L1: -3.7377824783325195, L2: 0.03981732204556465, L3: 0.00033354759216308594, L4: 0.05243759974837303, L5: 0.003313444321975112
Epoch 7000, Loss: -3.6259517669677734, Losses: L1: -3.7379250526428223, L2: 0.03993117809295654, L3: 1.800060272216797e-05, L4: 0.05089657008647919, L5: 0.003313278080895543
Epoch 7500, Loss: -3.626404047012329, Losses: L1: -3.738672971725464, L2: 0.04028128460049629, L3: 0.00014472007751464844, L4: 0.04957921802997589, L5: 0.0033136645797640085
Epoch 8000, Loss: -3.626943349838257, Losses: L1: -3.7383854389190674, L2: 0.040102940052747726, L3: 8.320808410644531e-05, L4: 0.048880577087402344, L5: 0.003314677393063903
Epoch 8500, Loss: -3.6265556812286377, Losses: L1: -3.7392611503601074, L2: 0.04033105820417404, L3: 0.0006058216094970703, L4: 0.04840470477938652, L5: 0.0033147772774100304
Epoch 9000, Loss: -3.6270713806152344, Losses: L1: -3.738846778869629, L2: 0.040261875838041306, L3: 0.0002321004867553711, L4: 0.04831661656498909, L5: 0.0033145996276289225
Epoch 9500, Loss: -3.6273272037506104, Losses: L1: -3.73858904838562, L2: 0.04021832346916199, L3: 3.552436828613281e-05, L4: 0.04824932664632797, L5: 0.0033146857749670744
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0212228298187256, Constraint losses: L1: 18.42068099975586, L2: 0.0009340152028016746, L3: 1.0009340047836304, L4: 1.00093412399292
Epoch 500, Loss: 0.0024063745513558388, Constraint losses: L1: -1.1063899993896484, L2: 0.0, L3: 0.002755463123321533, L4: 0.0007573013426735997
Epoch 1000, Loss: 0.0013799209846183658, Constraint losses: L1: -1.1184524297714233, L2: 0.0, L3: 0.0022488832473754883, L4: 0.00024949025828391314
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0229086875915527, Constraint losses: L1: 18.42068099975586, L2: 0.0014959548134356737, L3: 1.0014959573745728, L4: 1.0014960765838623
Epoch 500, Loss: 0.002384915016591549, Constraint losses: L1: -1.0615369081497192, L2: 0.0, L3: 0.0027222037315368652, L4: 0.0007242481806315482
Epoch 1000, Loss: 0.0013340041041374207, Constraint losses: L1: -1.1188033819198608, L2: 0.0, L3: 0.002226114273071289, L4: 0.00022669319878332317
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 94.75653839111328, Losses: L1: 15.731990814208984, L2: 0.0004663189756684005, L3: 1.0003610849380493, L4: 76.832763671875, L5: 0.38027048110961914
Epoch 500, Loss: 1.6760201454162598, Losses: L1: -2.951965093612671, L2: 0.2208459973335266, L3: 0.07121872901916504, L4: 4.0332231521606445, L5: 0.021265098825097084
Epoch 1000, Loss: -2.2366092205047607, Losses: L1: -3.3841514587402344, L2: 0.1343005895614624, L3: 0.04324162006378174, L4: 0.7898387312889099, L5: 0.005238090176135302
Epoch 1500, Loss: -2.1688425540924072, Losses: L1: -3.595937728881836, L2: 0.1257900446653366, L3: 0.010637521743774414, L4: 1.1507655382156372, L5: 0.006949105765670538
Epoch 2000, Loss: -3.0268194675445557, Losses: L1: -3.6289525032043457, L2: 0.033994127064943314, L3: 0.006334245204925537, L4: 0.5197687149047852, L5: 0.003415502840653062
Epoch 2500, Loss: -3.359001636505127, Losses: L1: -3.6968908309936523, L2: 0.04905443266034126, L3: 0.009224176406860352, L4: 0.21964678168296814, L5: 0.003370685502886772
Epoch 3000, Loss: -3.34773588180542, Losses: L1: -3.744723320007324, L2: 0.07249865680932999, L3: 0.015584945678710938, L4: 0.21898847818374634, L5: 0.003663684707134962
Epoch 3500, Loss: -3.498661518096924, Losses: L1: -3.721785545349121, L2: 0.046744778752326965, L3: 0.012104511260986328, L4: 0.10382542014122009, L5: 0.003200260456651449
Epoch 4000, Loss: -3.5106120109558105, Losses: L1: -3.7050514221191406, L2: 0.044755056500434875, L3: 0.009803235530853271, L4: 0.08370442688465118, L5: 0.0032368209213018417
Epoch 4500, Loss: -3.5431301593780518, Losses: L1: -3.730595111846924, L2: 0.04669015854597092, L3: 0.009334325790405273, L4: 0.07380890101194382, L5: 0.003214437048882246
Epoch 5000, Loss: -3.5605030059814453, Losses: L1: -3.7208259105682373, L2: 0.04333479329943657, L3: 0.003115415573120117, L4: 0.06584347784519196, L5: 0.0031577276531606913
Epoch 5500, Loss: -3.562976837158203, Losses: L1: -3.715071439743042, L2: 0.042781002819538116, L3: 0.0043528079986572266, L4: 0.056246742606163025, L5: 0.0031602741219103336
Epoch 6000, Loss: -3.582421064376831, Losses: L1: -3.7177531719207764, L2: 0.04269002005457878, L3: 0.001198410987854004, L4: 0.04597225785255432, L5: 0.003165580565109849
Epoch 6500, Loss: -3.582974672317505, Losses: L1: -3.7190418243408203, L2: 0.04270699992775917, L3: 0.00042694807052612305, L4: 0.0482126884162426, L5: 0.0031727468594908714
Epoch 7000, Loss: -3.587526798248291, Losses: L1: -3.7192161083221436, L2: 0.04268581047654152, L3: 2.682209014892578e-05, L4: 0.044680316001176834, L5: 0.003167338902130723
Epoch 7500, Loss: -3.588284730911255, Losses: L1: -3.7192556858062744, L2: 0.04272071272134781, L3: 0.00023287534713745117, L4: 0.043481871485710144, L5: 0.0031639349181205034
Epoch 8000, Loss: -3.5885186195373535, Losses: L1: -3.719771385192871, L2: 0.04280330240726471, L3: 0.0003064870834350586, L4: 0.043450742959976196, L5: 0.003164791502058506
Epoch 8500, Loss: -3.588754415512085, Losses: L1: -3.720028877258301, L2: 0.042756401002407074, L3: 0.0006066560745239258, L4: 0.04296690225601196, L5: 0.003162734443321824
Epoch 9000, Loss: -3.589369297027588, Losses: L1: -3.7192647457122803, L2: 0.04258699715137482, L3: 0.0001099705696105957, L4: 0.042920079082250595, L5: 0.0031623158138245344
Epoch 9500, Loss: -3.5897068977355957, Losses: L1: -3.7194669246673584, L2: 0.04261428862810135, L3: 5.328655242919922e-05, L4: 0.04284363240003586, L5: 0.0031624180264770985
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0032501220703125, Constraint losses: L1: 6.400315761566162, L2: 0.0, L3: 0.9984251260757446, L4: 0.9984246492385864
Epoch 500, Loss: 0.0025337471161037683, Constraint losses: L1: -1.0893070697784424, L2: 0.0, L3: 0.002810359001159668, L4: 0.0008126952452585101
Epoch 1000, Loss: 0.0014038973022252321, Constraint losses: L1: -1.1183491945266724, L2: 0.0, L3: 0.002260744571685791, L4: 0.0002615019620861858
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0124008655548096, Constraint losses: L1: 11.715545654296875, L2: 0.0008677809382788837, L3: 0.9999088048934937, L4: 0.9999087452888489
Epoch 500, Loss: 0.002307478804141283, Constraint losses: L1: -1.0380669832229614, L2: 0.0, L3: 0.002671658992767334, L4: 0.0006738868542015553
Epoch 1000, Loss: 0.001298674033023417, Constraint losses: L1: -1.1171510219573975, L2: 0.0, L3: 0.0022075772285461426, L4: 0.000208247933187522
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 76.77644348144531, Losses: L1: 5.5948100090026855, L2: 0.0, L3: 0.995940089225769, L4: 68.86467742919922, L5: 0.32507142424583435
Epoch 500, Loss: 1.303905725479126, Losses: L1: -2.3534698486328125, L2: 0.15945661067962646, L3: 0.08715546131134033, L4: 3.1517348289489746, L5: 0.012416617013514042
Epoch 1000, Loss: -1.5568313598632812, Losses: L1: -3.0418272018432617, L2: 0.14354629814624786, L3: 0.06273865699768066, L4: 1.0655430555343628, L5: 0.006882739253342152
Epoch 1500, Loss: -2.1529712677001953, Losses: L1: -3.4746687412261963, L2: 0.13861887156963348, L3: 0.0506441593170166, L4: 0.9378777742385864, L5: 0.005293812602758408
Epoch 2000, Loss: -0.5085588693618774, Losses: L1: -2.4271585941314697, L2: 0.33844587206840515, L3: 0.07883524894714355, L4: 1.077322006225586, L5: 0.006715438794344664
Epoch 2500, Loss: -2.8723955154418945, Losses: L1: -3.5906014442443848, L2: 0.05003173649311066, L3: 0.008526146411895752, L4: 0.5972923040390015, L5: 0.003797460813075304
Epoch 3000, Loss: -2.9934635162353516, Losses: L1: -3.6882424354553223, L2: 0.060780465602874756, L3: 0.005203962326049805, L4: 0.5590717196464539, L5: 0.0037382522132247686
Epoch 3500, Loss: -3.447373151779175, Losses: L1: -3.730956792831421, L2: 0.059765659272670746, L3: 0.005296230316162109, L4: 0.14986562728881836, L5: 0.0035942604299634695
Epoch 4000, Loss: -3.4991989135742188, Losses: L1: -3.766772747039795, L2: 0.06138868257403374, L3: 0.011906862258911133, L4: 0.1173693910241127, L5: 0.0036131369415670633
Epoch 4500, Loss: -3.455697774887085, Losses: L1: -3.758974313735962, L2: 0.058285776525735855, L3: 0.006798744201660156, L4: 0.16955536603927612, L5: 0.0035519907251000404
Epoch 5000, Loss: -3.579273223876953, Losses: L1: -3.7843220233917236, L2: 0.06244261935353279, L3: 0.0011053085327148438, L4: 0.07430775463581085, L5: 0.003645214717835188
Epoch 5500, Loss: -3.580007791519165, Losses: L1: -3.7887027263641357, L2: 0.06239207461476326, L3: 0.0011990070343017578, L4: 0.07790463417768478, L5: 0.0036078894045203924
Epoch 6000, Loss: -3.6005630493164062, Losses: L1: -3.794447898864746, L2: 0.06255679577589035, L3: 0.00041985511779785156, L4: 0.06430350244045258, L5: 0.0036283633671700954
Epoch 6500, Loss: -3.6011831760406494, Losses: L1: -3.7948195934295654, L2: 0.061863332986831665, L3: 0.0007777214050292969, L4: 0.06473388522863388, L5: 0.0036203069612383842
Epoch 7000, Loss: -3.606300115585327, Losses: L1: -3.797823905944824, L2: 0.062302976846694946, L3: 0.00025641918182373047, L4: 0.0627802237868309, L5: 0.003624815959483385
Epoch 7500, Loss: -3.608643054962158, Losses: L1: -3.79921555519104, L2: 0.0623665452003479, L3: 3.4928321838378906e-05, L4: 0.062145866453647614, L5: 0.0036235563457012177
Epoch 8000, Loss: -3.6093366146087646, Losses: L1: -3.800236463546753, L2: 0.06238558143377304, L3: 0.0003185272216796875, L4: 0.06186794489622116, L5: 0.0036237493623048067
Epoch 8500, Loss: -3.610081672668457, Losses: L1: -3.800671100616455, L2: 0.06238409876823425, L3: 0.000274658203125, L4: 0.061648815870285034, L5: 0.0036229246761649847
Epoch 9000, Loss: -3.610781192779541, Losses: L1: -3.800675868988037, L2: 0.06232929974794388, L3: 2.6464462280273438e-05, L4: 0.061560265719890594, L5: 0.003623082535341382
Epoch 9500, Loss: -3.6111092567443848, Losses: L1: -3.8007912635803223, L2: 0.06225776672363281, L3: 4.410743713378906e-05, L4: 0.06145554408431053, L5: 0.003622729331254959
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 1, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 1.9984652996063232, Constraint losses: L1: 5.638062953948975, L2: 0.0, L3: 0.99641352891922, L4: 0.9964137077331543
Epoch 500, Loss: 0.001934969681315124, Constraint losses: L1: -1.0333575010299683, L2: 0.0, L3: 0.002483367919921875, L4: 0.0004849593387916684
Epoch 1000, Loss: 0.0011733166174963117, Constraint losses: L1: -1.116937518119812, L2: 0.0, L3: 0.0021449923515319824, L4: 0.00014526184531860054
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0023293495178223, Constraint losses: L1: 6.286634922027588, L2: 0.0, L3: 0.9980213046073914, L4: 0.9980214834213257
Epoch 500, Loss: 0.0022868311498314142, Constraint losses: L1: -1.0809353590011597, L2: 0.0, L3: 0.002682924270629883, L4: 0.0006848421762697399
Epoch 1000, Loss: 0.001324174925684929, Constraint losses: L1: -1.1185812950134277, L2: 0.0, L3: 0.0022211074829101562, L4: 0.00022164886468090117
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 97.93728637695312, Losses: L1: 18.42068099975586, L2: 0.002812491962686181, L3: 1.0027883052825928, L4: 76.74028015136719, L5: 0.38256096839904785
Epoch 500, Loss: 1.8592567443847656, Losses: L1: -0.8219203352928162, L2: 0.16865456104278564, L3: 0.16025608777999878, L4: 1.9965643882751465, L5: 0.013395641930401325
Epoch 1000, Loss: 0.5982723832130432, Losses: L1: -3.0318946838378906, L2: 0.220377579331398, L3: 0.05669969320297241, L4: 3.0461008548736572, L5: 0.014955920167267323
Epoch 1500, Loss: -3.003579616546631, Losses: L1: -3.6674649715423584, L2: 0.10875539481639862, L3: 0.0033235549926757812, L4: 0.4322699308395386, L5: 0.003728909883648157
Epoch 2000, Loss: -2.5062549114227295, Losses: L1: -3.3230063915252686, L2: 0.09031961858272552, L3: 0.054525911808013916, L4: 0.5195435285568237, L5: 0.0037583629600703716
Epoch 2500, Loss: -3.1896820068359375, Losses: L1: -3.675814390182495, L2: 0.049315061420202255, L3: 0.0014034509658813477, L4: 0.3781404495239258, L5: 0.0032774084247648716
Epoch 3000, Loss: -3.3546035289764404, Losses: L1: -3.731255292892456, L2: 0.07125457376241684, L3: 0.022597074508666992, L4: 0.18201927840709686, L5: 0.0034645406994968653
Epoch 3500, Loss: -3.4464378356933594, Losses: L1: -3.7084853649139404, L2: 0.04505706951022148, L3: 0.0072612762451171875, L4: 0.15093982219696045, L5: 0.0032355543226003647
Epoch 4000, Loss: -3.4919755458831787, Losses: L1: -3.7096943855285645, L2: 0.04916316270828247, L3: 0.009696662425994873, L4: 0.09361319243907928, L5: 0.0031930659897625446
Epoch 4500, Loss: -3.5553359985351562, Losses: L1: -3.731638193130493, L2: 0.04775402694940567, L3: 0.0028803348541259766, L4: 0.06853331625461578, L5: 0.003250028472393751
Epoch 5000, Loss: -3.551839828491211, Losses: L1: -3.740708589553833, L2: 0.052493881434202194, L3: 0.007831931114196777, L4: 0.061752356588840485, L5: 0.00323231122456491
Epoch 5500, Loss: -3.568760395050049, Losses: L1: -3.735471725463867, L2: 0.04729060083627701, L3: 0.0026144981384277344, L4: 0.060431331396102905, L5: 0.003235003212466836
Epoch 6000, Loss: -3.5742573738098145, Losses: L1: -3.7317004203796387, L2: 0.04480261728167534, L3: 0.000634312629699707, L4: 0.06011703610420227, L5: 0.0032260282896459103
Epoch 6500, Loss: -3.5761468410491943, Losses: L1: -3.7318131923675537, L2: 0.04461248591542244, L3: 0.00035941600799560547, L4: 0.05926135927438736, L5: 0.0032305163331329823
Epoch 7000, Loss: -3.5776522159576416, Losses: L1: -3.73276686668396, L2: 0.044369280338287354, L3: 3.2782554626464844e-05, L4: 0.05986204743385315, L5: 0.003224119544029236
Epoch 7500, Loss: -3.5792837142944336, Losses: L1: -3.733250856399536, L2: 0.04441619664430618, L3: 0.0002930164337158203, L4: 0.05808841064572334, L5: 0.0032302169129252434
Epoch 8000, Loss: -3.5791854858398438, Losses: L1: -3.7337934970855713, L2: 0.044628843665122986, L3: 0.0004432201385498047, L4: 0.05800094082951546, L5: 0.0032313894480466843
Epoch 8500, Loss: -3.5802319049835205, Losses: L1: -3.7333731651306152, L2: 0.044244956225156784, L3: 0.00014579296112060547, L4: 0.05789930745959282, L5: 0.003230232046917081
Epoch 9000, Loss: -3.580522060394287, Losses: L1: -3.733341932296753, L2: 0.044180791825056076, L3: 8.881092071533203e-05, L4: 0.057821232825517654, L5: 0.0032297747675329447
Epoch 9500, Loss: -3.5806686878204346, Losses: L1: -3.7333950996398926, L2: 0.04415946081280708, L3: 8.416175842285156e-05, L4: 0.05778077244758606, L5: 0.0032292227260768414
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 0.5, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.008525848388672, Constraint losses: L1: 8.786506652832031, L2: 0.0, L3: 0.999869704246521, L4: 0.9998696446418762
Epoch 500, Loss: 0.002140352502465248, Constraint losses: L1: -1.0957942008972168, L2: 0.0, L3: 0.0026172995567321777, L4: 0.000618847319856286
Epoch 1000, Loss: 0.001280115800909698, Constraint losses: L1: -1.1141213178634644, L2: 0.0, L3: 0.0021968483924865723, L4: 0.00019738884293474257
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.022972822189331, Constraint losses: L1: 18.42068099975586, L2: 0.0015173162100836635, L3: 1.0015172958374023, L4: 1.0015175342559814
Epoch 500, Loss: 0.00244409148581326, Constraint losses: L1: -1.0943386554718018, L2: 0.0, L3: 0.002768218517303467, L4: 0.0007702117436565459
Epoch 1000, Loss: 0.001383802155032754, Constraint losses: L1: -1.1192909479141235, L2: 0.0, L3: 0.0022512078285217285, L4: 0.00025188527069985867
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 156.60302734375, Losses: L1: 12.712394714355469, L2: 0.000814341998193413, L3: 1.0000287294387817, L4: 70.85997009277344, L5: 0.3380091190338135
Epoch 500, Loss: 3.3046438694000244, Losses: L1: -1.4218190908432007, L2: 0.31868231296539307, L3: 0.11020714044570923, L4: 1.9306111335754395, L5: 0.0149237010627985
Epoch 1000, Loss: 2.9968860149383545, Losses: L1: -3.135572910308838, L2: 0.14907246828079224, L3: 0.08521437644958496, L4: 2.8298287391662598, L5: 0.008455893024802208
Epoch 1500, Loss: -1.3641221523284912, Losses: L1: -3.4924123287200928, L2: 0.1810913234949112, L3: 0.008618354797363281, L4: 0.8732099533081055, L5: 0.00490185059607029
Epoch 2000, Loss: 0.5011586546897888, Losses: L1: -3.577740430831909, L2: 0.16006819903850555, L3: 0.0235975980758667, L4: 1.8532384634017944, L5: 0.010181289166212082
Epoch 2500, Loss: -2.465362548828125, Losses: L1: -3.697230100631714, L2: 0.09958381205797195, L3: 0.00921773910522461, L4: 0.506157398223877, L5: 0.0038988692685961723
Epoch 3000, Loss: -2.8700218200683594, Losses: L1: -3.719985008239746, L2: 0.07763310521841049, L3: 0.0008856058120727539, L4: 0.3455424904823303, L5: 0.0036812557373195887
Epoch 3500, Loss: -3.2232136726379395, Losses: L1: -3.73769474029541, L2: 0.07763004302978516, L3: 0.006636619567871094, L4: 0.17200995981693268, L5: 0.0038555471692234278
Epoch 4000, Loss: -3.3136444091796875, Losses: L1: -3.7320008277893066, L2: 0.07240064442157745, L3: 0.0074002742767333984, L4: 0.12847131490707397, L5: 0.003623860888183117
Epoch 4500, Loss: -3.435105562210083, Losses: L1: -3.7576496601104736, L2: 0.0763464942574501, L3: 0.0032203197479248047, L4: 0.08078338205814362, L5: 0.0036875014193356037
Epoch 5000, Loss: -3.460676670074463, Losses: L1: -3.7584826946258545, L2: 0.07412074506282806, L3: 4.935264587402344e-05, L4: 0.07381680607795715, L5: 0.0036646502558141947
Epoch 5500, Loss: -3.463846206665039, Losses: L1: -3.7558248043060303, L2: 0.07098258286714554, L3: 0.0015105605125427246, L4: 0.07258403301239014, L5: 0.0036483798176050186
Epoch 6000, Loss: -3.4751486778259277, Losses: L1: -3.760549306869507, L2: 0.07077847421169281, L3: 0.0014177560806274414, L4: 0.0695904791355133, L5: 0.0036544103641062975
Epoch 6500, Loss: -3.4805920124053955, Losses: L1: -3.7620651721954346, L2: 0.07058314979076385, L3: 0.0008323192596435547, L4: 0.06840638816356659, L5: 0.0036592353135347366
Epoch 7000, Loss: -3.484241247177124, Losses: L1: -3.762202739715576, L2: 0.07013353705406189, L3: 0.0002206563949584961, L4: 0.06771247833967209, L5: 0.0036566085182130337
Epoch 7500, Loss: -3.4861629009246826, Losses: L1: -3.7623233795166016, L2: 0.0697232335805893, L3: 3.314018249511719e-05, L4: 0.06740975379943848, L5: 0.0036561687011271715
Epoch 8000, Loss: -3.487523317337036, Losses: L1: -3.7628724575042725, L2: 0.06957850605249405, L3: 8.594989776611328e-05, L4: 0.06709553301334381, L5: 0.0036582082975655794
Epoch 8500, Loss: -3.4885435104370117, Losses: L1: -3.762965202331543, L2: 0.06932779401540756, L3: 8.440017700195312e-05, L4: 0.06688427180051804, L5: 0.003657351480796933
Epoch 9000, Loss: -3.489006996154785, Losses: L1: -3.7628819942474365, L2: 0.06914539635181427, L3: 8.20159912109375e-05, L4: 0.066795714199543, L5: 0.0036571058444678783
Epoch 9500, Loss: -3.489630937576294, Losses: L1: -3.763080358505249, L2: 0.06910690665245056, L3: 2.956390380859375e-05, L4: 0.06667396426200867, L5: 0.003657075809314847
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 1, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.034501552581787, Constraint losses: L1: 18.42068099975586, L2: 0.005360003560781479, L3: 1.0053600072860718, L4: 1.0053609609603882
Epoch 500, Loss: 0.002392746973782778, Constraint losses: L1: -1.103405475616455, L2: 0.0, L3: 0.002747058868408203, L4: 0.0007490935386158526
Epoch 1000, Loss: 0.001367150223813951, Constraint losses: L1: -1.1179293394088745, L2: 0.0, L3: 0.00224226713180542, L4: 0.00024281239893753082
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0044796466827393, Constraint losses: L1: 6.758913040161133, L2: 0.0, L3: 0.9988604187965393, L4: 0.9988602995872498
Epoch 500, Loss: 0.0023172469809651375, Constraint losses: L1: -1.1101458072662354, L2: 0.0, L3: 0.002712726593017578, L4: 0.0007146662101149559
Epoch 1000, Loss: 0.001349904458038509, Constraint losses: L1: -1.1196064949035645, L2: 0.0, L3: 0.0022343993186950684, L4: 0.00023511171457357705
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 173.836181640625, Losses: L1: 18.42068099975586, L2: 0.0022165935952216387, L3: 1.001625418663025, L4: 76.5106430053711, L5: 0.38654136657714844
Epoch 500, Loss: 2.265092134475708, Losses: L1: -1.3803350925445557, L2: 0.22077123820781708, L3: 0.06850433349609375, L4: 1.5291017293930054, L5: 0.008672420866787434
Epoch 1000, Loss: 13.438799858093262, Losses: L1: -0.3592362701892853, L2: 0.555316686630249, L3: 0.19613522291183472, L4: 6.131834030151367, L5: 0.03146461024880409
Epoch 1500, Loss: 3.681746006011963, Losses: L1: -1.5079089403152466, L2: 0.26597264409065247, L3: 0.1271880865097046, L4: 2.196613311767578, L5: 0.01010688953101635
Epoch 2000, Loss: 3.4049394130706787, Losses: L1: -1.432937502861023, L2: 0.1269083023071289, L3: 0.12356048822402954, L4: 2.163026809692383, L5: 0.01088566891849041
Epoch 2500, Loss: 0.8138037919998169, Losses: L1: -1.591786503791809, L2: 0.14515216648578644, L3: 0.11644518375396729, L4: 0.9375396370887756, L5: 0.007316352799534798
Epoch 3000, Loss: 0.569536030292511, Losses: L1: -1.5777246952056885, L2: 0.11162378638982773, L3: 0.11676681041717529, L4: 0.8417255878448486, L5: 0.007028388790786266
Epoch 3500, Loss: 0.38233113288879395, Losses: L1: -1.5670008659362793, L2: 0.09138825535774231, L3: 0.11825823783874512, L4: 0.7616281509399414, L5: 0.0067827701568603516
Epoch 4000, Loss: 0.23263946175575256, Losses: L1: -1.5755620002746582, L2: 0.08420698344707489, L3: 0.11607229709625244, L4: 0.7006068825721741, L5: 0.006429112982004881
Epoch 4500, Loss: 0.15439794957637787, Losses: L1: -1.5875508785247803, L2: 0.08019030094146729, L3: 0.11457324028015137, L4: 0.6730657815933228, L5: 0.006290176417678595
Epoch 5000, Loss: 0.0853569433093071, Losses: L1: -1.5979136228561401, L2: 0.07715762406587601, L3: 0.11370885372161865, L4: 0.647659182548523, L5: 0.006219260860234499
Epoch 5500, Loss: 0.036868710070848465, Losses: L1: -1.603690266609192, L2: 0.0747624933719635, L3: 0.11265039443969727, L4: 0.6297832727432251, L5: 0.0061665973626077175
Epoch 6000, Loss: -0.0007105814293026924, Losses: L1: -1.6105166673660278, L2: 0.07329211384057999, L3: 0.11198192834854126, L4: 0.616567075252533, L5: 0.006123806349933147
Epoch 6500, Loss: -0.030478907749056816, Losses: L1: -1.613450050354004, L2: 0.07192900031805038, L3: 0.11143261194229126, L4: 0.6050720810890198, L5: 0.006103800609707832
Epoch 7000, Loss: -0.05101286247372627, Losses: L1: -1.6162029504776, L2: 0.07100279629230499, L3: 0.11104381084442139, L4: 0.5975029468536377, L5: 0.006091008428484201
Epoch 7500, Loss: -0.06592971086502075, Losses: L1: -1.6184097528457642, L2: 0.07039830833673477, L3: 0.11074566841125488, L4: 0.5920548439025879, L5: 0.0060823592357337475
Epoch 8000, Loss: -0.07638226449489594, Losses: L1: -1.620591163635254, L2: 0.0700911357998848, L3: 0.11054182052612305, L4: 0.5884331464767456, L5: 0.006076708901673555
Epoch 8500, Loss: -0.08388154208660126, Losses: L1: -1.6214072704315186, L2: 0.06977087259292603, L3: 0.11039656400680542, L4: 0.5855573415756226, L5: 0.006076172459870577
Epoch 9000, Loss: -0.0887652263045311, Losses: L1: -1.6220818758010864, L2: 0.06958415359258652, L3: 0.11029243469238281, L4: 0.5837438702583313, L5: 0.006075774785131216
Epoch 9500, Loss: -0.09208489209413528, Losses: L1: -1.6225759983062744, L2: 0.06947115063667297, L3: 0.11022096872329712, L4: 0.5825157165527344, L5: 0.006075494457036257
Training done
----------------------------------------------------------------------------
Running test with options: {'L1_weight': 1, 'L2_weight': 2, 'L3_weight': 2, 'L4_weight': 2, 'L5_weight': 2, 'batch_size': 2048, 'boundary_points': 50, 'epochs': 10000, 'lr': 0.1, 'num_layers': 3, 'num_neurons': 10, 'scheduler': 'exponential', 'solver': 'adam', 'uniform_points': 50}
Regular training
Run 1 of 1
cuda is used to train model
in parameter tester
[[ 1.76405235 -1.758217  ]
 [ 0.97873798 -0.94694989]
 [ 1.86755799 -1.88119169]]
---------------------------------------------------------------------
Marginal Model 1 Training
Epoch 0, Loss: 2.0248641967773438, Constraint losses: L1: 18.42068099975586, L2: 0.0021478000562638044, L3: 1.0021477937698364, L4: 1.0021477937698364
Epoch 500, Loss: 0.0024998255539685488, Constraint losses: L1: -1.0474977493286133, L2: 0.0, L3: 0.0027726292610168457, L4: 0.0007746941992081702
Epoch 1000, Loss: 0.0013650632463395596, Constraint losses: L1: -1.116428256034851, L2: 0.0, L3: 0.002240419387817383, L4: 0.00024107220815494657
---------------------------------------------------------------------
Marginal Model 2 Training
Epoch 0, Loss: 2.0354671478271484, Constraint losses: L1: 18.42068099975586, L2: 0.005681775510311127, L3: 1.0056817531585693, L4: 1.0056829452514648
Epoch 500, Loss: 0.002293819561600685, Constraint losses: L1: -0.9272481203079224, L2: 0.0, L3: 0.0026094913482666016, L4: 0.0006115762516856194
Epoch 1000, Loss: 0.001224894542247057, Constraint losses: L1: -1.1148111820220947, L2: 0.0, L3: 0.0021696090698242188, L4: 0.00017009678413160145
---------------------------------------------------------------------
Training copula model
Epoch 0, Loss: 148.501708984375, Losses: L1: 6.441441535949707, L2: 1.7646407002303022e-07, L3: 0.998598575592041, L4: 69.7015609741211, L5: 0.3299708068370819
Epoch 500, Loss: 0.21983571350574493, Losses: L1: -3.0287375450134277, L2: 0.2220204472541809, L3: 0.08318185806274414, L4: 1.310874342918396, L5: 0.00821003783494234
Epoch 1000, Loss: 0.8743330240249634, Losses: L1: -3.099026918411255, L2: 0.22320817410945892, L3: 0.0678412914276123, L4: 1.6902883052825928, L5: 0.005342187359929085
Epoch 1500, Loss: -2.1198108196258545, Losses: L1: -3.574692487716675, L2: 0.08139786869287491, L3: 0.02486598491668701, L4: 0.6173460483551025, L5: 0.003830854780972004
Epoch 2000, Loss: -1.5200790166854858, Losses: L1: -3.6941325664520264, L2: 0.14825639128684998, L3: 0.0183027982711792, L4: 0.91148841381073, L5: 0.008979164063930511
Epoch 2500, Loss: -2.998243570327759, Losses: L1: -3.801809787750244, L2: 0.10295510292053223, L3: 0.005239963531494141, L4: 0.28761646151542664, L5: 0.0059714955277740955
Epoch 3000, Loss: -3.208556652069092, Losses: L1: -3.8408000469207764, L2: 0.0888885110616684, L3: 0.0026460886001586914, L4: 0.21922579407691956, L5: 0.005361318122595549
Epoch 3500, Loss: -3.3459646701812744, Losses: L1: -3.8534891605377197, L2: 0.08943440020084381, L3: 0.003907561302185059, L4: 0.15538568794727325, L5: 0.0050345067866146564
Epoch 4000, Loss: -3.3655917644500732, Losses: L1: -3.8986189365386963, L2: 0.09593730419874191, L3: 0.002621769905090332, L4: 0.1630207747220993, L5: 0.004933834075927734
Epoch 4500, Loss: -3.5198161602020264, Losses: L1: -3.9022719860076904, L2: 0.09092850983142853, L3: 0.00043785572052001953, L4: 0.09529585391283035, L5: 0.004565639421343803
Epoch 5000, Loss: -3.5999488830566406, Losses: L1: -3.9100944995880127, L2: 0.08977809548377991, L3: 0.0002646446228027344, L4: 0.060647569596767426, L5: 0.0043824659660458565
Epoch 5500, Loss: -3.5939996242523193, Losses: L1: -3.913146495819092, L2: 0.08935877680778503, L3: 0.0007878541946411133, L4: 0.06504352390766144, L5: 0.004383155144751072
Epoch 6000, Loss: -3.6185214519500732, Losses: L1: -3.9171271324157715, L2: 0.08951941877603531, L3: 0.00017821788787841797, L4: 0.05529661849141121, L5: 0.004308598581701517
Epoch 6500, Loss: -3.624065399169922, Losses: L1: -3.9197282791137695, L2: 0.08980965614318848, L3: 6.318092346191406e-05, L4: 0.053661756217479706, L5: 0.0042969402857124805
Epoch 7000, Loss: -3.6276917457580566, Losses: L1: -3.921553611755371, L2: 0.09007052332162857, L3: 9.179115295410156e-06, L4: 0.052563589066267014, L5: 0.00428773695603013
Epoch 7500, Loss: -3.629924774169922, Losses: L1: -3.922839641571045, L2: 0.09026242792606354, L3: 5.1856040954589844e-05, L4: 0.05186011642217636, L5: 0.004283027723431587
Epoch 8000, Loss: -3.631352424621582, Losses: L1: -3.9235999584198, L2: 0.09032819420099258, L3: 0.0001590251922607422, L4: 0.05136176198720932, L5: 0.004274690058082342
Epoch 8500, Loss: -3.6326050758361816, Losses: L1: -3.9243438243865967, L2: 0.09040867537260056, L3: 0.00011134147644042969, L4: 0.051079075783491135, L5: 0.004270297475159168
Epoch 9000, Loss: -3.633558511734009, Losses: L1: -3.9247701168060303, L2: 0.09047064185142517, L3: 2.5987625122070312e-05, L4: 0.05084037780761719, L5: 0.004268788266927004
Epoch 9500, Loss: -3.6340672969818115, Losses: L1: -3.925023078918457, L2: 0.09048455953598022, L3: 1.7881393432617188e-06, L4: 0.050724245607852936, L5: 0.004267174284905195
Training done
----------------------------------------------------------------------------
############################ Result printout ##############################
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 157.2683868408203
Average training time of copula model: 127.06706938743591 seconds
Constraint loss: 114.35655212402344
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 126.67314910888672
Average training time of copula model: 126.41213598251343 seconds
Constraint loss: 112.75833892822266
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 4.810778617858887
Average training time of copula model: 126.26920146942139 seconds
Constraint loss: 11.058013916015625
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 20.017087936401367
Average training time of copula model: 126.70276017189026 seconds
Constraint loss: 16.85721778869629
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('L4_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 110.22183990478516
Average training time of copula model: 126.59018125534058 seconds
Constraint loss: 105.11692810058594
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 41.900577545166016
Average training time of copula model: 126.49202699661255 seconds
Constraint loss: 45.044376373291016
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 53.9969367980957
Average training time of copula model: 126.48043465614319 seconds
Constraint loss: 55.687564849853516
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 8.991037368774414
Average training time of copula model: 126.80872392654419 seconds
Constraint loss: 6.868968963623047
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('L3_weight', 0.5), ('L4_weight', 2), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 0.5490765571594238
Average training time of copula model: 126.66328177452087 seconds
Constraint loss: 4.210023880004883
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: -2.401865005493164
Average training time of copula model: 126.05432782173156 seconds
Constraint loss: 5.4252495765686035
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 122.23609161376953
Average training time of copula model: 126.7480700969696 seconds
Constraint loss: 109.00577545166016
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 13.942375183105469
Average training time of copula model: 126.63117594718933 seconds
Constraint loss: 18.16425132751465
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 11.80654525756836
Average training time of copula model: 126.19401850700379 seconds
Constraint loss: 16.281665802001953
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L4_weight', 1), ('L1_weight', 1), ('L2_weight', 0.5), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 8.084249496459961
Average training time of copula model: 126.11684098243714 seconds
Constraint loss: 11.20218563079834
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 6.258358955383301
Average training time of copula model: 126.11984972953796 seconds
Constraint loss: 9.311300277709961
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 46.82598876953125
Average training time of copula model: 126.38553667068481 seconds
Constraint loss: 53.6993408203125
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: -2.710787773132324
Average training time of copula model: 126.32625241279602 seconds
Constraint loss: 4.399184703826904
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('L4_weight', 2), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 2.903956890106201
Average training time of copula model: 126.43322467803955 seconds
Constraint loss: 6.516536235809326
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50)}) 
Total loss: 16.55343246459961
Average training time of copula model: 126.26335134506226 seconds
Constraint loss: 18.228309631347656
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50)}) 
Total loss: 117.9048843383789
Average training time of copula model: 126.36817736625672 seconds
Constraint loss: 115.58612060546875
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 128.04287719726562
Average training time of copula model: 126.39380826950074 seconds
Constraint loss: 104.238525390625
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50)}) 
Total loss: 5.791959762573242
Average training time of copula model: 126.56494064331055 seconds
Constraint loss: 10.08087158203125
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50)}) 
Total loss: 0.29970765113830566
Average training time of copula model: 126.75062284469604 seconds
Constraint loss: 6.213632583618164
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 10.243374824523926
Average training time of copula model: 125.89960064888001 seconds
Constraint loss: 12.433218002319336
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 5.113757610321045
Average training time of copula model: 126.4083176612854 seconds
Constraint loss: 7.753975868225098
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 8.47325325012207
Average training time of copula model: 126.6090308189392 seconds
Constraint loss: 6.218635559082031
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L2_weight', 0.5), ('batch_size', 2048), ('L4_weight', 2), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 7.050562381744385
Average training time of copula model: 126.20592226982117 seconds
Constraint loss: 8.753823280334473
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 0.6682279109954834
Average training time of copula model: 126.42069211006165 seconds
Constraint loss: 6.501983165740967
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 1.1300599575042725
Average training time of copula model: 126.60904712677002 seconds
Constraint loss: 7.055914878845215
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 138.183837890625
Average training time of copula model: 126.50139322280884 seconds
Constraint loss: 105.20759582519531
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 79.91657257080078
Average training time of copula model: 126.43799142837524 seconds
Constraint loss: 61.62654113769531
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('L4_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 5.679712772369385
Average training time of copula model: 126.32987122535705 seconds
Constraint loss: 7.382998466491699
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 2.71028470993042
Average training time of copula model: 126.5974889755249 seconds
Constraint loss: 8.70460319519043
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 0.14508581161499023
Average training time of copula model: 126.6416114807129 seconds
Constraint loss: 4.643198490142822
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 72.35385131835938
Average training time of copula model: 126.35332837104798 seconds
Constraint loss: 55.87026596069336
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('L4_weight', 2), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 8.374381065368652
Average training time of copula model: 126.4100866317749 seconds
Constraint loss: 5.671343803405762
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 68.7506332397461
Average training time of copula model: 126.64368062019348 seconds
Constraint loss: 71.66246795654297
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 98.65523529052734
Average training time of copula model: 126.4081639289856 seconds
Constraint loss: 95.26929473876953
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: -0.9618022441864014
Average training time of copula model: 126.1895251750946 seconds
Constraint loss: 4.649881839752197
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: 8.935799598693848
Average training time of copula model: 126.02610421180725 seconds
Constraint loss: 10.987122535705566
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50)}) 
Total loss: -0.6703712940216064
Average training time of copula model: 126.59101624488831 seconds
Constraint loss: 5.828668117523193
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 3.419602870941162
Average training time of copula model: 126.55351157188416 seconds
Constraint loss: 8.305014610290527
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 4.405444145202637
Average training time of copula model: 126.12244157791137 seconds
Constraint loss: 5.992247581481934
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 1.3406753540039062
Average training time of copula model: 126.43312973976136 seconds
Constraint loss: 4.58643102645874
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('L4_weight', 2), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: -4.045958995819092
Average training time of copula model: 126.680908203125 seconds
Constraint loss: 2.6681013107299805
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50)}) 
Total loss: 68.62094116210938
Average training time of copula model: 126.23698554039001 seconds
Constraint loss: 55.719058990478516
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50)}) 
Total loss: 65.7957763671875
Average training time of copula model: 126.26741900444031 seconds
Constraint loss: 55.49658966064453
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 0.28751134872436523
Average training time of copula model: 126.71637058258057 seconds
Constraint loss: 5.699199199676514
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50)}) 
Total loss: 65.86874389648438
Average training time of copula model: 126.42168712615967 seconds
Constraint loss: 53.612548828125
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50)}) 
Total loss: 68.63518524169922
Average training time of copula model: 126.38195443153381 seconds
Constraint loss: 54.778411865234375
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 58.164390563964844
Average training time of copula model: 126.51760439872741 seconds
Constraint loss: 55.30036163330078
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: -0.2793700695037842
Average training time of copula model: 126.78582415580749 seconds
Constraint loss: 5.830037593841553
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 20.082548141479492
Average training time of copula model: 126.70717787742615 seconds
Constraint loss: 11.541924476623535
----------------------------------------------------------------------------
Model: frozenset({('L2_weight', 1), ('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('L4_weight', 2), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: -4.751975059509277
Average training time of copula model: 126.85666117668151 seconds
Constraint loss: 2.095101833343506
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('L5_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 139.09725952148438
Average training time of copula model: 126.39719319343567 seconds
Constraint loss: 105.41093444824219
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 71.39845275878906
Average training time of copula model: 126.91483135223389 seconds
Constraint loss: 55.432960510253906
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 43.66600799560547
Average training time of copula model: 126.18801341056823 seconds
Constraint loss: 44.097320556640625
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 14.015182495117188
Average training time of copula model: 126.25212597846985 seconds
Constraint loss: 14.836194038391113
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('L4_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: -6.047605514526367
Average training time of copula model: 126.65797810554504 seconds
Constraint loss: 1.336338758468628
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 51.44392013549805
Average training time of copula model: 126.76808152198791 seconds
Constraint loss: 54.75175857543945
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 0.041498661041259766
Average training time of copula model: 126.58066244125366 seconds
Constraint loss: 4.13160514831543
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: -3.6835765838623047
Average training time of copula model: 126.58480472564698 seconds
Constraint loss: 2.265709638595581
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('L3_weight', 0.5), ('L4_weight', 2), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: -2.143136501312256
Average training time of copula model: 126.74137353897095 seconds
Constraint loss: 2.9328408241271973
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('L5_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 121.1619873046875
Average training time of copula model: 126.47279653549194 seconds
Constraint loss: 101.42521667480469
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 96.39611053466797
Average training time of copula model: 126.66163115501404 seconds
Constraint loss: 92.30224609375
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 10.93671989440918
Average training time of copula model: 126.36699938774109 seconds
Constraint loss: 12.455037117004395
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: -2.1607024669647217
Average training time of copula model: 126.8301824092865 seconds
Constraint loss: 2.765491008758545
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 11.35693359375
Average training time of copula model: 126.4355923652649 seconds
Constraint loss: 13.969049453735352
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 63.434749603271484
Average training time of copula model: 126.27670001983643 seconds
Constraint loss: 52.62907028198242
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 1.8597078323364258
Average training time of copula model: 126.60354261398315 seconds
Constraint loss: 4.308282852172852
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 70.40599060058594
Average training time of copula model: 126.58387484550477 seconds
Constraint loss: 53.98133087158203
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L3_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('L4_weight', 2), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: -4.387261390686035
Average training time of copula model: 126.36551733016968 seconds
Constraint loss: 1.8402910232543945
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 117.44282531738281
Average training time of copula model: 126.54905185699462 seconds
Constraint loss: 108.73172760009766
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 40.05317306518555
Average training time of copula model: 127.21477723121643 seconds
Constraint loss: 44.648033142089844
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L4_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 50.376983642578125
Average training time of copula model: 126.31554651260376 seconds
Constraint loss: 54.70782470703125
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 3.790663480758667
Average training time of copula model: 126.47584543228149 seconds
Constraint loss: 8.303655624389648
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50)}) 
Total loss: 2.7981905937194824
Average training time of copula model: 126.34052748680115 seconds
Constraint loss: 7.6182990074157715
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L4_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: -2.5744833946228027
Average training time of copula model: 126.7877649307251 seconds
Constraint loss: 3.340742826461792
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('L5_weight', 0.5), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: 1.6450488567352295
Average training time of copula model: 126.81689200401306 seconds
Constraint loss: 6.004011631011963
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L5_weight', 1), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50), ('L4_weight', 2)}) 
Total loss: -0.8119399547576904
Average training time of copula model: 126.4355501651764 seconds
Constraint loss: 2.2524256706237793
----------------------------------------------------------------------------
Model: frozenset({('boundary_points', 50), ('epochs', 10000), ('L1_weight', 1), ('scheduler', 'exponential'), ('batch_size', 2048), ('L4_weight', 2), ('solver', 'adam'), ('num_layers', 3), ('num_neurons', 10), ('lr', 0.1), ('L3_weight', 2), ('L2_weight', 2), ('uniform_points', 50), ('L5_weight', 2)}) 
Total loss: 2.6597900390625
Average training time of copula model: 126.71644186973572 seconds
Constraint loss: 4.478581428527832
###########################################################################
